You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Imagine a stock-market operator viewing a rapid sequence of stock returns on which she needs to make a fast buy/sell decision, or alternatively, a person who faces a crowd of people, each exhibiting a distinct emotional expression towards the person, who then needs to decide if to approach or not. In situations such as this, the rapid extraction of summary statistics of the elements (numerical returns or emotional expressions), in particular their average, has obvious advantages. Recent research over the last two decades has convincingly demonstrated that humans have a remarkable ability to extract summary statistics from large sets of visual elements, briefly presented together or in fast sequence, with regards to visual properties such as size, orientation and even emotional expression 
(Allik, Toom, Raidvee, Averin, & Kreegipuu, 2013;
Ariely, 2001;
Chong & Treisman, 2005;
Dakin, 2001;
Haberman & Whitney, 2011;
Khayat & Hochstein, 2018;
Robitaille & Harris, 2011;
Parkes et al., 2001)
. Similarly, it has been reported that humans can extract the arithmetic average (the simplest summary statistic) from rapid numerical sequences 
Malmi & Samson, 1983
) For example, 
Brezis et al., (2017)
 reported that human observers are able to provide quite accurate estimates of numerical average for sequences of 2-digit numbers (sequence length 6-12) that are presented at a rate of 4/sec. Moreover, they demonstrated the precision of these estimates increases with sequence length, and decreases with the sequence mean and variance.
Finally, they proposed a model based on a population of broadly number-magnitude detectors, which accounted for all these data patterns (see next section).
While this extensive research has focused on the extraction of an ensemble-average, there is less research on the extraction of higher order summary statistics, such as the variance 
(Bronfman et al., 2015;
Kareev, Arnon, & Horwitz-Zeliger, 2002;
Morgan, Chubb, & Solomon, 2008;
Solomon, 2010;
Ward, Bear, & Scholl, 2016)
, in particular for numerical sequences. This shortage stands out, given the well-known impact of the variance of a payoff-set on risk-preferences 
(Erev et al., 2017;
Glickman, Tsetsos, & Usher, 2018;
Ludvig et al., 2014;
Summerfield & Tsetsos, 2012;
Vanunu, Hotaling & Newell, 2020;
Vanunu, Pachur, & Usher, 2019;
Weber, 2010;
Zeigenfuse, Pleskac & Liu, 2014)
. Motivated by this shortcoming, the aim of this paper was to probe further into the capacity of human observers to extract summary statistics of rapid numerical sequences. In particular, we extend previous investigations with regards to the following questions. i) Can human observers extract higher order summary statistics (such as the relative sequence-variance 1 ) at the same time as they extract the average? ii) What types of mechanisms do people deploy when making such estimations? We contrast here between holistic frequency-based estimations and more sequential rule-based and working-memory limited strategies such as the mid-range; see next section for details. iii) Are there individual differences in the mechanism or the strategy that human observers deploy in these tasks?
and iv) which of those strategies/mechanisms result in more efficient estimations?
We start with a brief computational section that provides a motivation for our experiments.
Following, we present four experiments in which human observers were asked to evaluate summary statistics of rapid numerical sequences. In Experiment 1 (A and B) only the average is evaluated, while in Experiments 2 and 3, the participants are required to make two estimations for each sequence: average and (relative) variance in Experiment 2, and average and confidence in Experiment 3, respectively. Finally, we present a computational analysis of the data, which is focused on individual differences with regards to the estimation mechanism and we examine their relative efficiencies.


Computational modeling of numerical averaging: dependency on sequence-length
We are focusing on the intuitive averaging of the type that people can make for rapid sequences (four per second) of two digit numbers under time pressure (see methods of Experiment 1). This belongs to the domain of approximate numerical estimation 
(Dehaene, 1992;
Dehaene, Dehaene-Lambertz & Cohen 1998;
Feigenson, Dehaene & Spelke, 2004)
 and excludes an explicit computation of the average based on summing the numbers and division by the sequence length. 
Malmi and Samson (1983)
 considered two alternative ways of computing a sequence average: i) a running average with decreasing weights, ii) the estimation of the "center of mass" from a frequency distribution, and they concluded in favor of the latter. More recently, 
Brezis et al., (2016
Brezis et al., ( , 2017
 population averaging model (see 
Fig. 1
), provides a computationally explicit mechanism that first generates a noisy frequency representation of a numerical sequence and estimates its center of mass.  
Brezis et al., 2016)
.
Accordingly, when presented with a sequence of numbers, the sequence's average is estimated from the population-averaging of the number-magnitude tuned activation profile, by weighting the contribution of each detector's activity according to its preferred number magnitude 
(Georgopoulos, Schwartz, & Kettner, 1986)
. At display's offset, the center of mass is estimated by summing each neuron's detector's activation multiplied by its preferred magnitude and dividing by the sum of the overall network's activity (see 
Brezis et al., 2017
, for a biological plausible neural implementation):
= (∑ • ) ∑ ⁄
(1)
where for each detector i, F=firing rate; T=the detector's preferred magnitude. The sum is taken over all numerosity detectors.
The population averaging model makes a particular prediction on how the precision of the estimate depends on the length of the sequence. As the sequence-length (n), increases, the frequency representation becomes less noisy (due to Poisson variability of neural detectors, which decreases with the activation magnitude) and therefore the precision of the estimate increases ( 
Figure 1A
). This is thus equivalent to a computation of the average, based on noisy representations of its magnitudes.
= ∑ + =1 , ~(0, 2 )
(2)
where, Xi is the i th item of the sequence and 2 is the variance of the encoding noise.
For simplification, we will here approximate the population averaging with this simplified model, which we label the normative-holistic averaging model (Normativity here corresponds to the property that all the items are used and weighted equally in the estimation of the average; see contrast with heuristic models below). The normative-holistic model predicts that the precision of estimation would improve with 1 √ ⁄ 
(Figure 2 blue line),
 which results from the averaging of the encoding noise, and is similar to that of the population-averaging model 
(Figure 2
 black line).
We contrast the normative-holistic model estimation with a heuristic computation based on symbolic representations of the numbers that are subject to working memory capacity limitations 
(Ashcraft, 1992)
. The simplest such model, assumes that out of the n-numbers, the observers are able to remember few samples (2 or 3) and use them to evaluate the average of the sequence by computing their mean 2 . For the case in which the samples stored in working memory are random, we label this the analytical-random model, as it relies on explicit (rule based) computation of the average based on what is available in working memory 3 . This analytic-random model is a variant of the procedural arithmetic model 
(Anderson, Reder, & Lebiere, 1996)
, in which procedural operations are serially performed on symbols available in WM. Since with increasing n, the few WM-samples provide a less  It is possible, however, to consider a more sophisticated "analytic" version of this strategy, which still computes the average based on few (e.g., two samples), but selects those samples in a non-random way 
(Myczek & Simons, 2008
; but see 
Chong et al., 2008)
. For example, an efficient way to select two samples is to select the maximum and minimum of the sequence, resulting in the so called, mid-range heuristic. As shown in 
Fig. 2
 (Magenta line), the mid-range heuristic predicts a milder improvement with sequence-length (for n>7), since the mid-range provides a better estimate of the average, the longer the sequence is.
Note that despite using one less samples (2 instead of 3) the mid-range precision is higher than that of the random-analytic with n>3. However, this advantage comes with a cost. For the case that the numbers are selected from a non-symmetric, skewed distribution, the midrange strategy predicts systematic deviations.


Summary of computational contrasts between estimations strategies
We have contrasted several mechanisms that observers can deploy to estimate the average of a numerical sequence. The normative-holistic mechanism assumes each item contributes to the estimate but is subject to a potentially large encoding noise, which averages out with n. The analytical-random model assumes an exact (symbolic) computation of the average based on few (2-3) random samples, and it predicts precision to decrease with n. Finally, the mid-range model, predicts a milder improvement in the precision estimate with n (for n>7), but it also predicts that only the extreme values contribute to the average estimate.
Thus to contrast between estimations strategies, we will focus on how the precision of the estimate (computed either as RMSD or as a Pearson correlation between actual and estimated sequence-average 4 ) depends on sequence-length. In addition, we focus on the decision weights of the ranked items (De Gardelle & 
Summerfield, 2011)
, in order to probe the deployment of mid-range strategies.
To anticipate our results, we found that observers can estimate relative-variance of rapid numerical sequences remarkably well, while they also estimate the sequence average.
Moreover, while we find individual differences in the estimation strategy, most observers deploy a holistic mechanism when the task requires average estimation only, and about half of them deploy such a holistic mechanism even when they estimate both the average and the relative variance. Finally, we find that the participants who deploy the holistic mechanism tend to be more precise in their estimations.


Experiments
Four experiments were carried out to probe individual differences in the mechanism by which human observers evaluate rapid numerical sequences. In all the experiments the sequences presented two digit numbers at a rate of 4/sec and sequence-length was randomly selected to be either 6 or 12 items (based on Brezis et al., 2015, we avoided shorter sequence lengths to discourage explicit computation strategies, which were found for sequences of 4 items). Previous research has indicated that the number magnitude is automatically encoded when subjects are presented with two digit numbers 
(Dehaene et al., 1990;
Fitousi & Algom, 2019)
. In Experiments 1a and 1b, we require participants to evaluate only the sequence average (see 
figure 3)
. These experiments differ in the distribution from which the numbers are sampled: uniform in 1a, and skewed in 1b. Under an adaptive observer assumption, skewed distributions are likely to make the deployment of a mid-range estimations less likely. In Experiments 2 and 3 we used (like Experiment 1a) numbers that are sampled from a uniform distribution, but we required the participants to provide two estimates for each sequence. In addition to the average, Experiment 2 required an estimation of sequence-variance, while Experiment 3 required an estimation of the confidence in the estimation of the average. Since confidence is expected to reflect the uncertainty on the value of the estimate 
(Lebreton, Abitbol, Daunizeau, & Pessiglione, 2015;
Yeung & Summerfield, 2012)
 and this is likely to increase with the variance of the sequence, we consider the confidence estimation, an indirect/implicit estimation of the variance. Since mid-range strategies provide a simple and natural way to estimate the sequence-variance, we can expect that the deployment of this strategy will increase in Experiments 2 and 3 (see experimental methods for participants and procedure details for all experiments).  


Results


Experiment 1a
We used two measures to quantify each subject's precision in averaging. The first is the Pearson correlation of the real and estimated averages of the sequences of each participant (see 
Figure 6A
, for an example of an individual observer). The average Pearson correlation was high (r=0.75, SD=0.12) and was significantly higher than zero (all participants' p's<0.001). Second, we computed the root mean square deviation (RMSD) between the real averages and the participants' responses (note that higher value of RMSD imply lower accuracy). The RMSD was significantly lower than the simulated RMSD generated by randomly shuffling participant's responses across trials (Actual RMSD=7.7; Shuffled RMSD=14.8; t(23)=17.7, p<.001).
To test the sequence-length effect, we carried out a paired sample t-test between the RMSD of the six items condition compared to the twelve items condition, which showed a significant difference. The precision improved (RMSD decreased) with sequence-length: six items sequences (Mean=7.77, SD=3.4) and 12 items sequences (M=6.90, SD=3.2); t(23)=3.66; p<.01 (see 
Figure 5A
; Experiment 1a). These results are consistent with the predictions of the normative-holistic model which predicts better performance for the 12 items sequences relative to the six items sequences due to the fact that uncorrelated single item noise averages out, but is also consistent with predictions of the mid-range model. In addition we found that precision decreases with sequence variance (see 
Figure 4B
):
repeated measure ANOVA with the within subject factor of the 3 groups of variance; F(1.2,28)=44.8; p<.001, indicating a linear trend. In order to probe whether participants based their average estimations mostly on extreme values, as predicted by a midrange strategy (see 
Figure 5
 red plot), or on all items with equal weights as predicted by a normative-holistic strategy (see 
Figure 5
 blue plot), we ran separate regressions for each of the sequences' length conditions, using the sequence ranked numbers as predictors (see Method section; in the twelve-items sequences we paired the items in order to have six predictors in both conditions) and we averaged both conditions weights. As shown in 
Figure 5A
, the regression weights show a mild U-shaped pattern (black line), indicating a tendency to overweight extreme values as predicted by a midrange strategy, but note that the decision weights are closer to normative-holistic model (blue line), according to which participants based their estimations on all items. A paired sample t-test between the weight given to inlying ranks [2-5] and outlying ranks [1 and 6] 
(Vandormael, Herce, Balaguer, Li, & Summerfield, 2017)
 was statistically significant; t(23)= 4.45, p<.001. The mean difference between outlying and inlying ranks across participants was 0.12. 5 We next examined individual differences. We found remarkable individual differences in the sequence-length effect (see 
Figure 6B
), in the curvature of the ranked decision weights (U-shape pattern), indicating the presence of different estimation strategies (see 
Figure 6C
), and in the precision of the estimations (see 
Figure 6D
). 


Experiment 1b
Experiment 1b was identical to Experiment 1a, with the only exception that in the majority of trials the distributions used to generate the sequences were skewed rather than uniform (same means). In addition, the variance was not manipulated factorially, as in Experiment 1a, however, the trials had a high variability in their sequence mean and variance (see
Methods).
Participants showed a high accuracy rate in evaluating sequences' average in both lengths.
Pearson mean correlation between the sequences' actual average and participants' estimation of the average was high (r=0.71, SD =0.12) and significantly higher than zero (all p's<.001). In addition, RMSD between the real averages and participants' responses was also measured and was significantly lower than simulated RMSD generated by (see 
Figure 5b
).


Experiment 2
Experiment 2 was identical to Experiment 1a with the exception that in addition to evaluating the sequences' average, participants were also instructed to estimate the sequences' relative "spread" 6 (high, medium, low). The experiment had two aims: First we wanted to see if people have the ability to extract this higher order statistic, together with the average, when viewing rapid sequences of numbers. Second we wanted to see if introducing this demand, would change the strategy the participants deploy to estimate the average.
The participants had a high accuracy rate in evaluating sequences' average in both lengths.
Pearson mean correlation across participants between the sequences' actual average and participants' estimation of the average was high (r=.73, SD=.09) and significantly higher than zero (all p's<.001). In addition, the RMSD between the real averages and participants' responses was significantly lower than simulated RMSD generated by randomly shuffling participants' responses across trials (RMSD=7.68, RMSD random Shuffle=14.23; t(23)=-21.88, p<.001). In contrast to previous experiments, however, while precision was still numerically higher for longer sequences (lower RMSD), this effect did not reach statistical significance (see 
Figure 4
 Experiment 2); t(23)=1.84, p=.07), and it was subject to marked individual differences 
(Fig. 7A
). Critically, the participants showed a high accuracy rate in the estimation of the sequences' relative-variance in both lengths (see 
figure 7B
). Spearman correlation between the sequences' actual variance and participants' (3-scale) estimation of the relative-variance was high and significant (r=.74, SD=0.1, p<.001; for all participants; see 
Figure 7C
).
As in Experiment 1 we averaged both regressions weights of each of the sequences' length conditions, using the sequence ranking's numbers as predictors. The results show a Ushaped pattern with a significant difference between the decision weights of the inliers [ranks 2-5] and outliers ranked numbers [ranks 1 and 6]; t(23)=6.78, p<.001. The mean difference between outlying and inlying ranks across participants was 0.16. The higher difference in this experiment compared with Experiment 1a (0.12) indicates that instructing the participants to estimate the variance in addition to the average, made them assign even higher weights to the extreme values (see 
Figure 5C
). This was also subject to individual differences (see 
Figure 7D
).


Experiment 3
Experiment 3 was similar to Experiment 2, but here we replaced the explicit estimation of the sequence relative-variance with a more implicit onea report of confidence in the average estimation (we expected that confidence will decrease with sequence variance; 
(Lebreton et al., 2015;
Yeung & Summerfield, 2012)
. Furthermore, we aimed here to measure the decision time for the average-estimation and to determine if it depends on sequence variance 
(Ratcliff & McKoon, 2020)
. As Experiment 1, there was a significant effect for sequence length in the RMSD indicating better performance in 12 items sequences t(23)=2.9; p<.01, which was subject to marked individual differences; see 
Figure 9A
). Critically, the confidence reported by the participants decreased with the sequence variance; F(1.39,3.1)=51.5; p<.001. ( 
Figure 9B
).
The Spearman correlation (for each participant across all responses) between the sequences' variance and the participants' (4-scale) confidence report was significant 
SD=0.18,
p<.001)
, but subject to marked individual difference ( 
Figure 9C
). Finally, we find that the RT of the average estimation increased with the sequence variance; F(3,69)=6.8; p<.001.
For the novel (bimodal) condition we found that the confidence and the RT were similar to those in the (unimodal) large variance condition ( 
Figure 9D
). Finally, we ran a ranking regression to test whether participants assign higher weights to extreme values. As in the previous experiments a paired t test indicated an over-weighting of the extreme values, t(23)=4.12, p<.001. Mean difference between the outlying and inlying ranks was 0.24 (see 
figure 5D
).


Summary of Experimental Results
The results of these experiments demonstrate that human observers have a high capacity to extract two major summary statistics -the average and the relative variance, and to evaluate them with a relatively high accuracy when viewing rapid numerical sequences presented at a rate of 4/sec. The novel aspect of the results is the accurate estimation of sequence relative variance, and the fact that confidence and RT in the average-estimation can be used as indirect measures of sequence variance.
The results also indicate significant variability in the strategy that the observers deploy to make these estimations. This variability is indicated in the variation of the averageestimation precision, in the variation of the sequence length effect and the curvature of the U-shape in the decision weights for ranked sequence elements (see 
Figure 5
). As all of these factors distinguish between the strategies we labeled as holistic-normative vs mid-range, it is likely that they reflect a variability in the strategy the participants deploy. In particular, it may be suggested, that type of distribution from which the numbers are sampled (see differences between Experiments 1a and 1b in the ranked regression) and the need to monitor variance (see differences between Experiments 1 and 2), affect the likelihood of a participant to deploy a mid-range or holistic normative estimation.
In order to quantify and validate these qualitative summaries of the data, we have carried out a computational analysis, aimed to contrast between the averaging estimation strategies we considered earlier (holistic-normative vs. mid-range). In the following section we use computational modeling methods to classify participants based on which of these strategies they deployed in each task.


Individual differences in the average-estimation strategy: strategy classification
To classify the averaging classification strategies, we used two complementary approaches.
The first approach is empirical-based while the second required the development of formal models and on model selection based on the account of the subjects' data. The empirical based classification is straightforward. For each subject (and in each experiment), we computed the correlation (across all trials) between the average/mid-range of the sequence and the subject's estimation. We classified a subject as using a holistic-normative or midrange strategy on the basis of the highest correlation. While this method is simple, it only relies on the average of the estimation and does not take the distribution of estimations into account.
In the second approach, we developed formal models that quantify the predictions of the holistic and of the mid-range strategies, under a number of assumptions. As these models include stochastic processing, they predict not only mean-estimation but full distribution of estimations, and thus we can compute for each trial the likelihood of the response given the model and its parameters. (Note that once we determine the noise sources, the models also make predictions for the RMSD as a function of sequence-length, and thus this analysis goes beyond what could be achieved via a regression approach).
For each type of model (holistic or mid-range) we examined two versions, a simple one in which the noise (variability) parameters are fixed, and a more complex one in which one variability parameter depends on the sequence-variance. The simpler models assume the presence of a common motor/output noise (that is invariant to sequence-length or sequencevariance) and an encoding noise in the holistic model, which operates in the conversion of each item from a numerical symbol to a population response over magnitude representations 
(Dehaene, 2007
; see also 
Fig 1)
 7 ; both of these noise distributions are assumed to be Gaussian. In the simple midrange model we assumed that the symbolic calculation of the average of two numbers is accurate and does not depend on their range.
In the complex models, variance dependent noise was introduced for both model types. This is motivated by this feature of the data 
(Fig. 4B
) and can be motivated in different ways for the two types of models. For the holistic model, the variance dependent variability is motivated by the holistic population-averaging model 
(Brezis et al., 2017)
, in which the estimation of the center of mass of the population response depends on the variance of the sequence (peaked distributions are more precise than flat ones; 
Fig 1C)
. For the mid-range model, the variance dependent noise corresponds to a type of "calculation-error", which increases with the range. Finally, in all models we allowed an intercept and a slope to mediate the transformation from an internal to an external space 8 (see Computational
Methods for details of the models). For each participant, we have carried out a model selection analysis of the data in the experiments presented. The models which we contrasted were the normative-holistic model and the mid-range model. The contrast was based on their relative likelihood to account to all the estimations a participant gave (maximum likelihood, subject to a standard penalty for degrees of freedom; AIC and BIC measures; 
Akaike, 1973)
.
In 
Table-
1 we present the group BIC-values (mean BIC across participants) for each of the four models for the data of our four experiments. We see that at the group level, the holistic model wins by far in Experiments 1a and 1b, in which subjects where only asked to estimate the sequence-average. In Experiments 2 and 3 (in which variance or confidence where queried in addition) we find more balanced results; the models are at a tie in Experiment 2 and there is a small advantage favoring the mid-range model in Experiment 3. We also see, that except for Experiment 1b (which used skewed number distributions), the presence of variance-noise improved the model fits.   
Table 3
. Same for the complex holistic midrange models.
First, we see a very high consistency between the simple-model classification and that based on trial by trial correlations between the models and the subject's estimates. Second, based on both models, we see that almost all subjects are classified as deploying a holistic estimation mechanism in Experiments 1a and 1b (only 2-3 out of 46 Ss were classified as midrange in these experiments). Consistent with the group data, we find that about half of the participants still use the holistic estimation in Experiments 2 and 3, when they are required to estimate not only the sequence-average but also its relative-variance (or to report their confidence).
As shown in 
Fig 10,
 the models' classifications account for the qualitative behavioral patterns in our experiments: the dependency of the precision-estimate (RMSD) on the sequence-length and on sequence-variance. As in the data, the sequence length effect was bigger in Experiments 1a and 1b (in which most participants were classified as holistic), compared to Experiments 2-3 (only about half of the participants holistic). This can be explained by the stronger sequence-length dependency in this model (see 
Figure 2
). 
Figure 10
. Models' best fit prediction. In order to test whether the models account for the sequence length and variance effect (see 
Figure 4A &
  The classification results are also consistent with the ranked regression results 
(Fig. 5)
,
where we see a gradation in the fraction of participants that deploy, a holistic/normative vs.
a mid-range strategy, respectively. While in Experiment 1b, which presented numbers selected from skewed distributions, all the participants were classified as holistic/normative and they showed flat ranked regression weights, in all other experiments, there were some participants classified as mid-range. Moreover, we see that the fraction of participants using a mid-range strategy increases (and the fraction of those using a holistic estimation decreases) when the participants are required to monitor the sequence variance or the confidence in the average estimation. This is consistent with the increased weights given to the extreme values at the group level, in these two conditions and with the marked variability in the sequence-length effect (and its reduced effect magnitude in Experiments 2 and 3).
Finally, we tested whether estimation precision (RMSD) differs between participants who were classified to the holistic vs. mid-range (this was done only for Experiments 2-3, where there roughly an equal number of participants were classified for both models). An un paired t-test indicates that holistic subjects were significantly more precise than mid-range subjects, t(46)=2.19, p<.05, in their sequence-average estimations. 
Figure 11
. Performance-strategy difference. RMSD as a function of model classification. The significant difference indicates that participants who used the holistic strategy performed better at the task.


Discussion
In four experiments we have shown that human observers can make quite accurate estimations of the average of rapid sequences of two digit numbers presented at a rate of 4/sec (as quantified by Pearson correlations in the range of .7-.8, between actual and estimated averages). Moreover, we show that the observers are able to estimate, in addition, the relative variance of the sequence (high, medium or low): the average Spearman correlation between estimated and actual (relative) variance was 0.74. Furthermore, the observers speed and confidence in the estimation of the average decreased with the variance of the sequence. These results demonstrate that the remarkable ability to extract summary statistics of perceptual sets 
(Ariely, 2001;
Bronfman et al., 2015;
Chong & Treisman, 2005;
Dakin, 2001;
Haberman & Whitney, 2011;
Parkes et al., 2001
), extends to rapid numerical sequences.
A central question that these results pose is the nature of the mechanism or strategy that the observers deploy to generate these estimates. Due to the rapid sequence presentation and the strict response-deadline we impose on response generation (3 sec, including the response on a continuous scale), we can exclude a fully analytical/symbolic strategy of adding the numbers and dividing by the sequence length, in favor of more intuitive estimation strategies. Two such "intuitive" strategies were considered in detail here. The first is the estimation of the center of mass from a noisy holistic (or frequency based)
representation of each sequence, and the second is an estimation based on few (efficiently selected) samples. For the former we have shown it to predict an improvement in precision with sequence-length and for the latter we distinguished between random sampling, which predicts a decreasing precision with sequence length, and a mid-range strategy which predicts a milder improvement 
(Figure 2
). Since most of the subjects in all experiments (and three out of our four experiments at the group level) show an improvement in precision with sequence-length (see 
Figure 4A
), this rules out the random sampling as an account for task performance in our experiments, leaving the holistic (or frequency) model and the midrange strategy, as more plausible candidates.
The most distinctive signature of the mid-range strategy (compared with the holistic/normative model) is the U-shape pattern in the decision weights of the ranked samples 
(Spitzer, Waschke & Summerfield, 2017;
Vanunu et al., 2019;
Vanunu et al., 2020)
. In all our experiments, except the one which utilized skewed distribution of numbers (experiment 1b), we found a small U-shaped modulation at the group level ( 
Figure 5
), which was subject to marked individual differences 
(Figures,
. Model classification of individual subjects confirmed the presence of individual differences. While all the subjects were classified as utilizing the holistic mechanism in Experiment 1b (skewed distributions), we found that 12% were classified to utilize mid-range in Experiment 1a (uniform distribution), where this strategy is a viable one for the task.
Furthermore, the fraction of subjects that appear to utilize the mid-range strategy appears to increase in Experiments 2-3 (54%), in which the participants were asked to estimate the sequence relative spread or their confidence in the average estimation. Nevertheless, even in these experiments, almost half of the participants appear to rely on a holistic estimation.
These results parallel those obtained in tasks of probabilistic inference or in multiatribute decisions, in which the majority of participants rely on a holistic compensatory strategy of evaluation, while a minority rely on Take the Best 
(Betsch & Glöckner, 2010;
Brusovansky, Glickman, & Usher, 2018;
Glöckner & Betsch, 2008;
Newell & Shanks, 2003)
.
Although we found that most observers deployed the holistic estimation mechanism, both estimation models can be subject to variations. For example, one can modify the holistic model so as to give differential attentional weights to numbers based on their values, while still summing over all items 9 . Similarly, one can modify the mid-range strategy by making it probabilistic, by including a probability parameter to fail in detecting the maximum/minimum in the sequence and then recursively select the value next in rank.
Future studies will be necessary to contrast such estimation mechanisms for the extraction of summary statistics of rapid numerical sequences and to characterize their individual differences. Below we discuss the relative efficiency of these two types of strategies, their relation with the two-pathway theory of numerical processing and the implications for the general field of decision-making.


Estimation efficiency of numerical averaging and its computation
Work in numerical cognition, has highlighted the presence of two processes or pathways in number processing: i) exact vs. ii) approximate 
(Dehaene, 1992;
Dehaene & Cohen, 1991)
.
While the former is based on symbolic representation and on rule based operations 
(Ashcraft, 1992)
, the latter is based on analog/magnitude representations and on perceptual type operations 
(Dehaene, 2007;
Dehaene, Dehaene-Lambertz, & Cohen, 1998;
Piazza, Pinel, Bihan, & Dehaene, 2007)
. For example, both numerical symbols and numerosity (dot) displays activate the same distance-dependent approximate number representation in the parietal cortex 
(Piazza et al., 2007)
. Moreover, an analog representation of symbolic numbers is also supported by distance-effects in the comparison of symbolic numbers 
(Dehaene, Dupoux, & Mehler, 1990;
Moyer & Landauer, 1967)
 and by data from patients with dyscalculia 
(Dehaene & Cohen, 1991)
. Finally, it was suggested that this analog representation of magnitudes is part of a core system for numerical processing, which is shared with other animal species (and non-verbal humans) and grounds the processing of symbolic representations 
(Feigenson, Dehaene, & Spelke, 2004
; see also 
Verguts & Fias, 2004
 for a computational modeling illustration).
While most previous work has focused on mathematical operations, such as addition or subtraction 
(Barth et al., 2006)
, here we have focused on averaging. Obviously, one way (a symbolic one) to compute an average is via summation and division by n. The numerical cognition literature discussed above, suggests an alternative type of estimation: a population averaging of the analog magnitude representation, as was shown to be possible for perceptual properties 
(Ariely, 2001;
Chong & Treisman, 2005;
Dakin, 2001;
Haberman & Whitney, 2011;
Parkes et al., 2001
). Thus the approximate and the exact pathways may map into the types of models we have contrasted here, with the exact pathway mapping on to the (rule-based) mid-range strategy, and the approximate pathway onto the holistic estimation of all (but noisy) samples. A central question that can be raised is which of these pathways or processes is more efficient for tasks that require the extraction of summary statistics from rapid sequences. Note that this is not straightforward, as the two processes face a tradeoff. While the holistic model takes all items into account, it is subject to significant encoding noise on each one. By contrast, the mid-range strategy, relies on only two items, but due to its symbolic nature is subject to minimal encoding noise. Motivated by this tradeoff, we have examined the data for association (across participants) between task precision and strategy use. As shown in 
Figure 11
, we found that participants who were classified to the holistic model, had a higher precision in the task. 10


Implications for decision-making
The obvious importance of having a mechanism that automatically extracts summary statistics of rapid sequences of numerical payoffs, is that one can rely on it for preference formation, in situations that do not require explicit estimations. Indeed, statistical summaries are central to normative preference, as formalized by the prominent risk-return model, according to which the attractiveness of a risky alternative is an additive function of the alternative's average reward and its riskthat is, between the mean and the variance of the payoff distribution 
Weber, 2011)
. While most frequently, preferences are probed via choices between sets of alternatives, in which the canonical models involve some type of accumulation over sampled valued 
(Bhatia, 2013;
Krajbich, Lu, Camerer, & Rangel, 2012;
Roe, Busemeyer & Townsend, 2001;
Stewart & Simpson, 2008;
Townsend & Busemeyer, 1993;
Usher & McClelland, 2004)
, it is also possible to probe relative preferences for individual alternatives using an analog (like) rating scale 
(Krajbich et al., 2012
; see also 
Becker, Degroot & Marschak, 1964
 for BDM procedure).
Moreover, recently risk-preferences have been probed using analog rating-scale for rapid sequences of payoffs. The results were well accounted by a risk-return model, in which the preference depends on the mean and the variance of the payoffs (the latter accounting for risk-biases). We propose that such summary statistics can be holistically computed in an automatic way when we are exposed to alternatives consisting of numerical sequences (see also 
Betsch & Glöckner, 2010;
Betsch, Plessner, Schwieren & Gutig, 2001;
Brusovansky, Glickman, & Usher, 2018)
, contributing a general preference towards these alternatives.
Finally, the automatic extraction of summary statistics of sets of values (payoffs or affective attributes) can provide a mechanism for intuitive decisions or forecasts, in which participants appear to rely on "gut-feeling" resulting in decision outcome that sometimes exceed those of conscious deliberations 
(Bechara & Damasio, 2005;
Dijksterhuis & Nordgren, 2006;
Lee, Amir & Ariely, 2009;
Pham, Lee & Stephen, 2012;
Rusou, Zakay & Usher, 2013;
Usher et al., 2011;
but see Gonzalez-Vallejo, Lassiter, Bellezza & Lindberg, 2008
). numerical values which were presented with a presentation rate of 4 HZ and were uniformly distributed. To generate the sequences, we used a 3x3 orthogonal design of mean: 40, 50, or 60 and ranges (to control variance) of mean ± 10, mean ± 25 or mean ± 39. The numbers in each sequence were independently sampled from one of these nine distributions (random between trials). 11


Experimental
Procedure and design. Each trial began with a fixation display that consisted of a black 0.2º × 0.2º fixation cross (+) that remained on the screen for 250 ms. Then, a sequence of six or twelve numbers (randomized between trials) was presented. Once the sequence terminated, the participants were required to estimate the sequence's mean value using an analog ruler that was displayed and ranged from 1 to 100 (see 
Figure 2
). Participants underwent 300 experimental trials divided into 10 blocks. Each block terminated with performancefeedback (real-average/estimated-average correlation) and a short, self-paced break.


Experiment 1b:
Method Participants. Twenty-two undergraduate from Tel-Aviv University (Mean age=22.5;


SD=2
.3) participated in the experiment. All participants were naive to the purpose of the experiment and had normal, or corrected-to-normal, vision. Informed consent was obtained from all subjects. Participants were awarded with course credit for their participation. All procedures and experimental protocols were approved by the ethics committee of the Psychology department of Tel Aviv University (Application 743/12). All experiments were carried out in accordance with the approved guidelines.


Stimulus Materials and Procedure
The only difference from Experiment 1a was that the sequences in each trial were sampled from predefined three distributions ranged between 1 and 100; with means of: 40, 50 or 60.
Two of the distributions were triangular skewed density distributions (one from each side), and the third one was a uniform distribution (see 
Figure 11
). Each sequence was sampled independently from one of the three distributions. 


Stimulus Materials and Procedure
Same as in Experiment 1a, but after evaluating the average using the numbers ruler,
participants were asked to evaluate the "spread of the sequence" on a 3 category scale: i) small, ii) medium, iii) large (the participants were shown 2 example sequences of each kind at the beginning of the experiment).


Experiment 3:
Method Participants. Twenty-four undergraduate from Tel-Aviv University (Mean age=22.4; SD= 2.7) participated in the experiment. All participants were naive to the purpose of the experiment and had normal, or corrected-to-normal, vision. Informed consent was obtained from all subjects. Participants were awarded with course credit for their participation. All procedures and experimental protocols were approved by the ethics committee of the Psychology department of Tel Aviv University (Application 743/12). All experiments were carried out in accordance with the approved guidelines.
Stimulus Materials and Procedure.
Experiment 3 was similar to Experiment 2 with three exceptions: i) In addition to the 9 distributions that the sequences were sampled from in the previous experiments, there was one more condition with bimodal sequences (mean of 50 in which half of the numbers were sampled from the uniform distribution: U (5,35) and the other half from U (65, 95). ii) The average estimation was made using a semicircle shaped scale. The mouse cursor was always at the middle of the circle at the beginning of the scale display, thus it had an equal distance from each point of the scale (see 
Figure 8
). The reason we changed the scale from a ruler to a semicircle was so we could measure more precisely the reaction time of the average estimation without introducing anchoring bias. iii) Instead of evaluating the spread of the sequence, after evaluating the average, the participants were instructed to rate their confidence rate on a 1-4 scale.


Computational Method
To apply the models to data, we had to make some assumptions on the response variability in these 4 models. For the simple normative-holistic model we have 2 noise parameters, an encoding noise 12 (which is applied for each item, and thus averages out as 1√2 with sequence length, from 6 to 12) and a global (or motor noise 13 ), which does not change with sequence length:
= + ( ∑ + =1
) + , ~(0, 2 ) and ~(0, 2 ) (3)
where, xi is the i th item of the sequence, is the encoding noise and is the motor noise and a and b are intercept and slope parameters, respectively, that are used to map between the participant internal estimation to the external response scale.
For the more complex normative-holistic model we have three noise parameters. Additional to the motor noise (as before), the encoding now varies with the sequence-variance (two parameters instead of one):
= + ( ∑ + + • 2 =1
) + , ~(0, 2 ), ~(0, 2 ) (4) and
~(0, 2 )
where, xi is the i th item of the sequence, and are encoding noise parameters, is the motor noise and 2 is the sequence's variance.
In the simple mid-range model we only assumed the presence of global/motor noise, which does not depend on sequence length:
= + ( + 2 ) + ,~(0, 2 )
(5)
where a is the intercept , b is the slope , and are the smallest and highest items of the sequence and is the motor noise.
In the complex mid-range model we assumed a 'calculation' noise which depends on the range of the sequence in addition to the global/motor noise, which does not depend on sequence length:
= + ( + 2 + − 2 ) + ,~(0, 2 ) ~(0, 2 )
(6)
where a is the intercept , b is the slope , and are the smallest and highest items of the sequence, is the motor noise and is the calculation noise.
Thus, the simple holistic-normative model has four free parameters (slope, intercept, encoding/motor noises), while the simple mid-range model has three free parameters (slope, intercept, motor noise). For the complex models we added one more parameter for each model to allow variance dependent noise. These noise components are motivated by the holistic population-averaging model 
(Brezis et al., 2017)
 in which the estimation of the center of mass of the population response depends on the variance of the sequence (peaked distributions are more precise than flat ones; 
Fig 1C)
. For the mid-range model, the variance dependent noise corresponds to a type of "calculation-error", which increases with the range. For each trial in the experiment, we analytically computed the probability distribution for an estimation (x) as a function of the sequence of numbers the participants received on that trial and the model parameters, and we collected the Log of the Probability for the response on that trial given model parameters. This Log-Probability was aggregated across all the trials, and we searched the model parameter space (using a combination of grid and Simplex; see Optimization procedure in Supplement) for the set of parameters with highest log-likelihood. The model selection was then based on maximum likelihood model fits, and for each participant the model with the lowest AIC/BIC was selected.
exhaustively, and for each set of parameters, , the likelihood was calculated based on a Gaussian probability distribution function:
( ) = ∏ 1 √2 =1 −1 2 ( − ) 2
where is the number of trials, is the subject's estimated average in each trial, is the predicted average by the model excluding noise, and is the standard deviation such that 2 = 2 + 2 for the normative-holistic model (see equation 3) and 2 = 2 for the Mid-range model. The five parameters sets that had the highest likelihood were fed as starting points to a Simplex minimization routine, in which the cost function was defined as the negative log-likelihood. The mean best-fitting parameters (averaged across participants) are shown in 
Table S3
.
Model selection. In order to evaluate the quantitative fits of the models, we used two methods: i) Akaike Information Criterion (AIC; 
Akaike, 1974)
, and ii) Bayesian Information Criterion 
(BIC;
Schwarz, 1978
, Raftery, 1995
, these selection criteria implement a trade-off between model goodness of fit and complexity by penalizing additional free parameters according to the following formulas:
AIC = -2•LL+2•k BIC = -2•LL + k•log(N)
where LL is the log-likelihood for the best fitting parameters, k is the number of free parameters and N is the number of trials. AIC/BIC differences exceeding 10 are considered decisive evidence in favor of the model with the lower numerical values 
(Burnham & Anderson, 2002;
Raftery 1995)
. To calculate the AIC/BIC measures at the group level, we used the above formulas, but with the group LL, k, and N, which were obtained by summing the individual values across the group.
Figure 1 .
1
The population averaging model. (A) Numbers activate broadly tuned numbermagnitude detectors. (B) In this illustration we show the noisy population profile in response to the presentation of an example sequence of 3 numbers: 20, 50, 80. (C) The estimation of the average is based on the central of mass of the population response (based on


accurate representation of the set, the precision of the analytical-random model decreases with n (fig. 2, red line).


Figure 2 .
2
Accuracy as a function of sequence length-predictions for different models. The dashed rectangle indicates the relevant range of sequence-lengths in our experiments. In all simulations, sets of n numbers in the range of 0-100 are sampled from a uniform distribution. Blue & black: Normative-holistic and population averaging models. Both models show similar predictions in which accuracy improves as sequence length increases. Red: Analytic-random model. Accuracy deteriorates as sequence length increases. Magenta: Mid-range model. Non-monotonic function. Shows a mild improvement as sequence length increases in the relevant experimental range.


Figure
Figure 3. Illustration of an experimental trial (Exp. 1-2). (A) Each trial begins with a 250ms fixation cross, after which a sequence of two-digit numbers is presented (250ms/numeral). The sequence-length is 6 or 12 (randomized between trials). (B) The participants were asked to convey the sequence's average, by vertically sliding a mouse-controlled bar set on a number ruler (white bar) between 1 and 100. The number corresponding to the bar's location is being dynamically displayed (30 in the display).


Figure 4 .
4
(A) The sequence length effect for all four experiments. In all experiments, except Experiment 2, participants performed significantly better in the 12 items condition compared to the six items (in group level). (B) The Variance effect for all experiments excluding 1b which did not manipulated variance. All 3 experiments showed a linear trend in which precision decreases as variance increases.


Figure 5 .
5
Ranking-weighting profile of the numbers (A) Experiment 1a. Real data regression (black) compared with normative-holistic and mid-range predictions (blue and red, respectively). (B, C & D) Same analysis for Experiments 1b, 2 and 3, respectively.


Figure 6 .
6
(A) Trial by trial performance of a representative individual observer. The scatter plot depicts the participant's estimation (y-axis) for each of the presented number sequence averages (x-axis). Blue and red lines represent the regression and identity lines respectively. (B) Individual difference in RMSD-difference (δ) between the two sequence length conditions (positive values indicate improvement in performance as sequence length increases; sorted by value). (C) Individual differences in the difference between outliers' weight (the averaged coefficient of the first and last items in the sequence) and inliers' weight (the averaged coefficient of all items between the second and the one before last; sorted by value). (D) Individual differences in the correlations between the estimated average and the actual average (chance corresponds to r=0). Participants in panel B-D are sorted independently.


Figure 7 .
7
(A) Individual differences in ∆ RMSD between the sequence length conditions (positive values indicate improvement in performance as sequence length increases. (B) The average variance reported (y-axis) as a function of the real variance of the sequence (x-axis). (C) Individual difference in the Spearman correlation between variance reported and actual variance for each participant. (D) Individual differences in δ between outliers' weight (the averaged coefficient of the first and last items in the sequence) and inliers weight (the averaged coefficient of all items between the second and the one before last).


Figure 8 .
8
Response scale and confidence response in Experiment 3.The participants had a high accuracy in evaluating the sequences' average as shown by a high Pearson correlation between real and estimated averages (r=.727, SD=.09, all p's<.001). In addition, the precision of the estimation was significantly higher (RMSD was lower) between the real averages and participants' responses compared with that obtained by randomly shuffling participants' responses across trials (RMSD=8.0, RMSD random Shuffle=14.3; t(23)=-21.88, p<.001).


Figure 9 .
9
(A) Individual differences in ∆ RMSD between the sequence length conditions (positive values indicate improvement in performance as sequence length increases. (B) Confidence reported as a function of variance. (C) Spearman correlations between variance and confidence rate for each participant. (D) RT as a function of variance.


Twenty-four undergraduate from Tel-Aviv University (Mean age=22.2; SD=1.7) participated in the experiment. All participants were naive to the purpose of the experiment and had normal, or corrected-to-normal, vision. Informed consent was obtained from all subjects. Participants were awarded with course credit for their participation. All procedures and experimental protocols were approved by the ethics committee of the Psychology department of Tel Aviv University (Application 743/12). All experiments were carried out in accordance with the approved guidelines.Apparatus and stimuli. Displays were generated by an Intel I7 personal computer attached to a 24'' Asus 248qe monitor with a 144 Hz refresh rate, using 1920×1080 resolution graphics mode. Responses were collected via the computer mouse. Viewing distance was approximately 60 cm from the monitor. The stimulus consisted of sequences of 6 and 12


Figure 11 .
11
The distributions from which the numbers were sampled in Experiment 1b. Twenty-four undergraduate from Tel-Aviv University (Mean age=23.3; SD= 2.7) participated in the experiment. All participants were naive to the purpose of the experiment and had normal, or corrected-to-normal, vision. Informed consent was obtained from all subjects. Participants were awarded with course credit for their participation. All procedures and experimental protocols were approved by the ethics committee of the Psychology department of Tel Aviv University (Application 743/12). All experiments were carried out in accordance with the approved guidelines.


Due to the fact that in this experiment the numbers were selected from skewed distributions, we expected participants to rely less on extreme values which could mislead them in average estimation. In order to test this adaptivity hypothesis, the same ranking analysis from Experiment 1a was used in the current experiment. Unlike, in Experiment 1a, no significant differences between in/out-lying ranking weights was found; t(21)=1.07, p=.3    
randomly shuffling participants' responses across trials; RMSD=10.3, RMSD random
Shuffle=18.48; t(21)=-19.67 p<.001. Just like Experiment 1a, there was a significant
decrement in RMSD with sequence-length (see Figure 4A Experiment 1b; 6 items
sequences (M=10.6, SD= 2.6) and 12 items sequences (M=10.0, SD=2.6) trials; t(21) =2.3,
p<.05.


Table - Simple Holistic Simple Mid-range Percentage Holistic
-
Experiment
Experiment 1a
22 (22)
2 (2)
92%
Experiment 1b
22 (22)
0 (0)
100%
Experiment 2
15 (16)
9 (8)
62%
Experiment 3
19 (19)
5 (5)
79%
2: Number of participants classified as using the simple holistic vs mid-range in their average estimations, in the four experiments. Values in parentheses correspond to the comparison of correlations (see text).


Models prediction to the variance effect in experiment 1a, 2 and 3. All predictions are based on best fit parameters for each participant.
effect. (B)
Experiment
Complex-holistic Complex Midrange Percentage Holistic
Experiment 1a
21
3
88%
Experiment 1b
22
0
100%
Experiment 2
12
13
46%
Experiment 3
11
13
46%
4B), we simulated the best fit
predictions in each experiment (for the variance effect we simulated only experiments 1a,
2 and 3 in which variance was manipulated). (A) Models prediction to the sequence length


As we only aim to examine sensitivity to relative-variance (i.e, to ordinal comparison of variance magnitudes) this is the same as relative-SD, relative-spread (or dispersion). We will use this terms interchangeably in the text (but see Methods for how this was presented to participants).


We assume that subjects are able to compute the average of 2-3 numbers with reasonable precision. 3 The term "analytic" refers to the fact that subject to WM-capacity limitation, one relies on a symbolic, rule-based and error less computation. However, since this strategy does not use all of the information available, one may also think of it as an intuitive one
(Kruglanski & Gigerenzer, 2011)
.


The Pearson correlation between actual and estimated values, and the RMSD (root mean square deviations) provide complementary but well correlated aspects of precision. The RMSD (but not the correlation) is affected by systematic biases, while correlation (but less the RMSD) is affected by the range of the values. Here we report both, but we focus on RMSD when examining differences in precision with sequence-length (as this variable affects the range).


We also estimate the U-shape pattern by extracting a curvature parameter for the parabolic fit of the ranked regression, for each participant. We found a very high correlation (r=.93, p<.001) between the curvature parameter and the difference between the mean of outlying and inlying ranks. SeeFigure S1in the Supplement.


We intentionally used the term "spread" (rather than variance or SD), appealing to the subjects' preexperimental knowledge in order to prevent participants from engaging in an explicit computation.


Note that despite the invariance of the encoding noise to sequence-length the estimation-precision improves with sequence-length due to noise-averaging (seeFig. 2). 8 The intercept can correspond to subjective biases in the mapping of the internal estimation to the external scale, while the slope to a 'regression to the mean' that is normative when the distribution of sequences is centered around a mid-range value (50 in our case).


For example, we have explored a model in which the numbers are weighed with Beta functions over the interval 0-100.


In principle a subject classified as Mid-range, can have better accuracy than one classified as Holistic, if the latter, resorts to a higher encoding noise. The results reported here indicate that this is not the case.


As shown inFigure 4A, the mean of the actual sequences varies continuously in the range (30-70).


The encoding noise corresponds to the encoding of the symbolic number into an analog magnitude response
(Dehaene, 2007)
.13  Note that the responses are provided via the mouse on a continuous scale.








Acknowledgments
We wish to thank Vincent De-Gardelle, Zohar Bronfman, Danny Algom and Naama Katzin for helpful discussions and comments on the manuscript.






Supplementary Information


Model Comparison
Model Fitting Optimization procedure. The free parameters of the normative-holistic and the midrange models were fitted to the data of each participant separately, using maximum likelihood estimation. We first constructed an n-dimensional grid (n is the number of free parameters for each model), with ranging from -20 to 20 in increments of 10, ranging from 0 to 3 in increments of .75, (only for the normative-holistic model) and ranging from 0 to 10 with increments of 2.5, (complex normative-holistic model) and (complex mid-range model) ranging from 0 to 1 with increments of 0.1. This grid was searched  
Figure S1
. Correlations between curvature parameter for the parabolic fit of the ranked regression and the difference between the mean of outlying and inlying ranks. The high correlations indicate that both measures are similar in estimating the U-shape patterns. A-D represents experiments 1a, 1b, 2 and 3 respectively.


Experiment 1a
 










Information theory and an extension of the maximum likelihood principle




H
Akaike








Proceedings of the 2nd International Symposium on Information Theory


BN, Petrov & F. Csaki


the 2nd International Symposium on Information Theory
Budapest




Akademiai Kiado
















An almost general theory of mean size perception




J
Allik






M
Toom






A
Raidvee






K
Averin






K
Kreegipuu








Vision Research




83


















10.1016/j.visres.2013.02.018














Working memory: Activation limitations on retrieval




J
R
Anderson






L
M
Reder






C
Lebiere








Cognitive Psychology




30


3


















10.1006/cogp.1996.0007














Seeing Sets: Representation by Statistical Properties




D
Ariely




10.1111/1467-9280.00327








Psychological Science




12


2
















Cognitive arithmetic: A review of data and theory




M
H
Ashcraft








Cognition




44


1-2
















The somatic marker hypothesis: A neural theory of economic decision




A
Bechara






A
R
Damasio








Games and economic behavior




52


2
















Measuring utility by a singleresponse sequential method




G
M
Becker






M
H
Degroot






J
Marschak








Behavioral science




9


3
















Intuition in judgment and decision making: Extensive thinking without effort




T
Betsch






A
Glöckner








Psychological Inquiry




21


4
















I like it but I don't know why: A value-account approach to implicit attitude formation




T
Betsch






H
Plessner






C
Schwieren






R
Gütig








Personality and Social Psychology Bulletin




27
















Associations and the accumulation of preference




S
Bhatia








Psychological review




120


3


522














Adaptive Spontaneous Transitions between Two Mechanisms of Numerical Averaging




N
Brezis






Z
Z
Bronfman






M
Usher




10.1038/srep10415








Nature Publishing Group














Decisions reduce sensitivity to subsequent information




Z
Z
Bronfman






N
Brezis






R
Moran






K
Tsetsos






T
Donner






M
Usher




10.1098/rspb.2015.0228








Proceedings of the Royal Society B: Biological Sciences




282














Fast and effective: Intuitive processes in complex decisions




M
Brusovansky






M
Glickman






M
Usher








Psychonomic Bulletin and Review




25


4


















10.3758/s13423-018-1474-1














Statistical processing: Not so implausible after all




S
C
Chong






S
J
Joo






T
A
Emmmanouil






A
Treisman








Perception & Psychophysics




70


7
















Attentional spread in the statistical processing of visual displays




S
C
Chong






A
Treisman








Perception and Psychophysics




67


1


















10.3758/BF03195009














Information limit on the spatial integration of local orientation signals




S
C
Dakin








JOSA A




18


5
















Robust averaging during perceptual judgment




V
De Gardelle






C
Summerfield




10.1073/pnas.1104517108








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






108














Varieties of numerical abilities




S
Dehaene




10.1016/0010-0277(92)90049-N








Cognition




44


1-2
















Symbols and quantities in parietal cortex : elements of a mathematical theory of number representation and manipulation




S
Dehaene








Numerical Cognition






XXII














Two mental calculation systems: A case study of severe acalculia with preserved approximation




S
Dehaene






L
Cohen








Neuropsychologia




29


11
















Abstract representations of numbers in the animal and human brain




S
Dehaene






G
Dehaene-Lambertz






L
Cohen








Trends in Neurosciences




21


8
















Is Numerical Comparison Digital ? Analogical and Symbolic Effects in Two-Digit Number Comparison




S
Dehaene






E
Dupoux






J
Mehler








Journal of Experimental Psychology




16


3
















A theory of unconscious thought




A
Dijksterhuis






L
F
Nordgren








Perspectives on Psychological science




1


2
















From anomalies to forecasts: Toward a descriptive model of decisions under risk, under ambiguity, and from experience




I
Erev






E
Ert






O
Plonsky






D
Cohen






O
Cohen








Psychological review




124


4


369














Core systems of number




L
Feigenson






S
Dehaene






E
Spelke








8














10.1016/j.tics.2004.05.002














A model for two-digit number processing based on a joint Garner and system factorial technology analysis




D
Fitousi






D
Algom




10.1037/xge0000679








Journal of Experimental Psychology: General
















Attentional Selection Mediates Framing and Risk-Bias Effects




M
Glickman






K
Tsetsos






M
Usher








Psychological Science




29


12


















10.1177/0956797618803643














Multiple-Reason Decision Making Based on Automatic Processing




A
Glöckner






T
Betsch




10.1037/0278-7393.34.5.1055








Journal of Experimental Psychology: Learning Memory and Cognition




34


5
















Save angels perhaps": A critical examination of unconscious thought theory and the deliberation-without-attention effect




C
González-Vallejo






G
D
Lassiter






F
S
Bellezza






M
J
Lindberg








Review of General Psychology




12


3
















Efficient summary statistical representation when change localization fails




J
Haberman






D
Whitney








Psychonomic Bulletin and Review




18


5


















10.3758/s13423-011-0125-6














American Finance Association Portfolio Selection Author ( s )




Harry
Markowitz




















Harry Markowitz Source










Wiley for the American Finance Association Stable URL






7








The Journal of Finance








Comparing set summary statistics and outlier pop out in vision




S
Hochstein






M
Pavlovskaya






Y
S
Bonneh






N
Soroker




10.1167/18.13.12








Journal of Vision




18


13
















On the misperception of variability




Y
Kareev






S
Arnon






R
Horwitz-Zeliger








Journal of Experimental Psychology: General




131


2


















10.1037/0096-3445.131.2.287














Perceiving set mean and range: Automaticity and precision




N
Khayat






S
Hochstein








Journal of vision




18


9
















The attentional drift-diffusion model extends to simple purchasing decisions




I
Krajbich






D
Lu






C
Camerer






A
Rangel








Frontiers in Psychology




3
















10.3389/fpsyg.2012.00193














Intuitive and Deliberate Judgments Are Based on Common Principles




A
W
Kruglanski






G
Gigerenzer








Psychological Review




118


1


















10.1037/a0020762














Automatic integration of confidence in the brain valuation signal




M
Lebreton






R
Abitbol






J
Daunizeau






M
Pessiglione




10.1038/nn.4064








Nature Neuroscience




18


8
















In search of homo economicus: Cognitive noise and the role of emotion in preference consistency




L
Lee






O
Amir






D
Ariely








Journal of consumer research




36


2
















Intuitive averaging of categorized numerical stimuli




R
A
Malmi






D
J
Samson








Journal of Verbal Learning and Verbal Behavior




22


5


















10.1016/S0022-5371


















Erratum: A "dipper" function for texture discrimination based on orientation variance




M
Morgan






C
Chubb






J
A
Solomon




1-8)10.1167/8.11.9








Journal of Vision




8


11










Journal of Vision








Better than average: Alternatives to statistical summary representations for rapid judgments of average size




K
Myczek






D
J
Simons




10.3758/PP.70.5.772








Perception and Psychophysics




70


5
















Take the Best or Look at the Rest? Factors Influencing "One-Reason" Decision Making




B
R
Newell






D
R
Shanks




10.1037/0278-7393.29.1.53








Journal of Experimental Psychology: Learning Memory and Cognition




29


1
















Compulsory averaging of crowded orientation signals in human vision




L
Parkes






J
Lund






A
Angelucci






J
A
Solomon






M
Morgan








Nature neuroscience




4


7
















Feeling the future: The emotional oracle effect




M
T
Pham






L
Lee






A
T
Stephen




https://psycnet.apa.org/doi/10.1086/663823








Journal of Consumer Research




39


3
















A Magnitude Code Common to Numerosities and Number Symbols in Human Intraparietal Cortex




M
Piazza






P
Pinel






D
Bihan






Le






S
Dehaene








Neuron




















10.1016/j.neuron.2006.11.022














Decision making in numeracy tasks with spatially continuous scales




R
Ratcliff






G
Mckoon




10.1016/j.cogpsych.2019.101259








Cognitive Psychology




116


101259














When more is less: Extraction of summary statistics benefits from larger sets




N
Robitaille






I
M
Harris








Journal of Vision




11


12


















10.1167/11.12.18














Multialternative decision field theory: A dynamic connectionst model of decision making




R
M
Roe






J
R
Busemeyer






J
T
Townsend








Psychological review




108


2


370














Pitting intuitive and analytical thinking against each other: The case of transitivity




Z
Rusou






D
Zakay






M
Usher








Psychonomic bulletin & review




20


3
















Visual discrimination of orientation statistics in crowded and uncrowded arrays




J
A
Solomon








Journal of Vision




10


14
















Selective overweighting of larger magnitudes during noisy numerical comparison




B
Spitzer






L
Waschke






C
Summerfield








Nature Human Behaviour




1


8
















A decision-by-sampling account of decision under risk. The probabilistic mind: Prospects for Bayesian cognitive science




N
Stewart






K
Simpson




















Building bridges between perceptual and economic decision-making: Neural and computational mechanisms




C
Summerfield






K
Tsetsos




10.3389/fnins.2012.00070








Frontiers in Neuroscience




6
















Decision field theory: A dynamic -congitive approach to decision making in an uncertain enviroment




J
T
Townsend






J
; M
Busemeyer






J
L
Mcclelland










Psychological Review




100


3










Psychological Review










10.1037/0033-295X.111.3.757














The impact of the mode of thought in complex decisions: Intuitive decisions are better




M
Usher






Z
Russo






M
Weyers






R
Brauner






D
Zakay








Frontiers in psychology




2


37














Robust sampling of decision information during perceptual choice




H
Vandormael






S
Herce






J
Balaguer






V
Li






C
Summerfield




















10.1073/pnas.1613950114














Elucidating the differential impact of extreme-outcomes in perceptual and preferential choice




Y
Vanunu






M
Hotaling






R
Newell








Cognitive Psychology
















Constructing Preference From Sequential Samples: The Impact of Evaluation Format on Risk Attitudes




Y
Vanunu






T
Pachur






M
Usher




10.1037/dec0000098




















T
Verguts






W
Fias




10.1162/0898929042568497




Representation of Number in Animals and Humans : A Neural Model Representation of Number in Animals and Humans : A Neural Model
















Can you perceive ensembles without perceiving individuals?: The role of statistical perception in determining whether awareness overflows access




E
J
Ward






A
Bear






B
J
Scholl








Cognition




152


















10.1016/j.cognition.2016.01.010














Risk attitude and preference




Elke
U
Weber








Wiley Interdisciplinary Reviews: Cognitive Science




1


1
















Thinking too much: introspection can reduce the quality of preferences and decisions




T
D
Wilson






J
W
Schooler








Journal of personality and social psychology




60


2


181














Metacognition in human decision-making: Confidence and error monitoring




N
Yeung






C
Summerfield




10.1098/rstb.2011.0416








Philosophical Transactions of the Royal Society B: Biological Sciences




367
















Rapid decisions from experience




M
D
Zeigenfuse






T
J
Pleskac






T
Liu








Cognition




131


2

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]