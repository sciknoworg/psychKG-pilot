You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Economies are driven by consumer purchasing behaviour and purchasing behaviour is, fundamentally, a decision process. The evolution of offered products and services is driven by consumer demand and marketplaces contain increasingly more complex arrays of information. With more information, consumers require more deliberation time to make informed choices. However, time to decide is finite, and decisions are made under time constraints that vary from one context to another. For example, a choice between multiple alternatives each defined by multiple features, or attributes, requires more time, on average, than a choice between two items each defined by a single feature. To take a real-world example, choosing between multiple insurance policies each with numerous policy inclusions and exclusions requires more time than a choice between a pair of chocolate bars.
Behavioural economics and consumer decision research has acknowledged the importance of decision time and its impact on preferential choice. For example, time pressure can alter decision strategies such that consumers base their choice on a salient product attribute such as brand name 
(Liu, Hsieh, Lo, & Hwang, 2017;
Nowlis, 1995)
, induce the use of pricequality heuristics where high price is assumed to indicate higher quality products 
(Suri & Monroe, 2003)
, or lead one to consider unique attributes and ignore common attributes when choosing between a set of options 
(Dhar & Nowlis, 1999)
. Restricting decision time may also enhance the perceived value of a product and strengthen purchase intention 
(Krishnan, Dutta, & Jha, 2013)
. For example, when presented with advertisements for DVD players with exaggerated advertised reference pricing (i.e., inflated retail prices presented in conjunction with the current discounted price) and plausible advertised reference prices, 
Krishnan et al.
 found that respondents, unsurprisingly, reported greater value for products with exaggerated reference prices compared to plausible reference prices. However, when considering the same offers under time pressure, the perceived value of exaggerated reference prices increased significantly compared to the same offers considered without time pressure, whereas the value of a plausible reference price remained stable whether evaluating the offers with or without time pressure. Respondents were also more likely to consider purchasing a product from an advertiser with exaggerated reference prices when evaluating offers under time pressure than considering the same offers free from time pressure. In related work, imposing time pressure in the form of stock quantity limits ("stock-out threats") and time-limited price promotions encouraged consumers to rely on simple, non-compensatory decision strategies; participants based their choices on fewer attributes within a set of options for consumer products like digital cameras 
(Godinho, Prada, & Garrido, 2016)
. These results suggest time pressure impacts the signal of value respondents use to inform their decisions. That is, at least in some instances, time pressure appears to qualitatively change the way information is being processed.


Psychological Explanations of the Speed-Accuracy Tradeoff
of the most widely supported findings is the speed-accuracy trade-off (SAT; 
Heitz, 2014;
Reed, 1974;
Wickelgren, 1977)
, which states that choice accuracy increases as responses become slower. The SAT has been observed in choice contexts spanning two-choice brightness discrimination tasks (e.g., 
Ratcliff & Rouder, 1998)
, recognition memory (e.g., 
Dosher, 1976;
McElree & Dosher, 1989;
Reed, 1974)
 and lexical decisions (e.g., 
Wagenmakers, Ratcliff, Gomez, & McKoon, 2008)
, to name but a few. The SAT has even been observed across species including monkeys (e.g., 
Heitz & Schall, 2012)
, mice (e.g., 
Rinberg, Koulakov, & Gelperin, 2006)
, and even slime mould (e.g., 
Latty & Beekman, 2011)
.
The dominant psychological explanation of the SAT assumes a cognitive process of sequentially sampling information. Sequential sampling theories propose that the decision making process involves gradually sampling information or evidence from the environment in favour of competing choice options until the agent has accumulated sufficient information/evidence to be confident in their decision (i.e., reaches a threshold level of information for one of the options) and subsequently makes a choice (for reviews, see 
Donkin & Brown, 2018;
Forstmann, Ratcliff, & Wagenmakers, 2016a;
Ratcliff, Smith, Brown, & McKoon, 2016)
. Sequential sampling models thus translate observed variables (e.g., choices and response time; RT) into latent psychological variables of greater theoretical interest (e.g., processing speed, response caution, bias, and so on).
Sequential sampling models are typically composed of three key latent psychological variables. First, an evidence accumulation process that evolves over time, reflected in a quantitative model parameter known as the drift rate that is typically interpreted as the quality or strength of decision evidence. Second, the criterion or threshold at which one has sampled sufficient evidence to inform their decision, typically interpreted in terms of how cautiously people make decisions. Third, the time taken for factors that are not related to the evidence accumulation process, such as the time to perceptually encode the stimulus and instigate a motor response to communicate a choice once the decision process is complete, known as the non-decision time.
Sequential sampling models have natural mechanisms to explain the decisions people make and the time taken to make them. For instance, when choice behaviour systematically changes as a function of decision time then the model can explain those changes through at least two psychologically plausible avenues: accumulating a different quantity of information (i.e., a threshold change) or a different quality of information (i.e., a drift rate change). This capability to partition observed variables to different latent causes has been one of the primary motivating factors for the widespread use of sequential sampling models in the psychology literature (e.g., 
Forstmann et al., 2016a;
Ratcliff et al., 2016)
. In terms of the SAT, the dominant explanation is a strategic adjustment to the amount of evidence one considers prior to committing to a choice (i.e., the threshold): a lower threshold leads to faster but more error-prone responses and a higher threshold leads to more accurate but slower responses, on average (e.g., 
Dutilh et al., 2019;
Forstmann et al., 2008;
Ratcliff & Rouder, 1998;
Voss, Rothermund, & Voss, 2004)
.
Nevertheless, some research focusing on speeded perceptual decisions has found the SAT may be the outcome of adjusting both the quantity (threshold) and the quality of accumulated information (drift rate). For instance, 
Rae, Heathcote, Donkin, Averell, and Brown (2014)
 found instructions to emphasise the speed of decisions lowered the decision threshold and reduced the quality of evidence driving the decision process across domains of brightness discrimination, lexical decision, and recognition memory. In more recent work, 
Dutilh et al. (2019)
 investigated whether users of sequential sampling models could detect which component of a model had been the target of an experimental manipulation, when the users were blind to the experimental manipulations. They reported that rates of correctly identifying the experimental manipulation were considerably improved when assuming both the quantity and quality of information accumulation are modulated in manipulations of time pressure. For similar results to these studies, see also 
Evans (2021)
, 
Hawkins and Heathcote (2021)
, 
Starns, Ratcliff, and McKoon (2012)
, 
and Vandekerckhove, Tuerlinckx, and Lee (2008)
.


Sequential Sampling Models in Preferential Choices
While sequential sampling models have predominantly been used to understand 'low level' speeded decisions such as perception, lexical access and recognition memory, they have also been modified to understand the cognitive processes involved in 'high level' decisions, including value-based preferential choice. For example, the Linear Ballistic Accumulator (LBA; 
Brown & Heathcote, 2008)
 has been modified to explain choice behaviour in the presence of context effects; context effects occur when preferences for options in a fixed choice set are altered by the inclusion of additional options 
(Trueblood, Brown, & Heathcote, 2014)
. The psychologically-centred decision field theory can explain preferential choices in multi-alternative consumer choice scenarios 
(Busemeyer & Townsend, 1993;
Roe, Busemeyer, & Townsend, 2001)
. The diffusion decision model has explained value-based decisions in binary 
(Krajbich, Armel, & Rangel, 2010)
 and ternary 
(Krajbich & Rangel, 2011)
 choice scenarios, as well as simple purchasing decisions 
(Krajbich, Lu, Camerer, & Rangel, 2012)
. Analytically tractable sequential sampling models for preferential choice have also been extended to more general-purpose models of consumer-like decisions 
(Hawkins et al., 2014a
(Hawkins et al., , 2014b
Otter, Allenby, & van Zandt, 2008;
WollschlÃ¤ger & Diederich, 2012)
.
In sequential sampling models of preferential choices, the decision variable accumulated as a function of time is thought to represent the subjective value or preference for an option or options. The signal that drives preference accumulation can thus be thought of as the utility of the available choice options. Utility here is a latent construct that represents the subjective value the decision maker places on an option and its constituent features, which links to the well known random utility theory that is commonly studied in applied choice scenarios (e.g., 
Louviere, Hensher, & Swait, 2000)
. Options with greater utility, and hence greater accumulation rates, are more likely to reach threshold first and hence be chosen.
It has been repeatedly demonstrated that considering choices and RTs in sequential sampling models of preferential choices generates deeper insights into behaviour. For instance, analysing eye movements as a function of decision time generates insights into the attentional focus in multiattribute preferential choice, where ungazed attributes are discounted more heavily than gazed attributes 
(Yang & Krajbich, 2023)
. We also generate deeper insights into the behaviour of the models, and the ability to discriminate between competing models, when jointly analysing preferential choices and RTs (e.g., 
Evans, Holmes, & Trueblood, 2019;
Molloy, Galdo, Bahg, Liu, & Turner, 2019)
. For reviews of the importance of choices and RTs in preferential choice, see 
Busemeyer, Gluth, Rieskamp, and Turner (2019)
, 
Trueblood (2022)
, and 
Clithero (2018)
.


Preferential Choices Under Time Pressure
Although the importance of decision time is acknowledged, the manipulation of decision time is comparatively rare, with evidence suggesting the rate of preference accumulation may change in some cases but not others. For instance, 
Larson and Hawkins (2023)
 observed that time pressure impacted decision thresholds in a numerosity-style shopping task with no changes to utilities, and 
Gluth, Spektor, and Rieskamp (2018)
 observed that time pressure did not induce violations of independence of irrelevant alternatives. In contrast, in a probabilistic inference task 
Rieskamp and Hoffrage (2008)
 observed time pressure led to the use of a lexicographic heuristic strategy, yet when time pressure eased participants used a weighted additive representation of attribute information. In a study context effects, Pettibone (2012) observed the asymmetric dominance and compromise effects were more pronounced when given more (vs less) time to make decisions, while 
Trueblood et al. (2014)
 observed more pronounced similarity effects with greater decision time.
Our question of interest is whether experimentally manipulated time pressure impacts the latent representation of utility in preferential choices. Questions of this form have been investigated in great detail in the perceptual decision making literature, most often with experimental manipulations of the time available to process stimulus information and choose, combined with analyses based on sequential sampling models. Although theories of perceptual choices have been translated to preferential choices, the techniques of investigation haven't been broadly translated to the same level of detail. Specifically, when time pressure is manipulated in preferential choices we see inconsistent results across studies. This leaves open the possibility that decision thresholds and latent utilities change under time pressure in preferential choices, or it may be that only thresholds are adjusted. To our knowledge, the question has not been addressed in preferential choices with standard methods of manipulating time pressure, particularly for the value-based consumer-like goods we study here.
We directly tested whether time pressure affects the latent representation of utility in preferential consumer-like choices. To this end, we combined classic SAT manipulations from experimental psychology with discrete choice experiments from behavioural economics across a set of four experiments. We used two effective and well-validated manipulations of time pressure (for review of manipulations, see 
Heitz, 2014)
. In Experiments 1a and 1b we used a direct manipulation: an explicit, experimenter-imposed upper limit or deadline on the available decision time. This manipulation is exogenous in the sense that the decision maker does not have complete control over when they make a decision. In Experiments 2a and 2b we used an indirect manipulation: verbal instructions or cues to make fast or careful decisions. This manipulation is endogenous in the sense that the decision maker maintains complete control over when they make a decision.
Across the four experiments we also investigated two choice contexts to enhance the generality of our findings. In Experiments 1a and 2a we study preferences for features of residential pizza delivery, including the cost, wait time, and additional inclusions. In Experiments 1b and 2b we study preferences for features of mobile phones, including ongoing cost, camera quality, storage capacity, and battery capability. These contexts were chosen to represent frequent or 'low stakes' purchases (pizza delivery) and infrequent or 'high stakes' purchases (mobile phones). We also manipulated across the two contexts the complexity of the composition of the preferential options. We used quantitative model comparison to contrast two theoretical explanations across the set of four experiments, through the lens of sequential sampling models of preferential choice. The first theory states that decision makers adapt to time pressure by solely adapting their level of caution (decision threshold). The second theory states that decision makers adapt to time pressure by adapting their level of caution and the subjective value they place on the options under consideration (utility).


Experiment 1a: Deadline-Based Speed-Accuracy Tradeoff -Choice Context 1


Method Participants
Forty-five undergraduate psychology students from the University of Newcastle participated in exchange for course credit. This experiment and all subsequent experiments were approved by the University of Newcastle Human Research Ethics Committee.


Materials
Discrete Choice Experiment (DCE) Stimulus. DCEs are a quantitative tool used to capture consumer preferences for products or services 
(Mangham, Hanson, & McPake, 2009)
. Participants were asked to repeatedly choose their most-preferred option from a selection of three pizza delivery options, where the set of available pizza options (the choice set) differed on each trial; 
Figure 1
 shows an example trial. Each pizza option was defined by three attributes: Price, Delivery time and Sides. Each attribute could take on one of three levels (Price: $19.95, $23.95, $27.95; Delivery time: 15 minutes, 30 minutes, 45 minutes; Sides: No sides, Garlic bread or drink, Garlic bread and drink). The attributes and levels used in the DCE were derived from an informal survey of Australian pizza chains. The three options presented in each choice set were generated by randomly sampling a level for each attribute, resulting in 3 3 = 27 unique pizza delivery options. This process means that an attribute could contain a different level in each option (e.g., Price and Sides in 
Figure 1
) or have levels in common across two or more options (Delivery time in 
Figure 1
). To prevent order effects, we randomised the order in which the three attributes were presented to each participant. That is, Price, Delivery time or Sides could appear in the second, third or fourth row of the DCE stimulus (cf. 
Figure 1)
. Importantly, the attribute presentation order was fixed from one trial to the next (i.e., it was not randomised within participants). The DCE was written in JavaScript and ran through a web browser.
Participants made decisions under three levels of time pressure; high (five second), moderate (ten second) or low (twenty second) response deadlines ('time-outs'). The deadline times were derived from pilot testing and a previous study with similar DCE stimuli 
(Hawkins et al., 2014a)
. The response deadline for each trial was displayed as a countdown timer above the DCE stimulus with the text "You have X seconds remaining", where X corresponds to the randomly sampled deadline for the trial. The text was shown in black except for the numeric countdown value which was shown in red, bold point font to emphasise the time limit.


Procedure
Participants completed the study in a testing laboratory on campus. Task instructions were shown on a computer screen, which stated that they would see sets of pizza delivery options and would be asked to select their most preferred option from each choice set. Participants were also informed that they would sometimes be asked to make fast decisions, and sometimes careful decisions. Participants completed a total of 250 decisions, split into 10 blocks of 25 trials with self-paced breaks between blocks.
DCE trials commenced with a black fixation cross that was centred horizontally and vertically in the display. The fixation cross remained on screen for a duration that was randomly sampled from a shifted and truncated exponential distribution (minimum 1s, maximum 4s, mean 1.5s), which ensured that participants could not precisely predict the stimulus onset time and make premature choices. The fixation cross was then removed and a pizza delivery choice set presented, horizontally and vertically centred in the display. At stimulus onset the timer displayed the randomly sampled deadline time for the trial (i.e., 5s, 10s, or 20s) and was dynamically updated with 1s decrements until a response was made or the timer reached 0s, both of which terminated the trial. Participants reported their decision by mouse click on a "This one" button below their desired pizza option (see 
Figure 1)
. We recorded the chosen pizza delivery option and the time taken to respond on each trial, where the RT indicated the time from stimulus onset until the participant pressed a "this one" button. Once a choice was made, the pizza delivery stimulus was removed from the screen and a blank display presented for .5s, after which the black fixation cross for the next trial was shown.
Decisions that were too slow were defined as those where the participant failed to provide a response before the countdown timer reached 0s. On those trials, the participant received a 'too slow' message, was encouraged to make faster choices, and could continue to the next trial after a 2s time-out. If the participant made a very fast (<1s) choice they were presented with a warning (displayed for 2s) instructing them to make sure they read all option information before making their selection. Participants were instructed to take a short break between each block before continuing. Once the DCE was completed, participants completed a pen-and-paper version of a brief questionnaire; the questionnaire is not pertinent to our hypotheses and therefore is not discussed further. Total participation time was approximately 45-55 minutes.


Cognitive Modelling
Model Description. Our primary aim was to test whether the utilities that drive preference accumulation are sensitive to the time available to make preferential choices. To this end, we analysed the data with a sequential sampling model that predicts choices and RTs. We used the Racing Diffusion Model (RDM), an exemplar of the class of sequential sampling theories that explain cognitive processes driving observed choices and RTs 
(Tillman, Van Zandt, & Logan, 2020)
; for review, see 
Forstmann, Ratcliff, and Wagenmakers (2016b)
; 
Ratcliff et al. (2016)
. The RDM can explain choices and the time taken to make them in DCEs with two or more mutually exclusive options (i.e., nominal, unordered outcome variable). The RDM represents discrete options with separate nodes, typically referred to as accumulators, with a latent tally of the evidence or preference strength for each option in the choice set. The preference strength is dynamically accumulated until one accumulator crosses a pre-specified threshold, which triggers a choice. The accumulation processes themselves are driven by the utility (preference strength) of the options, where options with higher utility are chosen more often than options with lower utility, on average. As with all sequential sampling models, the RDM provides a good explanation of choice and RT trends observed in SAT manipulations (e.g., 
Tillman et al., 2020)
.
We made standard and simple assumptions to learn the subjective value of the product attributes in individual participant choices. First, we assumed the utility of an option is an additive function of the utility of the attribute levels that comprise the option (i.e., sum of the attribute-level utilities). Second, attribute-level utilities of an option are a linear function of the option's attribute levels. For example, the price-related utility of an option that costs $23.95 is obtained by multiplying the numerical value of the price attribute (23.95) by the utility coefficient for the price attribute, which is estimated from data. For estimation, we transformed the sides attribute to numerical values of 0 (no sides), 1 (drink OR garlic bread), or 2 sides (drink and garlic bread). Finally, we mean-centred the numeric values of each attribute for estimation (i.e., levels 0, 1, 2 of the sides attribute were transformed to -1, 0, 1). Since the utility for an option exists on the real line while drift rates in sequential sampling models are restricted to the positives, we calculated the drift rate for each option by taking the exponent of the utility for the option, following convention 
(Colonius & Marley, 2015;
Hawkins et al., 2014a
Hawkins et al., , 2014b
Jones, Hawkins, & Brown, 2015)
.
To test if latent utilities differ as a function of time pressure (deadline conditions), we used quantitative model comparison techniques to investigate the necessity of separate utility coefficients for each attribute for each deadline condition. In the saturated model we estimated three utility coefficients for the cost attribute -one each for the 5s, 10s and 20s deadline conditions -and similarly for the delivery time and sides attributes, for a total of nine utility coefficients; we refer to this model as '5,10,20'. We also estimated two simpler models, each with six utility coefficients, to assess if participants psychologically 'grouped' adjacent response deadlines and made decisions as if (or approximately as if) they were a single response deadline. The first of these models combined the fastest two deadlines such that there were 3 utility coefficients to describe choices in the 5s and 10s deadline conditions, one coefficient for each attribute, and a separate set of 3 utility coefficients for the 20s deadline; we refer to this model as '5/10,20'. The second of these models assumed the reverse grouping: one set of 3 utility coefficients for the 5s deadline and a separate set of 3 utility coefficients for the 10s and 20s deadline conditions; we refer to this model as '5,10/20'. We also tested the most parsimonious model, the 'null' model, that contained just 3 utility coefficients (one for each attribute). The 'null' model assumed that utility for each attribute does not differ between deadline conditions.
Consistent with a long history of findings in the SAT literature (for reviews, see 
Dutilh et al., 2019;
Forstmann et al., 2016b;
Heitz, 2014;
Ratcliff et al., 2016)
, in all four models we assumed the time pressure manipulation affected response caution. As such, we estimated a separate response threshold parameter for each of the three deadline conditions. Given the long time-scale of RTs relative to most applications of sequential sampling models in the speeded decision literature, we made the simplifying assumption that the time to encode the stimulus and to produce a motor response did not vary between deadline conditions; we estimated a single non-decision time parameter. Finally, the moment-to-moment diffusive variability of the accumulation process was fixed to 1 for all accumulators as a scaling parameter of the model. Taken together, the number of freely estimated parameters for the four models were 13 (5,10,20), 10 (5/10,20 and 5,10/20), and 7 (Null).
We included a contaminant process in the RDM likelihood to account for lapses of attention, which may occur both on trials where participants responded in time or failed to respond. This results in a mixture likelihood in which we assumed 95% of choices were generated from the RDM and 5% of choices were generated from a contaminant process. The contaminant generating process assumed RTs were randomly sampled from a uniform distribution with minimum 0s and maximum 20s and choices were randomly sampled from the set of available options. Contaminant mixture processes of this form are standard in the sequential sampling literature (see 
Ratcliff & Tuerlinckx, 2002)
 and limit the undue influence that outlying RTs may have on parameter estimates.
Model Estimation. All models were estimated in a hierarchical Bayesian framework to simultaneously capture group-level trends and individual differences, using the Particle Metropolis within Gibbs algorithm (PMwG; 
Gunawan, Hawkins, Tran, Kohn, & Brown, 2020)
. Utility coefficients were estimated on the real line and response thresholds and non-decision times were log transformed for estimation to ensure positivity. The prior distribution for the group-level parameters was multivariate normal with mean vector set to 0 for all elements, except the threshold parameters with mean set to 2, and covariance matrix set to 1 for the diagonal elements and 0 for the off-diagonal elements. The grouplevel covariance matrix was specified as the marginally non-informative prior distribution of 
Huang and Wand (2013)
. For motivation and discussion of the form of these prior distributions, see 
Gunawan et al. (2020)
 and 
Cooper et al. (2020)
.
Parameter estimation with PMwG includes three stages (for details, see 
Cooper et al., 2020)
. The initial 'burn-in' stage had 100 particles run for 1500 iterations. The adaptation stage used 100 particles run for 5000 iterations and the sampling stage used 25 particles run for 10000 iterations. Posterior inference was based on the 10000 samples from the sampling stage.
We used the Deviance Information Criterion (DIC; 
Spiegelhalter, Best, Carlin, & van der Linde, 2002)
 to select the most parsimonious utility parameterisation between the four models. DIC is a quantitative model comparison metric to compare models estimated in a Bayesian framework. It accounts for model flexibility in terms of the number of parameters and the way those parameters interact with each other (parametric and functional form complexity, respectively). The model with the lowest DIC is considered to provide the most parsimonious explanation of the data. Data and analysis code for all four experiments are available at https://osf.io/54gzy/.


Results
Prior to analysis, we removed 25 (0.2%) responses deemed too fast for the DCE stimulus (<1s). For an additional 226 trials (2% of the data set) a decision was not made prior to the trial deadline (i.e., trials where the participant failed to respond); 223 of these trials were from the 5s deadline condition and the remaining 3 were from the 10s deadline condition. We incorporated these missed trials into the modelling analysis under the assumption that a participant was in the process of making a decision in the same manner as trials where they responded prior to the deadline, however they didn't reach threshold (and hence make a response) prior to the trial timeout. The response model for these failed-response trials was the tail probability of the RDM (i.e., the probability that no accumulator crossed threshold prior to the deadline). 
Figure 2
 shows choices were faster, on average, in the presence of the 5s deadline compared to the 10s deadline, which in turn were faster than choices under the 20s deadline. A manipulation check confirmed that the deadline manipulation induced time pressure. A one-way repeated measures Bayesian ANOVA indicated decisive evidence for a main effect of deadlines on mean RT (BF > 1000). Participants made the fastest decisions when they were under the strongest time pressure (5s deadline; M = 2.98s, SD = 0.35) compared to moderate time pressure (10s deadline; M = 3.77s, SD = 0.69), and made the slowest decisions under the weakest level of time pressure (20s deadline; M = 4.34s, SD = 1.01); there was strong evidence that mean RT differed across all pairwise comparisons, all BF s > 1000. This finding indicates that participants adaptively modulated their decision speeds in response to the time pressure imposed by different deadlines. 
Table 1
 shows the outcome of the DIC-based model comparison for the set of 4 models. DICs are 'zero-referenced' so the model with the most parsimonious explanation of the data has a DIC of 0. DICs for the remaining models are shown as deviations from the DIC-best model (i.e., âˆ†DIC) where a positive value indicates a poorer explanation of the data than the DIC-best model, and the magnitude of the âˆ†DIC indicates how much poorer that explanation is; DIC differences greater than 10 units are generally considered strong evidence for the lower-DIC model 
(Pratte, Rouder, & Morey, 2010)
.


Modelling Outcomes
The DIC-preferred model required just one set of utility coefficients (i.e., the null model) to explain behaviour across the three deadline conditions. This suggests there was stability in the utilities (preference strengths) governing the choices and RTs across all studied levels of time pressure.
Descriptive Adequacy. 
Figures 2 and 3
 show model goodness of fit to RT and choice data by comparing group-averaged empirical data alongside group-averaged posterior predictive data from the DIC-preferred null model. For RTs, we calculated key statistics of the RT distribution: the .1 quantile representing the fastest responses, the so-called 'leading  
(Table 1)
 are shown in blue dots (posterior mean) and bars representing uncertainty (95% credible interval). The vertically aligned dots for each deadline represent, from lowest to highest, the .1, .5 (i.e., median), and .9 quantiles of the response time distribution. All data and model values were computed for individual participants and quantile averaged across participants for visualisation. edge' of the distribution, the .5 quantile as a measure of central tendency (median), and the .9 quantile representing the slowest responses, or the 'tail' of the distribution. This was performed separately for each deadline and participant, and we then averaged these quantiles across participants (i.e., quantile averaging; 
Gilchrist, 2000)
. We followed the same procedure for the posterior predictive data independently for each posterior predictive sample and visualise this with the posterior predicted mean for each of the .1, .5 and .9 quantiles (dots), and bars to represent uncertainty in the model's predictions. 
Figure 2 (left)
 shows the model captures the main trends in data. This includes the finding that responses were faster when placed under stronger time pressure, and there appeared to be a smooth transition through to slower responses across the 5s, 10s and 20s deadlines. In data, on average decisions under 5s deadlines were 21% faster than decisions under 10s deadlines, and 31% faster than 20s deadlines. The model quantitatively captured this trend: predicting 22% and 32% speed-ups, on average, respectively. The observed speeding from the 20s deadline to the 10s deadline in data was smaller, though non negligible, at 13%, which the model also predicted to be 13% faster. The data also show evidence of the standard finding from the perceptual decision literature that higher time pressure reduces the positive skew of the RT distribution compared to lower time pressure; positive skew is indicated by a larger difference between the .9 and .5 quantiles than between the .5 and .1 quantiles. The model closely captured these trends in data.
We assessed choice agreement between data and model for individual options. Recall that this experimental design had three attributes, each with three levels, and therefore 3 3 = 27 unique options. We calculated the proportion of times each of these 27 unique options was chosen in data, separately for each deadline, and compared these values to the same quantities as predicted by the model, shown in 
Figure 3
. 
Figure 3
 shows the model provides a good explanation of the observed choices. For all deadlines, the model frequently chose the options participants preferred (rightmost dots in each panel), and rarely chose the options participants disliked (leftmost dots). As an example, consider the upper left panel in 
Figure 3
. The most preferred option in data (rightmost dot) was the cheapest ($19.95) with the fastest delivery time (15 minutes) and included 2 sides -this is, objectively, the best option in the set of 27 options. The model also chose this option the most (uppermost dot). In contrast, the least preferred option in data (leftmost dot) was the most expensive ($27.95) with the slowest delivery time ($45) and had no sides -again, this is objectively the worst option in the set of 27 options. The model chose this option the least (lowermost dot).
Analyses of choice data underscore three important outcomes. First, participants were sensitive to option quality: they selected cheaper options over expensive options, faster over slower delivery times, and more over fewer included side dishes. Second, the pattern of agreement between data and model in choice orderings was generally consistent across all 27 unique options and 3 deadlines. This is captured with Kendall's rank order correlation coefficient of Ï„ = .90âˆ’.92, showing the model agreed strongly with the preferences observed in data. Although we focus on capturing the ordering of choice preferences throughout, we note that 
Figure 3
 shows the model has a tendency to quantitatively overestimate how frequently the least preferred options are chosen, and underestimate how frequently the most preferred options are chosen. Nevertheless, overall the model provides a reasonable descriptive account of the data, particularly in light of its parametric simplicity. Third, choice  
Figure 3
 . Choice proportions as a function of deadline (rows) in Experiments 1a and 1b (columns). In each panel, the x-axis shows choice proportions observed in data and the yaxis shows choice proportions predicted by the DIC-preferred model 
(Table 1)
, where dots represent the posterior mean and the bars represent uncertainty (95% credible interval). Each dot represents a unique option in the experimental design. Inset values in each panel shows Kendall's Ï„ rank order correlation between observed and predicted choice proportions (posterior mean and 95% credible interval).
outcomes didn't substantively change across the three deadlines despite strong evidence the time taken to make those choices differed.


Psychological Interpretation
The DIC-preferred model had just one set of utility coefficients for all time pressure conditions. The direction of the estimated utility coefficients for both models was as expected. Utilities were negative for cost (M = -0.063, 95% CI [-0.072, -0.054]) and delivery time (M = -0.011, 95% CI [-0.013, -0.009]), indicating participants placed greater value on cheaper options and shorter delivery times. The utility coefficient for the sides attribute was positive (M = 0.306, 95% CI [0.263, 0.350), indicating participants preferred options with more sides than options with fewer sides. These model-based conclusions reflect the patterns in choice data described above.
Differences in decision thresholds of the RDM appear to explain the pattern of observed choices and RTs across deadline conditions. The threshold estimates followed the expected ordering: the 5s deadline condition had the lowest average threshold (M = 1.62, 95% CI [1.58, 1.67]) followed by the 10s deadline (M = 1.76, 95% CI [1.71, 1.81]) and the 20s deadline (M = 1.82, 95% CI [1.76, 1.89]).
We tested whether decision thresholds reliably differed as a function of deadline by subtracting the group-level posterior distribution of the decision threshold for one deadline condition from the group-level posterior distribution of the decision threshold for another deadline condition, and then summarise the posterior distribution of the difference with a mean and 95% credible interval (CI). We infer a difference in thresholds as a function of time pressure when the 95% CI of the difference distribution excludes 0. Thresholds in the 5s deadline were reliably lower than in the 10s deadline (difference distribution: M = 0.14, 95% CI [0.08, 0.19]) and in the 20s deadline (M = 0.20, 95% CI [0.13, 0.27]). Thresholds in the 10s deadline were also reliably lower than in the 20s deadline (M = 0.06, 95% CI [0.02, 0.11]). Taken together, this suggests participants adapted to the response deadlines by adjusting their level of caution, where more lenient deadlines led to more cautious decisions.


Discussion
We used decision deadlines to assess the impact of explicit time pressure on latent utilities in multi-attribute preferential choices. Our analysis based on a dynamic model of preference accumulation, which considers choices and RTs, indicated latent utilities for the attributes of preferential stimuli did not vary as a function of time pressure. Rather, we found support for a psychological explanation where people adapted their level of caution as a function of time pressure. Participants increased their decision thresholds as time pressure eased, accumulating more information prior to committing to a choice. This is consistent with some speeded decision making research that finds people adapt to time pressure by adjusting the quantity of information they collect prior to decision, with time pressure exerting negligible impact on the quality of the information that informs decisions. Interestingly, we observed negligible changes in choice outcomes as time pressure eased even though these decisions were more cautious (i.e., made with more conservative decision thresholds, on average). This differs to the perceptual decision making literature which tends to observed strong covariation between choices and RTs, such that larger thresholds are associated with slower responses and greater accuracy. Here, we observed the former in data but not the latter. It may be that the 5s deadline was sufficiently long for participants to make decisions consistent with their latent preference states. So, even though the longer deadlines permitted more time for decisions, and participants appeared to use this time (i.e., we observed slower responses), they may not have needed this time (i.e., choice outcomes didn't differ as a function of deadline). If this interpretation is supported, it suggests that the same set of deadlines imposed on a more complex multi-attribute stimulus structure ought to lead to differences in choice outcomes under the strongest time pressure.
In Experiment 1b we aimed to replicate the core result and generalise it to another consumer-like choice context -a different category of preferential stimuli with a more complex attribute structure.


Experiment 1b: Deadline-Based Speed-Accuracy Tradeoff -Choice Context 2 Method
All methodological details were as described in Experiment 1a unless noted otherwise.


Participants
A different sample of 50 undergraduate psychology students from the University of Newcastle participated in exchange for course credit. Materials DCE stimulus. The DCE structure for Experiment 1b was the same as Experiment 1a except it contained attributes and levels describing mobile (cell) phones. As in Experiment 1a, the set of three mobile phone options (i.e., choice set) differed on each trial; an example trial is shown in 
Figure 4
. Each mobile phone option was defined by four attributes and each attribute could take on one of three levels: Cost per month (30, 45, 60 $AU), Battery life (10, 16, 24 hours of talk time), Camera resolution (8, 12, 16 megapixels, MP) and Memory capacity (16, 32, 64 gigabytes, GB). The attributes and levels were derived from an informal survey of prominent Australian consumer hifi retailers in the Summer of 2018 to determine the most widely advertised attributes and the most common 'levels' of those attributes. As in Experiment 1a, the value of each attribute for each option was randomly sampled from the possible levels for that attribute. This process resulted in 3 4 = 81 unique mobile phones/options in the DCE -a threefold increase in complexity of the option set relative to Experiment 1a.
Procedure. The procedure was as described in Experiment 1a except that participants completed a total of 200 decisions, split into 10 blocks of 20 trials with self-paced breaks between blocks. Total participation time was approximately 45-55 minutes.


Cognitive Modelling
We followed the same analysis procedure as outlined in Experiment 1a and estimated 4 RDMs with the same utility groupings across the 3 deadline conditions. The primary difference in Experiment 1b is that the mobile phone stimuli were defined by 4 attributes with a corresponding set of 4 utility parameters. This means each model contained 3 decision thresholds and 1 non-decision time parameter combined with 4 utilities (null model; total of 8 parameters), 4Ã—2 utilities (5,10/20 and 5/10,20 models; 12 parameters), or 4Ã—3 utilities (5,10,20 model; 16 parameters).


Results
Prior to analysis, we removed 20 (0.2%) responses deemed too fast (<1s). An additional 354 (3%) observed no response prior to the deadline; 339 of these trials were from the 5s deadline condition, 13 from the 10s deadline, 2 in the 20s deadline. These failed-to-respond trials were modelled in the same way as Experiment 1a. 
Figure 2
 shows responses were again faster in the 5s deadline condition than the 10s and 20s deadline conditions. The decision deadlines again had their intended effect on mean RT (BF > 1000). Participants made faster decisions, on average, when they were under the strongest time pressure (5s deadline; M = 3.43s, SD = 0.48) compared to moderate time pressure (10s deadline; M = 4.38s, SD = 0.95) and were the slowest under weakest time pressure (20s deadline; M = 5.20s, SD = 1.58). There was strong evidence that mean RT differed across all pairwise comparisons, all BF s > 1000. Taken together, these results replicate the RT observations from Experiment 1a: the deadline manipulation effectively modulated the time participants spent making their decisions.


Modelling Outcomes
DIC-based model comparison 
(Table 1)
 led to a different outcome than Experiment 1a with a preference for a model that required 6 utility coefficients. This model assumed one set of utilities for the 5s and 10s deadlines, and an independent set of utilities for the 20s deadline (i.e., model 5/10,20).
Descriptive Adequacy. 
Figures 2 and 3
 show the DIC-preferred model provided a good description of the RT and choice data in Experiment 1b. For RT, the model captured the trend of slower responses for longer deadlines. It also generally captured the impressive range in observed RTs across quantiles and deadlines, spanning a little over 2s (.1 quantile, 5s deadline) through to almost 8s (.9 quantile, 20s deadline). The model underpredicted the range of some of these statistics, shifted a little faster overall than observed data, though predicted the central tendency of observed responses quite closely. On average, observed decisions under 5s deadlines were 25% faster than 10s deadlines and 37% faster than 20s deadlines, while decisions under 10s deadlines were 16% faster than under 20s deadlines. The model captured these trends in decision speeding across deadlines quite well: 22%, 32%, and 13%, respectively.
We again assessed choice agreement between data and model for individual options. One aim in Experiment 1b was to investigate the impact of increased complexity of the option set on choice outcomes, with 3 4 = 81 unique options -a threefold increase in complexity of the option set compared to Experiment 1a. Even with this increased complexity, the model still tended to choose the options that participants also preferred, and didn't choose the options participants disliked. For example, in the upper right panel of 
Figure 3
, the most preferred option in data (rightmost) and model (uppermost) was the phone that was cheapest ($30/month) with the best available camera resolution (16MP), memory capacity (64GB) and battery life (24 hours talk time) -objectively, this is the best option in the set of 81 options. Similarly, the least preferred option in data (leftmost) and model (lowermost) was the phone that was most expensive ($60/month) with the worst features (8MP camera, 16GB memory, 10 battery). This again shows the participants were sensitive to the quality of the options, despite the increased complexity of the set, and the model captured these general trends. That is, participants tended to prefer options that were cheaper, with better cameras, greater memory capacity, and longer battery life.
To investigate whether the increased complexity of the option set impacted choice outcomes, we tested how faithfully the model could identify the observed ordering of preferences for the 81 options across the deadline conditions. The motivating principle of this analysis is that, if the time pressure manipulation does impose a speed-accuracy tradeoff, then choices under faster deadlines will be less predictable (i.e., closer to chance) than choices made under slower deadlines. The relevant statistic is the Kendall's tau correlation coefficient, shown in 
Figure 3
 for each deadline. Notably, in Experiment 1b there was a global decrease in predictably compared to Experiment 1a (i.e., all rank order correlation coefficients were lower), suggesting the increased complexity of the option set led to more randomness in choices. Specific to Experiment 1b, choices were less predictable under 5s deadlines compared to 20s deadlines (posterior difference in Kendall's Ï„ coefficients between conditions, M dif f Ï„ = .07, 95% credible interval [.02, .13]), and there was marginal evidence of the same result between 5s and 10s deadlines (M dif f Ï„ = .06, 
[0, .12]
). The predictability of choices was similar between the 10s and 20s deadlines (M dif f Ï„ = .01, 
[-.04, .07]
). This result suggests the increased complexity of the option set combined with the same deadlines as Experiment 1a led to a speed-accuracy tradeoff, at least when comparing the fastest deadline to the two slower deadlines -faster decisions were less accurate. 
Table 2
 shows the estimated utility coefficients for each attribute separated by the time pressure groupings of the DIC-preferred model. As in Experiment 1a, the sign of the utility coefficients were as expected: cost utilities were negative and utilities for the battery life, camera resolution and memory capacity were positive. Utilities were very similar, on average, between the higher time pressure (5/10) and low time pressure (20) deadlines. We tested whether the group-level mean of the utility coefficients differed between the two time pressure groupings, by assessing the posterior of the difference distribution; this is the same technique as applied to the decision threshold parameters in Experiment 1a. For all 4 attributes, the difference distribution was centred at 0, indicating no mean difference in utilities as a function of time pressure.


Psychological Interpretation
As in Experiment 1a, decision thresholds appear to explain the patterns of behaviour across levels of time pressure. Thresholds were, on average, lowest when placed under the strongest time pressure (5s deadline; M = 1.66, 95% CI [1.61, 1.71]) followed by the 10s deadline (M = 1.85, 95% CI [1.79, 1.91]) and the 20s deadline (M = 1.93, 95% CI [1.86, 2.01]). Thresholds in the 5s deadline were reliably lower than in the 10s deadline (M = 0.19, 95% CI [0.13, 0.24]) and the 20s deadline (M = 0.27, 95% CI [0.20, 0.35]), and thresholds in the 10s deadline were lower than in the 20s deadline (M = 0.09, 95% CI [0.03, 0.14]). 


Discussion
The findings of Experiment 1b generalise those of Experiment 1a to a context with a new preferential stimulus and increased attribute complexity. We again found that subjective valuations of preferential stimuli (i.e., latent utilities) do not vary as a function of time pressure -at least when evaluated by posterior inference. The DIC result (i.e., not favouring the null model) is not unexpected given DIC has a tendency to favour more complex models. Furthermore, since DIC evaluates the collection of individual participant likelihoods and parameter estimates, it may pick-up idiosyncratic individual differences that contribute to a better posterior likelihood but do not impact overall trends at the group level, which is particularly likely in the context of preferential decisions. From this perspective, we consider the weight of evidence within Experiment 1b and when combined with Experiment 1a: posterior inference indicates the group mean utility coefficients were highly similar between deadlines. Experiments 1a and 1b converge to a common conclusion in preferential choices: time pressure affects decision caution but not subjective valuation.
Thus far we have demonstrated our primary finding for just one type of time pressure: explicit deadlines. Deadlines are highly effective in manipulating the SAT 
(Ratcliff & Rouder, 2000;
Van Zandt, Colonius, & Proctor, 2000)
. Despite their efficacy, deadlines are exogenous in the sense that they are externally imposed. This has the effect of shifting the control of an agent's strategic decision about their level of caution to the experimenter, at least partially 
(Heitz, 2014)
. This heavy-handed SAT manipulation is very likely to induce time pressure effects on decision speed, as demonstrated in Experiments 1a and 1b.
While deadlines exist in everyday life, we also encounter many other forms of time pressure that are milder in nature and allow an agent to maintain control of their decision criterion. A primary example is verbal instructions, such as a cue to respond speedily or cautiously. Instructions of this form induce an internally-driven sense of time pressure that allows the agent to control their level of caution 
(Heitz, 2014)
. While every day decisions may not take place under 'verbal instructions' of this form, almost all daily decisions occur in a context where time is of some necessity, resulting in an internally-driven desire to monitor the passage of time. To this end, verbal instructions of this form have been very widely used to understand the SAT in other contexts, such as perceptual decisions, resulting in strong consensus that they modulate decision thresholds (e.g., 
Dutilh et al., 2019;
Forstmann et al., 2008;
Ratcliff & Rouder, 1998;
Ratcliff, Thapar, & McKoon, 2006;
Voss et al., 2004)
. Verbal instructions have also induced changes in drift rates, at least in some contexts (e.g., 
Dutilh et al., 2019;
Evans, 2021;
Hawkins & Heathcote, 2021;
Rae et al., 2014;
Starns et al., 2012;
Vandekerckhove et al., 2008)
.
In Experiments 2a and 2b, we test whether our findings about utility coefficients from an externally-imposed manipulation of time pressure generalise to an internally-driven manipulation of time pressure. We do so by testing the stimulus materials of Experiments 1a and 1b with a manipulation of time pressure based on verbal instructions. Given the similarities between the previous experiments and Experiments 2a and 2b, for a more concise presentation we group 2a and 2b into a single experiment description, noting that they were independently conducted studies.


Experiment 2a: Instruction-Based Speed-Accuracy Tradeoff -Choice
Contexts 1 & 2


Method
All methodological details were as described in Experiments 1a and 1b unless noted otherwise.


Participants
Separate samples of undergraduate psychology students from the University of Newcastle participated in exchange for course credit, with 45 participants in Experiment 2a and 51 participants in Experiment 2b.


Materials
Discrete Choice Experiment (DCE) stimulus. The DCE structure of Experiment 2a was identical to Experiment 1a, except we used verbal instructions to manipulate time pressure. Participants made decisions under time pressure (emphasising speedy decisions) or no time pressure (emphasising cautious decisions), randomised from one trial to the next. Time pressure trials were cued with verbal (printed) instructions to 'BE FAST!!' displayed in green, upper case text, horizontally and vertically centered, for 1 second prior to the fixation cross. Trials without time pressure were cued in the same way, except with the words 'BE CAREFUL!!' displayed in red, upper case text. To ensure that participants did not forget the time pressure instruction for the current trial (BE FAST / BE CAREFUL), the cue remained on screen throughout each trial, at the top of the screen in its respective color.
The DCE structure of Experiment 2b was identical to Experiment 1b with the exception that we manipulated time pressure with verbal instructions, as described for Experiment 2a.


Procedure
The trial timeline of Experiment 2a was as described in Experiment 1a, except for the use of verbal instructions to manipulate time pressure. Without deadlines terminating the trial, all choices were shown for a maximum of 40 seconds unless terminated earlier by a response. Experiment 2b was identical except participants completed a total of 150 decisions, split into 6 blocks of 25 trials.


Cognitive Modelling
We estimated two models in Experiments 2a and 2b: a 'Null' model and a 'SAT' model. The 'SAT' model had a utility coefficient for each attribute in each of the two time pressure conditions, for a total of 6 utility coefficients in Experiment 2a and 8 utility coefficients in Experiment 2b. The 'Null' model had a single set of utility coefficients for a total of 3 (Experiment 2a) or 4 (Experiment 2b) utility coefficients. Both models had the same additional parameters as the previous experiments: two decision thresholds, one for each level of the time pressure manipulation, and one non-decision time.


Results
In Experiment 2a we removed 45 (0.4%) 'too fast' trials from the data set. Unlike the deadline manipulation where trials are likely to be missed or timed-out, we did not include a tail probability for failed-response trials because there were no missed responses. In Experiment 2b we removed 67 (0.6%) 'too fast' trials from the data set. There were 6 (0.06%) 'too slow' trials (no response prior to trial timeout at 40s), which we accounted for with the tail probability of the model, as in Experiments 1a and 1b. 
Figure 5
 shows participants made faster decisions when cued to be speedy than when they were cued to be accurate in Experiments 2a and 2b. There was strong evidence for a main effect of verbal instruction on mean RT in both experiments, both BF s > 1000. In Experiment 2a, participants were 17% faster, on average, when cued to make fast choices (M = 3.50, SD = 1.22) than when they were cued to make careful choices (M = 4.21s, SD = 1.46). Similarly, in Experiment 2b participants were 31% faster when cued to make fast compared to careful choices (M = 4.80, SD = 1.99 vs. M = 6.94, SD = 2.69).


Modelling Outcomes
DIC-based model comparison 
(Table 3
) preferred the null model in both Experiment 2a and 2b, the same outcome as Experiment 1a. That is, the most parsimonious explanation of the data assumed a single set of utilities across both time pressure conditions.  
(Table 3)
 are shown in blue dots (posterior mean) and bars representing uncertainty (95% credible interval). The vertically aligned dots for each deadline represent, from lowest to highest, the .1, .5 (i.e., median), and .9 quantiles of the response time distribution. All data and model values were computed for individual participants and quantile averaged across participants for visualisation. Descriptive Adequacy. 
Figures 5 and 6
 shows the DIC-preferred models explained the main trends in RT and choice data across both experiments. For RT, the model captured the general slowing trend from 'speedy' cues to 'careful' cues, which was observed across the whole RT distribution (i.e., .1, .5 and .9 quantiles). The main misfit is to the slowest responses (.9 quantile) under 'careful' cues in Experiment 2b. This was primarily driven by a small subset of participants who appeared to follow the instructions to 'be careful' very seriously: 6 participants had mean RT > 10s in this condition, and 12 participants had a .9 quantile slower than 15s. These participants' data have the effect of quite markedly increasing the average of these statistics (.5 and .9 quantiles) shown in 
Figure 5
. The model isn't able to capture a range in RT quite this extreme -from a couple of seconds up to the trial time out at 40s, and hence its predictions err toward where the majority of the data fall; that is, toward generally faster responses. 
Figure 6
 shows the model generally predicted the pattern of choices well across both experiments -for option sets that were simpler (Experiment 2a) and more complex (Experiment 2b). In both experiments, the most preferred option observed in data and predicted by the model was always the objectively best option, as in the deadline experiments. The least preferred option for model and data was almost always the worst available option, with the only switch in the speed condition of Experiment 2b, with a minor swap in the observed data for one attribute (i.e., most expensive, worst camera and worst memory, but mid range battery); the model didn't make this switch in its predictions. 
Figure 6
 clearly shows choices were equally predictable (alternatively, equally random) when participants were instructed to make speedy or careful decisions. There was a global shift toward more random choices with the more complex option set of Experiment 2b compared to Experiment 2a, mirroring the findings of Experiments 1a and 1b. Nevertheless, within each experiment, the Kendall's Ï„ correlation coefficients were almost equal under the speeded and careful instructions. This provides further evidence that participants were able to effectively modulate the speed of their decisions but, in these instances, there were no appreciable corresponding changes to choice outcomes.


Psychological Interpretation
The DIC-preferred models in Experiment 2a and 2b had just one set of utility coefficients that were the same across the verbal instruction conditions, indicating subjective valuation did not differ between the two levels of time pressure -consistent with no change in choice outcomes across those two conditions. The sign of the utility coefficients were consistent with the earlier experiments. In Experiment 2a, utilities were negative for cost (M = -0.070, 95% CI 
[-0.079, -0.062
 Participants again adjusted their decision threshold -their level of caution -in response to the time pressure manipulation, generalising our earlier result to verbal instructions to emphasise response speed or accuracy. In Experiment 2a, thresholds were higher, on average, when making careful choices (M = 1.76, 95% CI [1.67, 1.85]) compared to speedy choices (M = 1.66, 95% CI [1.57, 1.74]), and this difference in thresholds was reliable 
(M = 0.11,
95% CI [0.03,
0.18]
). Similarly, in Experiment 2b thresholds were higher when participants were asked to make accurate decisions (M = 2.09, 95% CI [1.99, 2.20]) than when asked to make speedy decisions (M = 1.85, 95% CI [0.14, 1.95]). This difference was reliable (M = 0.24, 95% CI [0.14, 0.33]). Taken together, Experiments 2a and 2b extended and replicated the findings of the earlier experiments. Verbal instructions that induced an internally-driven sense of time pressure led to the same theoretical conclusion as externally-imposed time pressure. That is, time pressure impacted how much information people collected prior to making a choice (decision threshold), which extended their response times. However, time pressure did not impact the subjective valuation of attribute information (utilities), and thus did not change choice outcomes.


General Discussion
We have shown that decision makers adapt to time pressure by solely adapting their level of caution -the decision threshold -when making preferential choices. Across four experiments, we consistently supported this position over the competing hypothesis we investigated, that decision makers adapt to time pressure by adjusting the cautiousness of their decisions and the utility of the options under consideration. Our evidence for the threshold explanation came from quantitative model comparison of sequential sampling models adapted to preferential choices and applied to two qualitatively different forms of time pressure (deadlines, cues) and two types of multi-attribute consumer goods (simpler and more complex option sets).
Our sequential sampling analyses of choices and response times showed that preference strength did not differ as a function of time pressure for any attribute in any of the four experiments. Rather than adjusting their subjective valuation of attributes, our analyses suggest that participants considered less attribute-relevant information prior to decision commitment under high time pressure (lower decision thresholds). This pattern of results is consistent with many classic studies of the speed-accuracy tradeoff in speeded perceptual decisions (e.g., 
Forstmann et al., 2008;
Ratcliff & Rouder, 1998;
Voss et al., 2004)
. To our knowledge, our work is one of the first demonstrations that the way people manage the speed-accuracy tradeoff in speeded perceptual decisions may generalise to the way they manage the speed-accuracy tradeoff in higher-level decisions between complex, multiattribute preferential options. This is in the sense that they modulate their response speed by adjusting their threshold for committing to a decision.
Unlike the majority of studies in the perceptual decision literature, we observed no appreciable change to choice outcomes across levels of our time pressure manipulations, with the exception of the fastest deadline in Experiment 1b. This cannot be attributed to a failure of the manipulations to induce time pressure as we found consistently strong evidence for changes in response speed in the expected direction across all experiments. Rather, it may be attributable to other factors. For example, perceptual decisions are perceptually ambiguous by design such that longer inspection time may indeed improve accuracy because new information becomes available over time. Preferential decisions, in contrast, are not perceptually ambiguous -at least as they were studied here. This means that, conditional on sufficient time to encode the relevant stimulus information, longer inspection time may not necessarily translate to more reliable preferences (e.g., 
Milosavljevic, Malmaud, Huth, Koch, & Rangel, 2010)
.
Our findings regarding the psychological impact of time pressure in preferential choices differ to some modern evidence from the perceptual decision making literature, where decision thresholds and drift rates are both implicated in manipulations of the SAT (e.g., 
Dutilh et al., 2019;
Evans, 2021;
Hawkins & Heathcote, 2021;
Rae et al., 2014;
Starns et al., 2012;
Vandekerckhove et al., 2008)
. It is not clear why drift rates change as a function of SAT manipulations in some studies of perceptual decisions and not others. 
Rae et al. (2014)
 suggest some plausible hypotheses, such as experimental manipulations that induce large changes in choice accuracy between speed-emphasis and accuracy-emphasis conditions may be challenging for sequential sampling models to accommodate solely through a decision threshold adjustment, and hence also require a change to drift rates.
Nevertheless, studies of perceptual decision making that observed SAT-induced changes to decision thresholds and drift rates all tended to use a cognitive modelling methodology that allowed for the model comparison technique to discover whether both latent psychological variables (i.e., parameters) changed as a function of the SAT manipulation. That is, they did not assume selective influence. Selective influence is the assumption that an experimental manipulation, such as a decision deadline or cue to response speedily or carefully, only impacts one component of a model, such as the decision threshold in the case of SAT manipulations. Many studies in perceptual decision making have maintained this assumption. Studies that have not assumed selective influence have tended to conclude that decision thresholds and drift rates may both change (e.g., 
Dutilh et al., 2019;
Evans, 2021;
Hawkins & Heathcote, 2021;
Rae et al., 2014;
Starns et al., 2012;
Vandekerckhove et al., 2008)
.
We did not assume selective influence in our cognitive modelling methodology. That is, we quantitatively compared models that assume selective influence (i.e., the null model, where only decision threshold was adjusted) with models that do not assume selective influence (i.e., the SAT model, where decision threshold and utilities were adjusted). In all cases we supported the null model (only thresholds), by model comparison in three experiments and posterior inference in the fourth. This implies that selective influence was maintained in preferential choices under time pressure even when allowing for the possibility that it may not be maintained.
There are a few candidate explanations for this discrepancy between our findings in preferential choices and previous work in perceptual decisions. It may be that a fundamental component of the decision making process differs between perceptual and preferential choices. We consider this to be a strong conclusion. Resolving this question will require directed investigation that specifically targets both types of decisions in a common framework, which was beyond our scope here (for an example of this approach, see 
Dutilh & Rieskamp, 2016)
. An alternative explanation is that sequential sampling models are not sufficiently sensitive to discover nuanced changes in psychological processes when applied to the longer-time scale response times inherent in preferential choice behaviour. A sequence of cognitive operations surely occurs between stimulus onset and choice of a preferential option. We can apply a sequential sampling model to the observed choices and response times and obtain reasonable fit to data, and while this may indicate the model is a sound description of the cognitive processes that generated the observed behaviour, it does not compel this conclusion. This is a challenging problem to resolve as observed behaviour (choices, response times) is necessarily sparse in behavioural paradigms like those we studied here. Addressing this issue will likely require new methods of investigation and/or integration of additional data streams. We leave it to future research to disentangle these candidate explanations.
Along similar lines, we found that the sequential sampling model misfit some features of the observed response times across experiments, with more marked misfit in some experiments (e.g., Experiment 2b) compared to others (e.g., Experiment 1a). By their structure, sequential sampling models predict faster choices for options composed of desirable attribute levels (i.e., higher utility, hence higher drift rates), and similarly slower choices for options composed of less desirable attributes (i.e., lower utility, hence lower drift rates). This structural feature means the model captured the qualitative trends observed in choice and response time data but quantitatively underpredicted the magnitude of some of these effects. For example, all panels in 
Figures 3 and 6
 show moderate to strong linear relationships between observed and predicted choice data, though a slope coefficient less than 1. This indicates the model quantitatively overpredicted how often undesirable options were chosen and underpredicted how often desirable options were chosen.
We suggest this result arises from the architecture of theories based on the sequential sampling framework, which predict the joint distribution of choices and response times as a function of a single set of parameters. As such, as the model adjusts parameters to predict more or less extreme choices the predicted response times will also change. The model could have better captured one of the two components of the joint distribution, say, choice proportions closer to the observed frequencies, but this would have led to more extreme response times -the fastest responses would be even faster, and the slowest responses even slower. The model predictions we reported across experiments represent the best tradeoff between misfit to the two streams of data (highest posterior likelihood). We do not believe these trends cloud the results we report -indeed, the same trends have been previously reported in the literature (e.g., 
Evans et al., 2019;
Hawkins et al., 2014b)
, have been discussed elsewhere in detail 
(Hawkins, Cooper, & Cavallaro, 2023)
, and represent the best approach currently available to address our primary research question. Rather, we suggest this is a fruitful direction for future research to address the question of what features of sequential sampling models differ or could be expanded from low-level perceptual decisions (where the joint distribution of choices and response times are quantitatively well predicted) to higher-level multi-attribute, multi-alternative preferential decisions (where the joint distribution of choices and response times are quantitatively less well described).
In conclusion, few studies of preferential choice directly consider the impact of time pressure and simultaneously account for choices and choice times in a single analytic framework 
(Spiliopoulos & Ortmann, 2018)
. We have shown that decision time is an inextricable component of the cognitive process of deciding between preferential options, through the way people adapt to different forms of time pressure. We believe that cognitive process models that incorporate information about choices and choice times may provide a useful avenue to better understand how people decide between complex preferential options, particularly when internal or external constraints impose on their decision making processes.
Figure 1 .
1
Experiment 1a: Example of the DCE stimulus. Participants made a selection by clicking the "This one" button below their most-preferred pizza delivery option.


Figure 2 .
2
Response time distributions for each deadline condition (x-axes) in Experiments 1a (left) and 1b (right). Data are shown in red dots and model predictions of the DICpreferred model


Figure 4 .
4
Experiment 1b: Example of the DCE stimulus. Participants made a selection by clicking the "This one" button below their most-preferred option.


Figure 5 .
5
Response time distributions for each verbal instruction condition (x-axes) in Experiments 2a (left) and 2b (right). Data are shown in red dots and model predictions of the DIC-preferred model


]) and delivery time (M = -0.011, 95% CI [-0.013, -0.009]) and positive for sides (M = 0.306, 95% CI [0.267, 0.345]). In Experiment 2b, utilities were negative for cost (M = -0.012, 95% CI [-0.014, -0.010]) and positive for battery life (M = 0.016, 95% CI [0.013, 0.019), camera resolution (M = 0.024, 95% CI [0.017, 0.031]) and memory capacity (M = 0.006, 95% CI [0.005, 0.007]).


Figure 6 .
6
Choice proportions as a function of verbal instruction condition (rows) in Experiments 2a and 2b (columns). In each panel, the x-axis shows choice proportions observed in data and the y-axis shows choice proportions predicted by the DIC-preferred model (Table 3), where dots represent the posterior mean and the bars represent uncertainty (95% credible interval). Each dot represents a unique option in the experimental design. Inset values in each panel shows Kendall's Ï„ rank order correlation between observed and predicted choice proportions (posterior mean and 95% credible interval).


Table 1 DIC
1
Experiment
Parameterisation
No. free parameters âˆ†DIC
1a: Pizza Delivery
5, 10, 20
13
124.77
5/10, 20
10
53.72
5, 10/20
10
63.36
Null
7
0
1b: Mobile Phones
5, 10, 20
16
126.32
5/10, 20
12
0
5, 10/20
12
34.01
Null
8
38.52
model comparison for deadline experiments. The model that provides the best explana- tion of the data is shown as âˆ†DIC = 0.


Table 2
2
Experiment 1b: Estimated utility coefficients for the DIC-preferred model. Cell entries show the posterior mean and 95% credible interval of the group-level mean parameter of the respective models.
Deadline
Cost (95% CI)
Battery (95% CI)
Camera (95% CI)
Memory (95% CI)
5/10
âˆ’0.013
0.014
0.023
0.006
(âˆ’0.015, âˆ’0.010)
(0.009, 0.019)
(0.016, 0.031)
(0.005, 0.008)
20
âˆ’0.012
0.015
0.023
0.006
(âˆ’0.015, âˆ’0.009)
(0.011, 0.020)
(0.014, 0.033)
(0.005, 0.008)
Mean Difference (95% CI)
0.000 (âˆ’0.003, 0.003)
0.001 (âˆ’0.004, 0.006)
0.000 (âˆ’0.009, 0.010)
0.000 (âˆ’0.001, 0.001)


Table 3
3
DIC model comparison for verbal instruction experiments. Models providing the best expla-
nation of the data are shown as âˆ†DIC = 0.
Experiment
Parameterisation
No. free parameters âˆ†DIC
2a: Pizza Delivery
SAT
9
15.94
Null
6
0
2b: Mobile Phones
SAT
11
38.09
Null
7
0








Acknowledging the critical role of decision time in preferential choice is consistent with a long-studied history of research in perceptual decision making. In perceptual decisions, one












The simplest complete model of choice response time: Linear ballistic accumulation




S
D
Brown






A
Heathcote








Cognitive psychology




57


3
















Cognitive and neural bases of multi-attribute, multi-alternative, value-based decisions




J
R
Busemeyer






S
Gluth






J
Rieskamp






B
M
Turner








Trends in Cognitive Sciences




23


3
















Decision field theory: A dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend








Psychological Review




100
















Response times in economics: Looking through the lens of sequential sampling models




J
A
Clithero








Journal of Economic Psychology




69
















Decision and choice: Random utility models of choice and response time




H
Colonius






A
A
Marley








International Encyclopedia of the Social & Behavioral Sciences




5


















G
Cooper






R
Innes






C
Kuhne






J.-P
Cavallaro






D
Gunawan






G
Hawkins






S
Brown






pmwg: Particle metropolis within gibbs










Computer software manual. R package version 0.2.0)








The effect of time pressure on consumer choice deferral




R
Dhar






S
M
Nowlis








Journal of Consumer Research




25


4
















Response times and decision-making. Stevens' handbook of experimental psychology and cognitive neuroscience




C
Donkin






S
D
Brown








5














The retrieval of sentences from memory: A speed-accuracy study




B
A
Dosher








Cognitive psychology




8


3
















The quality of response time data inference: A blinded, collaborative assessment of the validity of cognitive models




G
Dutilh






J
Annis






S
D
Brown






P
Cassey






N
J
Evans






R
P
Grasman








Psychonomic bulletin & review




26


4
















Comparing perceptual and preferential decision making




G
Dutilh






J
Rieskamp








Psychonomic Bulletin & Review




23
















Think fast! the implications of emphasizing urgency in decision-making




N
J
Evans








Cognition




214














Response-time data provide critical constraints on dynamic models of multi-alternative, multi-attribute choice




N
J
Evans






W
R
Holmes






J
S
Trueblood








Psychonomic Bulletin & Review




26


3
















Striatum and pre-SMA facilitate decision-making under time pressure




B
U
Forstmann






G
Dutilh






S
Brown






J
Neumann






D
Y
Von Cramon






K
R
Ridderinkhof






E.-J
Wagenmakers








Proceedings of the National Academy of Science




105
















Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions




B
U
Forstmann






R
Ratcliff






E.-J
Wagenmakers








Annual Review of Psychology




67
















Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions. Annual review of psychology




B
U
Forstmann






R
Ratcliff






E.-J
Wagenmakers








67














Statistical modelling with quantile functions




W
Gilchrist








Chapman & Hall/CRC


London












Value-based attentional capture affects multialternative decision making




S
Gluth






M
S
Spektor






J
Rieskamp








Elife




7


39659














Under pressure: An integrative perspective of time pressure impact on consumer decision-making




S
Godinho






M
Prada






M
V
Garrido








Journal of International Consumer Marketing




28


4
















New estimation approaches for the hierarchical linear ballistic accumulator model




D
Gunawan






G
E
Hawkins






M.-N
Tran






R
Kohn






S
Brown








Journal of Mathematical Psychology




96


102368














The standard relationship between choice frequency and choice time is violated in multi-attribute preferential choice




G
E
Hawkins






G
Cooper






J.-P
Cavallaro








Journal of Mathematical Psychology




115


102775














Racing against the clock: Evidence-based versus time-based decisions




G
E
Hawkins






A
Heathcote








Psychological Review




128


2


222
















G
E
Hawkins






A
A J
Marley






A
Heathcote






T
N
Flynn






J
J
Louviere






S
D
Brown




The best of times and the worst of times are interchangeable. Decision






1














Integrating cognitive process and descriptive models of attitudes and preferences




G
E
Hawkins






A
A J
Marley






A
Heathcote






T
N
Flynn






J
J
Louviere






S
D
Brown








Cognitive Science




38
















The speed-accuracy tradeoff: history, physiology, methodology, and behavior




R
P
Heitz








Frontiers in Neuroscience




8


150














Neural mechanisms of speed-accuracy tradeoff




R
P
Heitz






J
D
Schall








Neuron




76
















Simple marginally noninformative prior distributions for covariance matrices




A
Huang






M
P
Wand








Bayesian Analysis




8


2
















Using best-worst scaling to improve psychological service delivery: An innovative tool for psychologists in organized care settings




L
G
Jones






G
E
Hawkins






S
D
Brown








Psychological Services




12
















Visual fixations and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel








Nature Neuroscience




13
















The attentional drift-diffusion model extends to simple purchasing decisions




I
Krajbich






D
Lu






C
Camerer






A
Rangel








Frontiers in psychology




3


193














A multi-alternative drift diffusion model predicts the relationship between visual fixations and choice in value-based decisions




I
Krajbich






A
Rangel








Proceedings of the National Academy of Science




108
















Effectiveness of exaggerated advertised reference prices: the role of decision time pressure




B
C
Krishnan






S
Dutta






S
Jha








Journal of Retailing




89


1
















Speed-accuracy tradeoffs in decision making: Perception shifts and goal activation bias decision thresholds




J
S
Larson






G
E
Hawkins








Journal of Experimental Psychology: Learning, Memory, and Cognition




49


1
















Speed-accuracy trade-offs during foraging decisions in the acellular slime mould physarum polycephalum




T
Latty






M
Beekman








Proceedings of the Royal Society B: Biological Sciences




278
















What consumers see when time is running out: Consumers' browsing behaviors on online shopping websites when under time pressure




C.-W
Liu






A.-Y
Hsieh






S.-K
Lo






Y
Hwang








Computers in Human Behavior




70
















Stated choice methods: Analysis and applications




J
J
Louviere






D
A
Hensher






J
D
Swait








Cambridge University Press


Cambridge, UK












How to do (or not to do). . . designing a discrete choice experiment for application in a low-income country




L
J
Mangham






K
Hanson






B
Mcpake








Health policy and planning




24


2
















Serial position and set size in short-term memory: the time course of recognition




B
Mcelree






B
A
Dosher








Journal of Experimental Psychology: General




118


4


346














The drift diffusion model can account for the accuracy and reactime of value-based choices under high and low time pressure




M
Milosavljevic






J
Malmaud






A
Huth






C
Koch






A
Rangel








Judgment and Decision Making




5
















What's in a response time?: On the importance of response time measures in constraining models of context effects




M
F
Molloy






M
Galdo






G
Bahg






Q
Liu






B
M
Turner








Decision




6


2


171














The effect of time pressure on the choice between brands that differ in quality, price, and product features




S
M
Nowlis








Marketing Letters




6


4
















An integrated model of discrete choice and response time




T
Otter






G
M
Allenby






T
Van Zandt








Journal of Marketing Research




45
















Testing the effect of time pressure on asymmetric dominance and compromise decoys in choice




J
C
Pettibone








Judgment and Decision Making




7


4
















Separating mnemonic process from participant and item effects in the assessment of ROC asymmetries




M
S
Pratte






J
N
Rouder






R
D
Morey








Journal of Experimental Psychology: Learning, Memory, and Cognition




36
















The hare and the tortoise: Emphasizing speed can change the evidence used to make decisions




B
Rae






A
Heathcote






C
Donkin






L
Averell






S
Brown








Journal of Experimental Psychology: Learning, Memory, and Cognition




40


5
















Modeling response times for two-choice decisions




R
Ratcliff






J
N
Rouder








Psychological Science




9
















A diffusion model account of masking in two-choice letter identification




R
Ratcliff






J
N
Rouder








Journal of Experimental Psychology: Human Perception and Performance




26
















Diffusion decision model: Current issues and history




R
Ratcliff






P
L
Smith






S
D
Brown






G
Mckoon








Trends in Cognitive Sciences




20
















Aging and individual differences in rapid two-choice decisions




R
Ratcliff






A
Thapar






G
Mckoon








Psychonomic Bulletin & Review




13
















Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability




R
Ratcliff






F
Tuerlinckx








Psychonomic Bulletin & Review




9
















Speed-accuracy trade-off in recognition memory




A
V
Reed








Science




181
















Inferences under time pressure: How opportunity costs affect strategy selection




J
Rieskamp






U
Hoffrage








Acta Psychologica




127


2
















Speed-accuracy tradeoff in olfaction




D
Rinberg






A
Koulakov






A
Gelperin








Neuron




51


3
















Multi-alternative decision field theory: A dynamic artificial neural network model of decision-making




R
M
Roe






J
R
Busemeyer






J
T
Townsend








Psychological Review




108
















Bayesian measures of model complexity and fit




D
J
Spiegelhalter






N
G
Best






B
P
Carlin






A
Van Der Linde








Journal of the Royal Statistical Society B




64
















The bcd of response time analysis in experimental economics




L
Spiliopoulos






A
Ortmann








Experimental economics




21


2
















Evaluating the unequal-variance and dualprocess explanations of zroc slopes with response time data and the diffusion model




J
J
Starns






R
Ratcliff






G
Mckoon








Cognitive Psychology




64


1
















The effects of time constraints on consumers' judgments of prices and products




R
Suri






K
B
Monroe








Journal of consumer research




30


1
















Sequential sampling models without random between-trial variability: The racing diffusion model of speeded decision making




G
Tillman






T
Van Zandt






G
D
Logan








Psychonomic Bulletin & Review




27
















Theories of context effects in multialternative, multiattribute choice




J
S
Trueblood








Current Directions in Psychological Science




31


5
















The multi-attribute linear ballistic accumulator model of context effects in multi-alternative choice




J
S
Trueblood






S
D
Brown






A
Heathcote








Psychological Review




121
















A comparison of two response time models applied to perceptual matching




T
Van Zandt






H
Colonius






R
W
Proctor








Psychonomic Bulletin & Review




7
















A Bayesian approach to diffusion models of decision-making




J
Vandekerckhove






F
Tuerlinckx






M
D
Lee








Proceedings of the 30th Annual Conference of the Cognitive Science Society


V. M. Sloutsky, B. C. Love, & K. McRae


the 30th Annual Conference of the Cognitive Science Society




Cognitive Science Society
















Interpreting the parameters of the diffusion model: An empirical validation




A
Voss






K
Rothermund






J
Voss








Memory & Cognition




32
















A diffusion model account of criterion shifts in the lexical decision task




E.-J
Wagenmakers






R
Ratcliff






P
Gomez






G
Mckoon








Journal of Memory and Language




58
















Speed-accuracy tradeoff and information processing dynamics




W
A
Wickelgren








Acta Psychologica




41
















The 2N-ary choice tree model for N-alternative preferential choice




L
M
WollschlÃ¤ger






A
Diederich




10.3389/fpsyg.2012.00189






Frontiers in Psychology




3














A dynamic computational model of gaze and choice in multiattribute decisions




X
Yang






I
Krajbich








Psychological Review




130


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]