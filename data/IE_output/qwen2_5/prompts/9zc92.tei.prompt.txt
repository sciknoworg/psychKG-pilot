You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



 
Keeble, Richardson, & Cragg, 2017)
, visuo--spatial processes 
(Crollen, Collignon, & Noël, 2017)
,the mental number line 
(Moeller, Neuburger, Kaufmann, Landerl, & Nuerk, 2009)
, neural tuning curves 
(Prather, 2014)
, decision making evidence accumulation (e.g., 
Purcell et al., 2010)
, amongst others. In the current study, we attempt to move towards a more comprehensive characterization of the processes involved while acknowledging that any progress made will undoubtedly still be incomplete and require further work.


The current study approach
The current study includes two behavioral experiments and a mathematical model of the non--symbolic numerical comparison and non--symbolic numerical estimation tasks. Our approach assumes that participants have a mechanism for representing relative values that can be used in completing these numerical tasks. We focus on value representation that may be constructed from a combination of numerical and non--numerical information in order to make accurate and ecologically valid conclusions. Participants' use of non--numerical information on numerical tasks is supported by prior work 
(e.g., Cohen Kadosh, Cohen Kadosh, & Henik, 2008;
Van Opstal, Verguts, Opstal, & Verguts, 2013;
Walsh, 2003)
, and participants' representation of value is not limited to numerical tasks. Any task in which assessing relative values is useful may involve value representation, such as decision--making tasks (e.g., 
Behrens, Woolrich, Walton, & Rushworth, 2007;
Rangel, Camerer, & Montague, 2008;
Sugrue, Corrado, & Newsome, 2005)
, and reward processing (e.g., 
Gottfried, O'Doherty, & Dolan, 2003;
Silvetti, Seurinck, & Verguts, 2011)
. While there has been some interest in defining a "pure" number sense the primary concern in the current study is to evaluate how participants construct the relative values in completing number tasks regardless of the perceptual information used.
We evaluate evidence for two cognitive processes, precision of number representation and decision--making threshold, which may contribute to completing the numerical comparison task.
Both are characterized at an algorithmic level of analysis 
(Marr, 1982)
 using a combination of behavioral experimentation and mathematical modeling. The goal is to create a reproducible formal model of variation in the cognitive processes and behavior relevant to numerical comparison. We consider the hypothesis that the precision of number value representation is the primary driver of individual variation in numerical comparison performance 
(Prather, 2014)
, where more precise representations are associated with better performance. Learners have some internal representation of number values, be it via neural tuning curves (e.g., 
Nieder, Freedman, & Miller, 2002;
Prather, 2012)
 or an internal space--to--number mapping such as the mental number line (e.g., 
Siegler & Opfer, 2003)
, in which numbers are represented as relative spatial positions, similar to a physical number line.
Learners with a more precise representation of number values are better able to make distinctions between numerical stimuli and answer correctly on a number comparison task (e.g., 
Prather, 2014)
. We model number representation as neural tuning curves associated with numbers as reported in both non--human primates and humans (e.g., 
Moskaleva & Nieder, 2014;
Andreas Nieder & Dehaene, 2009)
. The precision hypothesis is consistent with prior mathematical modeling work that demonstrates how increases in the precision of neural coding are associated with improved performance on numerical tasks 
(Dewind & Brannon, 2012;
Prather, 2012)
.
We also consider the hypothesis that individual differences in numerical comparison task performance are primarily due to variation in decision--making threshold, independent of numerical representation. Variations in thresholds for evidence accumulation contribute to performance in perceptual decision--making tasks 
(Busemeyer & Townsend, 1993;
Pleskac & Busemeyer, 2010;
Purcell et al., 2010
). The numerical comparison task can be framed simply as a version of perceptual decision--making task in which numerical information is relevant. We do not assume the Precision and Decision processes to be mutually exclusive. The current study evaluates the degree to which these two processes account for behavioral data across two numerical tasks. The behavioral experiments examine the relation between participants' accuracy and precision of number estimation as it relates to numerical comparison (e.g., 
Libertus et al., 2016)
. We draw on recent work that focuses on comparisons between performance on non--symbolic numerical comparison and free response non--symbolic estimations 
(Castronovo & Göbel, 2012;
Chesney, Bjalkebring, & Peters, 2015;
Guillaume, Gevers, & Content, 2016;
Libertus, Odic, Feigenson, & Halberda, 2016)
. For the free response estimation task, participants are shown a set of objects and asked to estimate how many there are.
Across two experiments we combine behavioral and modeling data to examine the possibility that variation in numerical comparison performance is driven primarily by individual differences in the precision of numerical representations. We also consider the possibility that variation in numerical comparison is primarily driven by variation in the decision--making processes and not representations of number value. There is mixed evidence in prior work regarding the relationship between numerical comparison and estimation task performance. In some cases, no relationship between numerical comparison accuracy and estimation accuracy is found 
(Guillaume et al., 2016;
Pinheiro--Chagas et al., 2014)
, in others a small positive correlation was reported 
(Chesney et al., 2015)
. In other studies a significant relationship between estimation variability and number comparison was found, but not between estimation accuracy and number comparison 
(Libertus et al., 2016)
.
In addition to estimation accuracy, we calculated the variation of participants' estimates, e.g., the precision 
(Izard & Dehaene, 2008
 If the variation in participants' performance is primarily due to variation in the precision of their numerical representations we expect a strong correlation between accuracy on the comparison task and estimation precision in the estimation task. If individual differences are due to variation in decision--making thresholds, we would not expect a significant correlation between accuracy on the comparison task and estimation precision. Numerical representation precision may not be all that there is to the estimation task or comparison task. The participant must map their internal representation of the stimuli to an output. In the case of the estimation task, the output is a specific cardinal value. For each participant, the model will fit their performance on the comparison and estimation tasks simultaneously. The question to be examined is if how well adjustments to the neural representation precisions fit participants' data relative to the fit when for total area, and size of the largest square. The location of the squares was randomly selected before the experiment. Participants were instructed to indicate which side contained more shapes via button press. Stimuli were displayed for 2 seconds after which the screen was blank. There was no response time limit; participants were instructed to respond as quickly as possible.
Free Response Estimation. Stimuli were 64 visually presented shape arrays. The number of objects ranged from 23 to 111 (see Appendix). Participants were instructed to respond with an estimate of how many shapes were in the display. The stimuli were displayed for 2 seconds after which the participants were presented with a prompt to type their response. There was no response time limit.


Results
Performance on the numerical comparison task. Participants' performance was calculated as the number of correct responses on the task. Performance ranged from 32% to 84% correct. For the remaining analysis, we only consider participants with performance statistically above chance (58%) on the numerical comparison task (n = 53). For this subset of participants' median performance on the task is 69% correct. Age ranged from 19 to 70 with a median of 31. Given the regression analysis to be performed 53 participants is sufficient for the expected medium effect size (f2 = 0.19, power = 0.81).
Free Response Estimation. Participants' performance was calculated using the deviations between the participants' response and the actual number of shapes displayed. Participants' mean deviation ranged from 7.78 to 44.51 with a median of 17.33. Deviations can also be calculated in terms of proportions (e.g., a response of 50 when 40 items were displayed would be a deviation of 0.25). Participants' mean deviation in terms of proportion difference ranged from 0.125 to 0.811 with a median of 0.255.
We also calculated the variation in participants' responses, separately from accuracy ( 
Figure 1
). The stimuli in this task included multiple stimuli with the same number of objects in different configurations. This allows us to evaluate how consistent participants' estimations for the eight target values. Participant's precision score was the average coefficient of variation across the eight target values. Participants' precision scores ranged from 0.09 to 0.42 with a median of 0.17.
Precision and accuracy scores were not significantly correlated where increased precision was associated with higher accuracy, R = 0.21, t(51) = 1.54 p = 0.13.
The relationship between numerical comparison and estimation tasks. We evaluated the relationship between participants' behavior on the two tasks using a linear regression with estimation deviation (e.g., accuracy), estimation precision, and participant age in predicting numerical comparison ( 
Figure 2
). Neither estimation deviation nor estimation precision significantly predicted numerical comparison score (  
Table 1
. Results for a linear regression using participant scores for Estimation Accuracy and Estimation precision to predict numerical comparison task score.  


Experiment 1b
Participants (N= 30, 17 male) were children aged 7 years to 8 years, 9 months. Parents of the children were recruited through a university participant pool. Protocols were approved by the  
Appendix)
. Participants were instructed to respond with an estimate of how many shapes were in the display. The stimuli were displayed for 2 seconds after which the participants were presented with a prompt to type their response. There was no response time limit.
Mathematical Ability. Participants completed the Test of Early Mathematics Ability 3rd Edition (TEMA), a standardized early mathematics assessment 
(Ginsburg & Baroody, 2003)
. The TEMA is designed to assess children's overall mathematical knowledge including formal and informal mathematics.


Results
Performance on the numerical comparison task. Participant's performance on the numerical comparison task ranged from 60% to 94% correct with a median of 80%. All Performance on the estimation task. We eliminated any trial for which participants did not make a response, representing 4% of trials. We also eliminated responses that represented the top 5% of estimates as many of these responses appeared to by types, e.g., '500000'. Participants' performance on the estimation task was calculated in the same manner as in Experiment 1a.
Accuracy was calculated by taking the absolute value of the difference between the target value and participants' given estimate and dividing by the target value. This gives us a ratio--difference score, e.g., an estimation of 13 for the target value 10 would produce a score of 0.3. Participant accuracy ranged from 0.30 to 1.06 with a median of 0.60.
We also calculated the variation in participants' responses, separately from accuracy. Participants' precision score calculation was the same as described in Experiment 1a. Participants' precision score ranged from 0.29 to 0.84 with a median of 0.56. Precision and accuracy scores significantly correlated where increased precision was associated with higher accuracy, R = 0.57, t(28) = 3.67 p < 0.001 ( 
Figure 3
).  


Comparison Score
Estimation Precision estimation accuracy, estimation precision and age and TEMA score as predictors. Given the regression analysis to be performed 30 participants is sufficient for a large effect size (f2 = 0.35, power = 0.74). We found no significant predictors of numerical comparison score: estimation accuracy, B = --0.02, t = 0.17, p = 0.86, estimation precision B = 0.06, t = 0.35, p = 0.73, TEMA score B = 0.0002, t = 0.10, p = 0.91, or age b = --0.04, t = 0.86, p = 0.39. A bivariate correlation between numerical comparison task and estimation accuracy score was non--significant, R = 0.12, p = 0.52.
A correlation between numerical comparison task and estimation precision was also non-significant R = 0.02, p = 0.91 (see 
Figure 4)
 Comparisons between adult and child participants. We found that adults' performance on the estimation task was significantly different in terms of accuracy (M= 0.289) compared to child (M = 0.60), t(81) = 8.67, p < 0.001. Adults estimation task precision score (M = 0.19) was also significantly different than children's (M = 0.56), t(81) = 15.21, p < 0.001. Adults did not show a significant correlation between estimation accuracy and prevision, while child participants did.
There are two possible explanations; the child participant data is a type 1 error due in part to the lower sample size, there is a developmental change in the relationship between estimation accuracy and precision.


Experiment 1 Discussion
For both experiments 1a and 1b we find no statistically significant relationship between participants' performance on the non--symbolic numerical comparison task and free response estimation for both estimation accuracy and estimation precision. Current study results differ from prior work which reported a significant relationship between estimation variability and number comparison but not estimation accuracy and number comparison 
(Libertus et al., 2016
).
Several differences between the studies may contribute to the difference in results. The range of numbers used here for estimation is larger than prior work. Estimation stimuli range was up to 111 whereas prior work was limited to no more than 20 
(Libertus et al., 2016)
. The participant age range was both older and broader than the 5 to 8 years of prior work. The current study combines data from participants 7 to 9 years old for Experiment 1b and 25 to 70 years old for Experiment 1a.
The behavioral data reported in data sets for Experiments 1a and 1b rely on the interpretation of a null effect. While the two experiments had a range of participant ages, we found the same pattern across both analyses for adults and children. In interpreting null findings for Experiments 1a and 1b, we additionally calculated Bayes factors against the null hypothesis. In both cases, Bayes factor values suggest evidence for the null effect when compared to the tested regression models. We also do not find that participants' TEMA scores significantly predicted numerical comparison scores, despite prior evidence of a connection 
(Schneider et al., 2017)
. The relatively small age range used in this experiment (7.0 to 8.75yrs) may affect the measured relationship.
We interpret the results of this experiment as inconsistent with the Precision hypothesis.
The lack of significant correlation between estimation precision and numerical comparison suggests that numerical representation precision is not the primary driver of behavior. We consider the aforementioned alternative hypothesis, that general decision--making processes not specifically tied to number primarily drive numerical comparison performance. We elaborate on this potential process using a mathematical model in experiment 2.


Mathematical Modeling
The purpose of the modeling experiment is to demonstrate how well the processes proposed by the Precision and Decision hypotheses fit the behavioral data from both experiments 1a and 1b. We evaluated the Precision hypothesis and the alternative Decision hypotheses using a dynamic neural field model (e.g., 
McClelland et al., 2010)
. We evaluate the two hypotheses using two versions of the same model. One model condition is designed to implement the Precision hypothesis; the other model implements the Decision hypothesis. Both model conditions were fit to each participant's behavioral data independently. Model optimization was implemented via an evolutionary algorithm that minimized the deviation between behavioral data and model output.
The optimization procedure included adjustments to a subset of model specifications while others remained fixed. For the Precision hypothesis model, the specification for the width of the tuning curves was variable, while specifications for the decision layer did not vary. For the Decision hypothesis model, the tuning curve widths are fixed while the intra--layer timing of evidence accumulation within the decision layer varies. This also changes the accuracy in detecting differences from the neural turning curves that connect to the decision layer.
An important point here is that the current model is much more strict than prior models of numerical comparison 
(Prather, 2014)
. As opposed to modeling participants' performance on only the numerical comparison task, the current model must simultaneously predict behavior on numerical comparison and estimation tasks for each participant.


Method
Model Specifications and Procedure. The model was implemented using MATLAB (MathWorks). The architecture was a multilayered dynamic systems model (e.g., 
Simmering & Perone, 2013;
Spencer, Smith, & Thelen, 2001
). Layers included two perceptual neural tuning curves and a decision layer. Perceptual layers modeled neural tuning curves associated with neural coding of stimuli (e.g., 
Prather, 2012
Prather, , 2014
Tudusciuc & Nieder, 2007)
. For the numerical comparison task, the external inputs for the model were the two numerical values to be compared, taken from the stimuli in Experiment 1. The two values were represented by proportionally scaled Gaussian curves that reproduce the ratio dependent distance effect. Perceptual layers of the model reproduced the stimuli while activity was forwarded to the decision layer. The internal decision layer connections were specified to produce competition within the layer through lateral inhibition and self--excitation. Thus the two perceptual layers output created competition within the decision layer. This dynamic corresponded to the "decision" which was the index of the first stable activation peak in the decision layer. For the estimation task, the external input for the model was the target value to be estimated, taken from the stimuli in experiment 1.
Each trial was comprised of 600 time--steps, which was selected to be large enough for activity from the input layers to create a decision in the output layer. Decisions were defined as when the decision layer produced a steady peak (activity with a peak value at the same layer index for 10 straight time--steps). The time--step of the decision was converted to the predicted reaction time of the decision. Thus on trials in which the model predicted a fast decision the steady peak was reached a relatively low time--step. On trials in which the model predicted a slower decision, the steady peak was reached on a higher time--step.
Model instantiations were fit to behavioral data from Experiment 1b using an evolutionary optimization algorithm. Model instantiations were completed in batches of 10, each corresponding to a generation. For each generation, the model instantiations were ranked based on their deviation from the behavioral data. Model instantiations with smaller deviations, smaller error, were ranked higher. For each generation instantiations ranked, 1--2 were moved forward as is to the next generation. Instantiations ranked 3--5 were 'mutated' by adjusting the specifications by a small random amount. Instantiations ranked 6 -10 were discarded. Thus each generation included 5 new instantiations were randomly generated specifications, 3 'mutated' instantiations and 2 instantiations carried over from the previous generation. The specifications of the evolutionary algorithm were selected to maximize the efficiency of the algorithm to keep the number of batches needed relatively low.
The same process was employed for modeling behavioral data from Experiment 1a (adult participants) and Experiment 1b (child participants).


Results: Experiment 1a Model


What are the model conditions performances on the tasks?
The precision condition model instantiations performance on the numerical comparison task ranged from 0.46 to 0.72 with a median of 0.62. Performance on the estimation task, in terms of average proportional deviation from the target, ranged from 0.08 to 0.27 with a median of 0.15.
We found that performance on the comparison task correlated with the neural tuning curve width R = --0.37, p < 0.01, where smaller tuning curve widths were associated with higher scores on the task. We found that performance on the estimation task correlated with the neural tuning curve width, R = 0.36, p < 0.01, where smaller tuning curve widths were associated with better performance on the task.
The decision condition model instantiations performance on the numerical comparison task ranged from 0.50 to 0.86 with a median of 0.65. Performance on the estimation task, in terms of average proportional deviation from the target, ranged from 0.08 to 0.23 with a median of 0.14.
We found that performance on the comparison task correlated with the neural tuning curve width R = --0.27, p = 0.22, where smaller tuning curve widths were associated with higher scores on the task. Performance on the comparison task was significantly correlated with the evidence rate parameter, R = 0.67, p <0.01. We found that performance on the estimation task was not correlated with the neural tuning curve width, R = 0.11, p = 0.36. Performance on the estimation task was not significantly correlated with the evidence rate parameter, R = 0.08, p = 0.50.


How well does each model fit participants' data?
Model data was evaluated using a similar analysis to the behavioral data. Each model version produced independent simulations of the numerical comparison and estimation task. We compared results for the Precision condition models (n = 71) to the Decision condition models (n = 71). For the Precision condition models, the median numerical comparison error was 0.02, with a range from 0.18 to 0.0. The median estimation error was 11.5 with a range from 5 to 41. For the Decision condition models, the median numerical comparison error was 0.01, with a range from 0.17 to 0. The median estimation error was 12 with a range from 6 to 39.


How does the model fit compare between Precision and Decision conditions?
To compare model fit for Precision and Decision conditions we compared the deviation from human data for both tasks. The model error for the numerical comparison task was significantly lower for the Decision condition models (median = 0.01) than for the Precision condition models (median = 0.2), t(70) = 5.41, p < 0.001, d = 0.70. For the estimation task the model error not significantly different between the Decision condition models (median = 11.5) and the Precision condition models (median = 12), t(70) = 1.33, p = 0.18, d = 0.049. We calculated overall model error by combining numerical comparison and estimation error amounts. The overall model error was calculated as ErrorComparison + ErrorEstimation / 100. The equation was created to equally weight error on both tasks. The overall model error for Decision condition models (median = 0.14) was significantly lower than overall model error for Precision condition models (median = 0.16), t(70) = 5.53 , p < 0.001, d = 0.32 ( 
Figure 5
).
These results show that the Decision condition models are better able to fit adult participants data for the numerical comparison task. Fit to participant data for the estimation task was equivalent. This suggests that the additional decision layer specification was only relevant to model fit to numerical comparison task and that it leads to superior model fit compared to the use of neural tuning curve precision. 


Results: Experiment 1b Model


What are the model conditions performances on the tasks?
The precision condition model instantiations performance on the numerical comparison task ranged from 0.58 to 0.72 with a median of 0.67. Performance on the estimation task, in terms of average proportional deviation from the target, ranged from 0.25 to 0.08 with a median of 0.13. 0" 10" 20" 30" 40" 50" 60" 70" 80"
Model"Error"
Par5cipant"
We found that performance on the comparison task did not significantly correlate with the neural tuning curve width R = --0.23, p = 0.22, where smaller tuning curve widths were associated with higher scores on the task. We found that performance on the estimation task did significantly correlated with the neural tuning curve width, R = 0.75, p < 0.01, where smaller tuning curve widths were associated with better performance on the task.
The decision condition model instantiations performance on the numerical comparison task ranged from 0.57 to 0.93 with a median of 0.77. Performance on the estimation task, in terms of average proportional deviation from the target, ranged from 0.22 to 0.08 with a median of 0.12.
We found that performance on the comparison task not significantly correlated with the neural tuning curve width R = --0.25, p = 0.18, where smaller tuning curve widths were associated with higher scores on the task. Performance on the comparison task was significantly correlated with the evidence rate parameter, R = 0.69, p <0.01. We found that performance on the estimation task correlated with the neural tuning curve width, R = 0.42, p = 0.02, where smaller tuning curve widths were associated with better performance on the task. Performance on the estimation task was not significantly correlated with the evidence rate parameter, R = 0.14, p = 0.46.


How well does each model fit participants' data?
Model data was evaluated using a similar analysis to the behavioral data. Each model version produced independent simulations of the numerical comparison and estimation task. We compared results for the Precision condition models (n = 30) to the Decision condition models (n = 30). For the Precision condition models, the median numerical comparison error was 0.15, with a range from 0.26 to 0.01. The median estimation error was 26 with a range from 14 to 42. For the Decision condition models, the median numerical comparison error was 0.03, with a range from 0.15 to 0. The median estimation error was 25 with a range from 9.5 to 44.5.


How does the model fit compare between Precision and Decision conditions?
To compare model fit for Precision and Decision conditions we compared the deviation from human data for both tasks. The model error for the numerical comparison task was significantly lower for the Decision condition models (median = 0.03) than for the Precision condition models (median = 0.15), t(29) = 7.78, p < 0.001, d = 1.76. For the estimation task the model error not significantly different between the Decision condition models (median = 25) and
the Precision condition models (median = 26), t(29) = 1.63, p = 0.11, d = 0.37.
We calculated the overall model error by combining numerical comparison and estimation error amounts. The overall model error was calculated as ErrorComparison + ErrorEstimation / 100. The equation was created to equally weight error on both tasks. The overall model error for Decision condition models (median = 0.28) was significantly lower than overall model error for Precision condition models (median = 0.39), t(29) = 4.17 , p < 0.001, d = 1.01 ( 
Figure 6
).
These results show that the Decision condition models are better able to fit participants data for the numerical comparison task. Fit to participant data for the estimation task was equivalent. This suggests that the additional decision layer specification was only relevant to model fit to numerical comparison task and that it leads to superior model fit compared to the use of neural tuning curve precision. 


Mathematical Model Discussion
The mathematical modeling results demonstrate that the Decision model instantiations fit both adult's and children's data significantly closer than the Precision model instantiations. Put more generally, a mathematical model that includes specifications for both numerical representation and decision--making is a better fit to human data than a model that only includes numerical representation. The modeling results suggest that behavioral data reported in behavioral experiments 1a and 1b cannot be well--characterized using only neural tuning curve precision. This is in contrast with the apparent success of using neural tuning curves to model numerical comparison task 
(Prather, 2014)
 or the number--line estimation task 
(Prather, 2012)
.
The current modeling study is different in two crucial respects; first, we model individual participant data, not group means; second performance on multiple tasks are modeled simultaneously. The fit of tuning curve precision models to behavioral data seems to be limited given these two considerations. The experiment demonstrates that the addition of a decision-making parameter allows for a far more accurate fit to participants' data. This suggests that neural tuning curve precision may be a necessary but not sufficient part of modeling the cognitive processes involved in completing numerical comparison and number--line estimation tasks.


General Discussion
The current study evaluated two models of the processes involved in comparing non-symbolic numbers. Results from both empirical and mathematical experiments are inconsistent with the hypothesis that numerical comparison performance is better characterized by variation in neural tuning curve precision. We find that participant's performance on free response estimation, used as an estimate of tuning curve precision, does not correlate with numerical comparison performance. Mathematical modeling results demonstrate that variation in the decision--making process can better account for participants' numerical comparison scores above and beyond variations in neural tuning curve precision. We interpret these results as inconsistent with the Precision hypothesis. Individual variation in performance on the numerical comparison task is not primarily due to variation in tuning curve precision.
The current results provide important evidence regarding the processes involved in non-symbolic numerical comparison. The current and recent results suggest that numerical representation precision does not play the primary role in the numerical comparison task. This contradicts some previous speculation about the role of neural tuning curve precision in numeral tasks 
(Prather, 2012;
2014)
. Of course, the precision and decision hypothesis are not mutually exclusive. We expect many factors relating to attention or inhibition may in part account for behavior on the comparison task. It is also possible that the processes involved in numerical comparison can change with experience or development. Learners' skill at numerical decision--making may contribute to performance in a wide range of numerical and arithmetic task.
If learners' performance on the numerical comparison task can be characterized without invoking their representations of number values it calls into question the source of the correlation between numerical comparison skill and later arithmetic skills. Recent meta--analysis show mixed evidence that numerical comparison skill, in and of itself, predicts later performance 
(Chen & Li, 2014;
Gilmore et al., 2010)
. It is possible that these correlations capture variations in domain general skills that happen to be involved in completing the task, such as inhibition (e.g., 
Gilmore et al., 2013
, Purpura & Simms, 2018
.
How do the numerical comparison measures used here relate to other work? The non-symbolic numerical comparison task has varying relationships to other measures depending on the details of the task (e.g., 
Dietrich, Huber, & Nuerk, 2015)
. The stimuli in the current study were controlled for item size but not item density of the display. This is not the same set up as some other studies (e.g., Panamath, 
Halberda, Mazzocco, & Feigenson, 2008)
. Of course, there is evidence that precisely controlling for non--numerical cues may be somewhat beside the point.
Participants develop an internal representation of the numerical values of the stimulus that may be informed in part by density, area, perimeter, or convex hull. The point here is that the accuracy of such comparisons does not have a significant relationship with the precision of the representations of the same stimuli. We are concerned with the relationship between individual learner's behavior on these tasks and what that may say about the cognitive processes involved.
Other work has even challenged if numerical comparison can be thought of a purely numerical task regardless of the controls employed 
(Gilmore, Attridge, & Inglis, 2011;
Smets, Gebuis, Defever, & Reynvoet, 2014)
.


Potential Limitations
Reliability of measures calculated using a split--half Spearman correlation. For the data in experiment 1a, we calculated the Spearman coefficient using split half as r = 0.70. This reliability level is similar to what was reported in Chesney et al. (2015) r = 0.74. This suggests an acceptable level of reliability for the current measures. For the estimation task, we can calculate what the confidence interval for the measure of the participants' standard deviation (SD), which is used in calculating their estimation precision score. With 64 trials for the estimation task the 95% confidence interval for the SD 0.85*SD to 1.21*SD.
Other models of decision--making such as drift diffusion models are fairly successful for weighing evidence in two--alternative decision--making 
(Purcell et al., 2010;
Park & Starns, 2015;
Pirrone, Marshall, & Stafford, 2017)
. The current approach does not contradict a drift diffusion model; there are some similarities in implementation. The model implementation of decision-making is comparable to the drift diffusion approach. The current model's implementation of evidence accumulation is the adjustment of thresholds for competition between two potential choices. Though the mathematics of the model implementations differs, we do not see the models as in conflict with each other. However, the current approach allows for a model implementation that can be applied to a two alternative forced choice task and a free response estimation task simultaneously. A considerable motivation of the use of a dynamic systems model is the potential to be broadly applied to behavioral and neural data for a variety of tasks. It is unclear how to adopt a drift--diffusion model, typically used for two alternative forced choice tasks to a free response task. Only recently has work been done using drift diffusion for multiple alternative choice tasks 
(Slezak, Sigman, & Cecchi, 2018)
.
Figure 1 .
1
Graph of participants' performance on the Estimation task by the Precision and Accuracy measures. Each dot represents one participant.


Figure 2 .
2
Scatter plot of participants' scores on the numerical comparison task (ANS Score) and their free estimation task precision score. Estimation precision was calculated as the mean variation in estimation for the target value expressed as a ratio of that value. Larger values represent less consistent estimation responses.


Figure 3 .
3
Graph of participants performance on the Estimation task by the Precision and Accuracy measures. Each dot represents one participant.


Figure 4 .
4
Scatter plot of participants' scores on the numerical comparison task (ANS Score) and their free estimation task precision score. Estimation precision was calculated as the mean variation in estimation for the target value expressed as a ratio of that value. Larger values represent less consistent estimation responses.Performance on TEMA. Participant's performance on the TEMA was calculated using the scoring instructions. Participant's scores ranged from 85 to 132 with a median of 114.Relationship between tasks. We conducted a linear regression to predict participants' numerical comparison score (arcsine transformation of the proportion of correct responses) using


Figure 5 .
5
Total Error for Precision (grey--square) and Decision (black--diamond) model instantiations. The vertical axis represents the calculated error for each model instantiation. The horizontal axis represents the individual human participants (n = 71). The order is sorted by difference between Precision and Decision model performances.


Figure 6 .
6
Total Error for Precision (grey--triangle) and Decision (black--squares) model instantiations. The vertical axis represents the calculated error for each model instantiation. The horizontal axis represents the individual human participants (n = 30). The order is sorted by difference between Precision and Decision model performances.


If the individual variation in numerical comparison accuracy is due to decision--making more so than number representation what does that tell us? The importance of decision--making in numerical comparison may be informative in the design of interventions to improve learner's performance on numerical tasks. Individual variation in numerical decision--making may contribute to the association between numerical comparison skill and general mathematical skill.


Free Response Estimation. Stimuli were 40 visually presented shape arrays. Arrays included randomly places black squares of varying sizes. The number of objects ranged from 23 to 111 (see
University of Internal Review Board. Participants completed three tasks during the experimental session; the Numerical Comparison, Free Response Estimation and the Test of Early Mathematics Ability, 3 rd Edition (Ginsburg & Baroody, 2003). Numerical Comparison task. Stimuli were 90 visually presented pairs of shape arrays with a midline separator. Shape arrays ranged in number from 23 to 111 (see Appendix). The difference between the two values being compared ranged from a ratio of 1.05 to 1.85. Participants were instructed to indicate which side contained more shapes via button press. Stimuli were displayed for 2 seconds after which the screen was blank. There was no response time limit; participants were instructed to respond as quickly as possible while being as accurate as possible. No feedback was given, and there were no practice trials. Participants completed all 90 comparisons. Stimuli were constructed to control for the overall area of presented shapes.


Table 2 .
2
Results based on a linear regression using participant scores for Estimation Accuracy, Estimation precision, TEMA score and participant age to predict numerical comparison task score.
df)
P value
ηp²
. A Bayes factor analysis suggests evidence for the null hypothesis, BF = 0.072 for the regression model with Estimation Accuracy, Precision, TEMA score and age as predictors. B CI (97.5 : 2.5) t value (








Appendix


Comparison Task Values
 










Learning the value of information in an uncertain world




T
E J
Behrens






M
W
Woolrich






M
E
Walton






M
F S
Rushworth




10.1038/nn1954








Nature Neuroscience




10


9
















Representation of the numerosities 1--9 by rhesus macaques (Macaca mulatta)




E
M
Brannon






H
S
Terrace




10.1037//0097--7403.26.1.31








Journal of Experimental Psychology




26


1










Animal Behavior Processes








Decision field theory: a dynamic--cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend








Psychological Review




100


3
















Impact of high mathematics education on the number sense




J
Castronovo






S
M
Göbel




10.1371/journal.pone.0033832








PloS One




7


4














Association between individual differences in non--symbolic number acuity and math performance: a meta--analysis




Q
Chen






J
Li




10.1016/j.actpsy.2014.01.016








Acta Psychologica




148
















How to estimate how well people estimate: Evaluating measures of individual differences in the approximate number system. Attention, Perception, & Psychophysics




D
Chesney






P
Bjalkebring






E
Peters




10.3758/s13414--015--0974--6








77














When brightness counts: the neuronal correlate of numerical--luminance interference




R
Cohen Kadosh






K
Cohen Kadosh






A
Henik




10.1093/cercor/bhm058








Cerebral Cortex




18


2
















Skills underlying mathematics: The role of executive function in the development of mathematics proficiency




L
Cragg






C
Gilmore




10.1016/j.tine.2013.12.001








Trends in Neuroscience and Education




3
















Visuo--spatial processes as a domain--general factor impacting numerical development in atypical populations




V
Crollen






O
Collignon






M.--P
Noël




10.5964/jnc.v3i2.44








Journal of Numerical Cognition




3


2
















Malleability of the approximate number system: effects of feedback and training




N
K
Dewind






E
M
Brannon




10.3389/fnhum.2012.00068








Frontiers in Human Neuroscience




6


68
















J
F
Dietrich






S
Huber






H
C
Nuerk




10.3389/fpsyg.2015.00295








Methodological aspects to be considered when measuring the approximate number system (ANS) --a research review






6














Core systems of number




L
Feigenson






S
Dehaene






E
S
Spelke






L
Feigenson






E
S
Spelke








Trends in Cognitive Sciences




8


















C
Gilmore






N
Attridge






S
Clayton






L
Cragg






S
Johnson






N
Marlow






M
Inglis




10.1371/journal.pone.0067374








Individual Differences in Inhibitory Control, Not Non--Verbal Number Acuity






8












Measuring the Approximate Number System




C
Gilmore






N
Attridge






M
Inglis




10.1080/17470218.2011.574710








Quarterly Journal of Experimental Psychology




64


11
















Non--symbolic arithmetic abilities and mathematics achievement in the first year of formal schooling




C
K
Gilmore






S
E
Mccarthy






E
S
Spelke




10.1016/j.cognition.2010.02.002


















The interaction of procedural skill, conceptual understanding and executive functions in early mathematics achievement




Keeble
Gilmore






S
Richardson






S
Cragg






L




10.5964/jnc.v3i2.51








Journal of Numerical Cognition




3


2


















H
Ginsburg






A
J
Baroody




Test of Early Mathematics Ability


Austin, TX












3rd Edition








Encoding predictive reward value in human amygdala and orbitofrontal cortex




J
Gottfried






J
Doherty






R
J
Dolan




10.1126/science.1087919








Science




5636
















Assessing the Approximate Number System: no relation between numerical comparison and estimation tasks




M
Guillaume






W
Gevers






A
Content




10.1007/s00426--015--0657--x








Psychological Research




80


2
















Developmental change in the acuity of the




J
Halberda






L
Feigenson




10.1037/a0012682








The Approximate Number System in 3--, 4--, 5--, and 6--year--olds and adults






44








Number Sense








Individual differences in non--verbal number acuity correlate with maths achievement




J
Halberda






M
M M
Mazzocco






L
Feigenson




10.1038/nature07246








Nature




455


7213
















Calibrating the mental number line




V
Izard






S
Dehaene




10.1016/j.cognition.2007.06.004








Cognition




106


3
















Preschool acuity of the approximate number system correlates with school math ability




M
E
Libertus






L
Feigenson






J
Halberda




10.1111/j.1467--7687.2011.01080.x








Developmental Science




14


6


















M
E
Libertus






L
Feigenson






J
Halberda




10.1016/j.lindif.2013.02.001




Is Approximate Number Precision a Stable Predictor of Math Ability? Learning and Individual Differences






25














The precision of mapping between number words and the approximate number system predicts children's formal math abilities




M
E
Libertus






D
Odic






L
Feigenson






J
Halberda








Journal of Experimental Child Psychology




150


















10.1016/j.jecp.2016.06.003














Approximate number sense shares etiological overlap with mathematics and general cognitive ability




S
L
Lukowski






M
Rosenberg--Lee






L
A
Thompson






S
A
Hart






E
G
Willcutt






R
K
Olson






B
F
Pennington




10.1016/j.intell.2017.08.005








Intelligence




65
















Vision: A Computational Approach




Marr


















Preschoolers' precision of the approximate number system predicts later school mathematics performance




M
M M
Mazzocco






L
Feigenson






J
Halberda




10.1371/journal.pone.0023749








PloS One




6


9
















J
L
Mcclelland






M
M
Botvinick






D
Noelle






D
C
Plaut






T
T
Rogers






M
S
Seidenberg






L
B
Smith




Letting Structure Emerge: Connectionist and Dynamical Systems Appriaches to Cognition. Trends in Cognitive Science
















Basic number processing deficits in developmental dyscalculia: Evidence from eye tracking




K
Moeller






S
Neuburger






L
Kaufmann






K
Landerl






H
C
Nuerk




10.1016/j.cogdev.2009.09.007








Cognitive Development




24


4
















Stable numerosity representations irrespective of magnitude context in macaque prefrontal cortex




M
Moskaleva






A
Nieder




10.1111/ejn.12451








The European Journal of Neuroscience




39


5
















Representation of number in the brain




A
Nieder






S
Dehaene




10.1146/annurev.neuro.051508.135550








Annual Review of Neuroscience




32
















Representation of Quantity of Visual items in the primate prefrontal cortex




A
Nieder






D
Freedman






E
K
Miller








Science




297
















A labeled--line code for small and large numerosities in the monkey prefrontal cortex




A
Nieder






K
Merten




10.1523/JNEUROSCI.1056--07.2007








The Journal of Neuroscience




27


22
















Training the approximate number system improves math proficiency




J
Park






E
M
Brannon




10.1177/0956797613482944








Psychological Science




24


10
















Improving arithmetic performance with number sense training: An investigation of underlying mechanism




J
Park






E
M
Brannon




10.1016/j.cognition.2014.06.011








Cognition




133


1
















The approximate number system acuity redefined: A diffusion model approach




J
Park






J
J
Starns




10.3389/fpsyg.2015.01955








Frontiers in Psychology




6
















Exact and approximate arithmetic in an Amazonian indigene group




P
Pica






C
Lemer






V
Izard






S
Dehaene




10.1126/science.1102085








Science




306


5695
















In how many ways is the approximate number system associated with exact calculation?




P
Pinheiro--Chagas






G
Wood






A
Knops






H
Krinzinger






J
Lonnemann






I
Starling--Alves






Haase




10.1371/journal.pone.0111155








PLoS ONE




11


9














A drift diffusion model account of the semantic congruity effect in a classification paradigm




A
Pirrone






J
A R
Marshall






T
Stafford




10.5964/jnc.v3i1.79








Journal of Numerical Cognition




3


1
















Two--stage dynamic signal detection: a theory of choice, decision time, and confidence




T
J
Pleskac






J
R
Busemeyer




10.1037/a0019737








Psychological Review




117


3
















Connecting neural coding to number cognition: a computational account




R
W
Prather




10.1111/j.1467--7687.2012.01156.x








Developmental Science




15


4
















Numerical discrimination is mediated by neural coding variation




R
W
Prather




10.1016/j.cognition.2014.08.003








Cognition




133


3
















Is variation in approximate number system acuity due to representational precision or accurate decisions?




R
W
Prather


















Neurally constrained modeling of perceptual decision making




B
Purcell






R
P
Heitz






J
Y
Cohen






J
D
Schall






D
Gordon






T
J
Palmeri






T
J
Palmeri




10.1037/a0020311








Psychological Review




117


4
















Domain--Specific and Domain--General Training to Improve Kindergarten Children's Mathematics




G
B
Ramani






S
M
Jaeggi






E
N
Daubert






M
Buschkuehl




10.5964/jnc.v3i2.31








Journal of Numerical Cognition




3


2
















A framework for studying the neurobiology of value--based decision making




A
Rangel






C
Camerer






P
R
Montague




10.1038/nrn2357








Nature Reviews. Neuroscience




9


7
















Associations of non--symbolic and symbolic numerical magnitude processing with mathematical competence: a meta--analysis




M
Schneider






K
Beeres






L
Coban






S
Merz






Susan
Schmidt






S
Stricker






J
De Smedt






B








Developmental Science




3


20
















10.1111/desc.12372














The development of numerical estimation: evidence for multiple representations of numerical quantity




R
S
Siegler






J
E
Opfer








Psychological Science




14


3
















Value and Prediction Error in Medial Frontal Cortex: Integrating the Single--Unit and Systems Levels of Analysis




M
Silvetti






R
Seurinck






T
Verguts




10.3389/fnhum.2011.00075








Frontiers in Human Neuroscience




5
















Working memory capacity as a dynamic process




V
R
Simmering






S
Perone




10.3389/fpsyg.2012.00567








Frontiers in Psychology




3














An entropic barriers diffusion theory of decision--making in multiple alternative tasks. bioRxiv




D
F
Slezak






M
Sigman






G
Cecchi




10.1101/245308








245308












Concurrent validity of approximate number sense tasks in adults and children




K
Smets






T
Gebuis






E
Defever






B
Reynvoet




10.1016/j.actpsy.2014.05.001








Acta Psychologica




150
















Tests of a Dynamic Systems Account of the A--not--B Error : The Influence of Prior Experience on the Spatial Memory Abilities of Two--Year--Olds




J
P
Spencer






L
B
Smith






E
Thelen








72














Choosing the greater of two goods: neural currencies for valuation and decision making




L
P
Sugrue






G
S
Corrado






W
T
Newsome




10.1038/nrn1666








Nature Reviews. Neuroscience




6


5
















Neuronal population coding of continuous and discrete quantity in the primate posterior parietal cortex




O
Tudusciuc






A
Nieder








Neuron




36


104














Is there a generalized magnitude system in the brain? Behavioral, neuroimaging, and computational evidence




F
Van Opstal






T
Verguts






F
Opstal






Van






T
Verguts




10.3389/fpsyg.2013.00435








Frontiers in Psychology




4


435














A theory of magnitude: common cortical metrics of time, space and quantity




V
Walsh




10.1016/j.tics.2003.09.002








Trends in Cognitive Sciences




7


11
















Large number discrimination in 6--month--old infants




F
Xu






E
S
Spelke








Cognition




74

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]