You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
A substantial area of interest within the field of confidence judgment is the examination of the concept of 'confidence' from a metacognitive perspective and the investigation of the factors that make up and influence our subjective 'feeling of knowing' or subjective conviction about the validity of our choice 
(Kanai and Rees, 2011;
Fleming et al., 2012;
Song et al., 2010)
.
Gaining insights into the computational intricacies of how humans utilize (or fail to utilize) available information to draw such metacognitive judgments when making decisions can provide significant insights for engineering various systems, e.g. educational 
(England and Serra, 2012)
, clinical 
(Redelmeier et al., 2001
) and commercial 
(Wu and Cheng, 2011)
, to optimize human decision-making.
Numerous theoretical accounts have explained the cognitive basis of how subjective confidence is constructed (see 
Navajas et al., 2016
 for a review). The majority of these accounts assume that computation of confidence is a decisional process, performed by the same neuronal circuitry that determines the choice. One well-supported reading of these decisional accounts of confidence posits that confidence should (and does) only reflect the probability that the choice was correct 
(Sanders et al., 2016)
. By these accounts, any factor (e.g. perceptual input, action alternative etc.) that the agent experiences after having made her choice would not affect confidence.
However, many experiments have shown that confidence is indeed affected by post-decisional factors. For example, once we have made our decision in our mind, our confidence decreases the longer we have to wait for the opportunity to announce our decision 
(Kiani and Shadlen, 2009)
. Such demonstrations of post-decisional modulations of confidence present critical challenges for the normative accounts of metacognition. 
Tversky and Kahneman (1974)
 illustrated in a number of studies how people rely on various heuristic principles in an attempt to reduce the complexity of inferring probabilities into simpler quantities that guide their judgments. Importantly, these heuristics often distort confidence reports as they are based on factors outside of the distributional representation 
(Barthelme ́ and Mamassian, 2010;
Meyniel et al., 2015)
. Whether the distorting impact of such heuristics on confidence extends to post-decisional computations of confidence is unknown.
One commonly observed post-decisional heuristic in decision-making is anchoring. When making an estimate of a given variable, our judgment is strongly affected if we are given an initial landmark, i.e. an anchor to start from. 
Tversky and Kahneman, (1974)
 suggested that we arrive at our estimate by starting from the anchor and drifting away, but we often fail to drift off adequately. Anchoring effects are prevalent in universal knowledge tasks 
(McElroy and Dowd, 2007)
 and in probability approximations 
(Chapman and Johnson, 1999)
. In addition, 
Oppenheimer et al. (2008)
 showed that anchoring has loose confines and can bias judgments across modalities and dimensions, even in areas such as time estimation. Since confidence is also an estimate of a subjective state, it may be amenable to anchoring 
(Carroll et al., 2009;
Carroll and Petrusic, 2006
. These studies showed that asking participants to first compare their confidence to an initial starting point (e.g. are you more or less confident than 5 out of 6 on a Likert scale?) significantly modulates their subsequent confidence judgments towards the anchor. As a consequence, confidence judgments were affected by random starting points assigned by the experimenter rather than exclusively and accurately reflecting the participant's subjective sense of uncertainty.
As a post-decisional prime that affects confidence, the anchoring effect offers a unique opportunity to empirically challenge the normative, decisional accounts of confidence by asking several questions about the nature of computations of confidence. Previous studies have found consistent individual differences in the way people communicate their inner sense of confidence 
(Ais et al., 2016;
de Gardelle and Mamassian, 2015;
Fleming et al., 2010;
Graziano and Sigman, 2009;
Zylberberg et al., 2014)
. Despite inter-individual differences in the way stimulus variability affected performance accuracy and confidence 
(Zylberberg et al., 2014;
de Gardelle and Mamassian, 2015)
, the mean and shape of the confidence distribution, as well as confidence judgments' correlation with performance were constant across individuals in these studies (de Gardelle and Mamassian, 2015; 
Fleming et al., 2010)
.
These studies show that subjects consistently tracked the mean and variance of different distributions in a similar fashion, in what appears to be an idiosyncratic manner 
(Ais et al., 2016)
. Here, employing the anchoring effect, we asked if the effects of anchoring on confidence are similarly idiosyncratic. We designed two experimental tasks to study confidence judgments under conditions of varying uncertainty. On two different testing days, each participant performed either the cognitive or the perceptual experiment. In both experiments, participants made a choice and expressed their confidence in repeated trials. The initial starting point of the confidence scale was randomized across trials to enable measuring the anchoring of metacognition.


Methods


Participants
Thirty undergraduate psychology students, studying at University College London, participated in the current study (22 female and 8 male, age range: 19-22 years, mean: 20.54 years, SD: 0.88). Signed informed consent was obtained from all participants before completing the study. All participants had normal or corrected to normal vision and had no history of neurological or psychiatric disease. The inclusion criteria -met by all participants was being right-handed and having no history of dyscalculia or epilepsy. The experiment was conducted over two sessions that took place on two different days and all subjects were compensated £30 upon completion of the second session. This study was approved by the University College London Research Ethics Committee.


Display
Stimuli and tasks were programmed in MATLAB version 8.0 (MathWorks) using the Cogent 2000 toolbox (http://www.vislab.ucl.ac.uk/cogent.php). The tasks were displayed on a 21inch LCD display monitor at a 1024 × 768 pixels resolution and a viewing distance of around 60 cm with the display refreshing at a 60 Hz rate.


Stimuli and procedure
Each participant completed two experimental sessions -each on a different day-visual and arithmetic, in a randomized order, with each session lasting around 90 minutes. 'smaller' or 'greater' was then presented and the participant had to choose by pressing either 'q' which corresponded to the choice presented on the left side of the screen or 'p' which corresponded to the choice presented on the right side. The participant was then presented with a scale ranging from 1 to 6 and asked to rate how confident she was about her answer. The inter-trial interval was between 0.7-0.9 seconds. (C) Probability distributions: the stimuli in both tasks were sampled from uniform distributions U(m-v,m+v) where parameters m=+-3 and v=10,14,24,45. (D) Confidence scale: participants were presented with a scale ranging from 1 to 6 and were asked to rate how confident they were about the initial choice. Top left panel: Example of an initial starting point of '2' and a final confidence decision of '3'. Top right panel: Example of an initial starting point of '6' and a final confidence of '4'. (Bottom). The starting point changed its position randomly on each trial.
The visual task consisted of visual displays composed of 30 serially presented Gabor patches that appeared one at a time at the fixation point with a changing orientation, either clockwise or counter clockwise 
(Fig. 1A
).
Participants were asked to report whether the mean orientation of the 30 Gabor patches was tilted clockwise or counter-clockwise relative to the vertical meridian.
In the arithmetic task, participants were asked to decide whether the average of a sequence of numbers was greater or smaller than 50 ( 
Fig. 1B)
.
Each trial consisted of 30 two-digit numbers flashed consecutively at 4 Hz (stimulus duration: 200 milliseconds, inter-stimulus interval: 50 milliseconds), and were presented at a fixation point in the center of the screen. The arrangement and display of stimuli for the perceptual, or orientation discrimination, and the arithmetic tasks were identical with the exception of substituting Gabor patches for digits.
The words 'smaller' or 'greater' for the cognitive task, and '/' or '\' for the perceptual task were then presented on the two sides of the screen and the participant had to choose one option by pressing either the 'q' key on the keyboard corresponding to the word presented on the left side of the screen, or the 'p' key, corresponding to the choice presented on the right side. The location of the two choices changed randomly from one trial to the next and the colors of the number alternated between black and white within each trial, so as to avoid any habituation effects. Participants were presented with a scale ranging from 1 to 6 and asked to rate how confident they were about their answer. Participants used the same two keys to navigate up and down the scale and then pressed 'space bar' on the keyboard to confirm their response and move to the next trial. The starting point of the indicator on the confidence scale changed position randomly across trials. The inter-trial interval lasted between 0.7-0.9 seconds. Following every block of 20 trials, feedback was provided about the number of correct decisions in that block.
Each block had an equal number of trials from each variance condition presented in random order.
Participants reported confidence on a Likert scale (Likert, 1932) by clicking one of two keys on the keyboard ('q' or 'p') to move up or down the values from 1-6 along a horizontal line, which spanned the range from completely unsure on the left to absolute certainty on the right 
(Fig. 1D
).
Subjects were explicitly asked to use the full range of the scale.


Experimental conditions
On each trial, items were sampled from uniform distributions with mean m and four possible variances (defined by the support endpoints m±v). In the visual task, the mean m could either be +3 or -3 degrees and the parameter v could either be 10, 14, 24, or 45 degrees 
(Fig. 1C
). In the numerical task, the mean m could either be 47 or 53, and the parameter v could either be 7, 9, 11, and 33. These parameters were selected through pilot experiments to yield similar performances across both tasks. The distributions were pseudorandomly sampled to ensure that the mean on each trial was exactly m. Half of the participants performed the visual task first.


Data analysis
To analyze the data, we used Matlab R2010 (function rm_anova2 by Schurger from the Matlab Central File Exchange). Confidence ratings were analyzed using a two-way repeated-measures analysis of variance (ANOVA), with performance, starting points, and variance levels as the within-subject variables. This analysis was performed separately for each session (cognitive versus perceptual).
The anchoring effect was measured by calculating the distance between the final confidence value and the initial starting point of the cursor. We calculated the anchoring measure by fitting an ordinal logistic regression (confidence as a function of variance and starting point). The slope represents the anchoring effect with a steeper slope indicating a stronger anchoring effect. The slope is calculated using the following ordinal logistic regression equation:
( > ) = ! + ! + ! + ,
with 1 ≤ < 6, denoting confidence, V denoting variance, Sp denoting starting point, ! are intercepts, and ε as the error term. According to this equation ′ 1 ′ represents the variance effect and ′ 2 ′ represents the anchoring effect. In this model, both the dependent variable (C) and the independent variables (Sp and V) are ordinal.


Results
We observed a significant main effect of variance level on subjects' performance accuracy. Accuracy was higher in low-compared to highvariance conditions ( 
Fig. 2A, C)
. This effect was present both in the perceptual (F (3, 29)= 92.3, p < .001; 
Fig. 2A
) and the cognitive tasks (F (3, 29)= 147.8, p < .001; 
Fig.2C
). There was a similar effect of variance level on confidence ratings; confidence ratings were significantly higher in lowvariance trials as compared to high-variance trials 
(Fig. 2B, D)
. This effect was observed in both the perceptual (F (3, 29)= 41.07, p < .01; 
Figure 2B
) and the cognitive tasks (F (3, 29)= 50.7, p < .01; 
Figure 2D
). These findings show that our experimental manipulations were successful in producing different levels of accuracy and confidence across different variance conditions. 


Anchoring of Confidence
Next, we tested our main hypothesis by looking at whether the arbitrary starting point on the confidence scale had an effect on confidence. Trials with a larger starting point were reported with higher confidence 
(Fig. 3)
. This effect was present in both the perceptual (F (5, 29)= 13,84, p < .001; 
Fig. 3A
) There was no significant interaction effect between the variance level and starting point in either the perceptual (F (15, 29) = 1.40, p= 0.14) or the cognitive task (F (15, 29) = 0.80, p= 0.67). This suggests that the effect of the starting point was independent of the difficulty level of the trial. We will come back to this point in the discussion.


Quantifying the anchoring effect
Our findings show that the starting point in the confidence scale, which was randomly chosen across trials in our tasks, serves as an anchor for confidence. To quantify this anchoring effect and examine differences between individuals, we used a multivariate ordinal regression (see Methods).
We first asked if the anchoring effect was statistically different from zero in our


A B
population. We measured the regression slope for each subject (α 2 , see Methods) and found that they were significantly larger than zero in both the perceptual (t(29)= 2.9, p< 0.001) and cognitive tasks (t(29)= 3.9, p= 0.007).
Next, we focused on the effect of variance on anchoring. In principle, the reliance on anchors could differ across conditions with varying levels of difficulty. To test this, we measured the anchoring effect for each variance condition separately, but we found no effect of variance, in either the perceptual (F (3,29)= 1.26, p= 0.29) or the cognitive task (F (3,29)= 0.8, p= 0.49; 
Fig. 4A
).


Stability and individual differences
We first looked at the stability of the anchoring effect within each task.
We measured the anchoring effect in the first and second halves of each experimental session and then measured the correlation between the two effects obtained from data from each half-session. We observed that these measures were consistently correlated for both the perceptual (r= 0.44 n= 30, p= 0.01) and the cognitive tasks (r= 0.60 n= 30, p< 0.001). This indicates that the anchoring effect was stable over time and idiosyncratic within each task.
Finally, we tested whether the anchoring effect observed in one task was informative of the anchoring effect observed in the other task, we observed that, indeed, anchoring was consistent across tasks (r= 0.74 n= 30, p= 0.001 
(Fig. 4B
). This suggests that the impact of anchors in metacognition is a domain-general property of confidence that is stable across the visual and numerical domain. ----


Discussion
We set out to examine the impact of anchoring on decision confidence.
We conducted two experiments in which participants made categorical decisions in the visual and numerical domains and reported their confidence.
We manipulated anchoring by varying the starting point of the confidence marker on the Likert scale. We found that overall, confidence reports reflected performance accuracy and, more importantly, confidence was consistently anchored by starting points. Furthermore, the anchoring effect was robust because it was both independent of uncertainty and idiosyncratic in nature.
Within each participant, the anchoring effect was stable across time and across two different task domains.
Our findings show that anchoring is observed in the metacognitive process of confidence judgment, specifically in people's subjective reports of their 'feeling of knowing' in choices across perceptual (visual) and cognitive (numerical) domains. They point to an important idiosyncratic bias that was not previously reported in the literature. Previous research in anchoring mainly focused on anchoring choices themselves rather than the agent's confidence estimates in those choices. This marks an important difference between our findings and earlier works showing that susceptibility of choices to anchoring was a function of uncertainty 
(Jacowitz and Kahneman, 1995)
.
The idiosyncratic nature of the observed anchoring effect suggests that the impact of the anchor cannot be explained away as external noise. Thus, we consider a number of alternative explanations. On the one hand, anchoring could be due to laziness. One might euphemistically call this an "effort-reducing" heuristic. When a lazy participant is given a starting point of 5 on a scale of 1 to 6 and his subjective confidence is 2, pure laziness may bring him to a stop at 3, not adjusting enough 
(Tversky & Kahneman, 1974
).
On the other hand, anchoring may arise from the uncertain nature of the decisions and the participant's desire to combine any available (external) cues -such as an anchor -in reporting her confidence. Simple integration of the "post-cue" anchor with the task-related information could lead to anchoring of confidence 
Strack 1999, 2000;
Strack & Mussweiler, 1997)
.
However, the more sophisticated versions of cue integration models posit that each cue is weighted by its variance such that increasing the variance in one type of information would increase the contribution of the other cues to the choice 
(Deneve, Latham, & Pouget, 2001
). This view would predict stronger anchoring with increasing uncertainty in high variance conditions, which is inconsistent with our data.
Our findings are inconsistent with the previously proposed view that self-monitoring is immune to anchoring effects. Proponents of this view claim that our judgments of ourselves are based on extensive, ordered information and that individuals tend to prefer information that is congruent with their selfperception 
(Quattrone et al., 1985;
Tversky & Kahneman, 1974)
. Since confidence judgments are conspicuously self-evaluative, a strong reading of these previous works would be inconsistent with our data. However, there is an important distinction to be made between confidence in one's self and confidence in a specific judgment. Thus, one can argue that the confidence probed in our experiments has a transient, state-like quality that separates it from the more stable, trait-like self-evaluations that those previous studies might have been referring to.


Conceptualization of debiasing influences that depend on first breaking
down the psychological mechanisms underlying a bias and then designing a counteractive plan to offset these mechanisms is an effective way of improving human judgment 
(Lord, Lepper, & Preston, 1984)
. The 'consider-
the-opposite' strategy has been effective in reducing overconfidence in the accuracy of one's performance by making contradictory evidence more salient 
(Griffin, Dunning, & Ross, 1990)
. Future studies are needed to investigate whether this, or other strategies, is effective in attenuating anchoring effects in metacognitive judgments of confidence. However, the knowledge that anchoring does indeed affect metacognition is useful in and of itself, because it can be used to mitigate introduction of unintentional biases when constructing future instruments.
In summary, this study presents evidence for how our sense of confidence can be distorted by external factors that interfere with postdecisional processing and how such a tendency is intrinsic to behavior regardless of task domain or the level of uncertainty. Research on individual difference in confidence reporting has identified various heuristics 
(Merkle, 2009;
Baranski & Petrusic, 1994;
Zylberberg et al. 2014
 The table shows the actual numerical values for figure 3(A). 
We deconstructed this question to several components: (a) is anchoring of confidence reports stable and predictable across time within each participant? (b) Is such anchoring effect domain-specific or rather, traitlike and domain-general across perceptual and cognitive modalities? In other words, is a given participant's vulnerability to anchoring of confidence in a visual perceptual task predictive of anchoring when she is making numerical (arithmetic) judgments? Finally, (c) does the magnitude of anchoring depend on informational uncertainty and task difficulty? This latter question is particularly important for the normative accounts of confidence (see Discussion).


Figure 1 .
1
(A) Timeline of the perceptual task: subjects made a decision of whether the average orientation of 30 consecutively presented Gabor patches was tilted clockwise or counterclockwise relative to the vertical meridian, and stated their confidence. The choice screen presented '/' to indicate clockwise and '\' to indicate counterclockwise, the positions changed randomly on the right and left of the screen on each trial. The inter-trial interval was randomly sampled between 0.7-0.9 seconds. (B) Timeline of the cognitive task: subjects made a decision of whether the average of 30 consecutively presented numbers was above or below '50', and were asked to state their confidence. Each trial consisted of 30 two-digit numbers flashed consecutively. A screen displaying the words


Figure
Figure 2. (A,C) Performance accuracy as a function of variance for the perceptual (A) and cognitive (C) tasks. In both tasks, the rate of correct answers decreased as variance increased for the perceptual task. This indicates that as uncertainty increased, subjects made more erroneous decisions. (B,D) Confidence as a function of variance for the perceptual (B) and cognitive (D) tasks. Confidence decreased with increasing variance. The error bars in all panels represent the standard error of the mean (SEM).


Figure 3 .
3
Confidence as a function of starting point for the (A) perceptual and (B) cognitive tasks. The increase in confidence ratings for each variance level clearly shows the effect of starting point at each level of task difficulty. Error bars represent the standard error of the mean (SEM).


Figure 4 .
4
(A) Susceptibility to anchoring as a function of variance condition (uncertainty); there is no significant effect of variance level on anchoring in either the cognitive or the perceptual tasks. The error bars represent the standard error of the mean (SEM). (B) Anchoring effect across domains; there is a positive correlation in the anchoring effect between the perceptual and cognitive tasks. A B


Table 1. Mean confidence ratings in the perceptual task (Variance (V) x
Supplementary Material 1
starting point (Sp))
V=10
V = 14
V = 24
V = 45
Sp =1
3.6437
3.4913
3.3665
2.9951
Sp =2
3.6910
3.5156
3.3335
3.1537
Sp =3
3.7968
3.7172
3.3695
3.1638
Sp =4
3.9252
3.6748
3.5832
3.2055
Sp =5
3.8940
3.7678
3.4115
3.3079
Sp =6
3.8385
3.7357
3.5171
3.2433
; Griffin & Tversky,


Table 2 .
2
Mean confidence ratings for the cognitive task (Variance (V) x The table shows the actual numerical values for figure 3(B).
starting point (Sp))
V=10
V = 14
V = 24
V = 45
Sp =1
3.9271
3.7488
3.4409
3.0606
Sp =2
4.0657
3.7851
3.5863
3.1263
Sp =3
4.1735
3.9827
3.5859
3.2745
Sp =4
4.3354
4.0468
3.8035
3.3568
Sp =5
4.2629
4.0585
3.7704
3.4078
Sp =6
4.3260
4.0275
3.8561
3.3357








1992; Kahneman, 2013), our findings add anchoring as a significant bias that is persistent across metacognitive reports of confidence.












Individual consistency in the accuracy and distribution of confidence judgments




J
Ais






A
Zylberberg






P
Barttfeld






M
Sigman








Cognition




146
















The calibration and resolution of confidence in perceptual judgments. Attention, Perception and Psychophysics




J
Baranski






W
Petrusic








55














Flexible mechanisms underlie the evaluation of visual confidence




S
Barthelme






P
Mamassian








Proceedings of the National Academy of Sciences




107
















On the Locus and Time Course of Confidence Processing




S
Carroll






W
Petrusic








Proceedings of Fechner Day


Fechner Day






22












Numerical Distance and Anchoring Effects in Judging confidence




S
Carroll






W
Petrusic








Proceedings of Fechner Day


Fechner Day






23












The Time Course of Confidence Judgments




S
Carroll






W
Petrusic








Proceedings of Fechner Day




24
















Anchoring effects in the judgment of confidence: Semantic or numeric priming? Attention




S
Carroll






W
Petrusic






C
Leth-Steensen








Perception & Psychophysics




71
















Anchoring, activation, and the construction of values




G
Chapman






E
Johnson








Organizational Behavior and Human Decision Processes




79
















Weighting mean and variability during confidence judgments




V
De Gardelle






P
Mamassian








PloS one




10


3


120870














Efficient computation and cue integration with noisy population codes




S
Deneve






P
Latham






A
Pouget








Neuroscience




4


8
















The contributions of anchoring and past-test performance to the underconfidence-with-practice effect




B
D
England






M
J
Serra








Psychonomic bulletin & review




19


4
















The neural basis of metacognitive ability




S
Fleming






R
Dolan








Philosophical transactions of the royal society of London, Series B, biological sciences






367


















S
M
Fleming






R
S
Weil






Z
Nagy






R
J
Dolan






G
Rees


















Relating introspective accuracy to individual differences in brain structure






Science




329


5998














The spatial and temporal construction of confidence in the visual scene




M
Graziano






M
Sigman








PLoS One




4


3


4909














The role of construal processes in overconfident predictions about the self and others




D
Griffin






D
Dunning






L
Ross








Journal of Personality and Social Psychology




59
















The weighing of evidence and the determinants of confidence




D
Griffin






A
Tversky








Cognitive Psychology




24
















Measures of Anchoring in




K
Jacowitz






D
Kahneman


















Estimation Tasks. Personality and social psychology bulletin




21














The structural basis of inter-individual differences in human behaviour and cognition




R
Kanai






G
Rees








Nature Reviews Neuroscience




12
















Representation of confidence associated with a decision by neurons in the parietal cortex




R
Kiani






M
Shadlen








Science




324
















Considering the opposite: a corrective strategy for social judgment




C
G
Lord






M
R
Lepper






E
Preston








Journal of personality and social psychology




47


6


1231














Susceptibility to anchoring effects: how openness-to-experience influences responses to anchoring cues




T
Mcelroy






K
Dowd








Judgment and Decision Making




2
















The disutility of the hard-easy effect in choice confidence




E
C
Merkle




10.3758/PBR.16.1.204






Psychonomic Bulletin & Review




16


1


















F
Meyniel






M
Sigman






Z
Mainen








Confidence as Bayesian Probability: From Neural Origins to Behavior






88














Numeric judgments under uncertainty: The role of knowledge in anchoring




T
Mussweiler






F
Strack








Journal of Experimental Social Psychology




36
















Numeric judgments under uncertainty: The role of knowledge in anchoring




T
Mussweiler






F
Strack








Journal of Experimental Social Psychology




36
















Post-decisional accounts of biases in confidence




J
Navajas






B
Bahrami






P
E
Latham








Current Opinion in Behavioral Sciences




11
















Anchors aweigh: a demonstration of cross-modality anchoring and magnitude priming




D
Oppenheimer






R
Leboeuf






N
Brewer








Cognition




106




















G
Quattrone






C
Lawrence






D
Warren






K
Sousa-Silva






S
Finkei














On overcoming the anchoring bias across a number of domains. Unpublished manuscript




D
Andrus












Stanford University












Problems for clinical judgement: introducing cognitive psychology as one more basic science




D
A
Redelmeier






L
E
Ferris






J
V
Tu






J
E
Hux






M
J
Schull








Canadian Medical Association Journal




164


3
















Signatures of a statistical computation in the human sense of confidence




J
I
Sanders






B
Hangya






A
Kepecs








Neuron




90


3
















Relating inter-individual differences in metacognitive performance on different perceptual tasks




C
Song






R
Kanai






S
Fleming






R
Weil






D
Schwarzkopf






G
Rees








Consciousness and cognition




20


4
















Explaining the enigmatic anchoring effect: mechanisms of selective accessibility




F
Strack






T
Mussweiler








Journal of Personality and Social Psychology




73




















A
Tversky






D
Kahneman












Judgment under uncertainty










Biases
Heuristics




Utility, probability, and human decision making


Netherlands




Springer














The joint effect of framing and anchoring on internet buyers' decision-making




C
S
Wu






F
F
Cheng








Electronic Commerce Research and Applications




10


3




















A
Zylberberg




cognition








P
R
Roelfsema




cognition








M
Sigman




cognition










27















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]