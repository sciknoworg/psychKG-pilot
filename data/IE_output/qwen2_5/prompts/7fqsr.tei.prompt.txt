You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Planning is a form of decision-making that involves the mental simulation of potential futures. Everyday life frequently requires planning for achieving short and long-term goals, from selecting the most efficient commute home to making sound investment choices. A large cognitive development literature has demonstrated that planning improves from childhood well into early adulthood 
(Albert & Steinberg, 2011;
Korkman, Kemp, & Kirk, 2001;
McCormack & Atance, 2011)
. However, prior studies have not yet characterized the development of the component processes that underlie planning within a single task. Planning is a particularly complex construct that has several cognitive component processes: to evaluate a potential sequence of actions, one must identify and attend to relevant features of the current state, and mentally simulate potential actions and their future consequences within working memory 
(Sutton & Barto, 2018)
.
In recent years, there has been a growing focus on characterizing the cognitive computations underlying planning using simple decision-making tasks that are amenable to detailed mathematical modeling 
(Daw, Gershman, Seymour, Dayan, & Dolan, 2011;
Huys et al., 2012)
. The paradigmatic example is the Two-Step Task 
(Daw et al., 2011
), a reinforcement learning task which dissociates model-based and model-free decision-making 
(Drummond & Niv, 2020)
. In the past decade, this task has been widely used in developmental studies 
(Decker, Otto, Daw, & Hartley, 2016;
Potter, Bryce, & Hartley, 2017;
Vaghi et al., 2020)
. However, a shortcoming of the two-step task is that it only requires two steps of thinking ahead, and the resulting decision tree is small enough to exhaustively explore. Other current assays of planning, including the widely used Tower of London are comparatively simple, and the simplicity limits their capacity to assess the strategies involved in complex planning, where the decision tree is too large to render exhaustive search feasible 
(van Opheusden & Ma, 2019)
. Real-world planning is often of this nature. In planning tasks with large decision trees, the value of intermediate states is often uncertain and has to be evaluated through heuristic means 
(Sutton & Barto, 2018)
. Additionally, the small number of distinct states that participants encounter and the number of actions available in a given state in the current planning tasks limit their ability to distinguish the cognitive component processes of planning, such as the ability to evaluate states, think ahead, and attend to state features. As a result, there is a need for a sufficiently rich planning paradigm in which age-related changes in these component processes can be examined. Accordingly, the current study proposes a child-friendly game -the Four-in-arow task 
(van Opheusden, Galbiati, Kuperwajs, Bnaya, & Ma, 2021)
 -and a corresponding computational modeling framework as a means to formally quantify the maturation of complex planning and its cognitive component processes across development.


Methods


Participants and procedure
Participants were 8 to 25 years old (n = 156), uniformly distributed across age and gender. We excluded participants who were color blind, not fluent in English, or had a learning disability, neurodevelopmental disorder, or psychiatric disorder. Prior to the study, we instructed participants that they would be compensated with a $15 Amazon gift card for full participation, plus a performance-based bonus; in reality, all participants were compensated with a $17 Amazon gift card. Parental permission and child assent were obtained prior to participation. Participants first completed the Four-in-a-row Task, then individual differences in fluid reasoning, daily life impulsive choices and orientation towards future events were assessed using the Matrix Reasoning Item Bank (MaRs-IB 
(Chierchia et al., 2019)
), Barratt Impulsiveness Scale -Brief (BIS-Brief 
(Steinberg, Sharp, Stanford, & Tharp, 2013)
), and the Future Orientation Scale (FOS 
(Steinberg et al., 2009)
), respectively. The study took place online. Participants were automatically directed from one task to the next. This study was approved by the Institutional Review Board at New York University (IRB-FY2016-1194).


Four-in-a-row
The Four-in-a-row Task is a variant of Tic-Tac-Toe. The player and the computer opponent alternate placing tokens on a 4-by-9 board ( 
Fig 1A)
, and the first to complete four in a row (horizontally, vertically, or diagonally) wins. If no player wins before the board fills, the game is drawn. We chose this board size to allow for sufficiently many winning opportunities, while being small enough to be experimentally and computationally tractable. The task was programmed in JavaScript and played in a web browser. The computer opponents were calibrated to human play to create a wide range of difficulty levels, which were then used in a staircasing algorithm to approximate a 2 win to 1 loss ratio (see below). The task began with brief written instructions followed by a comprehension check to ensure that participants understood all three winning Four-in-a row orientations (i.e., diagonal, horizontal, and vertical). This was quizzed in the form of three multiple choice questions, where participants were shown final game states and were asked to indicate the winner of the game. If the response was incorrect, the instructions were repeated. After the quiz, the main task started, consisting of 35 games. Simulations demonstrated that 35 games were sufficient to reliably estimate the computational model parameters. The task has approximately 1.2 × 10 16 non-terminal states and therefore has a state space complexity that far exceeds tasks commonly used in cognitive science 
(van Opheusden & Ma, 2019
). Yet, this task has proven to be amenable to rigorous computational modeling 
(van Opheusden et al., 2021)
.
The computer opponents' algorithm was similar to our main model (see below). We created 200 computer opponents that all used the same algorithm but with different parameters. We started by fitting the model on all participants in laboratory experiments from 
(van Opheusden et al., 2021)
, resulting in 1650 agents. We then ran an all-versus-all tournament between these 1650 agents and ranked their performance using the Elo system (see below). Finally, we selected 200 agents such that their Elo ratings uniformly covered an interval ranging from slightly weaker than the worst human players to slightly stronger than the best. We fine-tuned this interval in pilot experiments. We divided the set of 200 agents into 20 categories, with 10 agents per category. We matched participants with computer opponents using a two-win-to-one-loss staircase, starting at category 2. That is, when a participant won two consecutive games, the category of their opponent in the next game increased by one. When a participant lost, the category decreased by one, and after a draw the category was kept keep the same. An opponent was randomly selected from the 10 agents within that category.
We estimated the depth of planning from a participant's moves using the computational model in 
(van Opheusden et al., 2021)
. This model combines a heuristic value function with best-first search. The value function V (s) assigns values to board states s. We use a weighted linear sum of features
V (s) = 4 ∑ i=0 w i f i (s),
(1)
where f i denote the features and w i their weights. We use 5 features: center, connected 2-in-a-row, unconnected 2-in-arow, 3-in-a-row and 4-in-a-row. The center feature measures how close to the center of the board a player's pieces are distributed, and the other 4 features count how often the corresponding patterns occur on the board. The evaluation function guides the construction of a decision tree 
(Fig. 1D
), using a best-first search algorithm. This algorithm explores promising branches of the decision tree first, thus focusing computational resources on relevant branches of the tree. More precisely, given a partially constructed decision tree, the algorithm decides which node to consider next by exploring the principal variation, that is, the sequence that results if both players choose the highest-value moves in the current tree. The algorithm expands the final node in this principal variation, evaluates candidate moves using the value function defined above, backpropagates the result according to the minimax rule, and continues to the next iteration. After each iteration, the model has a probability γ to terminate search, and make the move that is best according to its current tree.
The model contains additional components which improve its ability to match human data. First, we include a pruning rule: when expanding a node, we prune all candidate moves whose value differs from the best by more than a threshold ω. To account for variability in people's choices, we add three sources of noise. First, before constructing the decision tree, we randomly drop features at specific locations and orientations with a probability δ; these features are omitted during the calculation of V (s). This mechanism is intended to account for attentional oversights. Second, during tree search, we add Gaussian noise to V (s) at each node. Finally, we also include a generic lapse rate λ. For details on the computational model, see 
(van Opheusden et al., 2021)
. Model-derived metrics There are four model-derived metrics: Playing strength (Elo ratings), planning depth, heuristic quality, and feature drop rate. To estimate a participant's playing strength from games against computer opponents, we used the Elo system 
(Elo, 1978)
, implemented using the publicly available Bayeselo algorithm (https://www.remicoulom.fr/Bayesian-Elo/). This algorithm treats the problem as a Bayesian parameter estimation problem, with a model that specifies the probability of a win/loss as a logistic function of the rating difference of the players. The algorithm takes as input a database of game results and estimates all ratings. Constant offsets to all players' ratings do not affect the predictions of the algorithm. Individual players' Elo ratings are sufficiently precise that they can be used as a metric for playing strength.
Planning depth was estimated as follows: After fitting the parameters of our main model for a given participant, we ran the model forward in generative mode. In each position, we generated 100 simulations using the fitted parameters. In each simulation, we recorded the depth of the principal variation (sequence of moves considered best); we then averaged across simulations and positions. The result is the planning depth estimate for that participant. Heuristic quality was defined as the correlation between V (s, w) and the objective value (1 for wins, −1 for losses, 0 for draws), across a pre-generated set of observed game states s. The heuristic quality only depends on the feature weights in the model, and not on the parameters of the tree search algorithm. The feature drop rate is simply the parameter δ in the model.


Results


Descriptive statistics
With age, participants took longer on average to make a move (correlation between decision time and age: ρ = 0.234, p = 0.003) and made more moves per game (ρ = 0.200, p = 0.012. Opponent category stabilized over games for all ages, which suggests that the staircasing algorithm converged within the 35 games.


Age-related differences in model-derived metrics
We tested both linear and polynomial age models on the model-derived metrics and report the results for the best fitting age model. The metrics contained influential outliers in the residuals, therefore, we applied robust regression using the bisquare weighting function, which downweighs mild outliers and deletes extreme outliers (those which are > 6 times the median absolute deviation of the residuals are set to zero weight).
We found that performance on the planning task improved with age, as shown by an age-related improvement in Elo ratings, especially during early adolescence (linear age effect B = 58.46, p = 8.55 • 10 −8 , 95% CI [37.93; 78.99], quadratic age effect B = -30.77, p = 6.06•10 −3 , 95%CI 
[-52.62; -8
.92]) (see 
Fig.2A
). As a result of the five-fold cross validation method, each subject had five estimates of planning depth, heuristic quality, and feature drop rate. The average of each metric per subject was therefore used as a dependent variable in the regression models. We found that planning depth monotonically improved with age (B = 0.83, p = 1.45•10 −6 , 95%CI[0.50; 1.16]), while heuristic quality showed a polynomial age effect, suggesting that age-related improvements in heuristic quality emerged most strongly between childhood and early adolescence (linear B = 0.03, p= 5.37•10 −7 , 95% CI[0.02; 0.04]; quadratic: B = -0.02, p = 2.32•10 −3 , 95% CI[-0.03; -0.01]). Feature drop rate did not significantly change with age (B = 0.00, p = 0.884, 95% CI[-0.02; 0.02]).


Relation between Elo and model-derived metrics
Next, we used robust regression models to predict Elo ratings using planning depth, heuristic quality, feature drop rate, and their interaction with age. We found that planning depth and heuristic quality indeed showed age-dependent effects on Elo ratings 
(Fig.2B)
. Specifically, planning depth became more predictive of Elo ratings with age (interaction between planning depth and age B = 35.17, p = 1.19•10 −4 , 95% CI[17.59, 52.75]), while heuristic quality became less predictive of Elo ratings with age (interaction between age heuristic quality and age B = -38.82, p = 1.48•10 −5 , 95% CI 
[-55.94, -21
.70]). These findings suggest an order in which these cognitive component processes contribute to solving planning problems, by first relying most on heuristic quality at younger ages, and with age, gradually plan by expanding the tree size. In addition, lower feature drop rate was associated with better playing strength (main effect B = -38.19, p = 9.60•10 −6 , 95% CI 
[-54.65, -21.73]
) and this relationship did not differ significantly with age (interaction effect B = -4.07, p = 0.615, 95% CI 
[-20.04, 11.90]
), which confirm that fewer attentional oversights were associated with better Four-in-a-row playing strength and that this relation did not change with age.
Post-hoc robust regressions per age group were performed to further explore the interactions between age and planning depth and age and heuristic quality. We applied Bonferroni-Holm corrections for multiple comparisons. We found that heuristic quality was significantly predictive of Elo ratings for Illustration of the algorithm. Black is playing in the leftmost position, and considers three potential moves whose values are calculated using V (s). The top configuration is propagated back to the root node and subsequently further expanded because it has the highest value. Now three moves that white could make in response are considered, and the one with the lowest value (since it is the opponent's move) is selected and will be propagated back to the parent node in the tree. That value will be compared against its alternatives to decide in which direction to expand the tree in the algorithm's next iteration. (D) Actual decision tree for one simulation in one position for one participant, after parameter fitting. Red: principal variation, the sequence of most promising moves for both players. In this example, the depth of planning is 5. Different branches are evaluated to different depths. the 8-12 year olds (B = 87.46, p = 6.98•10 −5 , 95% 
CI[46.96,
127.95]
), but planning depth and feature drop rate were not (planning depth B = 10.23, p = 0.608, 95% CI 
[-29.61, 50.07]
; feature drop B = -33.50, p = 0.110, 95% CI 
[-75.01, 8.03]
). For the 13-17 year olds, heuristic quality remained a significant predictor of Elo ratings (B = 55.03, p = 5.95•10 −4 , 95% 
CI[24.97,
85.10]
). Feature drop rate additionally became a significant predictor (B = -43.44, p = 0.634•10 −3 , 95% CI 
[-74.03, -12
.86]), but not planning depth (B = -7.22, p = 0.622, 95% CI 
[-36.50, 22.05]
). For 18-25 year olds, heuristic quality was no longer significantly predictive of Elo ratings (B = -11.97, p = 0.250, 95% CI 
[-32.64, 8.70]
). Instead, for this age group planning depth was most predictive of Elo (B = 72.49, p= 1.61•10 −8 , 95% CI 
[-51.06, 93.92]
) followed by feature drop rate (B = -31.55, p = 0.005, 95% CI 
[-52.98, -10.12]
). Together, these results further support an age-related shift in the use of the cognitive component processes that underlie planning decisions, with heuristic refinement during childhood to increasingly dominant reliance on expanding the decision tree towards young adulthood.


Individual differences
Age and fluid reasoning were positively correlated (Spearman's ρ = 0.301, p = 1.80•10 −4 ). Robust mediation anal-yses with fluid reasoning as a mediator were performed on model-derived metrics demonstrating evidence of age-related change (i.e., planning depth and heuristic quality) using 5000 bootstrapped replicates. While fluid reasoning partially mediated the relationship between age and heuristic quality (bootstrapped total effect 0.162, p = 2.40•10 −4 ), the relationship between age and heuristic quality remained significant (bootstrapped direct effect 0.135, p = 1.61•10 −3 ), confirming that heuristic quality improved with age. Fluid reasoning also partially mediated the relationship between age and planning depth (bootstrapped total effect 0.359, p = 2.88•10 −6 ), again not fully accounting for the age-related changes seen in planning depth (bootstrapped direct effect 0.295, p = 4.83•10 −05 ). Together, these results suggest that the age-related changes in heuristic quality and planning depth were not fully explained by individual variation in fluid reasoning, which supports the interpretation that they are unique measures.
As expected, self-reports showed an increase in daily life future orientation with age (ρ = 0.374, p = 1.661•10 −6 ) and a decrease in impulsive choices, albeit to lesser extent (ρ = -0.177, p = 0.027). However, we did not find a relation between either measures and any of the metrics (all p ≥ 0.156) after controlling for age. This suggests that the Four-in-a-row model-derived metrics capture different cognitive processes  


Discussion
Previous studies have not yet distinguished between the developmental trajectories of different cognitive component processes underlying planning decisions. Measuring planning ability is notoriously complex as it relies on heuristics, forward reasoning, and attention (Ward and 
Morris, 2004)
. Here we used a novel task called "Four-in-a-row" and a computational model to assess the developmental trajectories of these distinct cognitive components. Four-in-a-row has a larger state space than existing planning tasks 
(van Opheusden & Ma, 2019)
. This large state space makes it impossible to make a decision by reasoning about all the steps needed to reach a goal state, including reasoning backwards from a goal state. Thereby, Four-in-a-row is a planning task with increased ecological validity for real-world complex planning problems.
As expected, Four-in-a-row playing strength, as measured by Elo ratings, improved with age. By fitting a best-firstsearch computational model, we found distinct developmental trajectories of cognitive component processes that accounted for this improvement. Specifically, at younger ages (approximately early to mid-adolescence), we observed a rapid improvement in heuristic quality, which contributed to better playing strength. In contrast, planning ability showed stronger improvement and supported better playing strength at older ages (approximately mid to late-adolescence). Fewer attentional oversights were associated with better playing strength and did not show age differences. Together, these results suggest an order in which the use of cognitive component processes of planning develop into, during, and out of adolescence, starting by first refining the heuristic strategies, then gradually increasing the number possible future actions, states, and consequences considered towards young adulthood.
To further examine the uniqueness and novelty of the model-derived metrics, we assessed to what extent variation in planning depth and heuristic quality could be explained by individual differences in fluid reasoning (the capacity to apply logic to solve problems in new situations), future orientation, and impulsivity. We focused our analyses on planning depth and heuristic quality, as these showed age-related changes. As expected based on previous studies 
(Cattell, 1987;
Ferrer & McArdle, 2004;
Albert & Steinberg, 2011)
, fluid reasoning and future orientation increased with age, while impulsivity decreased. Neither planning depth nor heuristic quality was correlated with self-reported future orientation or impulsivity. Moreover, fluid reasoning only partially mediated the developmental changes in both planning depth and heuristic quality. These results complement a prior study in which fluid reasoning was found to be an important component process of model-based learning 
(Potter et al., 2017)
. Finding that fluid reasoning only partially mediated the relation between age and planning depth is consistent with the notion that planning crucially involves thinking ahead about future states, actions, and outcomes (i.e. planning depth), which is not part of fluid reasoning.
Our findings contribute to the growing literature on the development of model-based decision-making and reinforcement learning (for review see 
(Drummond & Niv, 2020)
). Model-based decisions are more prevalent when playing Four-in-a-row than model-free decisions, as participants often encounter novel states in this task. Of all the states our participants encountered, on average 88.7% (sd = 2.0%) were unique states that the participant did not observe before. It is particularly important to understand age-related change in model-based decision-making, as several recent studies suggest that it shows a more protracted development than modelfree learning 
(Decker et al., 2016;
Palminteri, Kilford, Coricelli, & Blakemore, 2016;
Potter et al., 2017)
 (but see 
(Smid, Kool, Hauser, & Steinbeis, 2020)
. Our findings contribute to the literature of model-based decision-making by, for the first time, examining planning in a large state-space and revealing distinct developmental trajectories of the component processes that underlie planning.
Taken together, the current study investigated the developmental trajectories of heuristic quality, planning depth, and feature drop rate in a single planning task. In the future, our approach may be useful for the study of psychiatric disorders, as planning deficits are prevalent in a wide range of disorders, including ADHD, OCD, and schizophrenia 
(Harrier & DeOrnellas, 2005;
Kofman, Gidley Larson, & Mostofsky, 2008;
Nigg, Blaskey, Huang-Pollock, & Rappley, 2002;
Morris, Rushe, Woodruffe, & Murray, 1995)
. Further research is needed to identify how our model-derived metrics relate to other cognitive mechanisms. Planning depth for example, likely relies on working memory to remember the consequences of possible moves 
(Gilhooly, 2005)
. Nevertheless, our findings move the field of cognitive development towards a more complete account of the development of planning and its component processes.
Figure 1 :
1
Four-in-a-row planning task and computational model re-printed from van Opheusden et al. (2021) with permission. (A) Example board position in the Four-in-a-row game. Two players, black and white, alternate placing pieces on the board, and the first player to achieve 4-in-a-row wins the game. In this position, black is about to win by moving on the 3rd square in the bottom row (open circle, mouse cursor). (B) Features used in the heuristic function. Features with identical colors are constrained to have identical weights. The model also includes a central tendency feature and a 4-in-a-row feature. (C)


A
. Elo ratings and model-derived metrics B. Relation between model-derived metrics and Elo ratings


Figure 2 :
2
A. Elo ratings and Model-derived metrics per age bin (in years). Age was a continuous variable in the analyses; bins are for visualization purposes. Line represents the median per group and the errorbars show the bootstrapped 95% confidence interval of the median. B. Elo rating as a function of the model-derived metrics per age bin. Lines show the robust regression fit and the bootstrapped 95% confidence interval. In all plots light green = children (8-12 years old), green = adolescents (13-17 years old), dark green = adults (18-25 years old) than those indexed by these self-report measures.














Age differences in strategic planning as indexed by the tower of london




D
Albert






L
Steinberg








82








Child development








Intelligence: Its structure, growth and action




R
B
Cattell








Elsevier












The matrix reasoning item bank (mars-ib): novel, open-access abstract reasoning items for adolescents and adults




G
Chierchia






D
Fuhrmann






L
J
Knoll






B
P
Pi-Sunyer






A
L
Sakhardande






S.-J
Blakemore








Royal Society open science




6


10














Model-based influences on humans' choices and striatal prediction errors




N
D
Daw






S
J
Gershman






B
Seymour






P
Dayan






R
J
Dolan








Neuron




69


6
















From creatures of habit to goal-directed learners: Tracking the developmental emergence of model-based reinforcement learning




J
H
Decker






A
R
Otto






N
D
Daw






C
A
Hartley








Psychological science




27


6
















Model-based decision making and model-free learning




N
Drummond






Y
Niv








Current Biology




30


15
















The ratings of chess players. Past and Present




A
Elo








Arco Pub












An experimental analysis of dynamic hypotheses about cognitive abilities and achievement from childhood to early adulthood. Developmental psychology




E
Ferrer






J
J
Mcardle








40


935












Working memory and planning. The cognitive psychology of planning




K
Gilhooly




















Performance of children diagnosed with adhd on selected planning and reconstitution tests




L
K
Harrier






K
Deornellas








Applied Neuropsychology




12


2
















Bonsai trees in your head: how the Pavlovian system sculpts goal-directed choices by pruning decision trees




Q
J
Huys






N
Eshel






E
O'nions






L
Sheridan






P
Dayan






J
P
Roiser








PLoS computational biology




8


3


1002410














A novel task for examining strategic planning: Evidence for impairment in children with adhd




O
Kofman






J
Gidley Larson






S
H
Mostofsky








Journal of Clinical and Experimental Neuropsychology




30


3
















Effects of age on neurocognitive measures of children ages 5 to 12: A cross-sectional study on 800 children from the united states




M
Korkman






S
L
Kemp






U
Kirk








Developmental neuropsychology




20


1
















Planning in young children: A review and synthesis




T
Mccormack






C
M
Atance








Developmental Review




31


1
















Problem solving in schizophrenia: a specific deficit in planning ability




R
G
Morris






T
Rushe






P
Woodruffe






R
Murray








Schizophrenia research




14


3
















Neuropsychological executive functions and dsm-iv adhd subtypes




J
T
Nigg






L
G
Blaskey






C
L
Huang-Pollock






M
D
Rappley








Journal of the American Academy of Child & Adolescent Psychiatry




41


1
















The computational development of reinforcement learning during adolescence




S
Palminteri






E
J
Kilford






G
Coricelli






S.-J
Blakemore








PLoS computational biology




12


6


1004953














Cognitive components underpinning the development of model-based learning




T
C
Potter






N
V
Bryce






C
A
Hartley








Developmental Cognitive Neuroscience




25




















C
R
Smid






W
Kool






T
U
Hauser






N
Steinbeis


















Model-based decision-making and its metacontrol in childhood












Age differences in future orientation and delay discounting




L
Steinberg






S
Graham






L
O'brien






J
Woolard






E
Cauffman






M
Banich








Child development




80


1
















New tricks for an old measure: The development of the barratt impulsiveness scale-brief (bis-brief)




L
Steinberg






C
Sharp






M
S
Stanford






A
T
Tharp








Psychological assessment




25


1


216














Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT press












Compulsivity is linked to reduced adolescent development of goal-directed control and frontostriatal functional connectivity




M
M
Vaghi






M
Moutoussis






F
Váša






R
A
Kievit






T
U
Hauser






P
E
Vértes








Proceedings of the National Academy of Sciences




117


41








others (2020)








Revealing the impact of expertise on human planning with a two-player board game




B
Van Opheusden






G
Galbiati






I
Kuperwajs






Z
Bnaya






W
J
Ma








Current Opinion in Behavioral Sciences


PsyArXiv. van Opheusden, B., & Ma, W. J.




29










Tasks for aligning human and machine planning









"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]