You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
In previous survey studies using decision-making vignettes in which respondents rated and ranked the appropriateness of universally implementing one intervention for all relevant people (A), universally implementing another intervention (B), or conducting an experiment (or A/B test) to compare these interventions before implementing the superior one, we have found that people are often averse to the A/B test, even when they approve of implementing either of the interventions the experiment contains 
(Heck et al., 2020;
Meyer et al., 2019)
. However, these vignettes did not say explicitly whether or not consent to the A/B test-or to universal imposition of either A or B, untested-would be obtained. In a preregistered analysis, when we asked respondents in four of our previous survey experiments to explain their rating, 18% of those who rated the A/B test commented negatively on the apparent lack of consent, compared to fewer than 1% of participants who rated the A or B conditions offering the same objection 
(Meyer et al., 2019
).
Because implementing A and implementing B, collectively, entail imposing the same risks on people as conducting an A/B test, this contrast is puzzling. Moreover, pragmatic trials of the sort our vignettes describe are often not feasible to conduct with consent. Although it is a common misconception that human subjects research always requires informed consent, the U.S. Policy for Protection of Human Research Subjects (better known as the Common Rule) explicitly permits institutional review boards (IRBs) to waive consent when certain conditions apply, including that the study involves no more than minimal risk to participants and that the research could not practicably be conducted without a waiver 
(45 CFR § 46.116(f)
). The Common Rule also only applies to "research," i.e., activities that are "designed to develop or contribute to generalizable knowledge," 45 CFR § 46.102(l); IRBs can determine that other learning activities are instead designed to be part of healthcare operations or to improve the quality of healthcare or its delivery and therefore are not subject to the Common Rule, including its default rule requiring consent. Accordingly, IRBs have not uncommonly waived the Common Rule's default requirement of research consent when approving pragmatic RCTs (e.g., 
Coronado et al., 2018;
Huang et al., 2019;
Jarvik et al., 2015;
Milkman et al., 2021
Milkman et al., , 2022
Shermohammed et al., 2021
 and many other pragmatic RCTs conducted by the National Institutes of Health Collaboratory [https://rethinkingclinicaltrials.org/demonstration-projects/]). IRBs have also determined that some pragmatic RCTs do not meet the Common Rule's definition of research (e.g., the seven RCTs reported in 
Horwitz et al., 2019)
. Ethicists and others have also argued that consent is not always ethically required for research, and even that patients and physicians have an obligation to participate in research 
(Asch et al., 2017;
Campbell et al., 2017;
Evans, 2004;
Gelinas et al., 2016;
Harris, 2005;
Schaefer et al., 2009;
Tinetti & Basch, 2013)
.
Nevertheless, it is important to more precisely determine the role that consent or its absence plays in how people evaluate the appropriateness of experiments. Does clarifying that consent will not be obtained increase experiment aversion? Does stipulating that consent will be obtained eliminate experiment aversion? Here, in three studies, we used modified versions of two previously tested vignettes (from 
Meyer et al., 2019 and
Heck et al., 2020)
 to investigate whether positive and negative sentiments about experiments change when the vignette explicitly mentions that the decision-making agent will or will not obtain participants' consent to the A/B test, compared to the original versions, in which nothing is said about whether or not the agent will obtain consent.


Methods


Participants
All data reported here were collected on Amazon Mechanical Turk (MTurk) using CloudResearch. Recruitment was restricted to United States participants who were CloudResearch approved. Study 1 used the Best Drug: Walk-In Clinic vignette, and included 692 participants (53.8% male, 45.5% female) ranging in age from 19 to 72 years old (M = 39 years, SD = 12). Study 2 used the same vignette and included 863 participants (45.2% male, 53.5% female) ranging in age from 19 to 79 years old (M = 40 years, SD = 13). Study 3 used the Hospital Safety Checklist vignette and included 1,990 participants (39.0% male, 60.2% female) ranging from 18 to 81 years old (M = 41 years, SD = 13). See 
Table 1
 for complete sample demographics.


Procedure
In Study 1 and Study 2, participants read the Best Drug: Walk-In Clinic vignette from Study 5 of 
Meyer et al. (2019)
. In this vignette, some doctors in a walk-in clinic prescribe "Drug A" for all their hypertensive patients while others prescribe "Drug B"; both are affordable, tolerable, and FDA approved. Dr. Jones must choose among prescribing Drug A for all his hypertensive patients, prescribing Drug B, or running a randomized experiment to compare their effectiveness and offering the superior drug to all his patients. In Study 3, participants read the Hospital Safety Checklist vignette from Study 1 of 
Meyer et al. (2019)
. In this vignette, a hospital director similarly considers two locations where he might display a safety checklist for clinicians to help prevent catheter-based infections, or an A/B test to compare the effectiveness of these options.In both vignettes, the three decisions the agent can make were always presented on the same page, in a randomized order.
In all three studies, participants were randomly assigned to one of three conditions that manipulated the text of the A/B test option. The conditions differed by a single sentence at the end of the A/B test experiment scenario which noted whether consent had (in the Consent condition) or had not (in the No Consent condition) been elicited. The Silent condition did not contain this sentence-it was identical to the descriptions of the A/B tests used in our previous studies-and therefore did not explicitly reference consent at all.
Following 
Heck et al. (2020)
, after reading the vignette, participants rated the appropriateness of and rank-ordered each of the three possible decisions made by the doctor or hospital director 1 .
All study protocols and analyses for these studies were preregistered on the Open Science Framework, and will be released (along with all data, code, and complete materials) upon final publication of this paper.
The Geisinger IRB determined that these anonymous surveys were exempt (IRB# 2017-0449).
1 In Best Drug: Walk-In Clinic (Study 2) and Hospital Safety Checklist, participants also completed a brief free response entry explaining why they gave their ratings and rankings. They were also given a list of reasons that might explain their rankings from which they were to select all that applied to their choice. Those participants subsequently ranked their selected reasons by how important they were in their decision-making. Finally, all participants completed a standard demographic questionnaire and answered some questions probing their science literacy and beliefs in God vs. science (included in previous studies in this line of work; Meyer et al., 2019).


Measures
Following Meyer et al. (2019), we define an "A/B effect" as the difference between participants' mean policy rating and their rating of the A/B test-that is, the degree to which the policies are (on average) rated higher than the A/B test. We also report the percentage of participants whose mean policy rating is higher than their rating of the A/B test.
Following 
Heck et al. (2020;
see also Mislavsky et al., 2019)
, we define "experiment aversion" as the difference between participants' rating of their own lowest-rated policy and their rating of the A/B test. We also report the percentage of participants who express experiment aversion.
"Experiment rejection" (first reported in Heck et al., 2020, but without this name) occurs when a participant rates the A/B test as inappropriate (1 or 2 on the 5-point scale) while also rating each policy as neutral or appropriate (3-5 on the scale).
A "reverse A/B effect" is the difference between participants' rating of the A/B test and their mean policy rating-that is, the degree to which the A/B test is rated higher than the policies (on average). We also report the percentage of participants whose rating of the A/B test is higher than their mean policy rating.
"Experiment appreciation" is the difference between participants' rating of the A/B test and their rating of their own highest-rated policy. We also report the percentage of participants who express experiment appreciation. "Experiment endorsement" occurs when a participant rates the A/B as appropriate (4 or 5 on the 5-point scale) while also rating each intervention as neutral or inappropriate (1-3 on the scale).


Power analysis
We used a sequential design in the collection of data for all three studies reported here. We first conducted a standard fixed design power analysis to determine the sample size for detecting an interaction between the condition participants were randomized to (Consent/No Consent/Silent) and the decision being rated (policy or A/B test). We then applied the sequential design inflation factor for an alpha spending Pocock design with 3 looks, a 2-sided test, and an alpha of 0.05 to determine our sample size 
(Lakens et al., 2021)
. Finally, we divided this sample size by 3 to determine our per-look sample size. At each look, we compared our preregistered target interaction (Consent vs. Silent by lowest-rated policy vs. A/B test) to the adjusted alpha level associated with our chosen sequential design. If the interaction reached significance at one of the interim looks (as it did in Best Drug: Walk-In Clinic [Study 1] and Hospital Safety Checklist), we ended data collection at that point.
In Best Drug: Walk-In Clinic (Study 1), we had 95% power to detect up to a 75% reduction in experiment aversion from the Silent condition to the Consent condition with our final sample size (actual N = 692, planned N = 680). In Best Drug: Walk-In Clinic (Study 2), we planned our sample size to have 95% power to replicate our findings in Best Drug: Walk-In Clinic (Study 1), and in Hospital Safety Checklist, we planned our sample size to give us 80% power to detect a 50% reduction in experiment aversion from the Silent condition to the Consent condition (which was smaller than the approximately 63% reduction we had observed in the previous two studies); however, we ended up being slightly underpowered in our final sample sizes (Best Drug: Walk-In Clinic (Study 2): actual N = 863, planned N = 909; Hospital Safety Checklist: actual N = 1,990, planned N = 2,002) because of participant exclusions that we only recognized the need for in the data analysis stage, after the planned data collection had concluded (described below).


Analyses
First, for each condition (Consent, No Consent, and Silent), we computed a Cohen's d for the A/B effect and for experiment aversion 2 . Because these tests were preregistered, we use α = .05 as our significance level. We also computed a Cohen's d for experiment appreciation; however, we did not include this measure in our preregistration so we use a more conservative threshold of α = .005 for this test 
(Benjamin et al., 2018)
. For each condition, we also computed the percentage of people who exhibited an A/B effect, who were experiment-averse, who were experiment-appreciative, who rejected the A/B test, and who endorsed the A/B test. We also calculated the percentage of people who ranked each of the policies and the A/B test as best or worst.
Then, for each experiment sentiment (experiment aversion, A/B effect, experiment appreciation), we performed three mixed 2 by 2 ANOVAs with one repeated measures variable (decision being rated: A/B test or policy) and one between-subjects variable (condition: each possible pair from Consent, No Consent, and Silent) with rating as the dependent variable to determine whether there was a significant interaction between the type of decision the participant was rating and the condition to which they were assigned. We performed these ANOVAs in a pairwise fashion, separately comparing Consent to No Consent, Consent to Silent, and No Consent to Silent. Finding a significant interaction in the Consent vs. Silent ANOVA was our sequential design stopping rule; accordingly, these interactions will be regarded as statistically significant by comparison to a sequential design adjusted α ≈ .022.
All analyses were performed on the full sample of participants who completed the study with the exception of participants (identified by their MTurk IDs) who began the survey more than once (Best Drug: Walk-In Clinic (Study 1): n = 34 finished responses; Best Drug: Walk-In Clinic (Study 2): n = 40 finished responses; Hospital Safety Checklist: n = 40 finished response). A participant who began the study more than once (e.g., because of a Qualtrics error or because the survey timed out) might have been exposed to more than one condition 
(Consent, No Consent, Silent)
, and thus their responses may be contaminated. We did not preregister this exclusion criterion prior to data collection, as we only noticed this pattern of multiple surveys begun by the same participant upon review of MTurk IDs. Also excluded from the initial main sample are participants who self-reported an age lower than 18 years old (n < 10 per study).


Results


Do sentiments about experiments change when consent is explicitly present or absent from the AB test?
Across both the Best Drug: Walk-In Clinic and Hospital Safety Checklist vignettes, as well as all three conditions manipulating whether consent is obtained, there is significant experiment aversion and a significant A/B effect (see 
Figure 1)
. That is, even when consent is obtained, the lowest-rated policy (or the average policy, in the case of the A/B effect) is still preferred to the A/B test (see 
Table 2
 for mean appropriateness ratings of the A/B test, policy A, and policy B across conditions in each vignette). Correspondingly, across both vignettes and all three conditions, even those in which consent to the A/B test was explicitly to be obtained, we find no evidence of experiment appreciation: in all cases, the A/B test was still rated lower than the average of participants' highest-rated policy.
Experiment aversion (as well as the less conservative A/B effect) is strongest in the No Consent condition (Best Drug: Walk-In Clinic (Study 1): d = 1.17, p < .0001; Best Drug: Walk-In Clinic (Study 2): d = 1.09, p < .0001; Hospital Safety Checklist: d = 0.85, p <.0001; see 
Table 2
 for related A/B effect sizes). That is, when participants are explicitly told that consent will not be obtained prior to the doctor or hospital director conducting the A/B test, participants strongly dislike the A/B test compared to policy A (drug A in the Best Drug: Walk-In Clinic vignette; badge in the Hospital Safety Checklist vignette) and policy B (drug B in the Best Drug: Walk-In Clinic vignette; the poster in the Hospital Safety Checklist vignette).
Experiment aversion (as well as the less conservative A/B effect) is weakest, but still significantly present, in the Consent condition (Best Drug: Walk-In Clinic (Study 1): d = 0.20, p = 0.023; Best Drug: Walk-In Clinic (Study 2): d = 0.18, p = .026; Hospital Safety Checklist: d = 0.14, p = .003; see 
Table 2
 for related A/B effect sizes). When consent is explicitly going to be obtained prior to the doctor or hospital director conducting the A/B test, participants still think imposing policy A or policy B is more appropriate than running an A/B test, but by a smaller margin.
The Silent condition, where, unlike the Consent and No Consent conditions, nothing explicit is said about the presence of consent, has an experiment aversion effect (as well as the less conservative A/B effect) in between those of the Consent and No Consent conditions (Best Drug: Walk-In Clinic (Study 1): d = 0.55, p < .0001; Best Drug:Walk-In Clinic (Study 2): d = 0.40, p < .0001; Hospital Safety Checklist: d = 0.43, p < .0001; see 
Table 2
 for related A/B effect sizes). These effect sizes are somewhat larger than those found in our previous studies with the same vignettes (Best Drug Walk-In Clinic, d = 0.31; Hospital Safety Checklist, d = 0.24; 
Heck et al., 2020)
, and therefore constitute a replication of those findings.


Figure 1


Percentage of participants rating each decision inappropriate by vignette and condition
Note. Percentages of participants objecting to implementing policy A, policy B, and the A/B test (objecting was defined as assigning a rating of 1 or 2-"very inappropriate" or "somewhat inappropriate"-on a 1-5 scale) in the Best Drug: Walk-In Clinic (Study 1) (A), Best Drug: Walk-In Clinic (Study 2) (B), and Hospital Safety Checklist (C).


Figure 2
Mean appropriateness ratings by vignette and condition Note. Mean appropriateness ratings, on a 1-5 scale, with SEs, for policy A, policy B, the highest-rated policy, the average policy, the lowest-rated policy, and the A/B test. The A/B test ratings are reported by condition, but the policy based ratings are reported as an average across the three between-subjects conditions (Consent, Silent, No Consent) for visual parsimony. The by-condition policy ratings can be found in 
Table 2A-C.
 We find the largest share of participants appreciating the experiment (rating it higher than their highest-rated policy) and endorsing the experiment (rating it a 4 or 5 while ranking each policy a 1, 2, or 3) in the Consent condition compared to the No Consent and Silent conditions, across vignettes. However, in no condition is the share of participants appreciating or endorsing the experiment higher than the share of participants averse to or rejecting the experiment. These results highlight that even when consent is explicitly obtained, more people express negative sentiments against the A/B test than positive sentiments toward it.
Participant rankings of policy A, policy B, and the A/B test produce a similar pattern. When consent is explicitly obtained, the A/B test is ranked as best by 59% of participants in Best Drug: Walk-In Clinic (Study 1), by 64% of participants in Best Drug: Walk-In Clinic (Study 2), and by 39% of participants in Hospital Safety Checklist. When consent is explicitly not obtained, the A/B test is ranked as best by 33% of participants in Best Drug: Walk-In Clinic (Study 1), by 32% of participants in Best Drug: Walk-In Clinic (Study 2), and by 21% of participants in Hospital Safety Checklist. When nothing explicit is said about consent, the A/B test is ranked as best by 51% of participants in Best Drug: Walk-In Clinic (Study 1), by 57% of participants in Best Drug: Walk-In Clinic (Study 2), and by 30% of participants in Hospital Safety Checklist.
On the other hand, when consent is explicitly obtained, the A/B test is ranked as worst by 35% in Best Drug: Walk-In Clinic (Study 1), by 32% of participants in Best Drug: Walk-In Clinic (Study 2), and by 39% of participants in Hospital Safety Checklist. When consent is explicitly not obtained, the A/B test is ranked as worst by 64% of participants in Best Drug: Walk-In Clinic (Study 1), by 63% of participants in Best Drug: Walk-In Clinic (Study 2), and by 62% of participants in Hospital Safety Checklist. When nothing explicit is said about consent, the A/B test is ranked as worst by 44% of participants in Best Drug: Walk-In Clinic (Study 1), by 40% of participants in Best Drug: Walk-In Clinic (Study 2), and by 51% of participants in Hospital Safety Checklist.
These results highlight that even when consent is explicitly obtained, a large proportion of participants (32-39%) still preferred imposing either policy option to running an experiment to figure out which one would be best. 
experiment sentiment effect (i.e., experiment aversion, A/B effect,  experiment appreciation)
 vary based on the presence or absence of consent?


Does the size of the
In Best Drug: Walk-In Clinic (Study 1), across each pairwise comparison of conditions 
(Consent vs. Silent, Consent vs. No Consent, No Consent vs. Silent)
, there is a significant interaction between condition and type of decision being rated (policy vs. A/B test) showing that the size of the experiment sentiment effects vary based on whether consent is present, absent, or not mentioned. For example, when comparing the Consent condition to the Silent condition and the A/B test to the lowest-rated policy (as experiment aversion is defined), there was a significant interaction, F(1,916) = 7.75, p = .006. Similarly, when comparing the Consent condition to the Silent condition and the A/B test to the average policy (as the A/B effect is defined), there was a significant interaction, F(1,916) = 8.48, p = .004. When comparing the Consent condition to the Silent condition and the A/B test to the highest-rated policy (as experiment appreciation is defined), there was a significant interaction, F(1,916) = 8.82, p = .003. In all cases, the A/B test is rated directionally higher in the Consent condition than in the Silent condition while the policy is rated directionally lower in the Consent condition than in the Silent condition. These interaction effects are even larger in the other two pairwise comparisons 
(Consent vs
 In Best Drug: Walk-In Clinic (Study 2), the general pattern of interactions repeat, with the exception of the Consent vs. Silent interactions, which do not reach significance at our sequential design adjusted alpha level of .022 (A/B test vs. lowest-rated policy (experiment aversion): F(1,1138) = 4.13, p = .042, A/B test vs. average policy (A/B effect): F(1,1138) = 3.93, p = .048, A/B test vs. highest-rated policy (experiment appreciation): F(1,1138) = 3.51, p = .061). All other pairwise comparisons produced significant interactions showing that the size of the experiment sentiment effects depends on whether consent is present or absent and whether consent is absent or not mentioned 
(Consent vs
 In Hospital Safety Checklist (Study 3), like Best Drug: Walk-In Clinic (Study 1), across each pairwise comparison of conditions 
(Consent vs. Silent, Consent vs. No Consent, No Consent vs. Silent)
, there is a significant interaction between condition and type of decision being rated (policy vs. A/B test) showing that the size of the experiment sentiment effects varies based on whether consent is present, absent, or not mentioned. When comparing the Consent condition to the Silent condition and the A/B test to the lowest-rated policy (experiment aversion), there was a significant interaction, F(1,2716) = 14.57, p < .001. Similarly, when comparing the Consent condition to the Silent condition and the A/B test to the average policy (A/B effect), there was a significant interaction, F(1,2716) = 19.28, p < .0001. When comparing the Consent condition to the Silent condition and the A/B test to the highest-rated policy (as experiment appreciation is defined), there was a significant interaction, F(1,2716) = 21.58, < .0001. In all cases, the A/B test is rated directionally higher in the Consent condition than in the Silent condition while the policy is rated directionally lower in the Consent condition than in the Silent condition. These interaction effects in the other two pairwise comparisons are even larger (Consent vs. No Consent: A/B test vs. lowest-rated policy (experiment aversion): F(1,2602) = 86.9, p < .0001, A/B test vs. average policy (A/B effect): F(1,2602) = 106.1, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,2602) = 110.5, p < .0001; No Consent vs. Silent: A/B test vs. lowest-rated policy (experiment aversion): F(1,2630) = 32.1, p < .0001, A/B test vs. average policy (A/B effect): F(1,2630) = 37.2, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,2630) = 36.9, p < .0001).


Discussion
Several previous surveys have investigated people's preferences for written or verbal consent to participate in pragmatic RCTs versus receiving general notice that RCTs are typically conducted at a site 
(Cho et al., 2015;
Dal-Ré, Carcas, Carné, et al., 2017a
, 2017b
Dal-Ré et al., 2017;
Kelley et al., 2015;
Morain & Largent, 2021;
Nayak et al., 2015)
. Of these, the studies closest to ours are those that have also asked those favoring consent whether, if consent were impractical, they would prefer general notice or forgoing the trial entirely (e.g., 
Cho et al., 2015)
. None of these studies, however, have compared people's attitudes to conducting a trial, without or without consent, to implementing one of its arms. Nor have they investigated whether people still object to low-risk pragmatic RCTs even with consent.
Across three studies with two vignettes, we find that negative sentiments towards experiments persist even when people will be included in the A/B test only if they consent to participate, even though no consent is obtained for the imposition of policy A or policy B on everyone, and even though the A/B test is the only option of the three that allows the actor to set policy based on what what works best. Specifically, 29-31% of participants were averse to the experiment and 32-39% ranked it as the worst decision the agent could make. Notably, participants were averse to the consensual Best Drug: Walk-In Clinic experiment even though there is no reason to prefer "Drug A" to "Drug B," and patients outside the trial are effectively already randomized to A or B based on which clinician happens to see them (which occurs wherever unwarranted variation in practice determines treatments, such as urgent care clinics and emergency departments). Correspondingly, across both vignettes and all three conditions, even those in which consent to the A/B test was explicitly to be obtained, we observe no experiment appreciation: in all cases, the A/B test was still rated lower than the average of participants' highest-rated policy.
Not surprisingly, the presence of consent does reduce some negative sentiments and increase some positive sentiments towards experiments. On average, participants rated the A/B test higher when consent is present compared to when it is not mentioned (and much higher compared to when it is absent) while the policies are rated higher when consent is not mentioned compared to when it is present showing that the rating of the A/B test is dependent on whether consent is present, absent, or not mentioned. Additionally, in the Consent condition, 20-28% of participants were appreciative of the experiment (rated it higher than their highest-rated policy) compared to 8-14% of participants in the No Consent condition and 11-25% of participants in the Silent condition. However, in no condition, across either vignette, are there more participants who are appreciative of the experiment than there are participants who are averse to it. These results suggest that the omission of participant consent cannot fully explain the experiment aversion phenomenon we have documented: even when consent is explicitly included, a substantial proportion of people still indicate that running an experiment is worse than nonconsensually imposing on everyone each participant's least-favorite policy contained in the experiment.
. No Consent: A/B test vs. lowest-rated policy (experiment aversion): F(1,918) = 63.0, p < .0001, A/B test vs. average policy (A/B effect): F(1,918) = 63.7, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,918) = 62.3, p < .0001; No Consent vs. Silent: A/B test vs. lowest-rated policy (experiment aversion): F(1,922) = 26.1, p < .0001, A/B test vs. average policy (A/B effect): F(1,922) = 25.4, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,922) = 23.8, p < .0001).


. No Consent: A/B test vs. lowest-rated policy (experiment aversion): F(1,1154) = 67.9, p < .0001, A/B test vs. average policy (A/B effect): F(1,1154) = 78.3, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,1154) = 84.0, p < .0001; No Consent vs. Silent: A/B test vs. lowest-rated policy (experiment aversion): F(1,1148) = 36.2, p < .0001, A/B test vs. average policy (A/B effect): F(1,1148) = 43.1, p < .0001, A/B test vs. highest-rated policy (experiment appreciation): F(1,1148) = 48.3, p < .0001).


In all cases where a d-value was calculated (i.e., A/B effect, experiment aversion, reverse A/B effect, experiment appreciation), we used Cohen's d recovered from the t-statistic, n, and correlation between the two measures being compared(Dunlap et al., 1996, equation 3: d = t c [2(1-r)/n] ½ ; see also
Westfall, 2016)
. To calculate this d-value, we use the following R code: effsize::cohen.d(x,y, paired = TRUE).








Acknowledgements
This research was supported by the Office of the Director, National Institutes of Health (NIH) (3P30AG034532-13S1) and funded by the Food and Drug Administration (FDA). The content is solely the responsibility of the authors and does not necessarily represent the official views of the NIH or the FDA. Meyer and Chabris contributed equally to this article.












Misdirections in Informed Consent-Impediments to Health Care Innovation




D
A
Asch






T
A
Ziolek






S
J
Mehta




10.1056/NEJMp1707991








The New England Journal of Medicine




377


15
















Redefine statistical significance




D
J
Benjamin






J
O
Berger






M
Johannesson






B
A
Nosek






E.-J
Wagenmakers






R
Berk






K
A
Bollen






B
Brembs






L
Brown






C
Camerer






D
Cesarini






C
D
Chambers






M
Clyde






T
D
Cook






P
De Boeck






Z
Dienes






A
Dreber






K
Easwaran






C
Efferson






V
E
Johnson




10.1038/s41562-017-0189-z








Nature Human Behaviour




2


1














Do doctors have a duty to take part in pragmatic randomised trials?




M
K
Campbell






C
Weijer






C
E
Goldstein






S
J L
Edwards




10.1136/bmj.j2817








BMJ




357














Attitudes Toward Risk and Informed Consent for Research on Medical Practices




M
K
Cho






D
Magnus






M
Constantine






S
S
Lee






.-J
Kelley






M
Alessi






S
Korngiebel






D
James






C
Kuwana






E
Gallagher






T
H
Diekema






D
Capron






A
M
Joffe






S
Wilfond






B
S




10.7326/M15-0166








Annals of Internal Medicine




162


10
















Effectiveness of a Mailed Colorectal Cancer Screening Outreach Program in Community Health Clinics: The STOP CRC Cluster Randomized Clinical Trial




G
D
Coronado






A
F
Petrik






W
M
Vollmer






S
H
Taplin






E
M
Keast






S
Fields






B
B
Green




10.1001/jamainternmed.2018.3629








JAMA Internal Medicine




178


9
















Who is willing to participate in low-risk pragmatic clinical trials without consent?




R
Dal-Ré






A
J
Carcas






X
Carné




10.1007/s00228-017-2332-1








European Journal of Clinical Pharmacology




73


12
















Public preferences on written informed consent for low-risk pragmatic clinical trials in Spain




R
Dal-Ré






A
J
Carcas






X
Carné






D
Wendler




10.1111/bcp.13305








British Journal of Clinical Pharmacology




83


9
















Patients' beliefs regarding informed consent for low-risk pragmatic trials




R
Dal-Ré






A
J
Carcas






X
Carné






D
Wendler




10.1186/s12874-017-0424-3








BMC Medical Research Methodology




17


1


145














Meta-analysis of experiments with matched groups or repeated measures designs




W
P
Dunlap






J
M
Cortina






J
B
Vaslow






M
J
Burke




10.1037/1082-989X.1.2.170








Psychological Methods




1
















Should patients be allowed to veto their participation in clinical research?




H
M
Evans




10.1136/jme.2003.002444








Journal of Medical Ethics




30


2
















When and Why Is Research without Consent Permissible?




L
Gelinas






A
Wertheimer






F
G
Miller




10.1002/hast.548








Hastings Center Report




46


2
















Scientific research is a moral duty




J
Harris




10.1136/jme.2005.011973








Journal of Medical Ethics




31


4
















Objecting to experiments even while approving of the policies or treatments they compare




P
R
Heck






C
F
Chabris






D
J
Watts






M
N
Meyer




10.1073/pnas.2009030117








Proceedings of the National Academy of Sciences




117


32
















Creating a Learning Health System through Rapid-Cycle, Randomized Testing




L
I
Horwitz






M
Kuznetsova






S
A
Jones




10.1056/NEJMsb1900856








New England Journal of Medicine




381


12
















Chlorhexidine versus Routine Bathing to Prevent Multi Drug-Resistant Organisms and All-Cause Bloodstream Infection in General Medical and Surgical Units: The ABATE Infection Cluster Randomized Trial




S
S
Huang






E
Septimus






K
Kleinman






J
Moody






J
Hickok






L
Heim






A
Gombosev






T
R
Avery






K
Haffenreffer






L
Shimelman






M
K
Hayden






R
A
Weinstein






C
Spencer-Smith






R
E
Kaganov






M
V
Murphy






T
Forehand






J
Lankiewicz






M
H
Coady






L
Portillo






R
Platt




10.1016/S0140-6736








Lancet




18
















Lumbar Imaging with Reporting of Epidemiology (LIRE)-Protocol for a Pragmatic Cluster Randomized Trial




J
G
Jarvik






B
A
Comstock






K
T
James






A
L
Avins






B
W
Bresnahan






R
A
Deyo






P
H
Luetmer






J
L
Friedly






E
N
Meier






D
C
Cherkin






L
S
Gold






S
D
Rundell






S
S
Halabi






D
F
Kallmes






K
W
Tan






J
A
Turner






L
G
Kessler






D
C
Lavallee






K
A
Stephens






P
J
Heagerty




10.1016/j.cct.2015.10.003








Contemporary Clinical Trials




45
















Patient Perspectives on the Learning Health System: The Importance of Trust and Shared Decision Making




M
Kelley






C
James






S
Kraft






D
Korngiebel






I
Wijangco






E
Rosenthal






S
Joffe






M
K
Cho






B
Wilfond






S
S
Lee






.-J




10.1080/15265161.2015.1062163








The American Journal of Bioethics




15


9
















Group Sequential Designs: A Tutorial




D
Lakens






F
Pahlke






G
Wassmer




10.31234/osf.io/x4azm


















Objecting to experiments that compare two unobjectionable policies or treatments




M
N
Meyer






P
R
Heck






G
S
Holtzman






S
M
Anderson






W
Cai






D
J
Watts






C
F
Chabris




10.1073/pnas.1820701116








Proceedings of the National Academy of Sciences


the National Academy of Sciences






116














A 680,000-person megastudy of nudges to encourage vaccination in pharmacies




K
L
Milkman






L
Gandhi






M
S
Patel






H
N
Graci






D
M
Gromet






H
Ho






J
S
Kay






T
W
Lee






J
Rothschild






J
E
Bogard






I
Brody






C
F
Chabris






E
Chang






G
B
Chapman






J
E
Dannals






N
J
Goldstein






A
Goren






H
Hershfield






A
Hirsch






A
L
Duckworth




10.1073/pnas.2115126119








Proceedings of the National Academy of Sciences




119


6














A megastudy of text-based nudges encouraging patients to get vaccinated at an upcoming doctor's appointment




K
L
Milkman






M
S
Patel






L
Gandhi






H
N
Graci






D
M
Gromet






H
Ho






J
S
Kay






T
W
Lee






M
Akinola






J
Beshears






J
E
Bogard






A
Buttenheim






C
F
Chabris






G
B
Chapman






J
J
Choi






H
Dai






C
R
Fox






A
Goren






M
D
Hilchey






A
L
Duckworth




10.1073/pnas.2101165118








Proceedings of the National Academy of Sciences




118


20














The minimum mean paradox: A mechanical explanation for apparent experiment aversion




R
Mislavsky






B
J
Dietvorst






U
Simonsohn




10.1073/pnas.1912413116








Proceedings of the National Academy of Sciences


the National Academy of Sciences






116














Public Attitudes toward Consent When Research Is Integrated into Care-Any "Ought" from All the "Is




S
R
Morain






E
A
Largent




10.1002/hast.1242








Hastings Center Report




51


2
















Pragmatic Randomized Trials Without Standard Informed Consent?




R
K
Nayak






D
Wendler






F
G
Miller






S
Y H
Kim




10.7326/M15-0817








Annals of Internal Medicine




163


5
























Rethinking Clinical Trials. NIH Pragmatic Trials Collaboratory
















The Obligation to Participate in Biomedical Research




G
O
Schaefer






E
J
Emanuel






A
Wertheimer




10.1001/jama.2009.931








JAMA




302


1
















Informing patients that they are at high risk for serious complications of viral infection increases vaccination rates




M
Shermohammed






A
Goren






A
Lanyado






R
Yesharim






D
M
Wolk






J
Doyle






M
N
Meyer






C
F
Chabris




10.1101/2021.02.20.21252015












p. 2021.02.20.21252015








Patients' Responsibility to Participate in Decision Making and Research




M
E
Tinetti






E
Basch




10.1001/jama.2013.5592








JAMA




309


22


















J
Westfall






Effect size | Cookie Scientist

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]