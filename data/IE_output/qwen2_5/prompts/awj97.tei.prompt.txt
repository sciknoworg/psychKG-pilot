You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



ACCURACY SELF-NUDGE 3


Statement of Relevance
Many online choice environments are designed to encourage certain behaviors, such as making a purchase or sharing personal information, and to keep users engaged for as long as possible. Powered by opaque algorithms, these online environments threaten users' autonomy and agency. Moreover, with individuals now linked through large social networks online, threats to individual decision autonomy can scale up to collective phenomena.
Targeting individual behavior such as the sharing of misinformation may therefore be part of the solution for preventing societal and individual harm. Here, we demonstrate the potential of a self-nudge-a transparent, nonpaternalistic behavioral intervention-to reduce the spread of misinformation and thus improve the public discourse online, while upholding users' autonomy and agency. ACCURACY SELF-NUDGE 4 An Accuracy Self-Nudge to Reduce Misinformation Sharing Online Online, the highly developed choice architecture reaches deep into people's private lives: the way choices are presented in websites, apps, and platforms can shape the behavior of users.
Companies and organizations (i.e., commercial choice architects) often have a vested interest in designing online choice architectures that encourage certain behaviors, such as making a purchase or sharing personal information, and in keeping users engaged for as long as possible. Public choice architects seeking to combat these efforts sometimes use nudges:
interventions that steer individuals' behavior in a particular direction without limiting their options or significantly changing the economic incentives 
(Thaler & Sunstein, 2008)
. But the nudging approach has its limitations 
(Hertwig & Grüne-Yanoff, 2017)
. For one, it assumes that the public choice architects know what makes choosers better off, by their own standards, and that they act benevolently and steer behavior according to people's true preferences 
(Hertwig, 2023)
. For another, nudges often leave people unaware of the mechanisms behind the nudge that changes their behavior. To the extent that a nudge exploits cognitive and motivational limitations or biases, it shapes behavior in ways that are not necessarily transparent to the chooser, thus curbing their ability to reverse the nudge and undermining their agency and autonomy 
(Reijula & Hertwig, 2022)
.
Self-nudging addresses these concerns. The aim of self-nudging interventions is to empower people to redesign aspects of their decision environments to make choices that are in their own best interests-that is, to become their own choice architects 
(Reijula & Hertwig, 2022)
. It is transparent, nonpaternalistic, respects individual autonomy, and offers people tools to use in the private sphere, where public choice architecture falls short 
(Hertwig, 2023)
. Digital self-nudging strategies, in combination with other behavioral interventions, has been shown to reduce email overuse in employees 
(van Roekel et al., 2023)
. Another example of digital self-nudging is the self-nudge app one sec to combat mindless social ACCURACY SELF-NUDGE 5 media usage. The app works by inducing friction: making users wait 10 seconds before they can open Facebook, Instagram, TikTok-or whichever target app they want to avoid. One sec has been shown to reduce users' opening of target apps by an average of 57% after six consecutive weeks 
(Grüning et al., 2023)
.
Self-nudging can also be applied to societal challenges such as the spread of false and misleading information online by targeting individual decision-making 
(Kozyreva et al., 2020)
. Within the many-to-many architecture of producing, sharing, and consuming news on social media, the dissemination of (false and true) information is much more dependent on individual decision-making than in classic one-to-many media, such as TV and print newspapers. Behavioral interventions that target individuals can therefore be an entry point for limiting the spread of false information (see 
Kozyreva et al., 2022, for examples)
. One of the most widely cited behavioral interventions in this context is the accuracy nudge by .
Studies suggest that people consider it important to share only accurate news, but that they often fail to act accordingly, as the social media environment distracts from that preference . A simple prompt reminding individuals to consider accuracy as they navigate the social media environment-in other words, aiming to redirect their attention to accuracy-has been shown to help reduce the sharing intentions of misinformation. Accuracy prompts aim to increase sharing discernment, defined as the difference in sharing intentions between true and false information. Sharing discernment is more relevant as an outcome than absolute reduction in the sharing of false news, as a risk of misinformation interventions is that they increase skepticism towards all information, including true news 
(Hoes et al., 2023)
. In several studies, 
colleagues (2020, 2021)
 delivered small but scalable accuracy prompts or nudges before participants made sharing decisions. The prompts took different forms, such as literacy tips, asking users how ACCURACY SELF-NUDGE 6 important it is to them to share only accurate content, telling users that most other people think it very important to share only accurate content (i.e., referring to norms), or-the most widely researched form-prompting users to evaluate the accuracy of a single headline 
(Epstein et al., 2021
). An internal meta-analysis by Pennycook's group found that accuracy nudges increase sharing discernment by 71.7% relative to control 
(Pennycook & Rand, 2022
). An independent direct replication of the accuracy nudge found smaller effects, with a 40% increase in sharing discernment in the treatment group relative to the control group 
(Roozenbeek et al., 2021)
.
Transforming an accuracy nudge applied by an external party (e.g., platform, regulator, or researcher) into a self-nudge employed by those navigating the online environment themselves could have three main benefits. First, it could increase the salience of sharing discernment as a goal in the decision-making process 
(Bordalo et al., 2012)
-and users who have actively decided on that goal may be more likely to commit to it in order to avoid cognitive dissonance 
(Festinger, 2001
). Second, it increases the transparency of the intervention. Transparency is key to distinguishing behavioral interventions for the public good from profit-oriented mechanisms, especially online (Lorenz-Spreen et al., 2020). Third, it makes no assumptions about users' preferences but encourages them to make an active decision, thus preserving their autonomy and agency.


The present study
In this study, we compare the effects of the accuracy nudge tested in Pennycook et al.
(2021) with those of its adaptation to a self-nudge: Participants in the self-nudge condition were first informed about the purpose and content of the nudge, and then given the option to apply it while completing the main task. Here, all participants completed a sharing task, in which they indicated how likely they would be to share 12 news headlines, of which six were false and six were true. After 24 hours, the participants were invited to a second assessment, ACCURACY SELF-NUDGE 7 in which they again applied the nudge and made decisions on whether or not to share headlines.
Four research questions were addressed: (1) Is the self-nudge effective in increasing sharing discernment? (2) Is the self-nudge more effective than the nudge in increasing sharing discernment? (3) Are findings on the effectiveness of the accuracy nudge replicated in the present sample? We were also interested in (4) whether and to what extent the treatment effects decayed over successive trials and, specifically, whether the nudge shows more decay than the self-nudge.
Based on previous findings, we formulated the following hypotheses: H1: Participants in the self-nudge condition show stronger sharing discernment than participants in the control condition. H2: Participants in the self-nudge condition show stronger sharing discernment than participants in the nudge condition.
H3: Participants in the nudge condition show stronger sharing discernment than participants in the control condition. H4: Participants in the self-nudge condition show a more sustained increase in sharing discernment than participants in the nudge condition.


Methods
The study was preregistered at the Open Science Framework (https://osf.io/sf45x). The preregistration specifies the research questions, hypotheses, conditions, exclusion criteria, and analysis model. All data, analysis code, and survey materials are available at https://osf.io/y4kgq/. Ethical approval was obtained from the Internal Review Board of the Max Planck Institute for Human Development.
ACCURACY SELF-NUDGE 8


Participants
After giving consent, all participants provided general demographic information including age, gender, and education. Sample size was comparable to other studies of similar design and sufficient to detect the small effect sizes observed in some previous studies on accuracy nudges 
Roozenbeek et al., 2021)
. In their replication study, 
Roozenbeek et al. (2021)
 found effect sizes of d = −.14 for the treatment group and d = −.10 for the control group, at the lower end of range for accuracy nudge effect sizes. Participants were recruited via Prolific Academic, balanced on gender, resulting in a sample of 469 men (48.6%), 479 women (49.6%), 12 participants who selected the "other" category, and 5 participants who preferred not to answer. The mean age was 38 years. Of the participants, 60.9% had a higher education degree. In terms of political orientation, 50.0% of the sample thought of themselves as Democrats, 14.8% as Republicans, and 30.1% as independent, with the remaining 50 participants choosing "other" or "not sure." Asked what they would choose if they absolutely had to choose between Republican and Democrat, 72.4% identified as Democrats. Finally, 51.5% reported that they would consider sharing political content on social media. More details on the sample split by condition can be found in 
Table A1
 in the Appendix.


Materials and Procedure
First, participants were assigned to three conditions: choice, nudge, and control.
Participants in the choice condition first saw an infobox that informed them about the accuracy nudge and how it works (see 
Figure A1
 in the Appendix). This enabled them to make an informed decision on whether or not to apply it to themselves as a self-nudge while completing the main task. A second, post-decision randomization controlled for the effects of exposure to the infobox: Half of the participants who opted for the self-nudge indeed received it before the task: They were shown a prompting question that asked them to rate the ACCURACY SELF-NUDGE 9 accuracy of a single headline that was not included in the main task set of 12 headlines mmediately before starting the main task (self-nudge). The other half were directed straight to the main task (potential adopters). Participants who opted against the self-nudge, like the control group, performed an unrelated task, namely, rating how funny a headline is (nonadopters). Participants in the self-nudge condition were therefore split into three subconditions: self-nudge, potential adopters, and non-adopters. Participants assigned to the nudge condition were asked to answer the prompting question, but without prior exposure to the infobox. Participants in the control condition were asked to rate the funniness of a headline. All participants completed an attention check before being directed to the main task. 
Figure 1
 provides a schematic overview of the study procedure.
All participants then completed a headline task assessing their sharing intentions for a set of 12 headlines. The stimuli were true and false political news headlines pretested and provided by Gordon Pennycook in April 2022 using the material and method laid out in . From a sample of 278 pretested headlines, we selected a subset of 12 headlines for each assessment, resulting in a total of 24 headlines. To this end, we first excluded all items that were shared or seen as accurate more or less than 1.5 times the interquartile range of the pretest data. We then selected three true and three false Democratleaning and Republican-leaning headlines per assessment. To ensure that the Democratleaning headlines were not more extreme in their political orientation than the Republican headlines or vice versa, we used the procedure suggested by .
After the main task, participants completed the Cognitive Reflection Test-2 (CRT-2;
Thomson & Oppenheimer, 2016). The CRT-2 was chosen because it is less dependent on numeracy than its predecessor and because many participants on online survey platforms are familiar with the items used in the original CRT. Participants were then asked to provide additional information, including their political orientation, voting intention, and the ACCURACY SELF-NUDGE 10 importance they personally placed on sharing only accurate information. To assess whether acceptance of the intervention differed across conditions, we asked participants for their subjective assessment of the intervention, asking them to rate the likelihood that they would implement it in their social media feed, how acceptable they would find its implementation for all social media users, and how effective they thought it was. At the end of the experiment, participants were comprehensively debriefed, with debunking techniques being used to correct the false headlines encountered in the study 
(Lewandowsky et al., 2020)
. They then had the option to withdraw their consent and data in light of the misleading content presented in the study. These steps are in line with recent ethical guidelines for misinformation research by 
Greene et al. (2022)
.
Twenty-four hours after the first assessment, we re-opened the survey for a second assessment to the participants of three of the (sub-)conditions: the self-nudge subcondition, the nudge condition, and the control condition. Participants in the self-nudge condition were again presented with the choice of whether or not to apply the nudge to themselves. As before, participants in the nudge condition received the accuracy nudge in the form of a prompting question. Participants in the control condition again rated the funniness of a headline. The main task again consisted of a set of 12 headlines (six false and six true), selected in the same way as in the first part of the experiment. At the end of the second assessment, participants were again debriefed and had the option to withdraw their consent.


Figure 1
Schematic Overview of the Study Procedure in the First Assessment


Results
We collected responses from 996 participants in the first assessment. Following the preregistered criteria, we excluded 13 participants who indicated that they did not use social media and 12 participants who failed the attention check. Additionally, we gave participants the option to withdraw their consent after the debriefing 
(Greene et al., 2022)
, resulting in the exclusion of another 6 participants. The final sample in the first assessment thus comprised 965 participants, of whom n = 240 were assigned to the nudge condition, n = 243 to the control condition, and n = 482 to the choice condition. In the choice condition, 371 participants (77.0%) decided for the nudge, of whom n = 186 were randomly assigned to receive the nudge before the task (self-nudge) and n = 185 to receive the nudge after the task (potential adopters); n = 111 decided against the nudge (non-adopters).
In the second assessment, which tested for evidence of decay in treatment effects, we collected additional data from 495 participants (self-nudge = 165, nudge = 165, control = 165). One participant in the nudge condition withdrew their consent after debriefing, resulting in a total of N = 494 participants in the second assessment.


ACCURACY SELF-NUDGE 12


Sharing Discernment
Sharing discernment was computed as a participant's mean likelihood of sharing true news headlines minus their mean likelihood of sharing false news headlines. A sharing discernment score of 0 would indicate that a participant shares the same amount of true and false news. In our study, mean sharing discernment across all conditions was 0.56 (SD = 1.0), indicating that, on average, participants were more likely to share true headlines than false headlines. 
As Figures 2a and 2c
 show, the data support H1-H3: Participants in the self-nudge group on average showed higher sharing discernment than participants in the control condition (H1) by a factor of 1.65 (Cohen's d = 0.29) or the nudge condition (H2) by a factor of 1.32 (Cohen's d = 0.18). 
1
 We also found that participants in the nudge condition showed higher sharing discernment than the control group by a factor of 1.26 (Cohen's d = 0.11), replicating the findings of Pennycook et al. (2021) (H3); note that this was a smaller effect than the one observed for the self-nudge. As can be seen in 
Figure 2c
, the higher sharing discernment in the self-nudge condition reflects higher sharing of true news as well as, generally speaking, lower sharing of false news compared to the control group. We ran a Bayesian hierarchical regression model to test the effect of the conditions on sharing likelihood. Our preregistered model included random effects for headline and individual, and sharing discernment is expressed by the interaction of headline veracity and condition. We consider an effect as credible if the 95% credibility interval (CI) of a parameter does not contain zero.
Consistent with H1, sharing discernment was higher in the self-nudge condition than in the control condition, with a positive coefficient for the interaction between the self-nudge condition and veracity (b = 0.31, 95% CI [0.17, 0.45]). In support of H2, sharing discernment was higher in the self-nudge condition than in the nudge condition, with b = 0.15 (95% CI 
[0.02, 0.29]
). In line with H3, sharing discernment was higher in the nudge condition than in the control group, with b = 0.16 (95% CI [0.02, 0.28]). 
Figure 3a
 visualizes each parameter including credibility intervals. Veracity was the strongest predictor of sharing likelihood, which means that whether a headline was true or false generally affected sharing likelihood.
In addition to our preregistered analyses, we conducted robustness analyses in the form of an intention-to-treat analysis, which included the participants who actively decided against a self-nudge. These participants need to be factored in when calculating effect sizes in order to estimate the potential magnitude of the intervention in a real-world setting. For that purpose, we duplicated the self-nudge subcondition (to account for the post-choice randomization, which would not occur in a real-world intervention) and combined it with the non-adopters, who decided against the self-nudge to create an "intention-to-treat" group. This was to test whether including the latter group would still result in findings of stronger sharing discernment among participants offered the nudge. Results showed that sharing discernment in the intention-to-treat group (expressed by the interaction of headline veracity and condition) was higher than in the control condition (b = 0.24, 95% CI [0.12, 0.35]), but not higher than in the nudge condition (b = 0.08, 95% CI [−0.04, 0.19]).
We ran an additional Bayesian regression model to analyze the effect of demographic and psychological variables on individual sharing discernment. We deviated from the original model, where sharing discernment is expressed as an interaction term, to reduce complexity and to minimize the number of multiple interactions. In this model, random effects for item and individual are therefore no longer included, as there is only one data point per person. model, we included interaction terms to control whether the effect of the self-nudge differed based on demographic factors. We found no effect for political orientation (b = 0.22, 95% CI [−0.20, 0.65]) but the effect of the self-nudge differed depending on education (b = −0.47, 95% CI [−0.89, −0.10]), with a stronger effect in people with no higher education degree.


Figure 3
Coefficients of the Bayesian regression models Note. (A) Regression coefficients of the preregistered model with random effects for headline and individual, in which general sharing intentions are the dependent variable and sharing discernment is expressed by the interaction of headline veracity and condition. Note that when a credibility interval excludes zero, the null hypothesis that the respective regression coefficient is zero (i.e. that there is no effect) is interpreted as not credible. (B) Coefficients of the additional Bayesian model, in which demographic and psychological factors (in addition to condition) were regressed directly on sharing discernment.


ACCURACY SELF-NUDGE


16


Decay Effects
To address H4, we next examined whether the effects of the nudge wore off more than those of the self-nudge over successive assessments. In the second assessment, 129 of the 165 participants (78%) in the self-nudge group again decided for the self-nudge after 24 hours.
Both they and the participants in the nudge condition were subsequently presented with the nudge a second time. Contrary to H4, the change in the effect of the interventions did not differ across the two groups after a delay of at least 24 hours. Instead, the effects of the interventions remained stable in size and direction. In Bayesian terms, expressed by the interaction of headline veracity and condition, sharing discernment remained higher in the self-nudge condition than in the control condition (b = 0.28, 95% CI [0.10, 0.44]) or the nudge condition (b = 0.17, 95% CI [0.01, 0.35]). However, sharing discernment was just slightly higher in the nudge condition than in the control group b = 0.10 (95% CI [−0.05,


0.26]).


Non-Adopters
In addition to the effects of the nudge and the self-nudge, we were interested in the characteristics of the participants who decided against the self-nudge (non-adopters) and their reasons for doing so. When asked for their reasons, the majority of the non-adopters (59.5%; n = 66) answered "I have other mechanisms to ensure that I don't share misinformation."
Another 26.1% (n = 27) answered that they were not interested in reducing their sharing of misinformation, 13 of them because they did not think they ever shared misinformation. In terms of demographic factors, a smaller proportion of non-adopters had a higher education degree (50.5%) than in the full sample (61.04%). The mean CRT-2 score (on a scale from 0 to 4) in non-adopters was 2.74 (SD = 0.93, t(220.77) = 3.00, p = .003); in the group that decided for the nudge it was 2.42 (SD = 1.16). For more details on demographic differences, see 
Table A1
 in the appendix.


Discussion
In this study, we investigated the effectiveness of an accuracy nudge adapted for use as a self-nudge and compared with to that of the original nudge. We found that a self-nudge redirecting users' attention towards the concept of accuracy increased sharing discernment beyond the effect of the regular nudge, which was in turn smaller than that observed in previous studies by 
Pennycook and colleagues (2020)
. For both interventions, the increase in sharing discernment was replicated in a second assessment after about 24 hours.
Higher sharing discernment can be a result of decreased sharing of false news and/or of increased sharing of true news. One concern about misinformation interventions is that they increase skepticism towards information in general, including true news 
(Hoes et al, 2023;
Modirrousta-Galian & Higham, 2023)
. 
Caulfield (2018)
 has coined the term "trust compression" to describe the generally lowered trust in information that results from the spread of misinformation. Our findings indicate that self-nudge did not decrease the likelihood of participants engaging with information that is true and potentially useful-an important feature of an informed citizenry.
Self-nudging interventions necessarily involve selection effects. This is not a bug but an ethical feature of self-nudging, in which an intervention is never imposed on people, but actively chosen by the individuals themselves. To rule out the possibility that the higher observed effectiveness of the self-nudge was attributable to systematic differences between participants who chose the nudge and those who decided against it and to test whether benefits on the societal level prevail when taking non-adopters into account, we performed an intention-to-treat analysis. This is established practice in clinical trials to account for dropouts and ensure the practical effectiveness of a treatment. In our study, it meant including participants who decided against the self-nudge in additional robustness analyses. The intention-to-treat group showed higher sharing discernment than the control group, indicating that the self-nudge would be effective if rolled out in practice, where application is up to the individual. The gain in effectiveness relative to the nudge group was no longer as pronounced for the intention-to-treat group. However, the ethical advantage of the self-nudging approach remains: upholding user autonomy and agency, and transparency of the intervention.
There was no evidence that opting for the self-nudge was associated political orientation; however, we did find that sharing discernment was lower in Republicans. The effectiveness of the self-nudge did not seem to be dependent on political orientation.
However, as our sample contained more Democrats than Republicans, these findings need to be replicated in a more balanced sample.
One strength of this study is the development of an experimental procedure to test self-nudging interventions. A second, post-choice randomization after exposure to the infobox allowed us to differentiate between the effects of actively choosing to apply the nudge to oneself and the effects of the nudge itself. Further studies could include an additional condition that provides the infobox, but does not allow participants to actively choose for or against it. This would offer a more nuanced perspective on which components of the self-nudge are most essential for its effect: Although self-selection is a necessary part of self-nudging, its consequences nonetheless need to be considered when interpreting the results. In this sense, the intention-to-treat analysis robustly showed that the self-nudge succeeded even when self-selection effects were taken into account. Capturing a withinperson baseline or introducing additional conditions can help to disentangle the intervention components-for example, introducing a condition that presents the infobox without the choice component would help to disentangle the effects of choice and commitment from the effect of exposure to the information.
The present study provides an experimental proof of concept for self-nudging in the digital sphere and demonstrates how one of the most widely discussed interventions in ACCURACY SELF-NUDGE 19 misinformation research-accuracy prompts-can be transformed into self-nudges. It contributes three key findings and methodological advances. First, it develops an experimental paradigm suitable for investigating self-nudging, thus laying the foundation for further advances in this direction. Second, the findings advance the debate on the accuracy nudge by showing that its transformation to a self-nudge can increase its effectiveness and address ethical concerns surrounding paternalism and transparency. Third, the findings can inform the development of further self-nudging interventions targeting other challenges in the online sphere, such as hateful speech and polarization. In summary, this study demonstrates the potential of self-nudging to improve the public discourse online while upholding user autonomy and agency, and transparency of the intervention.
Prefer not to answer 


Figure A1
Information Frame Disclosing the Purpose of the Nudge


Figure A2
Screenshot of the Prompting Question Used as Accuracy Nudge
Figure 2
2
Sharing Discernment Note. (A) Individual sharing discernment: boxplots (median, hinges for first and third quartile, whiskers represent 1.5 × interquartile range), violin plots, and jittered individual observations. (B) Mean sharing discernment from first to second assessment. (C) Average number of true and false headlines shared in the first assessment. Error bars reflect standard errors.


Findings
show a negative effect of Republican political orientation (b = −0.27, 95% CI [−0.42, −0.13]) and a positive effect of having a higher education degree (b = 0.23, 95% CI [0.10, 0.37]). Figure 3b presents all coefficients with credibility intervals. In an additional ACCURACY SELF-NUDGE 15


We use factors in addition to standard effect sizes to ease comparability with the effect sizes reported in studies by
Pennycook et al. (2022)
. A factor of 1.65 means that sharing discernment was 1.65 times higher in one group than in the other.








Appendix
 














J
B
Bak-Coleman






M
Alfano






W
Barfuss






C
T
Bergstrom






M
A
Centeno






I
D
Couzin






J
F
Donges






M
Galesic






A
Gersick






J
Jacquet






A
Kao






R
Moran






P
Romanczuk






D
Rubenstein






K
Tombak






J
J
Van Bavel






E
U
Weber


















Stewardship of global collective behavior


10.1073/pnas.2025764118








Proceedings of the National Academy of Sciences


the National Academy of Sciences




118












Salience theory of choice under risk




P
Bordalo






N
Gennaioli






A
Shleifer








The Quarterly Journal of Economics




127


3


















10.1093/qje/qjs018














Can nudges be transparent and yet effective




H
Bruns






E
Kantorowicz-Reznichenko






K
Klement






M
Luistro Jonsson






B
Rahali




10.1016/j.joep.2018.02.002








Journal of Economic Psychology




65
















Recalibrating our approach to misinformation




M
Caulfield
























Z
Epstein






A
J
Berinsky






R
Cole






A
Gully






G
Pennycook






D
G
Rand


















Developing an accuracy-prompt toolkit to reduce COVID-19 misinformation online














10.37016/mr-2020-71








Harvard Kennedy School Misinformation Review




2


3












A theory of cognitive dissonance




L
Festinger








Stanford University Press












Best practices for ethical conduct of misinformation research: A scoping review and critical commentary




C
M
Greene






De Saint






C
Laurent






G
Murphy






T
Prike






K
Hegarty






U
K
Ecker








European Psychologist




28


3


















10.1027/1016-9040/a000491




















ACCURACY SELF-NUDGE




21












Directing smartphone use through the self-nudge app one sec




D
J
Grüning






F
Riedel






P
Lorenz-Spreen




10.1073/pnas.2213114120








Article e2213114120






120












The citizen choice architect in an ultra-processed world




R
Hertwig




10.1017/bpp.2023.9








Behavioural Public Policy
















Nudging and boosting: Steering or empowering good decisions




R
Hertwig






T
Grüne-Yanoff








Perspectives on Psychological Science




12


6


















10.1177/1745691617702496














Prominent misinformation interventions reduce misperceptions but increase skepticism




E
Hoes






B
Aitken






J
Zhang






T
Gackowski






M
Wojcieszak




10.31234/osf.io/zmpdu


















Citizens versus the Internet: Confronting digital challenges with cognitive tools




A
Kozyreva






S
Lewandowsky






R
Hertwig




10.1177/1529100620946707








Psychological Science in the Public Interest




21


3
















Toolbox of interventions against online misinformation and manipulation




A
Kozyreva






P
Lorenz-Spreen






S
Herzog






U
Ecker






S
Lewandowsky






R
Hertwig




10.31234/osf.io/x8ejt


















Debunking handbook 2020




S
Lewandowsky






J
Cook






D
Lombardi




10.17910/B7.1182


















How behavioural sciences can promote truth, autonomy and democratic discourse online




P
Lorenz-Spreen






S
Lewandowsky






C
R
Sunstein






R
Hertwig




















10.1038/s41562-020-0889-7








Nature Human Behaviour




4














A systematic review of worldwide causal and correlational evidence on digital media and democracy




P
Lorenz-Spreen






L
Oswald






S
Lewandowsky






R
Hertwig




















10.1038/s41562-022-01460-1








Nature Human Behaviour




7




















ACCURACY SELF-NUDGE




22












Gamified inoculation interventions do not improve discrimination between true and fake news: Reanalyzing existing research with receiver operating characteristic analysis




A
Modirrousta-Galian






P
A
Higham




10.1037/xge0001395








Journal of Experimental Psychology: General. Advance online publication
















Shifting attention to accuracy can reduce misinformation online




G
Pennycook






Z
Epstein






M
Mosleh






A
A
Arechar






D
Eckles






D
G
Rand




10.1038/s41586-021-03344-2








Nature




592


7855
















Fighting COVID-19 misinformation on social media: Experimental evidence for a scalable accuracynudge intervention




G
Pennycook






J
Mcphetres






Y
Zhang






J
G
Lu






D
G
Rand








Psychological Science




7


















10.1177/0956797620939054














The psychology of fake news




G
Pennycook






D
G
Rand




10.1016/j.tics.2021.02.007








Trends in Cognitive Sciences




25


5
















Accuracy prompts are a replicable and generalizable approach for reducing the spread of misinformation




G
Pennycook






D
G
Rand




10.1038/s41467-022-30073-5








Nature Communications




13














Self-nudging and the citizen choice architect




S
Reijula






R
Hertwig




10.1017/bpp.2020.5








Behavioural Public Policy




6


1
















How accurate are accuracynudge interventions? A preregistered direct replication of Pennycook et




J
Roozenbeek






A
L J
Freeman






S
Van Der Linden
























Psychological Science




32


7
















10.1177/09567976211024535














Nudge: Improving decisions about health, wealth, and happiness




R
H
Thaler






C
R
Sunstein








Yale University Press












Investigating an alternate form of the cognitive ACCURACY SELF-NUDGE 23 reflection test




K
Thomson






D
Oppenheimer








Judgment and Decision Making




11


1


















10.1017/S1930297500007622














Nudges can be both autonomy-preserving and effective: Evidence from a survey and quasi-field experiment




H
Van Roekel






L
M
Giurge






C
Schott






L
Tummers




10.1017/bpp.2023.18








Behavioural Public Policy













"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]