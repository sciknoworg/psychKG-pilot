You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
The capacity to generalize previously acquired information to novel scenarios is essential for adaptive behavior in an uncertain world. Human language, as a generative system, enables the construction of an infinite number of complex expressions from simpler components. We excel at combining linguistic "building blocks" such as morphemes and words. This flexibility in communication allows us to adapt seamlessly to new situations, showcasing a hallmark of human cognition 
(Frankland & Greene, 2020)
. This innate ability to systematically construct new meanings from existing knowledge extends beyond language and underpins learning and problem-solving across various cognitive domains (Al 
Roumi et al., 2019;
Behrens et al., 2018;
Gärdenfors, 2004;
Liu et al., 2019;
Sablé-Meyer et al., 2022;
Schwartenbeck et al., 2023)
.
Natural languages and other symbolic systems such as music and mathematics, derive their power from compositionality, making "infinite use of finite means" through the flexible recombination of simpler parts 
(Dehaene et al., 2022;
van Humboldt, 1829)
. Here, we investigate the mechanisms of compositional generalization in the context of language, aiming to bridge the gap with other domain-general cognitive processes such as structural inference, visual perception and decision making.
In human language, we hierarchically bind basic structures like words and morphemes together to form larger structures like phrases and sentences 
(Chomsky, 2001;
Zaccarella et al., 2017)
. The generation of linguistic meaning depends not only on the constituent parts but also on how they are combined 
(Fodor, 1975;
Fodor & Pylyshyn, 1988;
Frege, 1892;
Martin, 2016
Martin, , 2020
Partee, 2008)
. Complex linguistic expressions are constructed by applying abstract syntactic operations to simpler symbolic representations. Relational structure plays an essential role in linguistic composition. Consider the two sentences "The cat chased the mouse" and "The LEARNING AND GENERALIZATION OF NOVEL COMPOSITIONAL MEANINGS 4 mouse chased the cat". Despite sharing identical linguistic building blocks, they convey distinct meanings. Unraveling the mechanism behind assembling these building blocks into an infinite number of complex expressions has been a pivotal question in language research 
(Fedorenko et al., 2016;
Flick et al., 2018;
Günther & Marelli, 2020;
Pylkkänen, 2019;
Zaccarella & Friederici, 2015)
.
It has been proposed that analogous mechanisms underlie the generativity of nonlinguistic thought in humans 
(Dehaene et al., 2022;
Fodor, 1975;
Fodor & Pylyshyn, 1988;
Jackendoff, 1992)
. Numerous nonlinguistic processes depend on abstract, transferable knowledge, such as relational structural rules. The act of BUILDing a LEGO world necessitates assembling blocks in specific orders. In constructing visual silhouettes resembling LEGO creations, the positioning of a horizontal brick "on top of" or "next to" a vertical brick can significantly alter the outcome 
(Schwartenbeck et al., 2023)
. However, while structural rules appear to be pivotal in language processing, nonlinguistic compositional processes do not universally depend on them. For instance, MIXing an apple-pear smoothie yields an unchanged product regardless of whether the apple or the pear is added first. This underscores our ability to construct novel experiences, such as imagining a tea-jelly dessert, by invoking and combining independent memories of tea and jelly 
(Barron et al., 2013)
. This raises the question to what extent we rely on abstract structural rules in compositional generalization. Our study aims to quantify participants' compositional ability by evaluating their reliance on generalizable structures rules and to assess how this ability helps us in new situations.
We developed an experimental paradigm aimed at quantifying the ability to infer and generalize abstract structural rules for constructing novel compositional word meanings.
Specifically, we use the linguistic phenomenon of "affixation", where a group of letters (the affix) is attached to a root word (the stem) to create a new word, either at the beginning 
(prefix)
 or the end (suffix) of the word. Participants learned an artificial language featuring compositional pseudo-words, each comprising a known stem (e.g., "good" in "good-kla") and an unknown affix (e.g., "kla"). We manipulated the meaning and affix form mapping based on sequential position (e.g., "-kla" as a suffix means "the opposite", whereas "kla-" as a prefix means "young version").
During a training phase, participants were exposed to pairs of compositional pseudowords along with their meanings (e.g., participants were taught that "goodkla" means "bad", and "kladog" means "puppy"). In the critical testing phase, participants evaluated the meanings of novel compositional pseudo-words that they had never encountered before (e.g. "white-kla" and "klawhite"). These novel words could be either congruent with the sequential order rule (e.g. for "white-kla", "-kla" as suffix means "the opposite", and the opposite of white is "black") or be incongruent (e.g. for "kla-white", "kla-" as a prefix means "the young version of", and the young version of white is meaningless). This experimental setup allowed us to assess whether individuals relied on abstract sequential order rules for generating novel meanings.
We hypothesize that if participants BUILD new meaning by generalizing abstract sequential order rules, then they should attribute meaning exclusively to congruent novel words, excluding incongruent ones. Conversely, if participants adopt a MIXing strategy and disregard sequential order for novel word meaning (e.g., the affix "kla" could mean "the opposite" OR "the young version of"), then they would attribute meaning to both congruent and incongruent novel words. Results from three behavioral experiments repeatedly demonstrate large individual variability in the extent to which participants rely on sequential order rules for constructing novel meaning. Some individuals exhibit clear evidence of a rule-based BUILDing strategy, while others adopt a MIXing strategy. In the third experiment, we also demonstrated that this LEARNING AND GENERALIZATION OF NOVEL COMPOSITIONAL MEANINGS 6 variability in reliance on the rule-based building strategy for meaning composition is partially explained by individual differences in well-established stable trait factors, including general nonverbal intelligence and vocabulary. Intriguingly, reliance on rule-based BUILDing also correlated with variability in the number of spoken foreign languages, suggesting that reliance on transferrable structural rules for compositionality may be a key feature of multilingualism 
(Culbertson & Adger, 2014;
MacWhinney, 1992)
.


Experiment 1
We assessed participants' compositional ability by asking them to infer the meaning of novel pseudo-words using implicitly learned morphological rules ( 
Figure 1
). If the learning process involves the deconstruction of meanings 
(Rastle & Davis, 2008;
Taft, 2010
, but see 
Häikiö et al., 2011;
Stites et al., 2016)
, participants would acquire the individual meanings of the compositional parts, and subsequently use this knowledge to infer the meaning of novel word they have not encountered. This paradigm further allows us to assess participants' reliance on generalizable structural rules (ie., MIXing vs BUILDing).
To quantify participants' ability to generalize during online composition, we measured participants' reaction times (RTs) using a semantic priming task. Participants made semantic decisions on the target synonym word (e.g., "black"), following a prime pseudo-word of which the compositional rule is congruent (e.g., "white-kla" where "-kla" means "opposite of") or incongruent ("kla-white" where "kla-" means "the young version of") to what they have learned.
As a result of semantic priming 
(McNamara, 2005;
Neely, 2012)
, we expected participants to respond faster on a target word when the preceding compositional word carries the same meaning.
The experiment's design and hypothesis were pre-registered in the format of a project proposal at the Donders Centre for Cognitive Neuroimaging (https://osf.io/27jf3).


Methods


Participants
Given missing priors for this novel task, sample size was estimated based on 80% power to detect a median-size effect (Cohen's d = 0.5) at an alpha of 0.05. We collected behavioral data from 36 right-handed, Dutch native speakers (meanage = 24.6, SDage = 3.3, 26 women, 10 men) via the online testing platform Prolific (www.prolific.co). Two participants were excluded due to low accuracy during the priming task and one participant was excluded since they did not follow the instruction, which leaves a final sample of 33 (meanage = 24.7, SDage = 3.4, 24 women, 9 men). All participants provided written consent and received monetary compensation. The experiment was approved by the local ethics committee (METC Oost-Nederland, 2014/288) and conducted in accordance with the Declaration of Helsinki.


Materials
For the learning phase, we constructed 30 compositional pseudo-words consisting of a known stem and an unknown affix. While we illustrate the design using English examples, the actual materials are in participants' native language, Dutch. The affix alters the word meaning depending on its position and leads to unique compositional meanings in different sequential combinations with the stems. We made sure that this sequential order rule cannot be explained by the word class of the stems by misaligning the transitions (e.g., "-kla" turns an adjective to an adjective, whereas "kla-" turns a noun into a noun, however the same rule does not hold for affix "ran", where both affix positions turn a noun into an adjective). In total, six meaning categories were selected, with five exemplar words in each category. These six affix meanings were assigned to three affix forms (as prefix and suffix, respectively), counterbalanced across participants. In this way, we ensured the priming effects were not confounded by visual input.
We also made sure that the compositional words do not resemble existing Dutch words.
For the testing phase, a separate set of compositional pseudo-words (i.e., not presented in the learning phase) was created using another 30 stems. The pseudo-words were manipulated using the same affixation rules. Specifically, we manipulated the way in which the affixes are attached to the new stems in triplets, with each stem appearing in three different experimental conditions:
(1) order-congruent: affixes are attached at the end, or at the beginning of the stem so that the novel compositional word is meaningful, given the position of the affix relative to the stem (e.g., white-kla = the opposite of white = black); (2) order-incongruent: affixes are attached at the end or beginning of the stem so that the novel compositional word is not meaningful, if participants had extracted the position-dependent rules from learning (e.g., kla-white = the small version of white = meaningless). We made sure that, in this case, there was no possibility of inferring any meaning for the incongruent words. However, if participants adopt a MIXing strategy (kla = the small version OR the opposite of), the incongruent words could still be meaningful; (3) mismatch: the stems are combined with alternative affixes, so that the novel compositional word is meaningless, regardless of the position of the affix (e.g., ran-white = "the color of" white = meaningless; white-ran = "the extreme version of" white = meaningless). For all pseudo-words in the learning phase and all order-congruent words in the testing phase, we made sure that there is an existing Dutch synonym which is not a compound word itself, to avoid a direct mapping of affix meanings. This synonym was paired with pseudo-words in all three conditions during the semantic priming task as the target word. Given the uniquely powerful compositionality of language, it turned out to be impossible to ensure that all mismatch pseudo-words were meaningless. Instead, we ensured that in those rare cases (see Data Analysis for more details), the meaning did not correspond to the target word.
A schematic diagram of the experiment is provided in 
Figure 1
. See SM 1 for a full set of stimuli used for learning and testing.


Figure 1
A schematic diagram for Experiments 1, 2 and 3a.
Note. (A) Participants learned artificial, compositional words and were tested on their memory of these words. Specifically, these compositional pseudo-words consisted of a known stem (e.g., "good" in "good-kla") and an unknown affix (e.g., "kla"). The affix alters the word meaning depending on its position (e.g., "-kla" as a suffix means the opposite, whereas "kla-" as a prefix means "young version"). Importantly, the structural rules were never made explicit to the participants. (B) We tested participants' knowledge with novel, compositional pseudo-words using a semantic priming task, in which they have to make a semantic judgment about the target word following the prime pseudo-words, which were either congruent with the sequential order rule presented during the learning phase (e.g., "white-kla", where "-kla" means "opposite"), or incongruent with the structural rule (e.g., "kla-white", where "-kla" but not "kla-" means "opposite"), or in a totally mismatched meaning regardless of order (e.g., "white-ran/ran-white", where neither "-ran" or "ran-" means "opposite"). (C) Afterwards, we explicitly tested their knowledge about the meaning of the novel compositional words and about the compositional rules. The actual stimuli were in participants' native language, Dutch. Experiment 2 and the artificial language learning task in Experiment 3 (Experiment 3a) are identical. They differ from Experiment 1 in the following perspectives: (*) participants had four instead of three blocks of learning; (**) in the memory test, four options of compositional words sharing the same stem were used (e.g., "which of the words means 'bad'? A. goodkla; B. goodran; C. goodlor; D.
goodsen"); (***) the presentation time of the prime, pseudo-word was prolonged from 1000 ms to 1500 ms; (****) the probe trials were counterbalanced across three experimental conditions.
Reproduced with permission from the authors from https://doi.org/10.17605/OSF.IO/5T6DE.


Procedure
Learning. Participants studied the learning set of 30 compositional pseudo-words in a self-paced manner ( 
Figure 1A
). Every compositional word was presented together with its synonym meaning and an example sentence using the word in context, till a maximum of 15 s or participants pressing to continue. After viewing all the words, participants completed a multiplechoice test where they were given a synonym meaning and needed to choose a matched compositional word. Each compositional word was presented once in a learning block and once in a memory test. The learning and memory tests were interleaved and repeated for 3 blocks, with 30 trials per block.
Priming. Next, participants went through a semantic priming task where they were presented with the testing set of compositional pseudo-words, followed by a target synonym ( 
Figure 1B
). Participants were asked to indicate the animacy of the synonym word. They responded by pressing the J ("human or animal") or the F key ("other") on the keyboard. Each prime word was presented on the screen for 1000 ms, preceded by a fixation of 250 ms, and followed by an interval screen of "***" for 1000 ms. The target word stayed on the screen for a maximum of 2000 ms or till the participant responded, followed by a jittered screen of 300-700 ms. Then the next trial started. To ensure that participants paid attention to the prime words, we included a probe question on 10% of the trials where participants needed to indicate if the prime pseudo-word shares the same meaning as the target synonym word ("probe trials"). Participants pressed J for yes and F for no. To avoid confusion from multi-tasking, the meanings of each key were presented on the screen during the task. The probe question stayed on the screen for a maximum of 10s or till participants responded. There were three blocks in total, with each prime (pseudo-word)-target (synonym) pair in each condition presented once in each block. The same stem word never repeats on two consecutive trials. Prior to the task, participants went through a practice block where they got familiarized with the task and received feedback on the animacy of all the synonym words.
Posttest. In a posttest, participants were asked whether all the compositional pseudowords they had seen in the priming task were meaningful, and if so, what they meant ( 
Figure   1C
). We also included the 30 pseudo-words from the learning set to access participants' memory performance. All the pseudo-words were presented to the participants in a randomized order. In the end, participants were asked explicitly about the meaning of the three sets of affixes.
The experiment was conducted via the online experiment platform Gorilla (https://gorilla.sc/).
The whole session took about 80 min.


Data Analysis
Preprocessing. As a sanity check, we confirmed that all participants scored above chance-level (25%) in the memory test after the last block of learning and recalled more than half of the learned words in the posttest. We only excluded participants whose accuracy was below chance level in the semantic judgment task (N = 2).
Our key measurement of interest is the RTs during the semantic priming task. Prior to the analysis, we excluded trials with missing responses, with an RT faster than 100 ms, or where participants accidentally pressed a button during the presentation of the prime word (in total 1.8%).
Based on the posttest, we additionally categorized the participants into three types of learners: the BUILDers (N = 15) who take into account the sequential order rule, the MIXers (N = 10) who simply integrate the meaning of the constituent parts, and the "non-generalizers" (N = 8) who failed to infer novel, compositional meanings. The non-generalizers were defined as those who consider more than half of the pseudo-words in the mismatch condition to match the synonym, or more than half of the pseudo-words in the congruent condition to not match the synonym. MIXers were categorized as those who consider more than half of the pseudo-words in the incongruent condition to match the synonym. The rest were defined as BUILDers, namely, those who mainly identify pseudo word meanings in the congruent condition, but not in the incongruent or mismatch conditions. The non-generalizers were excluded from the analysis of the priming task because they could not compute the meaning of the prime pseudo-words.
Participants' written responses to the pseudo-word meaning in the posttest were coded as (1) matching the synonym, (2) meaningless, (3) creative, unexpected answers (e.g., when one considers a mismatch pseudo-word "human-kla", the opposite of human, to be "animal"), and (4) unexpected but incorrect answers (e.g., when one confused the meaning of different affix forms, mistook "warm-ran" as "warm-kla' and reported the meaning to be "cold", the opposite of warm). We excluded the unexpected cases in the analysis, which concerns 4.4% of the trials. As a result of the paired presentations in the priming task (e.g., "white-kla" is always followed by "black"), when participants indicated the pseudo-word to be meaningful, they usually provided the target synonym to be the inferred meaning (Kendall's tau = .95). Therefore, we used the second measure (i.e., the percentage of inferred meaning to match the synonym word) as an indicator for participants' explicit inference, given that it provides more certainty than a binary choice.
Statistical Analysis. We performed the statistical analyses using mixed-effects models with the lme4 package (Version 1.1.27.1, 
Bates et al., 2015)
 in R (Version 4.1.0; R Core Team, 2017). For the primary analysis of reaction times in the priming task, the fixed effects included experimental conditions (congruent vs. incongruent vs. mismatch), accuracy, response button, and whether the current trial was preceded by a probe trial or not. Participants and items were included as random effects. The inclusion of a random slope for conditions resulted in convergence issues in some models (including the ones in Experiments 2 and 3). Therefore, for improved comparability across analyses, we opted to retain only the random intercept for all models. While we recognize that this might have increased the risk of false positive findings, this risk is mitigated by replicating the key effects across three independent experiments. For exploratory purposes, we additionally included the learner type (BUILDer vs. MIXer) as a group effect and tested its interaction with experimental conditions. For analysis of the posttest as well as the probe trials in the priming task, we used generalized linear mixed effects models (GLMEMs) and only included experimental conditions as a factor. The exact set of models are provided in SM 2. The significance of individual predictors was assessed using the Type II Wald Chi-square test. The multcomp package (Version 1.4.17, 
Hothorn et al., 2008)
 was used to perform multiple comparisons between the three experimental conditions.


Results
Analysis of the choice data from the memory trials during the initial learning phase revealed that participants learned all the pseudo-words after 3 blocks (all participants' memory accuracy > 80% in the last block, meanaccuracy = 96.2 %, SD = 5.7%, 
Figure 2A
, left panel). Note that they did not have to learn the structural affixation rules in order to perform well on these memory trials. Instead, they could have adopted a simple flat associative strategy, memorizing the presented synonym meaning of the pseudowords.
In fact, most participants did not adopt a flat associative learning strategy, but instead decomposed the pseudowords into a stem and an affix and inferred the structural affixation rule.
This was demonstrated by analysis of responses from the posttest ( 
Figure 2E
, left panel; 
Table   1
), during which participants composed the meanings of the novel pseudo-words based on learned affixation rules. This analysis suggested that 24% of participants (N = 8) were not able to generalize the structural affixation rules: They either considered more than 50% of the congruent words to be meaningless, or incorrectly assumed more than 50% of the mismatch words to be meaningful. These "non-generalizers", defined by the posttest, were excluded from the analysis of the priming task data. The majority of participants (76%) were able to infer the meaning of compositional pseudo-words when they were constructed using the same sequential order rules as in the learning (congruent condition, meanmeaningful = 82.5%, SD = 15.6%), while successfully rejecting the non-sensible composition of novel words in the mismatch condition (meanmeaningful = 17.5%, SD = 27.4%). A particularly intriguing pattern of responses was observed for the incongruent words: a bimodal distribution characterized by large individual variability (meanmeaningful = 41.8%, SD = 37.1%). While some participants (MIXers) considered the incongruent pseudo-words to be meaningful, others (BUILDers) did not. The reported meaningfulness differs significantly across all three conditions.
Critically, as predicted, participants also showed a significant difference in RTs across three experimental conditions in the semantic priming task ( 
Figure 2C
, left panel; 
Table 2
).
Participants were faster in making semantic decisions when the target word was primed by a congruent (mean = 587 ms, SD = 125) or incongruent (mean = 592 ms, SD = 126) pseudo-word, compared with a mismatched one (mean = 615 ms, SD = 119), suggesting that they considered the congruent or incongruent compositional wordbut not the mismatch onesto share the same meaning as the target word. However, contrary to our prediction, there was no difference in speeding between congruent vs. incongruent conditions.
On the other hand, participants' performance on the probe trials shared similar patterns with the posttest, where they indicated whether the prime meaning matched the target synonym and showed a significant difference between conditions ( 
Figure 2B
, left panel; 
Table 1
).
Specifically, they reported most of the congruent pseudo-words to match the synonym meaning (mean = 78.0%, SD = 22.6%), and the mismatch pseudo-words to carry a different meaning (mean = 25.2%, SD = 18.9%) while they showed more variant responses towards the words in the incongruent condition (mean = 51.1%, SD = 34.0%).
Together, these findings demonstrate that participants can compute novel compositional meaning online by learning and generalizing previously learnt structural rules. However, while data from the posttest and the probe trials indicate that most participants also learn and generalize the higher-order sequential order rules when asked explicitly, we did not obtain evidence for the implicit use of such higher-order sequential order rules during semantic priming.
We reasoned that such evidence for the implicit use of sequential order rules (i.e., a difference in RT between congruent and incongruent conditions during semantic priming phase) might surface only for individuals who BUILD rather than for those who MIX compositional meanings.
Therefore, we next explored RTs from the priming task in a subgroup of BUILDers (N = 15, as defined based on the posttest data). Likely due to the low statistical power given the small sample size, we found no difference between congruent and incongruent conditions for the BUILDers (meancong = 617 ms, SDcong = 120, meanincong = 621 ms, SDincong = 120, meanmismatch = 637 ms, SDmismatch = 116), nor any condition difference between the two learner groups ( 
Figure   2D
, left panel; 
Table 2
; For the MIXers: meancong = 543 ms, SDcong = 125, meanincong = 549 ms, SDincong = 128, meanmismatch = 582 ms, SDmismatch = 122).  Note.
*Non-generalizers, defined by the posttest, were excluded from the analysis of the semantic priming task and the probe trials (N = 8 in Experiment 1, N = 7 in Experiment 2 and N = 7 in Experiment 3a) 
Table 2
 Statistics for the RT data from the semantic priming task in the three experiments. ** while controlling for response accuracy (Χ 2 (1) = 2.02, p =.155), response button (Χ 2 (1) = 5.45, p = .020) and whether the current trial is preceded by a probe trial (Χ 2 (1) = 94.98, p < .001) *** while controlling for response accuracy (Χ 2 (1) = 22.47, p <.001), response button (Χ 2 (1) = 0.33, p = .568) and whether the current trial is preceded by a probe trial (Χ 2 (1) = 127.30, p < .001) *** while controlling for response accuracy (Χ 2 (1) = 20.41, p <.001), response button (Χ 2 (1) = 0.73, p = .394) and whether the current trial is preceded by a probe trial (Χ 2 (1) = 266.67, p < .001)


Discussion
Human language is powerful in terms of its creativity. Using an artificial language learning task, we show that the majority of participants decomposed word meaning into its constituent parts and generalized the acquired affixation rules to understand novel compositional pseudo-words (cf. 
Rastle & Davis, 2008;
Taft, 2010)
. This process is efficient and takes place on the fly: not only did the participants explicitly report the novel, compositional meanings (posttest), it is also reflected by implicit, online processing in terms of greater semantic priming (congruent > mismatch).
Both the posttest and the responses to the probe questions during the priming task suggested that (at least part of) the participants distinguished the inferred meaning in the congruent and incongruent conditions: they indicated that the congruent compositional pseudo-word matched the target synonym in meaning, whereas the incongruent pseudo-word did not, suggesting that they considered a different meaning of the same affix form based on its sequential order. However, we did not find evidence for this manipulation of the sequential order to have an effect on implicit priming (i.e., when comparing between congruent and incongruent trials), also not when we only consider the group of participants who relied on the sequential order rules (i.e., the BUILDers). We considered two reasons for this lack of greater priming of congruent versus incongruent words: (1) The sequential order rule memories might not have been strong enough due to insufficient training, leading to high effort-and time-costs of online inference processes during the priming task;
(2) Participants might not have had enough time to fully process the sequential order of the novel, compositional prime words onlinewhereas on a probe trial or in the posttest they were allowed sufficient time to reflect on the meanings. In other words, they might have taken a "good enough" approach 
(Ferreira et al., 2002;
Ferreira & Patson, 2007)
, ignoring the sequential orders even if they have learned them.
Therefore, we conducted the second experiment, with various parameters adjusted to optimize the learning and the online compositional process.


Experiment 2
In the second experiment, we aimed to replicate both the effects on explicitly inferred knowledge (i.e., participants are more likely to infer the meaning of a pseudo-word in congruent > incongruent > mismatch condition) and on implicit priming (i.e., larger priming in congruent > mismatch condition) found in Experiment 1. Furthermore, we optimized the learning and priming setup to increase sensitivity to the learning of the sequential order rules, that is, to putative differences between priming in the congruent and the incongruent conditions. To increase the statistical power and to be able to investigate the performance of different learner types (BUILDer vs MIXer), we also doubled our sample size.
The experiment's design and hypothesis were pre-registered in the format of a project proposal at the Donders Centre for Cognitive Neuroimaging (https://osf.io/27jf3). The experiment was adapted from Experiment 1 in the following ways: (1) we included a fourth block of learning to ensure that participants learned the word well enough, which might lead to more automatic, online inference processing;


Methods
(2) in the priming task, we prolonged the presentation time of the prime, pseudo-word from 1000 ms to 1500 ms, in order to ensure sufficient processing time 
(Figure 1
). Two additional minor changes are: (1) in the memory test following learning, we provided four options of compositional words sharing the same stem (e.g., "which of the words means 'bad'? A. goodkla; B. goodran; C. goodlor; D. goodsen"), so that the choice cannot be made based on the semantic association between the stem and the synonym;
(2) in the priming task, we now counterbalanced the probe trials across the experimental conditions.
We used the same exclusion criteria and analysis pipeline as in Experiment 1. 3.9% trials were excluded from the priming task and 4.6% trials were excluded from the posttest.


Results
Similar to Experiment 1, participants were able to recall the meaning of all the pseudowords after 2 or 3 blocks and reached ceiling performance after the 4th block (meanaccuracy = 95.2 %, SD = 9.2%, 
Figure 2A
, middle panel).
In the posttest 
(Figure 2E, middle panel)
, participants reported most of the congruent pseudo-words (meanmeaningful = 81.7%, SD = 16.7%) to be meaningful, but most of the mismatch words (meanmeaningful = 10.3%, SD = 20.0%) to be not meaningful. This suggests that participants decomposed the pseudowords into a stem and an affix during learning and inferred the novel pseudo-words using the structural affixation rule. We observed again inconsistency in the degree to which the words in the incongruent condition were considered meaningful (meanmeaningful = 32.9%, SD = 35.1%). While some participants considered an incongruent pseudo-word meaningful (MIXers), the others did not (BUILDers). The percentage of reported meaningfulness differed significantly across all three conditions 
(Table 1)
. Based on the posttest, we identified 63% BUILDers (N = 45) and 27% MIXers (N = 19). The remaining 10% of participants either report most of the mismatch word to be meaningful, or most of the congruent word to not be, suggesting that they were not able to generalize based on the learned compositional rules. These non-generalizers were excluded from the priming analysis (N = 7).
Importantly, the BUILDing-MIXing behavior is consistent across all affix pairs (SM3).
Again, participants' performance on the probe trials in the semantic priming task shared similar patterns with the posttest 
(Figure 2B
, middle panel). Participants were more likely to report the pseudo-words in the congruent condition to match the meaning of the target synonym word, compared with the incongruent condition, followed by the mismatch condition 
(Table 1;
 LEARNING AND GENERALIZATION OF NOVEL COMPOSITIONAL MEANINGS 26 meancong = 82.7%, SD = 22.3%; meanincong = 43.6%, SD = 32.2%; meanmismatch = 20.7%, SD = 22.5%).
When examining the priming effect in the semantic judgment task, we again observed a significant difference in RTs across the three experimental conditions ( 
Figure 2C
, middle panel; 
Table 2
). Participants were faster in making semantic decisions when the target word was primed by a congruent (mean = 576 ms, SD = 142) or incongruent (mean = 602 ms, SD = 158) pseudoword, compared with a mismatched word (mean = 616 ms, SD = 154), replicating what was found in Experiment 1. However, in contrast to Experiment 1, Experiment 2 did uncover a significant effect of congruency on semantic priming: Participants were faster to respond to target words that were primed by a congruent than an incongruent pseudo-word. This indicates that participants relied on sequential order rules when making inference, on the fly, of novel word meaning during the implicit semantic priming task.
Moreover, we observed different patterns in the semantic priming effects for the BUILD and the MIX learner types ( 
Figure 2D
, middle panel; 
Table 2
). The MIXers showed no priming difference between the congruent (mean = 541, SD = 162) and incongruent conditions (mean = 554, SD = 180,), although both conditions led to a stronger priming effect compared with the mismatch ones (mean = 581, SD = 181). On the other hand, the BUILDers showed a larger priming effect of the congruent (mean = 591, SD = 131) than the incongruent ones (mean = 623, SD = 145,), or compared with the mismatch condition (mean = 632, SD = 140), but no difference between incongruent and mismatch. The interaction between conditions and groups is, however, not significant. This suggests that, indeed, when participants were building the meanings based on sequential order rules, they recognize congruent compositional words but not incongruent ones. This process is likely to be less automatic and requires sufficient learning or longer processing time, therefore only surface Experiment 2, but not Experiment 1.


Discussion
Results from Experiment 2 replicate results from Experiment 1, substantiating the conclusion that most participants infer and generalize structural affixation rules for generating novel word meaning on the fly. This is evidenced by larger semantic priming of congruent versus mismatch words. Critically, a significant proportion of participants inferred, generalized and applied these structural rules in a manner that depends on the position of the affix in relation to the stem. This is evidenced by larger semantic priming of congruent versus incongruent words.
Individual performance depends on whether participants accounted for the sequential order rules or not: BUILDers assign distinct meanings to the same affix form depending on the sequential order rule, whereas the MIXers assign both meanings to the same affix form and compose novel meanings in a more flexible, context-dependent manner (e.g., interpreting "kla" as "opposite or young version", with the interpretation varying based on the compatibility with the stem, e.g. the stem "good" is compatible only with the "opposite" rule and not the "young version" rule).
However, it seems that even with sufficient training and enough online processing time, some of the participants still generalize the compositional rules without taking into account the sequential order (i.e., by MIXing). Thus, both Experiments 1 and 2 demonstrate that there is large individual variability in the degree to which people rely on sequential order rules for building novel word meanings. Moreover, the BUILDing-MIXing behavior is consistent across all three affix pairs, indicating high internal consistency. Together, these findings raise the question whether the degree to which individuals rely on sequential order for building novel word meaning reflects a stable trait characteristic. What individual trait factors determine whether someone does or does not rely on sequential order for selecting one of two affixation rules? What factors make some people (the MIXers) maintain two affixation rules and then apply either of them without taking into account the position of the affix with respect to the stem? And why can others (the BUILDers) adopt a higher-order strategy and take into account the position of the affix for selecting between two affixation rules?
In a third experiment, we assessed the external validity of our construct by assessing the degree to which individual differences in compositional generalization reflect variability in wellestablished stable trait factors, including both linguistic knowledge (such as someone's vocabulary size) and more domain-general cognitive abilities (such as nonverbal intelligence and working memory capacity).


Experiment 3
In two experiments, we have consistently observed two types of behaviors in compositional generalization: those involving reliance on structural rules (e.g., sequential order) and those which do not. The current experiment aims to reveal individual difference factors that are associated with the degree to which someone exhibits BUILDing or MIXing behavior.
Previous research has highlighted both domain-general and language-specific factors in individual differences in language learning, structural generalization, and rule abstraction. On the one hand, two cognitive factors that are commonly found to positively predict performance in learning and generalization are working memory 
(Craig & Lewandowsky, 2012;
Kempe et al., 2010;
Little & McDaniel, 2014;
Misyak & Christiansen, 2011
, but see Grey et al., 2015
Little &
McDaniel, 2014 for missing effects, and
DeCaro et al., 2008
 for reverse effects) and nonverbal
intelligence 
(Brooks et al., 2016;
Genesee, 1976;
Reber et al., 1991
; but see 
Little & McDaniel,
 language skills such as vocabulary and grammar have also been found to contribute to individual variation in language learning 
(Ellis, 2004;
Kidd et al., 2017;
Marchman & Bates, 1994
; but see 
Misyak & Christiansen, 2011)
.
Learning and generalizing compositional word meanings share characteristics with a variety of relevant nonlinguistic cognitive processes such as abstract rule learning 
(Collins & Frank, 2013)
 or statistical learning 
(Frost et al., 2019)
. Understanding what cognitive abilities contribute to the linguistic generalization process will help us leverage the knowledge from these research fields to address common questions. Accordingly, this third experiment will also help us evaluate the relative contributions of linguistic and nonlinguistic skills in this generalization process and how they lead to different types of participant behavior. The experiment was preregistered at AsPredicted.org (https://aspredicted.org/s7bb4.pdf).


Methods


Participants
We originally planned to invite all participants from Experiments 1 and 2 back for obtaining relevant individual difference measurements (N = 104, which gives 70% power to detect a median-size effect, Cohen's d = 0.5). However, due to the large dropout rate (only 17 subjects agreed to return for another testing session), we decided to recruit an additional 82 righthanded, Dutch native speakers who performed both the artificial language learning task and the individual differences tasks. Two participants were excluded due to below chance-level performance in the priming task, leaving a final sample of 80 (meanage = 24.7, SDage = 5.6, 28
women, 52 men). All participants were recruited via Prolific and received monetary compensation. All participants provided written consent. The experiment was approved by the same local ethics committee and conducted in accordance with the Declaration of Helsinki.
For the individual difference analysis, we excluded all the participants who were nongeneralizers, based on the criteria outlined for Experiments 1 and 2 (N = 8) and two additional participants due to incomplete datasets, leaving a final sample of 87 (meanage = 24.7, SDage = 5.2, 35 women, 52 men).


Materials
Artificial Language Learning Task. We used the identical setup as Experiment 2.


Individual Differences Measures.
We used a set of five tests from the Individual Differences in Languages Skills (IDLas) Test Battery 
(Hintz et al., 2020
(Hintz et al., , 2023
, a flexibly adaptable test battery for native speakers of Dutch. Specifically, we selected three tests of domain-general cognitive abilities (i.e., verbal and nonverbal working memory, and non-verbal intelligence) and two tests of linguistic skills (i.e., grammar and vocabulary). 
Figure 3
 provides an overview of the tests.


Figure 3
An overview of the individual differences tests battery comprising both domain-general and language-specific skills 
(Hintz et al., 2020
(Hintz et al., , 2023
.
Note. the actual tests were in participants' native language (Dutch). Reproduced with permission from the authors from https://doi.org/10.17605/OSF.IO/5T6DE.
Non-verbal working memory (nonverbal WM) was measured using a Corsi block clicking task 
(Chu et al., 2014;
Corsi, 1972
; test-retest reliability rforward = .66, rbackward = .68, 
Hintz et al., in prep)
. In each trial, participants recalled a sequence of identical spatially separated blocks by clicking on them in the order they were encountered (forward) or in the reverse order (backward). The sequence length was extended by one square when at least one of two consecutive trials was recalled correctly. The test started with three blocks, and was terminated after two consecutively failed trials, or when participants reached a maximum of nine blocks.
The total score was the sum of correct responses on all trials in forward and backward versions.
Verbal working memory (verbal WM) was assessed using an auditory digit span task (adapted from 
Wechsler, 1997
; test-retest reliability forward span r = 0.75, backward span r = 0.70, 
Hintz et al., 2022)
. Participants recalled sequences of digits by typing in forward or backward orders. The same testing and scoring procedures were applied as the non-verbal task, with the maximal digits being nine in the forward version and eight in the backward version.
A matrix reasoning test 
(Chierchia et al., 2019
; test-retest reliability r = 0.71) was employed to measure non-verbal intelligence. On each trial, participants indicated which of the four possible shapes completes a matrix of geometric patterns. There were in total 36 trials and the score was equal to the correctly responded trials.
Two tests were employed to measure participants' grammar and vocabulary skills, respectively. In the prescriptive grammar test (adapted from 
Favier et al., 2021;
Hubers et al., 2016
; test-retest reliability r = 0.86, 
Hintz et al., 2022)
, participants made grammatical judgements on spoken sentences with syntactic features known to be difficult for adult speakers of Dutch (e.g., ik vs. mij, als vs. dan, ze vs hun). In the receptive vocabulary test 
(Vander Beken et al., 2018)
, participants read target words and selected the correct meaning among four written alternatives. Both tests contained 40 trials and the scores equaled the number of correctly responded trials.
In addition, we measured participants' Need for Cognition ("the tendency for an individual to engage in and enjoy thinking", 
Cacioppo & Petty, 1982
; test-retest reliability r = 0.88, 
Sadowski & Gulgoz, 1992)
 and their language background (incl. the number of foreign languages they speak and self-reported proficiency on a seven-level Likert scale). The Dutch version of the Need for Cognition scale consists of 18 statements. Participants evaluated how characteristic each statement was of themselves on a scale from 1 (extremely uncharacteristic) to


Procedure
The experiment was conducted via the online experiment platform Gorilla, with the individual difference tests redirected to the external, IDLaS application. Participants performed the artificial language learning task (if they had not done it before), and then the battery of the individual difference tests, followed by the questionnaires.
The individual differences measures took about 50 minutes. For those participants who needed to complete the artificial language learning task as well, it took a total of around 2 hrs.


Data Analysis
For the artificial language learning task, we used the same exclusion criteria and analysis pipeline as in Experiments 1 and 2. A total of 3.0% trials were excluded from the priming task and 6.0% trials were excluded from the posttest.
Learner types (i.e., BUILDer vs MIXer) were categorized in the same way as in Experiments 1 and 2. Non-generalizers were excluded from the individual difference analysis, since their responses in the posttest were likely to be random. We further computed a learner index by subtracting participants' performance of the posttest (i.e., the percentage of words the individual participant reported to match the synonym) in the incongruent condition from the congruent condition. The higher the index, the greater the reliance on the structural rules for building new word meaning.
To examine what type of individual difference factors account for performance on the artificial language learning task, we performed a generalized linear model using a binomial distribution, with the five normalized individual test scores as predictors. We performed a principal components analysis (PCA) on the five individual difference measures to extract shared, relevant features. We then evaluated the contribution of these principal components to the compositional ability (measured by learner type), using a generalized linear model.
To capture potential non-linear relationships between the compositional behavior and the individual difference measures, we employed a more data-driven, non-parametric method of conditional inference tree from the party package in R 
(Hothorn et al., 2006)
. For the conditional inference tree, we recursively performed binary splits of the learner index as the dependent variable, based on scores of the five individual difference measures as predictors. The algorithm starts with the entire dataset and repeatedly splits it into two subsets based on a selected predictor. Each split is chosen by selecting the best predictor through a conditional inference test (α = .05). Only significant predictors are represented in the tree. The conditional inference tree helps to capture meaningful relationships in the data and to estimate the true effect of a predictor when all other effects are simultaneously considered.
In addition, we included in an exploratory model participants' score of Need for Cognition and the number of foreign languages spoken.


Results


Compositional Performance (Experiment 3a)
We analyzed all the data from the new participants who took part in the artificial language learning task (N = 80). All effects reported for Experiments 1 and 2 were replicated in the current experiment, thus providing a third independent replication. This also justifies the decision to merge the current, new dataset, with the sub-sample from the previous two experiments (N = 17), in order to explore the role of individual difference.
The participants were able to recall all compositional pseudo-words (last block of learning: meanaccuracy = 96.8%, SD = 6.2%, 
Figure 2A
, right panel). Importantly, they showed the same, distinctive pattern across the three experimental conditions when reporting the meaning of novel pseudo-words, both for the posttest (meancong = 83.8%, SD = 16.0%, meanincong = 36.8%, SD = 36.5%, meanmismatch = 10.2%, SD = 19.7%) and for the probe trials (meancong = 80.5%, SD = 17.0%, meanincong = 46.0%, SD = 32.7%, meanmismatch = 23.6%, SD = 19.8%; 
Figure 2B
, E, right panel; 
Table 1
). Again, the participants were categorized as BUILDers (N = 46, 58%),
MIXers (N = 27, 33%) and non-generalizers (N = 7, 9%) based on the posttest, with the nongeneralizers excluded from the priming analysis and the individual difference analysis.
In the semantic priming task, we replicated the findings in Experiment 2. Participants showed a significant difference in RTs across three experimental conditions ( 
Figure 2C
, right panel; 
Table 2
), with a larger priming effect in the congruent (mean = 626 ms, SD = 186) than the incongruent (mean = 645 ms, SD = 195) condition, followed by the mismatched condition (mean = 668 ms, SD = 204). When split between groups, the MIXers showed no priming difference between the congruent and incongruent conditions (meancong = 592 ms, SD = 198, meanincong = 593 ms, SD = 203, meanmismatch = 628 ms, SD = 216) whereas the BUILDers did (meancong = 645 ms, SD = 178, meanincong = 676 ms, SD = 185, meanmismatch = 692 ms, SD = 195).
However, the condition difference did not differ between groups ( 
Figure 2D
, right panel; 
Table   2
).


The Role of Individual Differences (Experiment 3b)
Participants' performance on the five individual difference tests are shown in 
figure 4A
 as a function of the learner types (nonverbal WM: mean = 17.2, SD = 3.2; verbal WM: mean = 15.6, SD = 3.8; general intelligence: mean = 25.6, SD = 5.2; grammar: mean = 26.2, SD = 4.24;
vocabulary: mean = 24.8, SD = 7.0). The BUILDers performed numerically better than the MIXers on all the tasks. Using a generalized linear model including all five individual difference predictors, we show that the learner type can be predicted best by general intelligence (β = 0.54, SE = 0.28, z = 1.97, p = .049). The effect of learner type predicted by vocabulary score only tended towards significance (β = 0.51, SE = 0.28, z = 1.80, p = .072). There is no effect of nonverbal WM (β = -0.21, SE = 0.27, z = -0.79, p = .431), verbal WM (β = 0.31, SE = 0.29, z = 1.05, p = .294), nor grammar (β = 0.03, SE = 0.30, z = 0.09, p = .929).
Since the five individual measures were not independent from each other (nonverbal WM vs. verbal WM: r = .24, p = .025; nonverbal vs. intelligence: r = .28, p = .009; verbal WM vs intelligence: r = .29, p = .007; verbal WM vs. grammar: r = .40, p < .001; verbal WM vs.
vocabulary: r = .30, p = .005; grammar vs intelligence: r = .30, p = .005; grammar vs.
vocabulary: r = .48, p < .001 ; all other ps > .13), we performed a PCA analysis to evaluate the structure underlying these individual cognitive abilities ( 
Figure 4B)
. Results show that the first two principal components accounted for 64% of the variance (PC1: 40.9%; PC2: 23.1%; PC3:
14.2%; PC4: 12.5%; PC5: 9.3%). PC1 likely reflects general task performance, with all individual difference measures loading positively. PC2 captures the difference between linguistic (grammar and vocabulary) and nonlinguistic tasks (WM and intelligence). There was an effect of PC1 scores on learner type ( 
Figure 4C
, β = 0.59, SE = 0.19, z = 3.15, p = .002), but not PC2 scores (β = 0.16, SE = 0.22, z = 0.73, p = .464), or any of the other components (all ps > .173).
Next, we explored compositional behavior using a learner index, defined by how likely participants consider a congruent pseudo-word to be meaningful compared with an incongruent word ( 
Figure 4D
). This index reflects how much participants rely on the sequential order rule for novel inference: the higher the index, the more likely they BUILD rather than MIX. Given the bimodal distribution of the learner index, we used a nonparametric, data-driven, conditional inference tree to evaluate the role of individual differences (see Methods for details). The outcome conditional inference tree represents significant predictors at each split ("Nodes") of the learner index data ( 
Figure 4E
). General intelligence was the most important predictor (p = .005) separating participants with higher learner index (Node 5) from participants with lower learner index (Nodes 3 and 4). The vocabulary score (p = .006) further split the group with slightly lower learner index (Node 4) and the lowest learner index (Node 3). Importantly, without the algorithm knowing the BUILDing-MIXing distinction, the output captured this individual difference: nodes 4 and 5 represent BUILDer-like participants, while node 3 represents MIXerlike participants. Reproduced with permission from the authors from https://doi.org/10.17605/OSF.IO/5T6DE.
Finally, we considered the number of spoken foreign languages as a reflection of language experience (mean = 1.56, SD = 0.87), and Need for Cognition scores (mean = 60.36, SD = 9.71) as a reflection of cognitive motivation. We included the two significant predictors that came out of the previous analyses (i.e., intelligence and vocabulary) in the same generalized linear model. Results showed that learner type can be predicted by the number of spoken foreign language (β = 0.55, SE = 0.27, z = 2.06, p = .039), but not by Need for Cognition (β = 0.35, SE = 0.25, z = 0.16, p = .167). Moreover, the inclusion of these two additional measures has largely reduced the explained variance by intelligence (β = 0.48, SE = 0.26, z = 1.82, p = .068) and vocabulary (β = 0.48, SE = 0.27, z = 1.78, p = .075).


Discussion
With a third, independent sample (N = 82), we replicated the findings in the previous two experiments. These demonstrate, first, that people infer and generalize the affixation rules when composing new word meaning, and second, that there is large individual variability in the strategy they adopt to do this: Some people are sensitive to the sequential order of the affix (BUILDer), some are not (MIXer). Together with a subsample recruited back from the previous experiments, we explored the contribution of the domain-general and language-specific factors to such individual variation in the degree to which they rely on a sequential rule-based building strategy.
Our results showed that the BUILDers tended to perform better than the MIXers in all the tasks. Specifically, non-verbal intelligence seems to be a crucial factor that distinguishes the BUILDers from the MIXers. This finding is consistent with previous findings that non-verbal intelligence predicts individual performance in grammar learning and generalization (e.g., 
Brooks et al., 2016;
Kempe et al., 2010)
. It is worth noting that the Matrix task used to measure intelligence here shares some similarities with our artificial language learning task: Their successful completion requires extracting the pattern from exemplars (i.e., decompose the word and infer the meaning of the affix vs. reason the commonality of the elements in the matrix).
Nonetheless, nonverbal intelligence is a central cognitive factor that influences a wide range of cognitive abilities 
(Carroll, 1993;
Gottfredson, 2002;
Spearman, 1961)
, it is therefore likely to also contribute to the ability of generalization, in and beyond language usage.
In addition, receptive vocabulary also contributes to the separation of the MIXer-like participants and the BUILDer-like participantsalthough only in the conditional inference tree, where individuals' reliance on BUILDing was scored on a continuous spectrum, rather than binarily categorized in two groups as in the generalized linear model. It is interesting that vocabulary rather than grammar plays a more essential role here, given that the artificial language learning task requires the inference of morphological rules. Likely, what underlies the relationship between vocabulary scores and compositional abilities is not the specific linguistic process per se, but rather the general, metalinguistic awareness 
(Nagy, 2007;
Tunmer & Herriman, 1984)
. While both tests were designed to measure Dutch native speakers' linguistic skills, our participants showed a larger variance in the vocabulary score compared to the grammar ones. This speculation is also in line with the fact that participants' language experience, reflected by the number of languages they speak, also explains this group difference.
We were surprised to find that neither verbal nor nonverbal WM plays a role in the performance of our task. This is also in contrast to previous work showing the positive relationship of WM and language and structural learning 
(Craig & Lewandowsky, 2012;
Kempe et al., 2010;
McDaniel et al., 2014;
Misyak & Christiansen, 2011
, but see DeCaro et al., 2008
Grey et al., 2015;
Little & McDaniel, 2014)
. It is possible that an association with WM would have surfaced if we had employed a WM task that relied on manipulation processes, such as the operation of listening span task, rather than maintenance and storage processes only.
In addition, we show that the individual differences are best predicted by general task performance (reflected by PC1 in the PCA analysis) and not by language-specific test performance, raising the question whether our task captures primarily processes that are shared between linguistic & nonlinguistic tasks, such as rule abstraction and generalization of abstract structure. Future work is required to investigate whether compositionality in natural language also involves such domain-general processes.


General Discussion
Human language is a powerful tool for communication, distinguished by its inherent compositionality. Through language, we possess the unique capacity to creatively combine words, forming sentences, or invent entirely new words, facilitating the expression of an infinite array of thoughts and ideas. In this study, we introduced an experimentally controlled artificial learning paradigm to quantify the human ability to construct compositional word meaning.
Without being explicitly instructed to do so, participants abstracted the compositional affixation rules when learning an artificial language and were able to generalize these rules to infer the meaning of novel words within the same language. The affixation rules structured the way the minimal units of the new word should be sequentially combined to construct a new meaningful word. Unlike many studies on nonlinguistic generalization which require participants to be trained for days (e.g., 
Mark et al., 2020;
Schwartenbeck et al., 2023)
, our artificial language learning task achieved rule abstraction in under 30 minutes. This aligns with the concept of oneshot learning in language acquisition (e.g., 
Lake et al., 2014)
, and emphasizes our ability to abstract rules with limited exposure to linguistic examples. The swift learning of compositional pseudo-words likely leverages our linguistic skills that have been developed across a lifetime to facilitate learning and generalization of previous structures when encountering a new language.
The semantic priming paradigm implemented in the task allows us to quantitatively probe the inferred representations of word meanings, which offers future possibilities to explore the neural underpinning of compositional generalization in language.
In three experiments, we consistently observed that individuals exhibited varying degrees of reliance on structural rules, as evidenced by diverse interpretations of word pairs like "whitekla" and "kla-white". We investigated cognitive factors contributing to these individual differences and found that general intelligence is a key determinant. Moreover, the pattern of individual differences effects suggests that shared, domain-nonspecific cognitive processes contribute to the ability to build new word meanings in our task. In this context, it is interesting to ask whether our task captures a principle that is shared across multiple "languages of thought"
and that has recently been invoked to account for compositionality across linguistic, musical and mathematical domains by combining discrete symbols based on structural rule 
(Dehaene et al., 2022)
.
Note that the lack of a significant interaction with the learner groups in the semantic priming task suggests that the BUILDing-MIXing difference might be better characterized by a continuous spectrum, rather than two distinct types of behaviors. Individual difference in the reliance on abstract structural rules might be reflected in the preference for a higher-order strategy, or alternatively, slower realization of the sequential order (i.e., an "aha" moment, 
Kounios & Beeman, 2014;
Löwe et al., 2023;
Stuyck et al., 2021)
. The latter case suggests that BUILDing and MIXing may instead represent different learning phases: it is possible that participants grasp the mapping of affix meaning and forms (e.g., understanding "kla" as signifying "opposite" or "young version") before assimilating the additional rule conveyed by sequential order. This assumption aligns with our observation of an increased proportion of BUILDers after more extensive learning (from 45% in Experiment 1 with three blocks of training, to 63% in Experiment 2 and 58% in Experiment 3 with four blocks of training) but remains open for future investigation.
The prominence of compositionality extends from language to other cognitive domains like visual perception, relational memory, and decision making, allowing us to navigate unfamiliar environments, solve complex problems, and adapt to ever-changing situations 
(Dehaene et al., 2022;
Frankland & Greene, 2015)
. Leveraging the linguistic phenomenon of affixation, we explored our ability to abstract and generalize structural rules and examined the interplay of language skills and nonlinguistic cognitive abilities in individual differences in compositional generalization. This study not only advances our understanding of the flexible and efficient nature of language processing, but also sheds light on shared mechanisms across diverse cognitive domains.  We analyzed the posttest data of Experiment 2 to address whether the experimental condition effect changes as a function of affix meaning pair (e.g., "kla" means opposite or young version of). In addition to the main effects of Condition (Χ 2 (2) = 2064.82, p < .001) and affix pair (Χ 2 (2) = 9.30, p =.010), there is also a significant interaction between condition and affix pair (Χ 2 (4) = 44.88, p < .001). Most importantly, the pattern of "cong > incong > mismatch" preserves in all affix pairs (all ps < .010, see the stats table and figures below). In other words, the building-mixing patterns persistently presented in all affix pairs. This is again replicated in Experiment 3a (Condition: Χ 2 (2) = 2332.39, p < .001; affix pair: Χ 2 (2) =40.17, p < .001;


Supplementary
interaction: Χ 2 (4) =30.37, p < .001).


Figure S1
Posttest results as a function of Experimental Condition and the three affix meaning pairs.
Figure 2
2
Main findings from Experiment 1 (left panel), Experiment 2 (middle panel), and the artificial language learning task of Experiment 3 (right panel). learning blocks. (B) Box plots of participants' probe response in the semantic priming task across three experimental conditions, where they indicated whether the prime words match the target words in meaning. (C) Raincloud plots of median reaction times of the semantic priming task across three experimental conditions. (D). Raincloud plots of median reaction times of the semantic priming task across three experimental conditions, split between two participant groups ("Builder" vs "Mixer"). (E) Box plots of participants' responses in the posttest across three experimental conditions, where they indicated whether the novel, compositional words are meaningful or not. For the raincloud plots, the outer shapes represent the distribution of the data over participants. For all plots, the thick horizontal line inside the box indicates the group median, and the bottom and top of the box indicate the group-level first and third quartiles of each condition. Each dot represents one participant. The thick lines connect the group median across conditions. Non-generalizers (N = 8 in Experiment 1, N = 7 in Experiment 2 and N = 7 in Experiment 3a) are excluded from the plots of the semantic priming task (B, C, D). Reproduced with permission from the authors from https://doi.org/10.17605/OSF.IO/5T6DE.


Experiment 1 (N = 25) * Experiment 2 (N = 64)* Experiment 3a (N = 73)* Priming Main effect of Condition**: Χ 2 (2) = 15.40, p < .001 Main effect of Condition***: Χ 2 (2) = 54.42, p < .001 Main effect of Condition****: Χ 2 (2) = 84.24, p < .001 0.01, SE = 0.01, z = -0.78, p = .714 β = -0.04, SE = 0.01, z = -3.59, p < .001 β = -0.02, SE = 0.01, z = -2.77, p = .016 β = -0.05, SE = 0.01, z = -7.18, p < .001 β = -0.03, SE = 0.01, z = -4.69, p < .001 β = -0.06, SE = 0.01, z = -9.15, p < .001 Inc β = -0.03, SE = 0.01, z = -2.69, p = .019 β = -0.03, SE = 0.01, z = -3.99, p < .001 β = -0.02, SE = 0.01, z = -3.74, p < .001 Learner group Builder (N = 15) Builder (N = 45) Builder (N = 46) Main effect of Condition: Χ 2 (2) = 6.48, p = .039 Main effect of Condition: Χ 2 (2) = 35.21, p < .001Main effect of Condition: Χ 2 (2) = 51.28, p < .001 and Condition: Χ 2 (2) = 0.91, p = .635Interaction between Group and Condition: Χ 2 (2) = 4.69, p = .096Interaction between Group and Χ 2 (2) = 2.18, p = .336Note. Con: congruent; Inc: incongruent; Mis: mismatch * Non-generalizers, defined by the posttest, were excluded from the analysis of the semantic priming task and the probe trials(N = 8 in Experiment 1, N = 7 in Experiment 2 and N = 7 in   Experiment 3a)    


72 right-handed, Dutch native speakers (meanage = 25.1, SDage = 4.3, 46 women, 25 men, 1 unknown) were recruited via Prolific. One participant was excluded since they failed to learn the compositional words, leaving a final sample of 71 (meanage = 25.1, SDage = 4.3, 45 women, 25 men, 1 unknown). All participants provided written consent and received monetary compensation. The experiment was approved by the same local ethics committee and conducted in accordance with the Declaration of Helsinki.


Figure 4
4
Individual differences and their relationship with compositional performance. Note. (A) Raincloud plots of individual difference task performance as a function of learner type (54 BUILDers vs. 33 MIXers). Each subplot is scaled to the maximal score of the respective test. The outer shapes represent the distribution of the data over participants, the thick horizontal line inside the box indicates the group median, and the bottom and top of the box indicate the grouplevel first and third quartiles of each condition. (B) Biplot of the first two components in the principal component analysis based on the individual difference test. The x-axis represents the first principal component, explaining 40.9% of the variance, while the y-axis represents the second principal component, explaining 23.1% of the variance. The colorbar shows the importance of a component for each individual measure (the squared cosine, cos2). (C) Raincloud of the first two principal components as a function of learner type. (D) Distribution of participants as a function of learner index. The lower the index, the more MIXer-like the individual participant is. (E) Outcome of the conditional inference tree, with learner index as the dependent variable and the five individual difference tests as predictors. Only significant predictors are presented in the tree. The ellipses indicate the significant decision point. The lines indicate the split of data based on each decision point, with the number indicating the splitting criteria of the respective predictors. The lower boxes represent the data-driven categorization of all the participants, with boxplots of the learner indices for each subgroup. The number of participants categorized into each subgroup is indicated above the boxes and the ellipses.


~ condition + (1|pNumber) + (1|StemWord),data= df_posttest, family="binomial", control = glmerControl(optimizer = "bobyqa")) temp = glht(glmer_meaningful, linfct = mcp(condition = "Tukey")) # for multiple comparison #----lmer (priming) ----------------------#### lmer_RT = lmer(log(ReactionTime) ~ condition + Accuracy + ResponseButton + postProbe + (1 |pNumber) + (1 |TargetWord) ,data= df_priming, control = lmerControl(optimizer = "bobyqa")) temp = glht(lmer_RT, linfct = mcp(condition = "Tukey")) # for multiple comparison # comparison between learner groups lmer_RT_byGroup = lmer(log(ReactionTime) ~ condition*group + Accuracy + ResponseButton + postProbe + (1 |pNumber) + (1 |TargetWord) ,data= df_priming, control = lmerControl(optimizer = "bobyqa"(ReactionTime) ~ condition + Accuracy + ResponseButton + postProbe + (1 |pNumber) + (1 |TargetWord), data= df_priming_MIX, control = lmerControl(optimizer = "bobyqa")) #----lmer (probe) ----------------------#### glmer_probe_matched = glmer(matched ~ conditionReco + (1|pNumber) + (1|TargetWord),data= df_probe, family="binomial", control = glmerControl(optimizer = "bobyqa")) temp = glht(glmer_probe_matched, linfct = mcp(condition = "Tukey")) # for multiple comparison SM3: Additional Analysis. Experimental condition effect as a function of affix type.


Table 1
1
Statistics for the posttest and the probe trials during the semantic priming task in the three experiments. In the posttest, participants reported whether a compositional pseudo-word was meaningful or not. On the probe trials, participants reported whether the target word matched the meaning of the preceding compositional pseudo-words.
Experiment 1 (N = 33)
Experiment 2 (N = 71)
Experiment 3a (N = 80)
Posttest
Main effect of Condition:
Main effect of Condition:
Main effect of Condition:
Χ 2 (2) = 871.4, p < .001
Χ 2 (2) = 2121.2, p < .001
Χ 2 (2) = 2390.4, p < .001
Con
Inc
Mis
Con
Inc
Mis
Con
Inc
Mis
Con
β = 2.52,
β = 4.29,
β = 2.73,
β = 4.61,
β = 2.67,
β = 4.85,
SE = 0.13,
SE = 0.15,
SE = 0.09,
SE = 0.10,
SE = 0.08,
SE = 0.10,
z = 19.27,
z = 29.52,
z = 31.80,
z = 45.68,
z = 32.62,
z = 48.68,
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
Inc
β = 1.76,
β = 1.88,
β = 2.19,
SE = 0.12,
SE = 0.09,
SE = 0.08,
z = 15.28,
z = 22.04,
z = 26.32,
p < .001
p < .001
p < .001
Probe*
Main effect of Condition:
Main effect of Condition:
Main effect of Condition:
Χ 2 (2) = 155.44, p < .001
Χ 2 (2) = 405.92, p < .001
Χ 2 (2) = 358.01, p < .001
Con
Inc
Mis
Con
Inc
Mis
Con
Inc
Mis
Con
β = 1.44,
β = 2.81,
β = 2.21,
β = 3.53,
β = 1.81,
β = 3.03,
SE = 0.23,
SE = 0.23,
SE = 0.18,
SE = 0.18,
SE = 0.17,
SE = 0.16,
z = 6.16,
z = 12.30,
z = 12.26,
z = 20.10,
z = 10.66,
z = 18.89,
p < .001
p < .001
p < .001
p < .001
p < .001
p < .001
Inc
β = 1.37,
β = 1.32,
β = 1.22,
SE = 0.20,
SE = 0.15,
SE = 0.15,
z = 6.87,
z = 8.99,
z = 8.40,
p < .001
p < .001
p < .001


These six affix meanings were assigned to three affix forms (as prefix and suffix, respectively), counterbalanced across participants in six lists. In this way, we ensured that the priming effects were not confounded by visual input LEARNING AND GENERALIZATION OF NOVEL COMPOSITIONAL MEANINGS 56
Materials
SM 1A: Stimuli for learning SM 1B: Stimuli for testing post Young version opposite SIM SIM SIM SIM RAN RAN RAN RAN LOR LOR Note: pre LOR LOR
SM 1: Experimental Stimuli pre post pre without color of person engaged RAN RAN LOR LOR LOR RAN SIM SIM LOR LOR LOR SIM SIM SIM RAN RAN RAN SIM
post stronger version LOR RAN LOR SIM RAN SIM
list1 list2 list3 list4 list5 list6


 (extremely characteristic). Half of the statements in the scale were reverse scored. The scores range from 18 to 90.


β = 2.43, SE = 0.29, z = 8.24, p < .001








Acknowledgements
This research is supported by the Language in Interaction consortium (Gravitation Grant 024.001.006 funded by the Dutch Research Council). We would like to thank Andrea E. Martin for stimulating discussions, Sybrine Bultena for feedback on an early version of this manuscript, Cesko Voten for advice on the data analysis, and Florian Hintz for helping with the individual difference study.






Table S1
Posttest statistics as a function of Experimental Condition for each of the three affix meaning pairs. Affix pair "without-color of"
Main effect of Condition:
Main effect of Condition: Χ 2 (2) = 600.33, p < .001 


Con
 










Acquisition and processing of an artificial mini-language combining semantic and syntactic elements




Al
Roumi






F
Dotan






D
Yang






T
Wang






L
Dehaene






S




10.1016/j.cognition.2018.11.006








Cognition




185
















Online evaluation of novel choices by simultaneous representation of multiple memories




H
C
Barron






R
J
Dolan






T
E J
Behrens




10.1038/nn.3515








Nature Neuroscience




16


10
















Fitting Linear Mixed-Effects Models Using lme4




D
Bates






M
Maechler






B
Bolker






S
Walker






R
H B
Christensen






H
Singmann






B
Dai






G
Grothendieck




10.18637/jss.v067.i01








Journal of Statistical Software




67
















What is a cognitive map? Organizing knowledge for flexible behavior




T
E J
Behrens






T
H
Muller






J
C R
Whittington






S
Mark






A
B
Baram






K
L
Stachenfeld






Kurth-Nelson




10.1016/j.neuron.2018.10.002








Neuron




100










Z.








Distributional effects and individual differences in L2 morphology learning




P
J
Brooks






N
Kwoka






V
Kempe








Language Learning




67


1


















10.1111/lang.12204














The need for cognition




J
T
Cacioppo






R
E
Petty




10.1037/0022-3514.42.1.116








Journal of Personality and Social Psychology




42


1
















Human cognitive abilities: A survey of factor-analytic studies




J
B
Carroll












1st ed.








The matrix reasoning item bank (MaRs-IB): Novel, open-access abstract reasoning items for adolescents and adults




G
Chierchia






D
Fuhrmann






L
J
Knoll






B
P
Pi-Sunyer






A
L
Sakhardande






S
J
Blakemore








Royal Society Open Science




10


6
















10.1098/rsos.190232














Derivation by phase




N
Chomsky








Ken Hale: A Life in Language


Michael Kenstowicz




MIT Press
















Individual differences in frequency and saliency of speech-accompanying gestures: The role of cognitive abilities and empathy




M
Chu






A
Meyer






Lu
Foulkes






S
Kita








Journal of Experimental Psychology: General




143


2


















10.1037/a0036311














Cognitive control over learning: Creating, clustering and generalizing task-set structure




A
G E
Collins






M
J
Frank








Psychological Review




120


1


















10.1037/a0030852














Human memory and the medial temporal region of the brain




P
M
Corsi












McGill University












Whichever way you choose to categorize, working memory helps you learn




S
Craig






S
Lewandowsky








Quarterly Journal of Experimental Psychology




65


3


















10.1080/17470218.2011.608854














Language learners privilege structured meaning over surface frequency




J
Culbertson






D
Adger




10.1073/pnas.1320525111








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






111














Individual differences in category learning: Sometimes less working memory capacity is better than more




M
S
Decaro






R
D
Thomas






S
L
Beilock




10.1016/j.cognition.2007.07.001








Cognition




107


1
















Symbols and mental programs: a hypothesis about human singularity




S
Dehaene






F
Al Roumi






Y
Lakretz






S
Planton






M
Sablé-Meyer




10.1016/j.tics.2022.06.010








Trends in Cognitive Sciences




26


9
















Individual differences in second language learning




R
Ellis








The handbook of applied linguistics
















Literacy can enhance syntactic prediction in spoken language processing




S
Favier






A
S
Meyer






F
Huettig




10.1037/xge0001042








Journal of Experimental Psychology: General




150


10
















Neural correlate of the construction of sentence meaning




E
Fedorenko






T
L
Scott






P
Brunner






W
G
Coon






B
Pritchett






G
Schalk






N
Kanwisher








113








Proceedings of the National Academy of Sciences of the United States of America














10.1073/pnas.1612132113














Good-enough representations in language comprehension




F
Ferreira






K
G D
Bailey






V
Ferraro








Current Directions in Psychological Science




11


1


















10.1111/1467-8721.00158














The "Good Enough" Approach to Language Comprehension




F
Ferreira






N
D
Patson








Language and Linguistics Compass




1


1-2


















10.1111/j.1749-818X.2007.00007.x














Building words and phrases in the left temporal lobe




G
Flick






Y
Oseki






A
R
Kaczmarek






M
Kaabi






A
Marantz






L
Pylkkänen








Cortex




106


















10.1016/j.cortex.2018.06.004
















J
A
Fodor




The language of thought




Harvard University Press




5












Connectionism and cognitive architecture: a critical analysis




J
A
Fodor






Z
W
Pylyshyn




10.1016/0010-0277(88)90031-5








Cognition




28
















An architecture for encoding sentence meaning in left LEARNING AND GENERALIZATION OF NOVEL COMPOSITIONAL MEANINGS 48 mid-superior temporal cortex




S
M
Frankland






J
D
Greene




10.1073/pnas.1421236112








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






112














Concepts and Compositionality: In Search of the Brain's Language of Thought




S
M
Frankland






J
D
Greene








Annual Review of Psychology




71


















10.1146/annurev-psych-122216-011829














Über Sinn und Bedeutung




G
Frege








Z. Philos. Kritik




100
















Statistical learning research: A critical review and possible new directions




R
Frost






B
C
Armstrong






M
H
Christiansen




10.1037/bul0000210








Psychological Bulletin




145


12
















Conceptual spaces as a framework for knowledge representation




P
Gärdenfors




10.1017/S0140525X04280098








Mind and Matter




2
















The role of intelligence in second language learning




F
Genesee




10.1111/j.1467-1770.1976.tb00277.x








Language Learning




26


2
















g: Highly General and Highly Practical




L
S
Gottfredson








The General Factor of Intelligence




Psychology Press










1st ed.










S
Grey






J
N
Williams






P
Rebuschat




10.1016/j.lindif.2015.01.019




Individual differences in incidental language learning: phonological working memory, learning styles, and personality. Learning and Individual Differences






38














Trying to make it work: Compositional effects in the processing of compound "nonwords




F
Günther






M
Marelli




10.1177/1747021820902019








Quarterly Journal of Experimental Psychology




73


7
















The development of whole-word representations in compound word processing: Evidence from eye fixation patterns of elementary school children




T
Häikiö






R
Bertram






J
Hyönä








Applied Psycholinguistics




32


3


















10.1017/S0142716411000208














Assessing the principal dimensions of speaking and listening skills




F
Hintz






M
Dijkhuis






V
Hoff






M
Huijsmans






R
A
Kievit






J
M
Mcqueen






Meyer




A. S. (n.d.












A behavioural dataset for studying individual differences in language skills




F
Hintz






M
Dijkhuis






V
Hoff






J
M
Mcqueen






A
S
Meyer




10.1038/s41597-020-00758-x








Scientific Data




7
















F
Hintz






O
Shkaravska






M
Dijkhuis






V
Hoff






M
Huijsmans






R
C A
Van Dongen






L
A B
Voeteé






P
Trilsbeek






J
M
Mcqueen






A
S
Meyer




10.3758/s13428-023-02156-8




IDLaS-NL -A platform for running customized studies on individual differences in Dutch language skills via the Internet. Behavior Research Methods, 0123456789
















Quantifying the relationships between linguistic experience, general cognitive skills and linguistic processing skills




F
Hintz






C
Voeten






J
Mcqueen






A
S
Meyer








Proceedings of the Annual Meeting of the Cognitive Science Society


the Annual Meeting of the Cognitive Science Society
















Simultaneous inference in general parametric models




T
Hothorn






F
Bretz






P
Westfall




10.1002/bimj.200810425








Biometrical Journal




50


3
















Unbiased recursive partitioning: A conditional inference framework




T
Hothorn






K
Hornik






A
Zeileis








Journal of Computational and Graphical Statistics




15


3


















10.1198/106186006X133933














How the brain processes violations of the grammatical norm: An fMRI study




F
Hubers






T
M
Snijders






H
Hoop






De








Brain and Language




163


















10.1016/j.bandl.2016.08.006
















R
Jackendoff




Semantic Structures




MIT Press




18












Cognitive predictors of generalization of Russian grammatical gender categories




V
Kempe






P
J
Brooks






A
Kharkhurin








Language Learning




60


1


















10.1111/j.1467-9922.2009.00553.x














Individual differences in language acquisition and processing




E
Kidd






S
Donnelly






M
H
Christiansen








Trends in Cognitive Sciences




22


2


















10.1016/j.tics.2017.11.006














The cognitive neuroscience of insight




J
Kounios






M
Beeman




10.1146/annurev-psych-010213-115154








Annual Review of Psychology




65
















One-shot learning of generative speech concepts




B
Lake






C.-Y
Lee






J
Glass






B
M
Lake






J
R
Glass






J
B
Tenenbaum








Proceedings of the Annual Meeting of the Cognitive Science Society


the Annual Meeting of the Cognitive Science Society






36












Individual differences in category learning: Memorization versus rule abstraction




J
L
Little






M
A
Mcdaniel








Memory & Cognition




43


















10.3758/s13421-014-0475-1














Human Replay Spontaneously Reorganizes Experience




Y
Liu






R
J
Dolan






Z
Kurth-Nelson






T
E J
Behrens




10.1016/j.cell.2019.06.012


640-652.e14








Cell




178


3


















A
Löwe






L
Touzo






P
Muhle-Karbe






A
Saxe






C
Summerfield






N
Schuck


















Regularised neural networks mimic human insight


















10.32470/ccn.2023.1026-0














Transfer and competition in second language learning




B
Macwhinney




10.1016/S0166-4115(08








Advances in Psychology




83


61506














Continuity in lexical and morphological development: a test of the critical mass hypothesis




V
A
Marchman






E
Bates








Journal of Child Language




21


2


















10.1017/S0305000900009302














Transferring structural knowledge across cognitive maps in humans and models




S
Mark






R
Moran






T
Parr






S
W
Kennerley






T
E J
Behrens




10.1038/s41467-020-18254-6








Nature Communications


















Language processing as cue integration: grounding the psychology of language in perception and neurophysiology




A
E
Martin








Frontiers in Psychology




7


















10.3389/fpsyg.2016.00120














A compositional neural architecture for language




A
E
Martin




10.1162/jocn_a_01552








Journal of Cognitive Neuroscience




11
















Individual differences in learning and transfer: Stable tendencies for learning exemplars versus abstracting rules




M
A
Mcdaniel






M
J
Cahill






M
Robbins






C
Wiener








Journal of Experimental Psychology: General




143


2


















10.1037/a0032963














Semantic priming: Perspectives from memory and word recognition




T
P
Mcnamara




10.4324/9780203338001








Psychology Press






1st ed.








Statistical learning and language: An individual differences study




J
B
Misyak






M
H
Christiansen




10.1111/j.1467-9922.2010.00626.x








Language Learning




62


1
















Metalinguistic awareness and the vocabulary-comprehension connection




W
Nagy




R


















K
Wagner




Vocabulary acquisition: Implications for reading comprehension


A. E. Muse, & K. R. Tannenbaum




The Guilford Press














Semantic Priming Effects In Visual Word Recognition: A Selective Review Of Current Findings And Theories




J
H
Neely








Basic Processes in Reading










Routledge








Compositionality in formal semantics: Selected papers




B
H
Partee








John Wiley & Sons












The neural basis of combinatory syntax and semantics




L
Pylkkänen




10.1126/science.aax005








Science




66
















Morphological decomposition based on the analysis of orthography




K
Rastle






M
H
Davis








Language and Cognitive Processes




23


















10.1080/01690960802069730














Implicit and explicit learning: Individual differences and IQ




A
S
Reber






F
F
Walkenfeld






R
Hernstadt




10.1037/0278-7393.17.5.888








Journal of Experimental Psychology: Learning, Memory, and Cognition




17


5
















A language of thought for the mental representation of geometric shapes




M
Sablé-Meyer






K
Ellis






J
Tenenbaum






S
Dehaene








Cognitive Psychology




139
















10.1016/j.cogpsych.2022.101527














Internal consistency and test-retest reliability of the Need for Cognition Scale




C
J
Sadowski






S
Gulgoz




10.2466/PMS.74.2.610-610








Perceptual and Motor Skills




74


2


610














Generative replay underlies compositional inference in the hippocampal-prefrontal circuit




P
Schwartenbeck






A
Baram






Y
Liu






S
Mark






T
Muller






R
Dolan






M
Botvinick






Z
Kurth-Nelson






T
Behrens




10.1016/j.cell.2023.09.004








Cell




186


22
















Statistical learning as an individual ability: Theoretical perspectives and empirical evidence




N
Siegelman






R
Frost








Journal of Memory and Language




81


















10.1016/j.jml.2015.02.001














General Intelligence" Objectively Determined and Measured




C
Spearman








J. J
















10.1037/11491-006




Studies in individual differences: The search for intelligence


Jenkins & D. G. Paterson




Appleton-Century-Crofts














Do morphemes matter when reading compound words with transposed letters? Evidence from eye-tracking and event-related potentials. Language




M
C
Stites






K
D
Federmeier






K
Christianson








Cognition and Neuroscience




31


10


















10.1080/23273798.2016.1212082














The Aha! moment: Is insight a different form of problem solving?




H
Stuyck






B
Aben






A
Cleeremans






E
Van Den Bussche




10.1016/j.concog.2020.103055








Consciousness and Cognition




90


103055














Morphological decomposition and the reverse base frequency effect




M
Taft








The Quarterly Journal of Experimental Psychology Section A




57


4


















10.1080/02724980343000477














The Development of Metalinguistic Awareness: A Conceptual Overview




W
E
Tunmer






M
L
Herriman








Metalinguistic Awareness in Children




Springer-Verlag














On the dual




W
Van Humboldt








Nouv Rev German




1
















Studying texts in a second language: No disadvantage in long-term recognition memory




H
Vander Beken






E
Woumans






M
Brysbaert




10.1017/S1366728917000360








Bilingualism: Language and Cognition




21


4
















WAIS-III: Wechsler Adult Intelligence Scale. The Psychological Corporation




D
Wechsler


















Merge in the human brain: A sub-region based functional investigation in the left pars opercularis




E
Zaccarella






A
D
Friederici








Frontiers in Psychology




6


















10.3389/fpsyg.2015.01818














Building by Syntax: The Neural Basis of Minimal Linguistic Structures




E
Zaccarella






L
Meyer






M
Makuuchi






A
D
Friederici




10.1093/cercor/bhv234








Cerebral Cortex




27


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]