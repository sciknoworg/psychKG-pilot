You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Selecting the appropriate stimuli for precise parameter estimation is important for conducting an efficient and informative psychological experiment. In experiments, researchers estimate a participant's traits based on their reactions to the stimuli. In this situation, informative stimuli lead to higher estimation accuracy, which is beneficial in terms of both measurement and subsequent analysis of psychological traits.
Historically speaking, the method of limits and staircase method are two of the early stimulus selection methods 
(Garcia-Perez 1998)
. Researchers have discussed the information provided by experiments or stimuli for several decades (e.g., 
Lindley 1956
).
More recently, adaptive stimulus selection methods have been developed with proven superiority. The term adaptive means to select a next-presented stimulus based on previous responses of a given participant.
This approach is effective because efficient stimuli are generally different among participants. One of the pioneers of adaptive stimulus selection methods is QUEST 
(Watson and Peri, 1983)
. With 
Kontsevich and Tyler (1999)
 proposing the Ψ method, there are now numerous studies relevant to this method. Such methods include the extension to multidimensional stimuli with fast computation algorithm (DiMattina 2015; 
Kujala and Lukka 2006)
, extension to multi-alternative task 
(Bak and Pillow 2018)
, and applications of entropy-based method 
(Doll et al. 2014;
Chen, et al. 2020;
Toubia et al. 2013)
, especially in psychophysics. Regarding the Ψ method, stimuli are selected to minimize the expected entropy of posterior probability distribution, which means the Ψ method is used for improving the estimation precision. In addition, adaptive design optimization (ADO; e.g., 
Cavagnaro et al., 2010;
Cavagnaro et al., 2013;
Myung & Pitt 2009;
Myung et al. 2013
) was proposed as a general framework for stimulus selection. In ADO, the stimulus selection criterion (i.e., the utility of stimuli) can be set either for optimizing the estimation precision or the model selection. In the field of educational measurement, computerized adaptive testing (CAT; e.g., 
Chang 2015;
Cheng and Morgan 2013;
Meijer and Nering 1999;
Segall 1996
Segall , 2004
Tian et al. 2007;
Triantafillou et al 2008;
Weiss and Kingsbury 1984)
 was developed for higher estimation precision.
In CAT, stimuli are selected to maximize the Fisher information because the variance of the maximum likelihood estimates convergence of the inverse of Fisher information when the parameter is unidimensional.
In multidimensional parameters, one of the well-known stimulus selection criteria is maximizing the determinant of Fisher information matrix 
(Segall 1996)
, which is named the D-optimal criterion. Basically, the Ψ method, ADO for parameter estimation, and CAT are similar approaches because their stimulus selection criteria are used for optimizing the estimation precision. As for the computational cost, CAT based on the Fisher information will be faster than the Ψ method (and ADO) based on the entropy or posterior probability distribution because, as we elaborate in the Methods section (see The ADO Framework and the CAT Framework), CAT can avoid computing numerical expectation and estimation with new hypothetical observation.
In existing literature, ADO has rarely used the Fisher information matrix as a stimulus selection criterion. In this paper, we focused on cognitive experiments rather than educational tests. Therefore, we name our method ADO based on D-optimality (ADO-D) even though we use the Fisher information matrix as the optimization criterion. ADO-D can be considered as an application of CAT to a non-testing situation.
Existing adaptive stimulus selection methods have essentially only considered individual-level model parameters. As we elaborate in the Methods section, CAT and ADO for parameter estimation were the methods for maximizing the estimation precision of individual-level parameters. In contrast, in cognitive experiments, researchers' interests are often on group-level parameters such as the group mean or difference of the group mean between the experimental conditions rather than each person's individual-level parameters. Hence, there was a significant gap between the available adaptive stimulus selection methods and actual research interest. Generalized linear mixed model (GLMM) and hierarchical Bayes are recommended to capture the repeated measurement structure, namely group-level structure, in experiments.
For example, 
Walsh (1947)
 showed that ignoring the dependency from the sampling process increase type I errors in hierarchical linear models (HLM). This means that an individual-level model is not sufficient for modeling repeated measurement experiments. Therefore, the stimulus selection method for estimation precision of group-level parameters is essentially needed in most real experiments.
However, the stimulus selection for group-level parameters is difficult in terms of computational cost. 
Kim et al. (2014)
 and 
Gu et al. (2016)
, two of the most related studies to the present one, proposed the hierarchical adaptive design optimization (HADO). Hierarchical here means that first the posterior distribution is derived with data of the first to ( − 1)-th participants, and second the prior distribution of individual-level parameters is derived for -th a participant's experiment with ADO. Although they also proposed the stimulus selection criterion for group-level parameters, this was not implemented, as we elaborate in the Methods section. The stimulus selection criterion remained for individual-level parameters.
In our understanding, the proposed criterion for group-level parameters is not feasible because of the computational cost. Specifically, it is reported that the hierarchical Bayes estimation took 11 seconds for a single estimation (see 
Kim et al. 2014
 for more detail about computational environment and procedure).
According to the method proposed by 
Kim et al. (2014)
, when stimulus selection criterion is used for grouplevel parameters, researchers need to repeatedly estimate the group-level parameters the number of stimuli times. Hence, the method is not practical in real experiments because it requires that the participant wait a long time (11 seconds times the number of stimuli in the above setting) before the adaptively-chosen next stimulus is presented.
Although the stimulus selection for group-level parameters is not feasible in terms of computational cost, it is reasonably expected that stimulus selection for individual-level parameters (i.e., conventional methods stated above) probably also improves the estimation precision of the group-level parameters. It is true that when the hierarchical model is correct, the models used in the individual-level ADO-D must be mis-specified because they ignore the hierarchical structure of the parameters. However, an increase in individual-level parameter estimation precision can lead to an increase of group-level parameter estimation precision because the individual-level parameters follow probability distributions that are specified by the group-level parameters. The group-level parameters are crucial for most cognitive experiments. However, previous studies about stimulus selection methods including the Ψ method, ADO for parameter estimation, and CAT have not investigated the effect of stimulus selection on group-level parameters.
In the present study, we investigated the effect of individual-level ADO-D on group-level parameter's estimation precision to bridge the gap to real experiments. If the individual-level ADO-D increases the estimation precision of group-level parameters, it can be recommended to use individual-level ADO-D even for the experiments where the research interest leans toward group-level parameters. To investigate this issue, we conducted two simulation studies to compare the random stimulus selection and individual-level ADO-D in terms of group-level parameter's estimation precision with two different models. These models include the delay discounting (DD) task model 
(Madden et al. 2003)
, and the cumulative prospect theory (CPT) model 
(Tversky and Kahneman 1992)
. We focused on these elaborated cognitive models in consideration of utility in cognitive modeling.
The present study's difference from previous studies lies in our focus on the group-level parameter's estimation precision. HADO considers the case in which the experimental data is obtained from multiple participants, and hence, have hierarchical structure. However, in the previous studies of HADO, stimulus selection methods for group-level parameters were not implemented, and root mean squared error 
(RMSE)
 and posterior standard deviation (PSD) were for individual-level parameters 
(Gu et al. 2016)
. Conversely, the present study investigated RMSE and PSD for group-level parameters. Further, the difference from most ADO, stimulus selection criterion of the present study is the Fisher information matrix. Therefore, the computational cost was lower than the entropy-based criterion.
The remainder of this paper is constructed as follows. We introduce the stimulus selection methods in the Methods section. Our third section, the Simulation Study presents two simulation studies to investigate the effect of individual-level ADO-D on group-level parameters. We conclude with a discussion in the fourth section.


Method


The ADO Framework
In general, adaptive stimulus selection procedure involves three iterative steps that are implemented on each trial: (1) A design optimization step in which the optimal design is selected based on the present state, which is represented as prior and utility of the design; (2) A experiment step in which the stimuli selected in design optimization step are presented to a participant and a response is observed; (3) A Bayesian updating step in which the observation is used to update the prior to posterior, which in turn becomes the prior on design optimization step of the next trial 
(Myung et al. 2013)
. This procedure was carried out separately for each participant in conventional individual-level ADO.
In the design optimization step, researchers have to solve the optimization problem to specify the stimuli set to provide the most utility and information. The design optimization step solves the problem defined as * = ( ),
where is the design (stimuli) set and ( ) is the global utility of design . In ADO, the global utility is defined as
( ) = ∑ ( ) ∫ ∫ ( , , ) ( | , ) ( ) ,
(2)
where = {1, … , } is a model index, ( ) is a model probability, ( | , ) is a likelihood function for hypothetical outcome, , with parameter and design under model , and ( ) is a prior distribution under model . In ADO for parameter estimation and CAT, researchers usually assume one model, which corresponds to the case of = 1, ( = 1) = 1. The ( , , ) is a local utility which is the utility of d with parameter and hypothetical outcome . In short, global utility is the expectation (integral) of local utility over model uncertainty ( ), outcome , and parameter .
In ADO, the local utility definition determines a characteristic of stimulus selection methods. For
parameter estimation precision, ( , , ) = log ( | , ) ( ) ,
(3)
which is the log ratio of prior and posterior distribution after obtaining data , is often used in existing studies. This leads to set global utility as the mutual information between the parameter and the outcome, namely the reduction of entropy about the parameters by the observation 
(Myung et al. 2013)
.
In this local utility, researchers have to estimate posterior distribution under design and hypothetical outcome , ( | , ). In this process and in the Bayesian updating step, researchers can estimate (individual-level) parameters using the Bayes rule directly. In addition, they can discretize parameters to reduce computational cost in the same manner as Ψ method (e.g., DiMattina 2015; 
Kontsevich & Tyler, 1999
).
In the HADO, which is an extension of the above framework, predictive distribution of n-th participant's parameter under model , , , conditional on the previous participant's data 1:( −1) (i.e., ( , | 1:( −1) ) can be used instead of prior, ( , ). In short, the term hierarchical in HADO means that data from first to ( − 1)-th participants are used for deriving the prior distribution of n-th participant's parameters 
(Kim et al. 2014)
. In contrast, individual-level ADO (and CAT) does not use other participants' data for the -th participant's experiment. In addition, researchers can use the log ratio of prior and posterior of group-level parameters as a local utility, ( , , ) = log 
( | , )
̂→ ( * , ( * ) − ),
(4)
where 
(
 
where log ( ; ) is the log-likelihood and ′ denotes the transposed matrix of A.
= ( 1 , … , )
is all outcomes of the -th participant, and is the observation of participant for -th trial ( = 1, … , ). The Fisher information matrix is dependent on stimuli, although it is customarily omitted. As we explained in Introduction section, D-optimal stimulus selection is one of the most common approaches in CAT literature. We call this method ADO-D to distinguish it from standard ADO, which is an entropy-based method.
Let : ( ) denote the Fisher information matrix calculated from the data of the first to t-th trials (i.e., multiple trials). In addition, let + ( ) denote the Fisher information matrix calculated from the ( + 1)-th trial (i.e., single trial). In the D-optimality, stimuli set that maximizes
det ( : (̂) + + (̂)) ,
(6)
is selected as the stimuli of the ( + 1)-th trial to be presented to the participant , where ̂ denotes the parameter estimates given by data of the first to t-th trials. Although the utility of equation 
3
requires the repetition of estimation for 2 ( ) × the number of design , the utility of equation 
6
needs only once estimation.
In CAT, point estimates are conventionally used as the prior, ( ), in equation 
2
. Moreover, from the definition of the Fisher information matrix, the expectation of outcome is already calculated.
Therefore, global utility ( ) becomes just the determinant of the Fisher information matrix, which is given in equation 
6
, from the perspective of ADO. In this study, we used this method for the simulation studies below.


The Calculation Technique
The Fisher information matrix-based ADO, ADO-D, has a much lower computational cost compared to entropy base ADO (equation 
3
) because the evaluation of equation 
6
 


Simulation Study
This section aims to investigate whether the ADO-D leads to higher estimation precision of group-level parameters than random stimulus selection through two models. The considered models, the DD model and CPT model, are elaborated decision-making models. It is difficult to select appropriate stimuli in these models because the model and task structure are not simple compared to more simple models such as logistic regression models. Therefore, a large effect of stimulus selection is expected. Our R codes used for below simulations are available at Open Science Framework (https://osf.io/a3fjd/?view_only=b390887455a74990b698c9e0a568d9e3).


Simulation study 1: Delay discounting model


Model
DD assesses how individuals prefer small but immediate rewards to large but delayed rewards.
The discount can be a form of impulsivity and is consistent within individuals 
(Odum 2011)
. Delay discounting is related to some cognitive abilities 
(Shamosh and Gray 2008)
, and is an important factor for predicting future success or clinical symptoms.
In the DD task, delayed reward alternative and immediate reward alternative are presented, and participants should choose one of them. Hence, the outcome (choice) of the participants can be coded with the binary variable. Let , be the delayed and immediate reward alternatives of -th participant atth trial, respectively. The immediate reward alternative comes with the reward value , and the delayed reward alternative comes with the reward value as well as the delay time .
Therefore, the three-dimensional stimuli of -th participant at -th trial is summarized as ( , , ).
DD model 
(Ahn et al., 2020)
 used in this study is formulated as below:
∼ ( ( )) ,
(7)
( ) = −1 { ( ( ) − ( ))} ,
(8)
( ) = ,
(9)
( ) = 1 + ,
(10)
where is the choice data of -th participant at -th trial, = ( 1 , 2 ) = ( , ) is -th participant's parameters, is discounting rate, and is inverse temperature parameter. ( ) is immediate reward alternative's utility of -th participant -th trial, which is defined as the reward value.
Similarly, ( ) is the delayed reward alternative's utility of -th participant at -th trial, which is defined as the reward value discounted by a hyperbolic function. Although hyperbolic function tends to perform better than exponential function 
(Madden et al. 2003)
, researchers may assume other functions.
The Fisher information of this model is presented in Appendix A. This model is used in the ADO-D procedure.
In the simulation, after collecting participant's entire data, the below group-level model was used to estimate group-level and individual-level parameters. The group-level model including random effect is assumed as below:
∼ ( , 2 ), = 1, 2.
(11)
Here, and represent the mean and SD of the -th parameters. The hierarchical Bayes estimation was applied to each group separately. Therefore, the group index was omitted in the above equations.
Suppose that researchers have collected the data first to -th trials from -th participant, and tries to select the stimuli for ( + 1)-th trial, ( ( +1) , ( +1) , ( +1) ). In the Bayesian updating step, the parameters = ( , ) are estimated using the data of first to -th trial with the assumed model, which is given by equations (7) to (10). Then, the next trial's stimuli, ( ( +1) , ( +1) , ( +1) ), are selected to maximize the determinant of the Fisher information, equation 
6
, from the set of candidate stimuli (e.g., 20
x 20 x 10 stimuli patterns in simulation study 1) given the estimated parameter values at the above step ̂. In the simulation, the next trial's data, ( +1) , was generated with true model (equations (7) to (10)) and the selected stimuli
( ( +1) * , ( +1) * , ( +1) *
) at the above step. This procedure was iterated up to -th participant and -th trial. After all the dependent and independent variables were generated, hierarchical Bayes (i.e., equations (7)-(11)) was applied to the entire data.
Researchers can interpret the effect of experimental manipulation by the group mean difference between experimental conditions or clinical vs. non-clinical populations. Without considering covariance, estimation variance of group difference result from estimation variance of each group's parameter. Therefore, it is important to focus on the estimation precision of group mean of a single group and estimation precision of difference of group mean between two groups. Especially, the discounting rate,


Methods
Simulation study flow can be divided into two parts: (A) individual-level simulation and (B) group-level analysis. In (A) individual-level simulation, the first to fifth trial's stimuli were generated at random. For the rest of the trials, we iterated the (1) design optimization step, (2) experimental step, and
(3) Bayesian updating step (see section 3.1.1). This individual-level simulation was conducted with each participant separately. In the (1) design optimization step, stimuli were selected at random in the random condition, while they were selected to maximize the determinant of the Fisher information in the ADO-D condition. In (B) group-level simulation, after collecting all participants' data, we analyzed the entire data with hierarchical Bayes to estimate the group-level parameters. Finally, the root mean square error (RMSE), the difference between estimated parameters and true parameter values, and posterior standard deviation (PSD) were calculated.
The number of trials ( ), participants ( ), groups ( ) were 20, 20, and 2, respectively. Each group consisted of /2 participants. As for (1) design optimization, candidate reward (i.e., candidate of , ) was 
[1,
20]
 with increment by 1, and candidate time (i.e., candidate of ) was [1, 10] with increment by 1. The stimuli were selected at random or by ADO-D. As for (2) experimental step, true mean, SD of group 1 were ( 1 = 0.2, 2 = 1) , ( 1 = 0.05, 2 = 0.25) . True mean, SD of group 2 were
( 1 = 0.3, 2 = 1), ( 1 = 0.05, 2 = 0.25). Therefore, the true difference of group mean was 0.1 in .
The true parameters of each participant were generated from equation 
11
. These true individual-level parameters were used to generate the choice data in the (2) experimental step. As for (3) Bayesian updating step, parameters were estimated with MCMC. The MCMC samples were generated from three chains with 5,000 iterations each, and the first 2,000 iterations were discarded as a warm-up. The prior of was Student's t(4, 0, 3) in which degree of freedom was 4, location parameter was 0, and scale parameter was 3. RMSE between estimated group-level parameters and true group-level parameter values were calculated.
For additional analysis, RMSE for individual-level parameters estimated by hierarchical Bayes was also calculated. PSD of each parameter was calculated based on MCMC. We iterated the simulation 100 times. 
Table 1
 represents the RMSE and PSD of group-level parameters for each stimulus selection condition. As indicated, the RMSE and PSD of group-level parameters were lower in the ADO-D condition than the random condition. Let us focus on the group mean of the discounting rate. 
Figures 1a and 1b
 represent the RMSE and PSD of the group mean parameters of 1 in the random condition. They indicate that some estimations do not work well with random stimuli. In fact, around 30% (70%) of RMSE 
(PSD)
 in the random condition performed worse than the maximum RMSE (PSD) of the ADO-D condition. To compare random condition vs ADO-D condition within the same figure, we excluded the results of random condition that had higher RMSE (PSD) than maximum RMSE (PSD) of ADO-D condition because RMSE (PSD) of random conditions is sometimes too large. Even if we collected the random condition's results the estimation of which was realistic, 
Figures 1c and 1d
 indicate that ADO-D condition performed better than random condition.


Results and discussion
As for the group mean difference, 
Figure 1e
 represents PSD of group mean difference of random and ADO-D condition. It indicates that the random condition sometimes cannot estimate the group mean of discounting rate well. In addition, 
Figure 1e
 indicates that ADO-D performed better than random stimulus selection even if we focus on the good results in random condition (around PSD=0 to 0.25). Further, the RMSE difference between stimulus selection conditions (Random -ADO-D) were 0.04, 54.47 for each individual-level parameter. The PSD of them were 0.08, 1.28.


Simulation study 2: Cumulative Prospect Theory


Model
In real decision-making situations, there are many cases that portray uncertainty, which means the objective probability of an event is unknown. Studies have shown that people tend to prefer the case in which the objective probability is known to the uncertainty situation (ambiguity aversion; e.g., 
Fox and Tversky 1995)
. This phenomenon is represented by the function curvature parameter, , in the probability weighting function 
(Gonzalez and Wu 1999;
Kilka and Weber 2001)
. Precise estimation of this parameter is necessary in studying human decision-making features and measuring belief (subjective probability)
while separating decision attitudes such as ambiguity aversion.
To measure the extent of ambiguity aversion and subjective probability, suppose that -th participant chooses between two gambles at -th trial ( and ). A gamble leads to either outcome 1 ( ) that occurs with known probability 1 ( ) or outcome 2 ( ) that occurs with probability 1 − 1 ( ) 
(Lauriola et al., 2007)
. This paper focuses on decisions under uncertainty 
(Ellsberg 1961;
Tversky and Fox, 1995)
 in which the probability of gamble is unknown. The gamble is called an ambiguous gamble.
The researcher's interest is in the subjective probability that the event occurs.
For these situations, 
Tversky and Kahneman (1992)
 proposed the CPT. In the CPT model, the subjective value of a gamble is defined as
( ) = ( 1 ) ( 1 ) + ( 2 )(1 − ( 1 )) 1 > 2 ≥ 0,
(12)
where (⋅) is the value function which represents the subjective value of the outcome, and (⋅) is the probability weighting function, which represents the decision weight. The (⋅) can be calculated with other reward order patterns (e.g., 1 < 0 < 2 ), as described in 
Tversky and Kahneman (1992)
. When and Weber 2001; Wakker 2004), the decision weight of gamble is defined as
( 1 ) = 1 ( 1 + (1 − 1 ) ) 1 ,
(15)
where 1 is the subjective probability for obtaining 1 ( ) in gamble . Then, it is assumed that choice data is determined by
∼ ( ( )),
(16)
( ) = −1 { ( ( ) − ( ))},
(17)
where = ( 1 , 2 , 3 , 4 ) = ( , , , ) are the parameters. The Fisher information of this model is presented in appendix A. This model is used in the ADO-D procedure.
The group-level model is assumed as below in the same manner with simulation study 1:
∼ ( , 2 ), = 1, 2, 3, 4.
(18)
Again, researchers interpret the effect of experimental manipulation by the group mean difference between experimental conditions, especially parameter 2 = , which is sometimes focused on.


Methods
The simulation study flow was the same as the simulation study 1. The number of trials ( ), participants ( ), groups ( ) were 20, 20, and 2, respectively. Each group had /2 participants. As for 
1
design optimization, candidate reward (i.e., candidate of ( ) , ( ) ) was 
[10,
100]
 with increment by 5, and candidate objective probability (i.e., candidate of 1 ( ) ) was the 16 evenly distributed numbers in [0.01, 0.99]. As for (2) experimental step, true mean, SD of group 1 were ( 1 , 2 , 3 , 4 ) = (0.5, 0.61, 0.8, 1.5),
( 1 , 2 , 3 , 4 ) = (0.1, 0.05, 0.05, 0.25), respectively. True mean, SD of group 2 were ( 1 , 2 , 3 , 4 ) = (0.5, 0.7, 0.8, 1.5), ( 1 , 2 , 3 , 4 ) = (0.1, 0.05, 0.05, 0.25), respectively. Therefore, the true difference of group mean was around 0.1 in . The true parameters of each participant were generated from equation 
18
. As for the (3) Bayesian updating step, MCMC settings were the same as the simulation study 1. The priors of , were Student's t(4, 1, 0.25) and Student's t(4, 0, 3), respectively. The priors of , were U(0,1) and U(0, 2), respectively. RMSE and PSD were calculated in the same manner as simulation study 1. We iterated the simulation 50 times. 
Table 2
 represents the RMSE and PSD of group-level parameters for each stimulus selection condition. As for RMSE, 
Table 2
 indicates that RMSE of group means in the ADO-D condition are lower than the random condition. As for PSD, 
Table 2
 indicates that ADO-D condition performed better than random condition except .


Results and Discussion
Let us focus on the group mean of . 
Figures 2a and 2b
 represent the RMSE and PSD of group mean parameters of . For both RMSE and PSD, 
Figures 2a and 2b
 indicate that ADO-D performed better than random stimulus selection. In the authors' experience, hierarchical Bayes leads to more appropriate estimation even in random stimulus selection condition compared to individual-level analysis. However, the ADO-D condition performed better than that.
As for group mean difference, 
Figure 2c
 indicates that ADO-D led to higher estimation precision of group mean difference than random condition, as is the case with 
Figure 2b
. Further, RMSE difference between stimulus selection condition (random -ADO-D condition) were 0.01, 0.02, 0.09, and 76.87 for each individual-level parameters. PSD of that were 0.05, 0.05, 0.03, and 0.39.


General Discussion
The present paper investigated the effect of individual-level ADO-D on parameter estimation precision of group-level parameters. Although group-level parameters are of primary interest in most real experiments, whether individual-level ADO-D leads to higher estimation precision for such a situation has been unclear. The simulation results in this paper indicated that individual-level ADO-D led to higher estimation precision on group-level parameters in elaborated decision making models.
As for RMSE and PSD difference of group-level parameters between stimulus selection conditions, ADO-D performed better than random stimulus selection in most of the parameters 
(Tables 1   and 2)
. We focused on the parameters and in simulation study 1 and 2, respectively, because they are important parameters of psychological interest. In these simulations, ADO-D led to higher estimation precision 
(Figures 1 and 2
). As for individual-level parameters in hierarchical Bayes, ADO-D led to lower RMSE and PSD.
Previous studies (e,g., 
Kim et al. 2014;
Ahn et al., 2020)
 indicated that individual-level ADO led to higher estimation for individual-level parameters. The present study's results are consistent with these study. The present study further indicated that individual-level ADO-D led to higher estimation precision even for group-level parameters. Therefore, from the above results, we recommend the individual-level ADO-D even for group-level cognitive experiments.


Limitation and Future Research
non-parametric stimulus selection using Gaussian process regression 
(Schulz et al. 2018)
 or Gaussian process classification 
(Chang et al. 2021
) can be used. Although this paper assumed the situation where we know the true model for simplicity, the effect of individual-level stimulus selection methods in the situation where researchers use the above advanced methods should be investigated in a future study. Note. Each row corresponds to RMSE and PSD of parameters for cumulative prospect theory model and each column corresponds to either group mean or group SD for each stimulus selection condition. The RMSE (c) and PSD (d) for the group mean parameter of . The black histogram represents the result in the random condition, and the red histogram represents the result in the ADO-D condition. Note that, for the random stimulus condition, the histograms were shown only for the RMSE (PSD) value less than 0.005 (0.05). (e): The PSD for the group mean difference between groups. The black (red) histogram represents the result of random (ADO-D) condition. Many decision-making models can be represented as a logistic regression model with elaborated structure in the exponential function of the logistic function. In most of the two-alternative choice tasks, it looks like logistic regression, the exploratory variables of which are the difference of alternative's value while evaluating each alternative's value separately. The Fisher information matrix can be derived with the same procedure in this model class. This appendix introduces the Fisher information matrix with a general formula for this model class.


FIGURES AND TABLES:
A model in this class can be represented by ( 1 ) ( 1 ) + ( 2 )(1 − ( 1 ))}, 1 > 2 ≥ 0 and ( ; ) is defined in the same way in the CPT model (simulation study 2). Although the logistic model does not include two alternatives, it can be written by ( ) = 1 1 + 2 1 when the number of independent variables are two. 
Fujita et al. (preprint)
 derived the Fisher information matrix of the model represented by equation (A1) and (A2) as below:
∼ ( ( )),
( 1)
F( ) , = ∑ ( ) (1 − ( )) [ ( )] =1 [ ( )] ,
( 3)
where F( ) , , , = 1, … , , is (m, n) element of the Fisher information matrix, F( ) .
( ) means the derivative of ( ) with -th parameter, . ( ) can be calculated with equation 
A2
. What the researcher should calculate is ( ) for = 1, … , .
In logistic model with two independent variables, the parameters are = ( 1 , 2 ) , and therefore, we obtain ( ) = − {1+ } 2 , from equations (9) and (10). In terms of the CPT model, although
* ) is the Fisher information matrix at * (Chang 2015). The Fisher information matrix (see Ly et al. 2017 for a recent tutorial) is given by


does not require the estimation of posterior for each outcome and each design , and does not require the numerical evaluation of expectation on the outcome. However, instead, researchers have to derive the Fisher information matrix analytically before conducting experiments. This may be a hurdle for statistical nonexperts. Fujita et al. (2022)'s tutorial paper describes the general formula of the Fisher information matrix for decision-making tasks. This paper uses this formula (see Appendix A). The simulation of ADO-D takes much time, especially on the elaborated models like a CPT model. In individual-level ADO-D, iterative calculations of the number of trials (e.g., 40) times the number of simulation repetition (e.g., 50, 100) are needed. In our experience, simulation for CPT in this situation takes around 10-12 hours with Intel core i5 2540M (single-core) and software R (R Core Team 2021). The method proposed in this study requires the simulation repetitions of the number of trials times the number of participants times the number of simulation repetitions, which sometimes leads to significant computational time (e.g., around one month) with a single core of CPU. Therefore, this study used a foreach package (Microsoft and Stee Weston 2020) of R for parallel processing and a 32 core machine from Amazon Web Service (c6g.8xlarge EC2 instance).


Fig. 1
1
Results ofRMSE and PSD of   in the delay discounting model.(a), (b): The RMSE (a) and PSD (b) for the group mean parameter of in the random condition. (c), (d):


Fig. 2
2
Results ofRMSE and PSD of   in Cumulative prospect theory model.(a), (b): The RMSE (a) and PSD (b) for group mean parameter of . The black and red histogram represents the result of random and ADO-D condition, respectively. (c): The PSD for group mean difference between groups. The black and red histogram represents the result of random and ADO-D condition, respectively.


of -th participant at -th trial. = ( 1 , … , ) is parameter values of -th participant, and P is the number of parameters. ( ; ), ( ; ) are functions for subjective value of alternative A, B, respectively. These subjective values are dependent on the stimuli of each alternative and parameters. Let ( ) = ( ; ) − ( ; ) be for brevity. For example,


it was not implemented (see
Kim et al. 2014
 for more details). Computational difficulties are faced when conducting a hierarchical Bayes estimation for each outcome and each design . Although the application fields where both approaches were applied were totally different, CAT (i.e., ADO-D in this paper) is a special case of ADO. The design optimization step of CAT uses the determinant of the Fisher information. The Bayesian updating step of CAT usually uses Markov Chain Monte Carlo (MCMC) methods without discretizing the parameters.Let * and ̂ denote the true parameter values and their estimates of participant ( = 1, … , ). Under regularity conditions, the estimator ̂ satisfies
parameters, although EFFECT OF ADO FOR GROUP LEVEL PARAMETERS 2.2 The CAT Framework
(
)
where
is group-level 6


Table 1 .
1
RMSE and PSD of each stimulus selection condition Each row corresponds to RMSE and PSD of parameters for delay discounting model and each column corresponds to either group mean or group SD for each stimulus selection condition.
Random
ADO-D
group mean
group SD
group mean
group SD
k
1.19
1.19
0.02
0.02
RMSE
β
6.89
3.73
0.4
0.39
k
0.43
1.16
0.02
0.02
PSD
β
1.21
1.27
0.32
0.36
Note. Table 2. RMSE and PSD of each stimulus selection condition
Random
ADO-D
group mean
group SD
group mean
group SD
η
0.04
0.04
0.03
0.03
γ
0.13
0.06
0.03
0.03
RMSE
α
0.32
0.09
0.09
0.09
φ
0.85
0.11
0.33
0.29
η
0.06
0.06
0.04
0.04
γ
0.06
0.06
0.03
0.03
PSD
α
0.08
0.07
0.06
0.06
φ
0.22
0.15
0.32
0.31


≥ 0, which is the case considered in this paper, the (⋅) and (⋅) are defined as ( ) = ,(13)( 1 ) = 1 ( 1 + (1 − 1 ) ) 1 ,(14)where ∈ [0, 1], ≥ 0 are the parameters. Without loss of generality, the present study considers only the gain condition. For decision under uncertainty, using two-stage model
(Abdellaoui et al. 2005;
Kilka
 


The present study has two limitations. First, the present method (i.e., individual-level ADO-D) does not directly optimize group-level parameters. Strictly speaking, this means it does not amount to the optimal stimulus selection for group-level parameters. This study used individual-level ADO-D even though it does not consider the hierarchical structure because optimizing group-level parameters is difficult in terms of analytical derivation. If some estimators for group-level parameters meet asymptotic efficiency, we can discuss stimulus selection criteria for optimal selection in terms of estimation precision and the loss of individual-level ADO-D from optimal performance. Second, the above simulation studies supposed that the assumed model was the true model. To weaken this assumption, it can be possible to employ stimulus selection methods that consider multiple models, such as ADO for model selection and model-averaged CAT. In addition,


Weiss, D. J., & Kingsbury, G. G. (1984). Application of Computerized Adaptive Testing to educational problems. Journal of Educational Measurement, 21(4), 361-375. https://doi.org/10.1111/j.1745-  3984.1984.tb01040.x   


[( )] is not easy, Fujita and Okada (2022) derived these derivatives.








Appendix A
 










Choice-based elicitation and decomposition of decision weights for gains and losses under uncertainty




M
Abdellaoui






F
Vossmann






M
Weber




10.1287/mnsc.1050.0388








Management Science




51


9




















W
Y
Ahn






H
Gu






Y
Shen






N
Haines






H
A
Hahn






J
E
Teater






J
I
Myung






M
A
Pitt


















Rapid, precise, and reliable measurement of delay discounting using a Bayesian learning algorithm


10.1038/s41598-020-68587-x








Scientific reports




10


1


12091












Adaptive stimulus selection for multi-alternative psychometric functions with lapses




J
H
Bak






J
W
Pillow




10.1167/18.12.4








Journal of Vision




18


12
















Optimal decision stimuli for risky choice experiments: An adaptive approach




D
R
Cavagnaro






R
Gonzalez






J
I
Myung






M
A
Pitt








Management Science




59


2


















10.1287/mnsc.1120.1558














Adaptive design optimization: A mutual information-based approach to model discrimination in cognitive science




D
R
Cavagnaro






J
I
Myung






M
A
Pitt






J
V
Kujala




10.1162/neco.2009.02-09-959








Neural Computation




22


4


















H
H
Chang




10.1007/s11336-014-9401-5








Psychometrics behind computerized adaptive testing






80














Data-driven experimental design and model development using Gaussian process with active learning




J
Chang






J
Kim






B
T
Zhang






M
A
Pitt






J
I
Myung




10.1016/j.cogpsych.2020.101360








Cognitive Psychology




125














The multivariate adaptive design for efficient estimation of the time course of perceptual adaptation




P
Chen






S
Engel






C
Wang








Behavior Research Methods




52


3


















10.3758/s13428-019-01301-6














Classification accuracy and consistency of computerized adaptive testing




Y
Cheng






D
L
Morgan




10.3758/s13428-012-0237-6








Behavior Research Methods




45


1
















Fast adaptive estimation of multidimensional psychometric functions




C
Dimattina




10.1167/15.9.5








Journal of Vision




15


9
















Tracking of nociceptive thresholds using adaptive psychophysical methods




R
J
Doll






J
R
Buitenweg






H
G E
Meijer






P
H
Veltink








Behavior Research Methods




46


1


















10.3758/s13428-013-0368-4














Adaptive optimal stimulus selection in cognitive models using a model averaging approach




K
Fujita






K
Okada




10.31234/osf.io/snhkp


















The Fisher information matrix: A tutorial for calculation for decision making models




K
Fujita






K
Okada






K
Katahira




10.31234/osf.io/hdwut


















Ambiguity aversion and comparative ignorance




C
Fox






A
Tversky




10.2307/2946693








The Quarterly Journal of Economics




110


3
















Forced-choice staircases with fixed step sizes: Asymptotic and small-sample properties




M
A
García-Pérez




10.1016/S0042-6989(97)00340-4








Vision Research




38


12
















On the shape of the probability weighting function




R
Gonzalez






G
Wu




10.1006/cogp.1998.0710








Cognitive Psychology




38
















A hierarchical Bayesian approach to adaptive vision testing: A case study with the contrast sensitivity function




H
Gu






W
Kim






F
Hou






L
A
Lesmes






M
A
Pitt






Z
L
Lu






J
I
Myung




10.1167/16.6.15








Journal of Vision




16


6
















What determines the shape of the probability weighting function under uncertainty?




M
Kilka






M
Weber








Management Science




47


12


















10.1287/mnsc.47.12.1712.10239














A hierarchical adaptive approach to optimal experimental design




W
Kim






M
A
Pitt






Z
L
Lu






M
Steyvers






J
I
Myung








Neural Computation




26


















10.1162/NECO_a_00654














Bayesian adaptive estimation of psychometric slope and threshold




L
L
Kontsevich






C
W
Tyler




10.1016/S0042-6989(98








Vision Research




39


16
















Bayesian adaptive estimation: The next dimension




J
V
Kujala






T
J
Lukka




10.1016/j.jmp.2005.12.005








Journal of Mathematical Psychology




50


4
















Common and distinct factors in decision making under ambiguity and risk: A psychometric study of individual differences




M
Lauriola






I
P
Levin






S
S
Hart




10.1016/j.obhdp.2007.04.001








Organizational Behavior and Human Decision Processes




104


2
















On a measure of the information provided by an experiment




D
V
Lindley




10.1214/aoms/1177728069








The Annals of Mathematical Statistics




27


4
















A tutorial on Fisher information




A
Ly






M
Marsman






J
Verhagen






R
P P P
Grasman






E
J
Wagenmakers








Journal of Mathematical Psychology




80


















10.1016/j.jmp.2017.05.006














Delay discounting of real and hypothetical rewards




G
J
Madden






A
M
Begotka






B
R
Raiff






L
L
Kastern








Experimental and Clinical Psychopharmacology




11


2


















10.1037/1064-1297.11.2.139














Computerized adaptive testing: Overview and an example




R
R
Meijer






M
L
Nering








Applied Psychological Measurement




23


3


















10.1177/01466219922031310














foreach: Provides foreach looping construct




Steve
Microsoft






Weston














R package version 1.5.1.








Multidimensional adaptive testing with optimal design criteria for item selection




J
Mulder






W
J
Van Der Linden




10.1007/s11336-008-9097-5








Psychometrika




74


2
















A tutorial on adaptive design optimization




J
I
Myung






D
A
Cavagnaro






M
A
Pitt




10.1016/j.jmp.2013.05.005








Journal of Mathematical Psychology




57
















Optimal experimental design for model discrimination




J
I
Myung






M
A
Pitt




10.1037/a0016104








Psychological Review




116


3


















A
L
Odum




10.1016/j.beproc.2011.02.007




Delay discounting: Trait variable? Behavioural Processes






87














R: A language and environment for statistical computing. R Foundation for Statistical Computing




R Core Team










Vienna, Austria












A tutorial on Gaussian process regression: Modelling, exploring, and exploiting functions




E
Schulz






M
Speekenbrink






A
Krause








Journal of Mathematical Psychology




85


















10.1016/j.jmp.2018.03.001














Multidimensional adaptive testing




D
O
Segall




10.1007/BF02294343








Psychometrika




61


2
















Computerized Adaptive Testing. Encyclopedia of Social Measurement




D
O
Segall




10.1016/B0-12-369398-5/00444-8




















Delay discounting and intelligence: A meta-analysis




N
A
Shamosh






J
R
Gray




10.1016/j.intell.2007.09.004








Intelligence




36


4
















An introduction to the Computerized Adaptive Testing. US-China Education Review




J
Tian






D
Miao






X
Zhu






J
Gong










4














The design and evaluation of a computerized adaptive test on mobile devices




E
Triantafillou






E
Georgiadou






A
A
Economides








Computers and Education




50


4


















10.1016/j.compedu.2006.12.005














Advances in prospect theory: Cumulative representation of uncertainty




A
Tversky






D
Kahneman








Journal of Risk and Uncertainty




5
















On the composition of risk preference and belief




P
P
Wakker




10.1037/0033-295X.111.1.236








Psychological Review




111


1
















Concerning the effect of intraclass correlation on certain significance tests




J
E
Walsh




10.1214/aoms/1177730495








The Annals of Mathematical Statistics




18
















QUEST: A Bayesian adaptive psychometric method




A
B
Watson






D
G
Pelli




10.3758/BF03202828








Perception & Psychophysics




33


2

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]