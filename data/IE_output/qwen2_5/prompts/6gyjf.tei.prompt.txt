You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Cognitive science relies on rigorous evaluations of behavioral performance, through which researchers investigate the effects of target variables, quantify individual differences, and uncover the mechanisms underlying various psychological phenomena. Since the early days of psychophysics, receiver operating characteristics (ROCs) and signal detection theory (SDT) have been central to this purpose 
(Green & Swets, 1966)
. Due to the inherent noise in neural processing, human observers may exhibit varying responses at different instances, even if exposed to identical stimuli. These analysis tools offer systematic descriptions of such probabilistic behavior, guiding principled performance evaluations.
ROC analyses are commonly applied when binary classification responses (hereafter referred to as primary responses) are accompanied by secondary numerical variables, such as confidence, response time (RT), and neural firing rate (e.g., 
Britten et al., 1992;
Peters et al., 2017;
Weidemann & Kahana, 2016;
Wixted, 2007)
. 1 Among these, confidence, along with similar introspective measures (e.g. visibility ratings, opt-out choice, or waiting time) has been most widely used for ROC analyses, highlighting the substantial research focus on subjective introspection within the existing research community (for a review, see .
However, when viewed solely as a secondary variable for constructing ROCs, collecting confidence ratings or related introspective measures introduces temporal and cognitive costs-an issue particularly pronounced when studying children or animals (e.g., 
Goupil & Kouider, 2016;
Lak et al., 2014;
Odegaard et al., 2018;
Watanabe & Moriguchi, 2023)
. Therefore, the present study delves into ROC analysis using RT, which does not require additional data collection and can be widely applied across various experimental situations.
Type-1 ROC analysis is perhaps the most widely used, addressing the discrimination between two external stimulus classes, S1 and S2 ( 
Figure A1
; 
Macmillan & Creelman, 2005, pp. 51-72)
. It examines the proportion of "S2" responses for each stimulus class: p(response = S2|stimulus = S1) and p(response = S2|stimulus = S2). Type-1 ROC is depicted by plotting these proportions using varying cutoffs on the secondary variable. The leftmost data point represents S2 responses at the highest cutoff, with subsequent points defined with progressively lower cutoff values.
Type-1 ROC thus quantifies an observer's ability to discriminate between external stimulus classes by incorporating both the primary response and the secondary variable. When the secondary variable provides additional information for stimulus discrimination, the area under the type-1 ROC curve (type-1 AUC) increases relative to when only the primary response is considered (for illustration, see 
Miyoshi & Nishida, 2024)
. In other words, type-1 ROC analysis may offer a more sensitive evaluation of stimulus discrimination performance by extracting richer information from experimental data, compared to methods based solely on the primary response, such as d′ and A′ measures 
(Macmillan & Creelman, 2005)
.
A counterpart to this approach is type-2 ROC analysis, which quantifies the diagnostic power of the secondary variable in discriminating the trial-by-trial correctness of primary responses ( 
Figure A2
; 
Clarke et al., 1959;
Galvin et al., 2003;
Maniscalco & Lau, 2012)
. Specifically, while type-1 ROC analysis concerns externally defined stimulus classes, type-2 ROC analysis examines the classification of response correctness, defined by an observer's own behavior. Type-2 ROC evaluates the proportion of instances where the secondary variable is labeled as "high," contingent on response correctness: p(secondary variable = high|response = incorrect) and p(secondary variable = high|response = correct). It is constructed by plotting these proportions using varying cutoffs for the secondary variable to be considered high. The leftmost data point corresponds to trials exceeding the highest cutoff, with subsequent points calculated using progressively lower cutoffs. The area under the type-2 ROC curve (type-2 AUC) increases as the secondary variable becomes more informative about response correctness.
Type-2 ROC analysis has been almost exclusively conducted with confidence ratings (or related subjective measures, such as visibility ratings), making it a widely used indicator of metacognitive accuracy (e.g., 
Maniscalco & Lau, 2012)
. To the best of our knowledge, this study is the first to leverage type-2 ROC analysis to characterize the interrelations among RT, confidence, and response correctness. Specifically, we utilized public datasets on perceptual decision-making 
(Rahnev et al., 2020)
, first conducting type-2 ROC analyses separately for RT and confidence. We then created their composite variable and compared its ROC with those of the individual variables, allowing us to investigate whether RT possesses unique diagnostic power in predicting response correctness on top of confidence. These approaches would uncover behavioral patterns often overlooked in traditional analyses, offering fresh insights into the related processes.
Subsequently, we conducted complementary simulations to bridge the findings from the empirical type-2 ROC analyses with computational modeling. The relationship between RT and response correctness has traditionally been explored within the framework of sequential evidence accumulation (e.g., 
Ratcliff & McKoon, 2008)
, and recent studies have further investigated potential links between RT and confidence 
(Hellmann et al., 2023;
Kiani et al., 2014;
Van Marcke et al., 2024)
. Here, we evaluated the simplest evidence accumulation models (see Methods) against the observed relationships among RT, confidence, and response correctness. To the extent that these models capture these relationships, observed human behavior can be interpreted through the processes they posit. At the same time, discrepancies between model predictions and empirical data may point to additional computational mechanisms, including potential interplays between RT and confidence-for instance, confidence could serve as a signal to terminate information gathering 
(Desender et al., 2018;
Lee et al., 2023)
.
Finally, based on observed findings, we discuss the potential of RT as a proxy for confidence. Using RT as an implicit metacognitive measure could be particularly useful in contexts where explicit introspective measures are not readily available, such as in animal studies. We, however, also outline conceptual caveats of this approach to appropriately constrain its applicability.


Methods


Empirical ROC Analyses
We conducted type-2 ROC analyses on datasets of perceptual decision-making selected from the Confidence Database 
(Rahnev et al., 2020)
. The datasets were selected based on the following criteria: two-alternative forced-choice (2AFC) task design, availability of both RT and confidence data, and constant task difficulty (or stimulus strength) across trials within a single experimental condition 
(Bang et al., 2019;
Rahnev & Fleming, 2019)
. Based on these criteria, we selected 16 datasets comprising nine different experiments and a total of 539 individuals (see 
Table A1
 for details). All analyses were performed using a free statistical programming language R (version 4.3.1), with the analysis code available at https://github.com/kiyomiyoshi/rt_type2_roc. For each dataset, we first constructed confidence-based ROCs for individuals and analyzed them using a meta-SDT model 
(Maniscalco & Lau, 2012)
. This model provides d′-an index of primary response accuracy-and meta-d′-an index that quantifies the diagnostic value of the secondary variable (confidence in this case) regarding primary response correctness. These two indices are directly comparable as they are both expressed in the same unit of signal-to-noise ratio 
(Fleming & Lau, 2014)
. Accordingly, we calculated meta-d′/d′ (known as m-ratio) to quantify type-2 performance relative to primary response accuracy.
Next, we performed the same analysis using RT. To maintain consistency with the confidence analysis, for datasets with n-level confidence ratings, we constructed ROC curves using the n quantiles of RT as cutoff points. As with the confidence analysis, we conducted a meta-SDT analysis for each individual.
Lastly, to assess the diagnostic power of the combination of RT and confidence on response correctness, we created their composite variable using logistic regression. Specifically, logistic regression was applied for each individual to predict trial-by-trial response correctness based on RT, confidence, and their interaction. The resulting logit (log-odds ratio of response correctness) was then used as a secondary variable for meta-SDT analysis. This approach enabled a quantitative comparison of the meta-d′ index derived from the composite variable versus that obtained using confidence or RT alone. Hereafter, the meta-SDT indices calculated using the three variables above are referred to as meta-d′confidence, meta-d′RT, and meta-d′confidence+RT.


Mixed Model Analyses
To extend the analyses above, we conducted mixed logistic regression for each dataset to predict trial-by-trial response correctness based on RT and confidence. The analysis was conducted in two stages to first evaluate the main effect of each variable and then assess their interaction. In the first stage, we specified a model with RT and confidence as fixed effects, including random intercepts and random slopes for RT and confidence across individuals. In the second stage, we added the interaction between RT and confidence as a fixed effect while retaining the same random effect structure from the first stage. While the above meta-SDT analysis summarizes observers' performance using the standardized meta-d′ index, this mixed model approach quantifies the contribution of each variable as model coefficients and also provides formal statistical tests. The analysis was implemented in R using the lme4 package, with the statistical significance of fixed effects assessed via Type II Wald chi-square tests using the car package.


Accumulator simulations
Findings from the above analyses are expected to provide valuable insights for advancing computational models of perceptual decision-making. As an initial step toward this goal, we performed 2AFC simulations using two classic sequential sampling models to assess their alignment with observed data patterns.
We considered the two simplest models that jointly account for response correctness, RT, and confidence. The first, Vickers' race model 
(Vickers, 1979)
, assumes two independent evidence accumulators, one for each stimulus, S1 and S2 ( 
Figure A3a)
. Evidence for each stimulus evolves over discrete time steps t (each corresponding to 1 ms), where the average rate of evidence accumulation is referred to as the drift rate. A decision is made when either accumulator reaches a decision boundary. Confidence is determined by the balance of evidence-the difference in accumulated evidence between the winning and losing accumulators at the moment of decision.
The second model is the two-stage dynamic signal detection model (2DSD; 
Pleskac & Busemeyer, 2010)
, which combines the classic drift-diffusion model 
(Ratcliff, 1978)
 with postdecisional confidence construction (e.g., 
Moran et al., 2015;
Navajas et al., 2016)
. In 2DSD, a single accumulator encodes the relative evidence for S1 versus S2 ( 
Figure A3b)
. When the accumulated evidence reaches the upper (lower) decision boundary, S1 (S2) is chosen. We implemented this model by tracking the difference between the two independent accumulators of the race model, which facilitates a direct comparison between the models. In 2DSD, the decision is made on the balance of evidence itself, meaning that its value at the decision moment is fixed at the boundary. Thus, to introduce meaningful variations in confidence across trials, an additional evidence accumulation period for confidence construction is assumed after the decision is reached 
(Fleming & Daw, 2017;
Herregods et al., 2023;
Miyoshi & Sakamoto, 2024;
Moran et al., 2015;
Navajas et al., 2016;
Pleskac & Busemeyer, 2010)
. Specifically, 2DSD's confidence is calculated based on the difference between chosen and unchosen stimulus evidence accumulated during the post-decisional period ( 
Figure A3b
, grey area). 
Table A2
 lists the parameters defining the models. To enhance model comparability, parameters shaded in gray are shared by both models. The three parameters shown in bold were manipulated in the simulation. The mean target drift rate νtarget was manipulated as a proxy for target stimulus intensity (S1 and S2 were the correct answer an equal number of times during the simulation). Trial-to-trial variability in the drift rate (η) and the accumulation starting point (sz) were also manipulated, given their known influence on the relationship between RT and response correctness (e.g., 
Ratcliff & McKoon, 2008)
.
In determining these parameter values, we first manually set the race model parameters to cover near-chance to near-perfect discriminability in type-1 ROC space (see 
Figure A1
). The resulting d′ averaged across all conditions was 1.13, which guided our adjustment of 2DSD's decision boundary (a2DSD) to match this average d′ value. Likewise, the resulting average meta-d′ of the race model was 0.81, which led us to adjust the number of post-decisional confidence construction steps for 2DSD (Tpd) to achieve this average meta-d′ value.
For each condition, we simulated 200,000 trials, counterbalancing the targetdistractor assignment between S1 and S2. In line with common practice in human experiments, we excluded trials with exceedingly slow RTs (RT > 3000) from the subsequent analyses. For confidence ratings, we used 10 quantiles of the balance of evidence (for the race model) and post-decisional evidence (for 2DSD) as discrete criteria to generate 10 levels of confidence (this process was carried out separately for each condition). Likewise, for each model, we discretized RTs into 10 levels using 10 quantiles, again separately for each condition. To generate the combined variable of confidence and RT for each model, we conducted logistic regression for each condition to predict trial-wise response correctness with confidence, RT, and their interaction (confidence variables and RT were not discretized at this stage). Then, we used 10 quantiles of the resulting logits to discretize them into 10 levels. Finally, we used these three variables to construct ROCs ( 
Figures A1 and A2)
, on which we performed meta-SDT analyses. 
Figure 1
 presents the results of the meta-SDT model analyses, aggregating estimates from 539 individuals across 16 datasets (Figures A4 and A5 report summary statistics for each dataset). The mean d′ value (M = 1.24, SE = 0.033) was significantly higher than the mean values of meta-d′confidence (M = 0.94, SE = 0.032), meta-d′RT (M = 0.62, SE = 0.028), and meta-d′confidence+RT (M = 1.08, SE = 0.029) (p < .001 for all). Furthermore, d′ showed significant correlations with all three meta-d′ indices (p < .001 for all). It has been well established that meta-d′ based on confidence correlates with d′ (e.g., Guggenmos, 2021; Rahnev, 2025), and our findings extend this by demonstrating that meta-d′ based on RT also correlates with d′.


Results


Empirical ROC Analyses
The mean meta-d′confidence was significantly higher than the mean meta-d′RT (0.94 vs. 0.62; t(538) = 10.68, p < .001), revealing that RT carries about two-thirds of type-2 diagnosticity compared to confidence. Additionally, the mean meta-d′confidence+RT was significantly higher than the mean meta-d′confidence (1.08 vs. 0.94; t(538) = 6.84, p < .001); combining confidence and RT increased meta-d′ by 15% compared to using confidence alone. That is, while RT alone showed limited predictive power for response correctness (m-ratio = 0.5 based on the mean values above), it provided unique information beyond what confidence captured.
As noted, the m-ratio index is intended as a type-2 performance measure standardized to primary response accuracy (e.g., 
Fleming & Lau, 2014)
. However, empirical evidence often indicates a negative correlation between m-ratio and d′ 
(Guggenmos, 2021;
Rahnev, 2025;
Xue et al., 2021)
. In this study, we also observed significant negative correlations between d′ and m-ratio indices derived from all three secondary variables (see 
Figure A6
), further exemplifying the limitation of the m-ratio index. Nevertheless, a closer inspection revealed that these negative correlations were primarily driven by excessively large m-ratio values associated with near-zero d′ values. When the analysis was restricted to cases with d′ > 1, the negative correlations were reduced substantially, with m-ratioRT showing no significant correlation with d′ (though m-ratioconfidence and m-ratioconfidence+RT continued to show a significant negative correlation with d′; 
Figure A7
). These findings suggest that collecting data within moderate or higher response accuracy ranges may mitigate the bias of m-ratio in indexing metacognitive efficiency independent of response accuracy.
Notably, meta-d′RT and meta-d′confidence displayed a moderate correlation (r = 0.518). One important consideration is that this correlation may be attenuated by the measurement reliability of each meta-d′ index. To account for this, we split each subject's data into even and odd trials and separately computed meta-d′RT and meta-d′confidence. Across subjects, the splithalf correlation of meta-d′RT between even and odd trials was 0.431, and the Spearman-Brown formula (e.g., 
Eisinga et al., 2013
) gave a split-half reliability of 0.602. Likewise, the split-half correlation of meta-d′confidence between even and odd trials was 0.588, yielding a split-half reliability of 0.741. Applying the standard attenuation correction formula, the disattenuated correlation between meta-d′RT and meta-d′confidence was estimated to be 0.776. These findings suggest that RT data may offer insights into the observer's explicit metacognitive sensitivity, while we consider potential limitations of using RT as an implicit metacognitive measure in the Discussion. Average meta-d′ based on confidence was 50% higher than that based on RT, quantifying the difference in the information each measure conveys about response correctness. Average meta-d′ estimated by combining both RT and confidence (see Methods) was 15% larger than meta-d′ based solely on confidence, indicating that RT conveys unique type-2 information not captured by confidence. Panels below the diagonal represent correlation plots between different indices, while those above the diagonal present Pearson's correlation coefficients (all p-values < .001). Meta-d′ derived from RT and confidence showed a moderate level of correlation (r = 0.518). 
Figure 2
 shows the estimated coefficients and their 95% confidence intervals from mixed logistic regressions predicting trial-by-trial response correctness using both confidence and RT (as well as their interaction). The significance of each variable can be examined from the overlap between the confidence intervals and the dashed line representing zero. Across the 16 datasets, RT's contribution was significant in 13 cases, while confidence showed significance in 14 cases (p < .05). These findings indicate that RT independently contributes to predicting response correctness, even after controlling for the confounding effect of confidence.


Mixed Model Analyses
Furthermore, a significant interaction (p < .05) was observed in 12 cases, featuring negative coefficient values, while confidence and RT had positive and negative coefficients, respectively. Given the signs of these coefficients (and insights from additional analyses below), the observed interaction can be interpreted as: (1) confidence more effectively predicted accuracy in trials with shorter RT, and (2) RT less effectively predicted accuracy in trials with lower confidence. The observed main effect and interaction involving RT were reflected in the above meta-SDT analysis, which revealed a 15% increase in meta-d′confidence+RT compared to meta-d′confidence. 
Figure 2
. Mixed logistic regression parameter estimates (circles) with 95% confidence intervals (error bars). The main effects of RT and confidence on predicting trial-by-trial response correctness were evaluated in the first-stage estimation without including the interaction. Then, the second-stage estimation assessed their interaction (see Methods for details). Due to this two-stage estimation, the non-overlap between the confidence intervals and zero directly indicates the significance of the main effects and interaction. Overall, both shorter RT and higher confidence were uniquely linked to greater response accuracy. We also found their interaction, where confidence better predicted response correctness in trials with faster RTs.
To further explore the observed interaction, we selected six datasets with a relatively large number of trials per individual (see 
Table A1
) that showed a significant interaction in the mixed modeling. First, we divided RT into 20 equally spaced bins for each subject. We then plotted the averaged response accuracy across subjects, smoothed over different RT bins for each confidence level 
(Figure 3)
. Here, we applied locally estimated scatterplot smoothing (loess) using the default parameters of the ggplot2 package (span = 0.75, degree = 2). For estimation stability, in datasets with six confidence levels (bottom row of 
Figure 3
), we collapsed them into three by grouping levels 1-2, 3-4, and 5-6.
On one end, the interaction is marked by steeper line slopes at higher confidence levels. This is likely because faster RTs are associated with more robust internal evidence development, leading to more efficient metacognitive monitoring (as demonstrated in later 2DSD simulations). Another key observation is that, at lower confidence levels, accuracy peaked at mid-range RT bins before declining toward the fastest RT bin, which limits the predictive value of RT for response accuracy at lower confidence levels. This inverted U pattern contrasts with the commonly assumed trend that faster RTs indicate higher accuracy. Perhaps, low confidence ratings in the fastest RT range partly reflect explicit error detection 
(Rabbitt, 1966;
van den Berg et al., 2016;
Yeung & Summerfield, 2012)
. That is, noisy evidence accumulation can sometimes produce extremely fast incorrect responses, but observers may consciously recognize these errors and report low confidence. This may underlie the inverted U curves observed at lower confidence levels (for further mechanistic insights, see 2DSD simulations in the next section. 
Figure 3
. Relationship between confidence, RT, and response accuracy. For six datasets, response accuracy was locally smoothed across RT bins at each confidence level (shaded areas indicate corresponding SEs). RT bins were defined individually, with smaller values indicating faster RTs. Overall, confidence better predicted response accuracy at faster RTs. This confidence-RT interaction is reflected in variations in line slopes across different confidence levels and in inverted U patterns at low confidence levels. 
Figure 4
 illustrates the choice proportions, mean RTs, and mean confidence levels for Vickers' race model 
(Vickers, 1979)
 and the 2DSD model 
(Pleskac & Busemeyer, 2010)
. The decision boundary for each model was set to match their average response accuracy across all conditions at d′ = 1.13. 
(Figure 4a
). The 2DSD model achieved this accuracy with faster RTs compared to the race model 
(Figure 4b
; for trial-wise RT distributions, see 
Figure A8
). This pattern is expected as the drift-diffusion process 
(Ratcliff, 1978)
 is known to be optimal in minimizing the time steps required to reach a predefined level of accuracy 
(Bogacz et al., 2006)
. Note that trials with RTs exceeding 3000 ms were excluded, meaning that the race model's RTs could potentially be even slower without the exclusion (8.6% of trials were omitted for the race model and 0.5% for 2DSD).


Accumulator simulations Descriptive statistics
As shown in 
Figure 4b
, increased drift rate variability (η) in 2DSD resulted in faster RTs for correct responses relative to incorrect ones (e.g., 
Ratcliff, 1978;
Ratcliff & McKoon, 2008)
. That is, greater drift rate variability strengthened the association between faster RTs and correct responses, and this effect was more pronounced under higher starting point variability (sz). In contrast, this type-2 performance modulation by drift rate variability was less evident in the race model compared to 2DSD.
Likewise, increased starting point variability in 2DSD also modulated the relative speed of correct and incorrect responses 
(Ratcliff & McKoon, 2008)
. In the extreme scenario, slower (rather than faster) RTs were associated with correct responses, indicating that RT can exhibit "negative" predictive power for response correctness. While relatively uncommon, this fast error phenomenon has occasionally been observed in human experiments and initially motivated the inclusion of the starting point variability parameter in the drift-diffusion model 
(Laming, 1968;
Ratcliff & McKoon, 2008)
. Consequently, it is important to recognize that RT can have either a positive or negative relationship with response correctness. For confidence, negative type-2 performance is typically attributed to random measurement errors, but for RT, it can arise from the proper drift-diffusion process. In contrast to these observations, the race model was less sensitive to the starting point variability manipulation and did not exhibit the fast error pattern within the current parameter range. 
Figure 4c
 displays a marked difference in average confidence between the models. The 2DSD model exhibited the "folded-X" pattern, with confidence in correct responses rising and confidence in incorrect responses falling as the target drift rate increased 
(Miyoshi & Sakamoto, 2024;
Rausch & Zehetleitner, 2019;
Sanders et al., 2016;
. In contrast, the race model showed a different trend, where confidence in correct responses remained constant or even decreased with higher target drift rates. 
2
 The decreasing confidence in correct responses deviates from typical patterns exhibited by human observers (e.g., 
Fung et al., 2025)
, suggesting the need for model adjustments. However, it is worth noting that the current simulation did not thoroughly explore the full parameter space of the race model-for example, we did not explore the possibility that the higher drift rate for the target is coupled with the lower drift rate for the distractor. Compared to the race model, 2DSD exhibited more flexible RT type-2 performance (i.e., relative speed of target versus distractor choice), depending on the variability in the drift rate and starting point. (c) Mean confidence for target and distractor choices. In the race model, confidence in target choices declined as the mean target drift rate increased, a pattern not typically observed in human experiments. These findings suggest that 2DSD is a more viable candidate for interpreting human data than Vickers' race model.


SDT measures
Figures 5a and 5b display d′, meta-d′, and m-ratio indices for each model. Across different parameter values, the race model showed m-ratioRT around 0.1 to 0.4, much smaller than the human average of 0.5 (see 
Figure 1)
. Note that this simulation did not consider trial-totrial variability in non-decision time (e.g., variability in motor execution), and including such variability would further reduce the model's m-ratioRT. In contrast, 2DSD's meta-d′RT spanned a wider range, including negative values, which reflect the fast error phenomenon we mentioned earlier 
(Laming, 1968;
Ratcliff & McKoon, 2008
; corresponding negative meta-d′RT values were observed in empirical data in 
Figure 1)
. These findings suggest that 2DSD may more closely align with human RT type-2 characteristics than Vickers' race model, at least based on the parameter space examined in these simulations. 
Figure 5c
 shows the extent to which meta-d′confidence+RT was elevated compared to meta-d′confidence. Here, meta-d′confidence across conditions was equated to an average of 0.81 between the models by adjusting 2DSD's Tpd parameter. The race model showed a substantial boost in type-2 performance when confidence was combined with RT, particularly under greater trial-totrial variability in the drift rate. In comparison, 2DSD showed up to a 1.08 times boost in meta-d′ through the confidence-RT combination, appreciably below the human average of 1.15. 
Figure 6
 illustrates the relationship between confidence (binned into three levels), RT (binned into 20 levels), and response accuracy for each model. Response accuracy was calculated using local smoothing across RT bins, separately for each confidence bin. Compared to the race model, 2DSD showed a closer resemblance to human data 
(Figures 3)
, demonstrating a marked confidence-RT interaction. Specifically, confidence was a better predictor of response accuracy at faster RTs, evident in steeper line slopes for higher confidence bins and inverted U curves for lower confidence bins.
Despite its simplicity, 2DSD captured human data reasonably well and may serve as a useful framework for interpreting human behavior. Under 2DSD, faster RTs are linked to higher evidence accumulation rates, which facilitate more accurate metacognitive monitoring during the post-decisional period. This mechanism likely accounts for the slope variations observed in 
Figure 3
. Furthermore, 2DSD revealed inverted U curves at low confidence bins, particularly under conditions of high mean target drift rate and substantial starting point variability (bottom right of 
Figure 6
). In these scenarios, biased accumulation starting points can occasionally produce incorrect responses with short RTs. However, during the post-decisional period, the high target drift rate drives the confidence variable in a direction opposing the initial choice, resulting in low confidence ratings (i.e., high confidence in alternative choice). This can be interpreted as a form of error detection (e.g., 
Fleming & Daw, 2017)
, with the current 2DSD simulation shedding light on the dynamics driving the inverted U pattern. The 2DSD model exhibited a broader range of RT type-2 performance depending on the parameter values, aligning more closely with the variability observed in human data (see 
Figure 1)
. Note that negative m-ratio values are not meaningfully interpretable, but they are plotted as they are for transparency. (c) Ratio of meta-d′confidence+RT to meta-d′confidence. The 2DSD model showed up to a 1.08-fold increase in meta-d′ when combining confidence and RT, slightly below the human average of 1.15. These results highlight 2DSD's ability to capture human data, though it is not without limitations.  
Figure 3
, successfully replicating the confidence-RT interaction (i.e., steeper slopes at higher confidence levels and inverted U curves at lower confidence levels). In contrast, the race model exhibits a limited confidence-RT interaction, with the lines for different confidence bins tending to appear parallel.


Discussion
This study highlights the often-overlooked methodology of RT-based ROC analysis. Unlike approaches relying on confidence ratings or related subjective measures (e.g., 
Lak et al., 2014;
Odegaard et al., 2018;
Wixted, 2007)
, RT-based ROC analysis imposes no additional cognitive or temporal demands on observers. Moreover, it offers greater experimental ease compared to methods involving biological markers such as neural firing rates (e.g., 
Britten et al., 1992)
. Its broad applicability, including studies with animals and infants, positions RT-based ROC analysis as a promising tool for advancing cognitive science.
The present study focused on type-2 ROC analysis, which examines the diagnostic power of a secondary variable on trial-by-trial correctness of the primary response ( 
Figure A2)
. Type-2 ROC analysis has traditionally been grounded in confidence, serving as an essential tool in metacognition research 
(Clarke et al., 1959;
Galvin et al., 2003;
Maniscalco & Lau, 2012;
. Here, we constructed type-2 ROCs using both RT and confidence to systematically quantify their relationships. Additionally, we introduced a novel method for conducting type-2 ROC analysis on a composite variable incorporating RT, confidence, and their interaction. As discussed below, these approaches have uncovered previously unrecognized patterns in human decision-making, providing new insights into its underlying mechanisms.


Empirical Analyses
Our analysis of perceptual 2AFC datasets revealed that RT, on average, conveys approximately two-thirds as much information about response correctness as confidence (average meta-d′ was 0.94 for confidence and 0.62 for RT; see 
Figure 1)
. While it has long been recognized that higher confidence is typically associated with shorter RTs (e.g., 
Moran et al., 2015;
Ratcliff & Starns, 2009;
Volkmann, 1934)
, our study offers a formal quantification of RT's type-2 diagnostic value relative to confidence via type-2 ROC analysis.
Moreover, we showed that RT is not merely a noisier proxy for confidence but carries unique type-2 diagnosticity on its own. Specifically, the composite variable of confidence, RT, and their interaction yielded an average meta-d′ that was 1.15 times higher than using confidence alone 
(Figure 1)
. The observed interaction indicates that confidence becomes more diagnostic of response correctness at faster RTs 
(Figures 2 and 3)
, which may offer a unique window into the dynamics of perceptual decision-making (see next section).
While these findings highlight the distinct properties of RT compared to confidence, when examining the correlation across subjects, meta-d′ derived from RT and confidence showed a moderately high Pearson correlation of 0.518. After adjusting for measurement reliability (e.g., 
Eisinga et al., 2013)
, the disattenuated correlation coefficient reached a notably high value of 0.776, suggesting that RT-based meta-d′ could serve as an implicit measure of metacognitive accuracy. The feasibility of using RT as a proxy for confidence, based on this correlation, will be further discussed in the following sections.


Accumulator simulations
We conducted 2AFC simulations using basic sequential sampling models-Vickers' race model 
(Vickers, 1979)
 and the 2DSD model 
(Pleskac & Busemeyer, 2010
)-to evaluate their consistency with the observed behavioral patterns. The race model posits two independent accumulators, with a decision being made when evidence in either accumulator reaches the decision boundary ( 
Figure A3a)
. The difference in accumulated evidence between the two (balance of evidence) determines confidence. The 2DSD model involves decision-making through a single accumulator, which integrates the evidence difference between two options at each time step ( 
Figure A3b)
. We further assumed that confidence is calculated based on additional evidence gathered during the post-decisional period 
(Fleming & Daw, 2017;
Herregods et al., 2023;
Miyoshi & Sakamoto, 2024;
Moran et al., 2015;
Navajas et al., 2016;
Pleskac & Busemeyer, 2010
).
The 2DSD model allowed for more flexible relationships between RT and response correctness, depending on trial-to-trial variability in drift rate and starting point 
(Figures 4 and  5)
. This flexibility enabled 2DSD to accommodate broader meta-d′RT values, including negative ones, better matching the variability observed in human data 
(Figure 1)
. In contrast, the race model's meta-d′RT remained consistently below the human average, regardless of the parameter settings 
(Figure 5a, b)
.
A key factor underlying these differences is likely the drift rate of the losing accumulator. In the 2DSD model, which tracks the difference in evidence between two accumulators, trials with relatively high drift rates in the losing accumulator lead to slower RTs and lower accuracy (as well as reduced confidence based on post-decisional evidence). This explains why RT serves as a reasonable predictor of response correctness in 2DSD. In contrast, in the race model, where two independent accumulators compete, trials with high drift rates in the losing accumulator result in shorter RTs but lower accuracy (along with reduced confidence determined by the balance of evidence). As a result, RT is a weaker predictor of response accuracy in the race model. Overall, our RT type-2 ROC analysis poses an important challenge to models assuming independent accumulator competition. Future research could benefit from exploring variations of race models in which evidence accumulation for different options is interdependent (e.g., mutually inhibitory; 
Ditterich, 2010;
Rafiei et al., 2024;
Usher & McClelland, 2001)
, as these models may better capture human RT type-2 characteristics.
It is noteworthy that the confidence-RT interaction observed in humans was replicated, particularly in 2DSD, where confidence becomes a stronger predictor of response correctness at shorter RTs 
(Figure 6)
. This observation suggests that fast RTs are associated with higher target drift rates, which, in turn, lead to more accurate metacognition in the postdecisional period (i.e., smaller overlaps in confidence between correct and incorrect responses). Moreover, as discussed earlier, 2DSD's behavior suggests the presence of explicit error detection 
(Fleming & Daw, 2017;
Rabbitt, 1966;
van den Berg et al., 2016;
Yeung & Summerfield, 2012)
 underlying the observed interaction. Specifically, incorrect responses with short RTs-arising from starting point bias-undergo post-decisional metacognitive reevaluation, which may lead to the inverted U pattern observed in the low-confidence range (see 
Figures 3 and 6)
. Notably, the confidence-RT interaction was only marginally exhibited by Vickers' race model, which calculates confidence based on the evidence difference between chosen and unchosen alternatives at the time of choice. Thus, the confidence-RT interaction may serve as a key empirical signature in future studies as well, potentially aiding in the comparison of different models.
These findings suggest that 2DSD may offer a more plausible basis for interpreting human behavior than Vickers' race model. Nonetheless, there remains room for refinement in 2DSD, as its meta-d′ improvement driven by the confidence-RT combination was smaller than that observed in humans 
(Figure 5c)
. In contrast, the race model showed a wider range of improvement values, better accommodating variability in human data. However, caution is warranted, as the race model displayed a fundamental irregularity, with confidence in correct responses remaining flat or even decreasing as the target's mean drift rate increased 
(Figure  4c)
.


RT as an implicit metacognitive measure
While the present findings emphasize the unique properties of RT in characterizing decision-making behavior, the stable correlation between RT and confidence-derived meta-d′ (disattenuated Pearson correlation of 0.776) suggests that RT could serve as an implicit measure of metacognition. Notably, the correlation coefficient is independent of the regression slope between the two variables. In other words, the correlation coefficient remains unchanged, if RT-based meta-d′ is uniformly scaled relative to confidence-based meta-d′ (e.g., by a factor of 2/3, as shown above). Therefore, while RT-based meta-d′ may not be directly comparable to confidence-based meta-d′ in absolute terms, it may still serve as a practical proxy for assessing metacognitive accuracy across individuals or experimental conditions.
Currently, our empirical findings remain correlational, and do not establish that RT directly reflects metacognitive processes. This also applies to the simulation results, in which neither tested model explicitly defines a causal relationship between RT and confidence. Instead, the 2DSD simulation suggests that RT stands in for the evidence accumulation rate and, in this indirect sense, predicts confidence levels formed during the post-decisional period. Therefore, while this study remains largely agnostic about whether RT directly reflects metacognitive processes, it highlights RT's empirical utility as a practical proxy for confidence.
Nevertheless, numerous studies have pointed to reciprocal causal links between RT and confidence. For example, the insight that RT influences confidence has long been recognized, as seen in the concept of the fluency heuristic (e.g., 
Ackerman & Zalmanov, 2012;
Kelley & Lindsay, 1993;
Thompson et al., 2013)
, and has been incorporated into evidence accumulation models in various ways 
(Hellmann et al., 2024;
Kiani et al., 2014;
Van Marcke et al., 2024)
. Conversely, confidence may also causally influence RT (e.g., 
Li et al., 2024)
. One compelling perspective is that confidence functions as a stopping signal for evidence accumulation, thereby influencing RT (e.g., 
Desender et al., 2018;
Lee et al., 2023)
. If these extended models better capture human RT type-2 characteristics than the classic models used in this study, they would offer process-level support for considering RT as an implicit indicator of metacognition.


Future Directions
One promising avenue for RT-based type-2 ROC analysis is the examination of past datasets that lack confidence ratings-including numerous studies on animals and infants. Future research could also benefit, as studies can be conducted more easily without the need to train animals to report confidence. RT-based type-2 analysis can also be utilized in animal neurophysiological studies. For example, studies have shown that chemical inactivation of the dorsal prefrontal cortex in monkeys 
(Miyamoto et al., 2017)
, as well as the pulvinar nucleus 
(Komura et al., 2013)
 and orbitofrontal cortex in rodents 
(Lak et al., 2014)
, affects subjective confidence levels or metacognitive accuracy. This raises the question of whether such inactivation similarly impairs meta-d′ derived from RT. Investigating this may further illuminate potential crosstalk between confidence and RT, revealing deeper insights into the mechanisms that shape decision-making and metacognition.
RT type-2 ROC analysis provides unique behavioral constraints that could advance models of perceptual decision-making in diverse directions. One such application is modeling the detailed temporal dynamics of confidence formation. While drift-diffusion models have largely focused on post-decisional confidence construction 
(Fleming & Daw, 2017;
Navajas et al., 2016;
Pleskac & Busemeyer, 2010)
, studies suggest that confidence begins to form before decision-making 
(Cai et al., 2022;
Shekhar & Rahnev, 2018;
Xue et al., 2023;
Zylberberg et al., 2012)
. The integration of pre-decisional confidence formation into computational models is still in its early stages 
(Miyoshi & Sakamoto, 2024)
, and RT type-2 ROC analysis could accelerate this effort. By introducing a novel approach for analyzing behavioral data, this study opens up fresh opportunities to foster research across multiple fronts. 


Grating contrast discrimination
The "Subjects" column indicates the number of individuals included in the present analysis, with the number before data exclusion shown in parentheses. Of the 588 individual samples, 11 were excluded based on original dataset instructions, and 38 were removed due to non-convergence in the meta-SDT analysis. The "Trial/Sub" column shows the number of trials per individual. For Massoni_2017, the continuous confidence range of 0.5-1 was evenly divided into three levels, while for Rayes_2015, continuous confidence ranging from 1 to 6 was rounded to the nearest integer to form six levels. The "Specification" column indicates the conditions extracted from datasets containing multiple experimental conditions, with italicized variables representing column names in the original datasets. Decision threshold for the single 2DSD accumulator with response boundaries set at ± a2DSD.


Tpd
Number of time steps used for post-decisional confidence construction in 2DSD. 
Figure A1
. Simulated type-1 ROCs from the race model and 2DSD. Type-1 ROC analysis considers the discrimination of external stimulus states (S1 and S2) by incorporating both the primary response and a secondary variable. The shape of the type-1 ROC is primarily determined by the intermediate point, which exclusively reflects the primary response (10th point from the left, as the present simulation used 10 levels of secondary variables). The contribution of the secondary variable is captured in the other points, though its effect is primarily limited to modifying the overall ROC curvature. Accordingly, the differences between the three variables are relatively minor in the type-1 ROC space. Differences between the three variables are more pronounced in type-2 than type-1 ROC space, potentially offering a nuanced characterization of the observer's behavior. Some notable differences can be seen between the models. For instance, the RT type-2 discriminability of the race model remains relatively stable across conditions, whereas that of 2DSD exhibits significant variation depending on the parameter values. 
Figure A3
. Graphical illustrations of the race model and 2DSD. (a) Vickers' race model assumes two independent accumulators. A decision is made when the evidence in either accumulator crosses the decision boundary (dashed line), with S1 chosen in this example.
Confidence in the race model is determined by the evidence difference between the two accumulators at the time of decision, indicated by the arrow. (b) The 2DSD model assumes a single accumulator that tracks the evidence difference between the two options. Confidence is computed during the post-decisional period, highlighted in grey shading. (1) the estimated values follow the order of d′, meta-d′confidence+RT, meta-d′confidence, and meta-d′RT, (2) RT carried roughly two-thirds of type-2 information compared to confidence, and (3) the confidence-RT combination yielded meta-d′ approximately 1.15 times larger than confidence alone. However, notable variability can be seen across different datasets. Although none were statistically significant, average meta-d′confidence+RT was numerically larger than average d′ in 6 out of 16 datasets. Additionally, average meta-d′RT was numerically larger than average meta-d′confidence in three datasets with one being significant (p < .05). 
Figure A5
 further highlights distinct patterns across datasets by displaying the ratios between these meta-SDT measures. 
Figure A5
. Ratio measures from meta-SDT analysis summarized for each dataset. Within each dataset, we calculated three ratio measures for individuals: m-ratioconfidence+RT, meta-d′RT/meta-d′confidence, and meta-d′confidence+RT/meta-d′confidence. Only cases where d′ and meta-d′ values ranged from 0 to 4 were included (412 out of 539 cases). The mean values of these ratio measures (circles) and their SEs (error bars) were then computed for each dataset. Triangular markers in the bottom row represent the mean values of the dataset-level means, with error bars indicating the corresponding SEs. The mean m-ratioconfidence+RT was distributed around 1 across datasets. Some datasets exhibited values well above 1, albeit with large individual differences (e.g., Massoni_unpub_2_2). The mean meta-d′RT/meta-d′confidence remained above 0.5 even in the lowest case and numerically exceeded 1 in some instances. Investigating the sources of this across-experiment variability would be an important avenue for future work. The mean meta-d′confidence+RT/meta-d′confidence ranged between 1 and 1.5, indicating that while RT provided substantial additional type-2 information beyond confidence in some experiments, its contribution was minimal in others. Understanding the factors driving these differences across datasets remains an intriguing question for future research. Only cases where the values of d′ and meta-d′ ranged from 0 to 4 were included in the analysis (412 out of 539 cases). Practically, it is not desirable that the mratio indices, standardized to primary response accuracy, still exhibited correlations with d′. The scatter plots indicate that these correlations are largely driven by data points with small d′ values, which serve as the denominator for the m-ratio indices. 
Figure A7
. Subset of empirical m-ratio measures. Only cases with d′ values of 1 or higher were included from 
Figure A6
 (275 out of 412 cases). Excluding cases with very small d' values reduced the correlations between d′ and m-ratio measures. Thus, collecting data within this performance range would reduce the bias of m-ratio in indexing metacognitive efficiency independent of primary response accuracy. 
Figure A8
. Trial-by-trial RT distributions simulated with the race model and 2DSD. In the current simulation, average response accuracy was matched across all conditions between the models. The 2DSD model reached this accuracy level with faster RTs, demonstrating more pronounced histogram peaks seen in the faster RT range. Technically, the overlap between the red and blue distributions represents the type-2 diagnostic power of RT. Sequentially setting cutoffs from the faster end of the RT histograms produces RT type-2 ROCs in 
Figure A2
.
Figure 1 .
1
Meta-SDT analyses on empirical datasets. Diagonal panels display density plots of estimated performance indices across individuals (N = 539), with dashed lines and corresponding annotations indicating the mean values.


Figure 4 .
4
Simulated model behavior. (a) Target and distractor choice proportions. Average response accuracy across conditions was controlled to be matched between the models. (b) Mean RTs for target and distractor choices.


Figure 5 .
5
Meta-SDT analyses on simulated model behavior. (a) Meta-d′ estimates based on three different variables, with dashed lines representing d′ estimates (orange data points are enlarged for better visibility). (b) Estimated m-ratio values.


Figure 6 .
6
Relationship between confidence, RT, and response accuracy for each model. Response accuracy was smoothed over RT bins (smaller values indicate faster responses) separately for different confidence bins (larger values represent higher confidence). Overall, 2DSD more closely mirrors human data in


Figure A2 .
A2
Simulated type-2 ROCs from the race model and 2DSD. Type-2 ROC visualizes the trend of a secondary variable discriminating the correctness of the primary response.


Figure A4 .
A4
Summary of meta-SDT measures for each dataset. Within each dataset, we computed the average meta-SDT indices across individuals (circles) along with their SEs (error bars). Triangular markers in the bottom row represent the mean values of the dataset-level means, with error bars indicating the corresponding SEs. The average results across datasets are consistent with the aggregate analysis across all individuals (Figure 1):


Figure
A6. M-ratio measures estimated from empirical 2AFC datasets. The diagonal panelsshow density plots of the estimated m-ratio values across individuals, with dashed lines and annotations indicating the mean values. The panels below the diagonal present correlation plots between different indices, while those above the diagonal display Pearson's correlation coefficients (all p-values < .001).


Table A1 .
A1
Dataset information
Dataset
Subjects
Trial/Su
Confidence scale
Task
Specification
b
Hainguerlot_2018
52 (65)
512
6
Dot number
discrimination
Hainguerlot_unpub
52 (69)
512
6
Dot number
discrimination
Maniscalco_2017_expt1
26 (30)
1000
4
Grating
detection
Maniscalco_2017_expt2_1 40 (41)
170
4
Grating
ContrastLevel = 1
detection
Maniscalco_2017_expt2_2 40 (41)
170
4
Grating
ContrastLevel = 2
detection
Maniscalco_2017_expt2_3 41 (41)
170
4
Grating
ContrastLevel = 3
detection
Maniscalco_2017_expt3
20 (21)
1000
4
Grating
detection
Maniscalco_2017_expt4
26 (33)
1000
4
Grating
detection
Massoni_2017_1
31 (31)
50
Continuous (0.5-1.0),
Dot number
Difficulty = 1
made into 3 levels
discrimination
Massoni_2017_2
53 (54)
50
Continuous (0.5-1.0),
Dot number
Difficulty = 2
made into 3 levels
discrimination
Massoni_2017_3
35 (35)
50
Continuous (0.5-1.0),
Dot number
Difficulty = 3
made into 3 levels
discrimination
Massoni_unpub_1_1
23 (23)
100
6
Dot number
Study = 1,
discrimination
Difficulty = 1
Massoni_unpub_1_2
23 (23)
100
6
Dot number
Study = 1,
discrimination
Difficulty = 2
Massoni_unpub_2_1
27 (27)
100
6
Dot number
Study = 2,
discrimination
Difficulty = 1
Massoni_unpub_2_2
27 (27)
100
6
Dot number
Study = 2,
discrimination
Difficulty = 2
Reyes_2015
23 (27)
320
Continuous (1-6),
made into 6 levels


Table A2 .
A2
Model parameters νdistracto
Mean drift rate for the distractor stimulus across trials.
0.001
r
νtarget
Mean drift rate for the target stimulus across trials.
0.0015,
0.0025, 0.0035
η
Standard deviation of across-trial Gaussian drift rate variability,
0.0005, 0.005
applied to both target and distractor stimuli.
s
Standard deviation of within-trial Gaussian noise added at each
0.03
time step, applied to both target and distractor stimuli.
sz
Width of the zero-centered uniform distribution representing
0.2, 1.2
variability in the evidence accumulation starting point for both
target and distractor stimuli, with the range of ± sz/2.
Ter
Non-decision time, capturing the time required for initial
300
stimulus encoding and motor response execution.
arace
Decision threshold for the race model accumulators.
2
a2DSD


An alternative approach for ROC construction involves manipulating the payoff of correct versus incorrect responses, or the baserate of stimulus presentation, to obtain primary response rates under different response criteria (e.g.,
Macmillan & Creelman, 2005)
. These methods fall outside the scope of the current paper, which focuses on the relationship between primary responses and secondary variables.


In the race model, the confidence variable (balance of evidence) is determined solely by the loser accumulator evidence with the winner evidence fixed at the boundary. The variance of the loser evidence increases with prolonged RT, while its maximum value is capped at the decision boundary. Here, a higher target drift rate leads to faster RT, which reduces the random chance of the loser evidence drifting far into negative values, resulting in lower confidence.








Appendix
 










The persistence of the fluency-confidence association in problem solving




R
Ackerman






H
Zalmanov




10.3758/s13423-012-0305-z








Psychonomic Bulletin & Review




19


6
















Sensory noise increases metacognitive efficiency




J
W
Bang






M
Shekhar






D
Rahnev








Journal of Experimental Psychology: General




148


3


















10.1037/xge0000511














The physics of optimal decision making: A formal analysis of models of performance in two-alternative forcedchoice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700








Psychological Review




113


4
















The analysis of visual motion: A comparison of neuronal and psychophysical performance




K
H
Britten






M
N
Shadlen






W
T
Newsome






J
A
Movshon




10.1523/JNEUROSCI.12-12-04745.1992








The Journal of Neuroscience




12


12
















Time-sensitive prefrontal involvement in associating confidence with task performance illustrates metacognitive introspection in monkeys




Y
Cai






Z
Jin






C
Zhai






H
Wang






J
Wang






Y
Tang






S
C
Kwok




10.1038/s42003-022-03762-6








Communications Biology




5


1


799














Two types of ROC curves and definitions of parameters




F
R
Clarke






T
G
Birdsall






W
P
Tanner




10.1121/1.1907764








The Journal of the Acoustical Society of America




31


5
















Subjective Confidence Predicts Information Seeking in Decision Making




K
Desender






A
Boldt






N
Yeung








Psychological Science




29


5


















10.1177/0956797617744771














A comparison between mechanisms of multi-alternative perceptual decision making: Ability to explain human behavior, predictions for neurophysiology, and relationship with decision theory




J
Ditterich




10.3389/fnins.2010.00184








Frontiers in Neuroscience
















The reliability of a two-item scale




R
Eisinga






M
Te Grotenhuis






B
Pelzer




10.1007/s00038-012-0416-3








International Journal of Public Health




58


4
















Self-evaluation of decision-making: A general Bayesian framework for metacognitive computation




S
M
Fleming






N
D
Daw




10.1037/rev0000045








Psychological Review




124


1
















How to measure metacognition




S
M
Fleming






H
C
Lau




10.3389/fnhum.2014.00443








Frontiers in Human Neuroscience




8


443














Similarities and differences in the effects of different stimulus manipulations on accuracy and confidence




H
Fung






M
Shekhar






K
Xue






M
Rausch






D
Rahnev




10.17605/OSF.IO/9MXF4


















Type 2 tasks in the theory of signal detectability: Discrimination between correct and incorrect decisions




S
J
Galvin






J
V
Podd






V
Drga






J
Whitmore




10.3758/BF03196546








Psychonomic Bulletin & Review




10


4
















Behavioral and neural indices of metacognitive sensitivity in preverbal infants




L
Goupil






S
Kouider








Current Biology




26


22


















10.1016/j.cub.2016.09.004














Measuring metacognitive performance: type 1 performance dependence and test-retest reliability




D
M
Green






J
A
Swets




10.1093/nc/niab040








Neuroscience of Consciousness




1


2021




John Wiley. Guggenmos, M






Signal detection theory and psychophysics








Simultaneous modeling of choice, confidence, and response time in visual perception




S
Hellmann






M
Zehetleitner






M
Rausch




10.1037/rev0000411








Psychological Review




130


6
















Confidence is influenced by evidence accumulation time in dynamical decision models




S
Hellmann






M
Zehetleitner






M
Rausch




10.1007/s42113-024-00205-9








Computational Brain & Behavior




7


3
















Modelling speed-accuracy tradeoffs in the stopping rule for confidence judgments




S
Herregods






P
Le Denmat






K
Desender




10.1101/2023.02.27.530208


















Remembering mistaken for knowing: Ease of retrieval as a basis for confidence in answers to general knowledge questions




C
M
Kelley






D
S
Lindsay




10.1006/jmla.1993.1001








Journal of Memory and Language




32


1
















Choice certainty is informed by both evidence and decision time




R
Kiani






L
Corthell






M
N
Shadlen




10.1016/j.neuron.2014.12.015








Neuron




84


6
















Responses of pulvinar neurons reflect a subject's confidence in visual categorization




Y
Komura






A
Nikkuni






N
Hirashima






T
Uetake






A
Miyamoto




10.1038/nn.3393








Nature Neuroscience




16


6
















Orbitofrontal cortex is required for optimal waiting based on decision confidence




A
Lak






G
M
Costa






E
Romberg






A
A
Koulakov






Z
F
Mainen






A
Kepecs




10.1016/j.neuron.2014.08.039








Neuron




84


1
















Information theory of choice-reaction times




D
R J
Laming








Academic Press












Evidence or confidence: What is really monitored during a decision?




D
G
Lee






J
Daunizeau






G
Pezzulo




10.3758/s13423-023-02255-9








Psychonomic Bulletin & Review




30


4
















Confidence ratings increase response thresholds in decision making




B
Li






X
Hu






D
R
Shanks






N
Su






W
Zhao






L
Meng






W
Lei






L
Luo






C
Yang




10.3758/s13423-023-02380-5








Psychonomic Bulletin & Review




31


3
















Detection theory: A user's guide




N
A
Macmillan






C
D
Creelman








Lawrence Erlbaum Associates Publishers






2nd ed.








A signal detection theoretic approach for estimating metacognitive sensitivity from confidence ratings




B
Maniscalco






H
Lau




10.1016/j.concog.2011.09.021








Consciousness and Cognition




21


1
















Causal neural network of metamemory for retrospection in primates




K
Miyamoto






T
Osada






R
Setsuie






M
Takeda






K
Tamura






Y
Adachi






Y
Miyashita




10.1126/science.aal0162








Science




355


6321
















Generalized Gaussian signal detection theory: A unified signal detection framework for confidence data analysis




K
Miyoshi






S
Nishida




10.1037/met0000654


















Pseudo-optimal evidence accumulation as a foundation for multi-choice irrationalities




K
Miyoshi






Y
Sakamoto




10.31234/osf.io/bc2zq




















K
Miyoshi






T
Webb






D
Rahnev






H
Lau




10.1016/b978-0-12-820480-1.00049-8




Confidence and metacognition. Encyclopaedia of the Human Brain




Elsevier








2nd edition








Post choice information integration as a causal determinant of confidence: Novel data and a computational account




R
Moran






A
R
Teodorescu






M
Usher




10.1016/j.cogpsych.2015.01.002








Cognitive Psychology




78
















Post-decisional accounts of biases in confidence




J
Navajas






B
Bahrami






P
E
Latham








Current Opinion in Behavioral Sciences




11


















10.1016/j.cobeha.2016.05.005














Superior colliculus neuronal ensemble activity signals optimal rather than subjective confidence




B
Odegaard






P
Grimaldi






S
H
Cho






M
A K
Peters






H
Lau






M
A
Basso




10.1073/pnas.1711628115








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






115














Perceptual confidence neglects decision-incongruent evidence in the brain




M
A K
Peters






T
Thesen






Y
D
Ko






B
Maniscalco






C
Carlson






M
Davidson






W
Doyle






R
Kuzniecky






O
Devinsky






E
Halgren






H
Lau




10.1038/s41562-017-0139








Nature Human Behaviour




1














Two-stage dynamic signal detection: A theory of choice, decision time, and confidence




T
J
Pleskac






J
R
Busemeyer




https://psycnet.apa.org/doi/10.1037/a0019737








Psychological Review




117


3
















Error correction time without external error signals




P
M A
Rabbitt




10.1038/212438a0








Nature




212


5060


438














The neural network RTNet exhibits the signatures of human perceptual decision-making




F
Rafiei






M
Shekhar






D
Rahnev




10.1038/s41562-024-01914-8








Nature Human Behaviour




8


9
















A comprehensive assessment of current methods for measuring metacognition




D
Rahnev




10.1038/s41467-025-56117-0








Nature Communications




16


701














The confidence database




D
Rahnev






K
Desender






A
L F
Lee






W
T
Adler






D
Aguilar-Lleyda






B
Akdoğan






A
Zylberberg




10.1038/s41562-019-0813-1








Nature Human Behaviour




4
















How experimental procedures influence estimates of metacognitive ability




D
Rahnev






S
M
Fleming




https://psycnet.apa.org/doi/10.1093/nc/niz009








Neuroscience of Consciousness




2019


1














A theory of memory retrieval




R
Ratcliff




10.1037/0033-295X.85.2.59








Psychological Review




85


2
















The diffusion decision model: Theory and data for two-choice decision tasks




R
Ratcliff






G
Mckoon








Neural Computation




20


4


















10.1162/neco.2008.12-06-420














Modeling confidence and response time in recognition memory




R
Ratcliff






J
J
Starns




10.1037/a0014086








Psychological Review




116
















The folded X-pattern is not necessarily a statistical signature of decision confidence




M
Rausch






M
Zehetleitner




10.1371/journal.pcbi.1007456








PLOS Computational Biology




15


10














Signatures of a statistical computation in the human sense of confidence




J
I
Sanders






B
Hangya






A
Kepecs








Neuron




90


















10.1016/j.neuron.2016.03.025














Distinguishing the roles of dorsolateral and anterior PFC in visual metacognition




M
Shekhar






D
Rahnev




10.1523/JNEUROSCI.3484-17.2018








The Journal of Neuroscience




38


22
















How do humans give confidence? A comprehensive comparison of process models of perceptual metacognition




M
Shekhar






D
Rahnev




10.1037/xge0001524








Journal of Experimental Psychology: General




153


3
















The role of answer fluency and perceptual fluency as metacognitive cues for initiating analytic thinking




V
A
Thompson






J
A P
Turner






G
Pennycook






L
J
Ball






H
Brack






Y
Ophir






R
Ackerman








Cognition




128


2


















10.1016/j.cognition.2012.09.012














The time course of perceptual choice: The leaky, competing accumulator model




M
Usher






J
L
Mcclelland








Psychological Review




108


3


















10.1037/0033-295X.108.3.550














A common mechanism underlies changes of mind about decisions and confidence. eLife, 5, e12192




R
Van Den Berg






K
Anandalingam






A
Zylberberg






R
Kiani






M
N
Shadlen






D
M
Wolpert




10.7554/eLife.12192


















Manipulating prior beliefs causally induces under-and overconfdence




H
Van Marcke






P
L
Denmat






T
Verguts






K
Desender




10.1177/09567976241231572








Psychological Science




35


4
















Decision processes in visual perception




D
Vickers








Academic Press












The relation of time of judgment to certainty of judgment




J
Volkmann








Psychological Bulletin




31
















Young children's subjective and objective thresholds and emergent processes of visual consciousness using a backward masking task




R
Watanabe






Y
Moriguchi




10.1016/j.concog.2023.103605








Consciousness and Cognition. 116, 103605
















Assessing recognition memory using confidence ratings and response times




C
T
Weidemann






M
J
Kahana




10.1098/rsos.150670








Royal Society Open Science




3














Dual-process theory and signal-detection theory of recognition memory




J
T
Wixted




10.1037/0033-295X.114.1.152








Psychological Review




114


1
















Examining the robustness of the relationship between metacognitive efficiency and metacognitive bias




K
Xue






M
Shekhar






D
Rahnev




10.1016/j.concog.2021.103196








Consciousness and Cognition




95


103196














The timing of confidence computations in human prefrontal cortex




K
Xue






Y
Zheng






F
Rafiei






D
Rahnev








Cortex




168


















10.1016/j.cortex.2023.08.009














Metacognition in human decisionmaking: Confidence and error monitoring




N
Yeung






C
Summerfield




10.1098/rstb.2011.0416








Philosophical Transactions of the Royal Society of London Series B, Biological Sciences




367
















The construction of confidence in a perceptual decision




A
Zylberberg






P
Barttfeld






M
Sigman




10.3389/fnint.2012.00079








Frontiers in Integrative Neuroscience

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]