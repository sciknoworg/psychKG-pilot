You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction


Stimulus Exposure Facilitates Perceived Animacy
Animacy perception, which distinguishes animate from inanimate visual stimuli 
(Rutherford & Kuhlmeier, 2013)
, is a necessary component of social interaction. Evidence shows that such perceptions emerge even in infancy 
(Gergely et al., 1995;
Leslie, 1982;
Rochatet al., 1997)
 but are disrupted by developmental disorders 
(Rutherford et al., 2006)
 and amygdala damage 
(Heberlein & Adolphs, 2004)
.
Previous research on factors driving the perception of animacy mainly focused on the properties of target stimuli, such as human-like appearances (e.g., a face) and motion (e.g., interactive motion between two geometric shapes). For instance, people consider an object comparatively more animate when the object has unique human features such as eyes and mouth; 
Looser & Wheatley, 2010)
, intelligence 
(Bartneck et al., 2009)
, and facial expressions of happiness 
(Bowling & Banissy, 2017;
Krumhuber et al., 2019;
Saito et al., 2022)
. Furthermore, individuals consider moving objects more animate when the motion seems to have specific goals, such as chasing and helping 
(Rochat et al., 1997;
Castelli et al., 2009;
Heider & Simmel, 1944;
Kuhlmeier et al., 2003;
Scholl & Tremoulet, 2000;
Tremoulet & Feldman, 2000)
.
Although most previous research has shown that factors in a target (e.g., human-like features of targets) play crucial roles in animacy perception, these factors do not necessarily facilitate it. According to the uncanny valley theory 
(Mori et al., 2012)
, inanimate objects (e.g., robots) resemblance to humans increases the perception of animacy. However, when the resemblance reaches a certain point, it provokes uncanny or strange feelings and hinders the perception. The uncanny valley theory suggests the importance of focusing not only on factors in a target but also on factors in a perceiver. However, minimal extant literature focuses on the factors (e.g., knowledge and mental state of participants) in animacy perception. For example, beliefs about the origin of moving objects (i.e., humans or robots; 
Cross et al., 2016)
 and the state of participants (i.e., loneliness) affect animacy perception 
(Powers et al., 2014)
. Thus, it is also essential to focus on factors affecting animacy perception in perceivers.
Notably, attention, which can be counted as a factor in perceivers, has a critical relationship with animacy perception and might be a causal effect in animacy perception. Previous studies show that animate objects capture attention 
(Calvillo & Jackson, 2014;
Jackson & Calvillo, 2013;
Pratt et al., 2010;
Yang et al., 2012)
. For example, when individuals are tasked with finding a category exemplar and are unexpectedly exposed to either an animate or inanimate object, they are more likely to notice the animate object 
(Calvillo & Jackson, 2014)
. Thus, the authors concluded that these findings reflect that detecting animate objects is vital in ancestral hunter-gatherer environments and is consistent with the animate-monitoring hypothesis 
(New et al., 2007)
. As mentioned above, animate objects attract attention. However, is there also a reversal relationship between them? Specifically, does attracting attention lead to animacy perception? This prediction could be the case considering recent research on judgment and decision-making.
The growing body of research on judgment, decision-making, and neuroeconomics highlights the crucial role of visual attention in decision-making 
(Armel et al., 2008;
Cavanagh et al., 2014;
Glöckner & Herbold, 2011;
Krajbich et al., 2010;
Krajbich et al., 2012;
Krajbich & Rangel, 2011;
Orquin & Loose, 2013;
Thomas et al., 2019)
. In particular, the attentional drift-diffusion model (aDDM), proposed by Krajbich and his peers, incorporates the role of visual attention in traditional decision-making models (i.e., the drift-diffusion model; 
Krajbich et al., 2010;
Krajbich et al., 2012;
Krajbich & Rangel, 2011;
Krajbich, 2019)
. The aDDM is a decision-making model assuming that the evidence of an item for reaching a decision is amplified when the item receives more attention. Notably, assuming that visual attention modulates the accumulation of evidence to reach a threshold to decide, decision times and choices can accurately be predicted 
(Krajbich et al., 2010)
. Previous neural studies present supportive evidence that there was neural activity related to fixation-dependent value coding but did not examine the validity of aDDM 
(Lim et al., 2011;
McGinty et al., 2016)
. Furthermore, numerous behavioral studies have shown that a longer gaze duration toward one option results in a higher choice probability for that option 
(Armel et al., 2008;
Krajbich et al., 2010;
Krajbich et al., 2012;
Thomas et al., 2019;
Motoki et al., 2021;
Saito et al., 2017;
Saito et al., 2020;
Shimojo et al., 2003)
. Moreover, behavioral studies indicate the causal role of attention in decisionmaking by manipulating the gaze toward options and that the probabilities of choices have changed 
(Armel et al., 2008;
Shimojo et al., 2003;
Pärnamets et al., 2015)
. As mentioned above, visual attention plays a crucial role in decision-making. By employing this perspective, we sought to specify factors in a perceiver affecting animacy perception in the current study.
Gaze manipulation does not always bias decision-making 
(Shimojo et al. 2003)
. Though, it is reported that there is a consistent effect on simple perceptual choice (Tavares et al., 2017). According to 
Shimojo et al. (2003)
, gaze manipulation can influence subjective (e.g., preference) rather than objective judgments. In other words, gaze manipulation is likely to influence higher-level cognition (e.g., preference) rather than low-level perception (e.g., morphological perception). Given that preference for targets contributes to an uncanny valley feeling 
(Wang & Rochat, 2017)
, animacy perception may be influenced by gaze manipulation through a preference for targets. This study directly tests this hypothesis where gaze manipulation influences the animacy perception.
Exposure duration (i.e., mere exposure effect 
(Zajonc, 1968)
) and gaze shifting (i.e., gaze orienting) may be potential mechanisms influencing the role of visual attention in animacy perception. The account of exposure duration is based on the mere exposure effect 
(Zajonc, 1968)
. Specifically, the more people look at a stimulus, the more they like it. It has also been assumed that gaze orienting is a precursor to higher-level cognition (e.g., preferences; 
Shimojo et al., 2003;
Simion & Shimojo, 2006;
Simion & Shimojo. 2007)
. More prolonged exposure durations with orientation (i.e., gaze shifting) can induce a preference shift. In contrast, longer exposure durations without orientation do not result in a preference shift 
(Shimojo et al., 2003)
. We further elucidated the potential underlying mechanisms by manipulating exposure duration and gaze orientation.
This study examines whether stimuli exposure time influences the perception of animacy. In particular, we investigated whether the manipulation influenced high-level perceptions, animacy perception (Study 1a), and preference (Study 1b). Additionally, we examined the effect on roundness judgment (Study 1c), which we considered low-level perception. We expected high-level cognition (i.e., animacy and preference), rather than low-level perception, would be biased by gaze manipulation. Furthermore, Study 2 examined the underlying mechanisms by separating the factors of gaze manipulation into exposure duration and arbitrary eye movements. As we mentioned above, it is reported that arbitrary eye movement is necessary for biasing high-level cognition 
(Shimojo et al., 2003)
. However, contradicting findings reported that extended exposure duration, regardless of gaze orientation, biased decision-making (e.g., 
Bird et al., 2012;
Nittono & Wada, 2009)
. Thus, we examined which factor of gaze manipulation, exposure duration, or arbitrary eye movements influence animacy perception in Study 2.


Study 1a to 1c
Stimulus Exposure Facilitates Perceived Animacy Study 1a examined the effects of gaze manipulation on animacy perception. The participants viewed two facial images with artificial features and then chose the image perceived as more animate. While viewing the images, participants' eye movements were manipulated using the paradigm of a previous study 
(Shimojo et al., 2003)
. Study 1b was designed to replicate the effect of gaze manipulation on preference judgment 
(Shimojo et al., 2003)
 in the current experimental procedure. The procedure was similar, except that it made participants choose their preferred facial images. Study 1c was designed to confirm the specificity of gaze manipulation for both preference and animacy perception. The procedure was almost the same, except that it required participants to choose a rounder facial image.


Methods


Participants
To the best of our knowledge, because no prior study has examined the effect of exposure time on animacy perception, we did not formally calculate the sample size for Studies 1a to 1c. We recruited university students who participated in each study during the 1st wave of the recruitment period. Finally, 43 participants for Study 1a (11 women, 32 men; mean age, 20.78; SD of age, 1.38), 61 participants for Study 1b (20 women, 41 men; mean age, 21.13; SD of age, 2.75), and 29 participants for Study 1c (12 women, 17 men; mean age, 21.41; SD of age, 1.37) were selected. We considered those sample sizes (i.e., 29-61) almost sufficient to detect the effect given previous studies' sample sizes ranged from 10 to 100 
(Armel et al., 2008;
Shimojo et al., 2003)
. The participants were all university students recruited via a university bulletin board and mailing list. After completing the study, participants received a small monetary compensation for their participation. This study was approved by the ethics committees of Tohoku University (Number: UMIN000025712) and Waseda University (Number 2019-357(1)) and conducted per the Declaration of Helsinki. For each study, the participants gave their free and informed consent.


Stimuli
In this study, we used 40 pairs of facial images (20 female and 20 male face pairs). To create these images, we selected 45 Asian faces (male and female faces) from the Chicago Face Database 
(Ma et al., 2015)
. All facial images displayed no emotional expression (i.e., neutral expression). The images depicted real human faces and might cause a ceiling effect on animacy perception that prevented the effects of gaze manipulation. Therefore, we modified these images to add artificial features using non-photorealistic rendering methods 
(Rosin & Lai, 2015)
. This method produces realistic cartoons from real images of the same identity 
(Figure 1
). The images were resized to a uniform width of 450 pixels and height of 600 pixels.
[Insert 
Figure 1
 


here]
We further conducted an online pre-experiment to manipulate the attractiveness of the images using Qualtrics. We recruited 40 participants via Lancers (https://www.lancers.jp) and asked them to rate the attractiveness of the images on a 7-point Likert scale (1 = very unattractive to 7 = very attractive). Based on these ratings, we created 40 pairs of facial images. Stimulus codes for the exact stimuli employed are available in the online supplemental material (https://osf.io/cr4yx/?view_only=633225a44c9f455993688e2c96ea382c). The average ratings of the faces in a pair were matched such that the difference in the average rating in each pair was < 0.10 points. The average rating for all faces was 3.12 (SD = 0.49). The faces in a pair were also matched in terms of sex. There was an equal number of face pairs in each sex (20 male and 20 female face pairs).


Procedure
We used similar experimental procedures and conducted the experiments almost concurrently. Based on a previous study 
(Shimojo et al., 2003)
, we manipulated stimuli exposure time to participants while perceiving a pair of faces 
(Figure 2A
).
[Insert 
Figure 2
 here] Participants completed the experiment individually on a computer (display resolution 14-inch, 1920 x 1080). The distance between the participant's eyes and the display was approximately 60 cm. After showing the fixation cross for 500 ms, we presented each face six times to the participants. Faces alternated between the left and right halves of the screen. Therefore, participants had to shift their gaze toward the visible face on the screen. The presentation duration for each face in a pair was different, 900 ms for one face and 300 ms for another face. At one trial, one face was shown for 5400 ms (900 ms × 6 times) and another for 1800 ms (300 ms × 6 times). These durations were identical to those of the previous study 
(Shimojo et al., 2003)
. Faces that were shown longer than other faces were counterbalanced across the participants. After viewing a pair of faces, participants chose a face in which they perceived animacy more (Study 1a), preferred more (Study 1b), or perceived rounder (Study 1c) by pressing the corresponding keys. For instance, the "f" key for the left-sided face and the "j" key for the right-sided face. The reaction time was not constrained, and the order of face pair presentation was randomized across trials. The total number of trials was set to 40. Before the experiment, we explained the procedure to participants and confirmed their understanding of the instruction by asking them.


Statistical analysis
Through Studies 1a to 1c, we used mixed logistic models to predict the choice of the target presented on the left side (1: left-sided target, 0: right-sided target), with the left-sided target shown for a long or short duration (1: shown longer, 0: shown shorter) as a fixed effect, and participants and pairs of stimuli included as a random slope and a random intercept. All analyses were conducted using the lme4 package 
(Bates et al., 2014)
 in the R software (R Core Team, 2021). Regarding the analysis in Study 1c, we excluded 12 trials in which the stimuli were not presented for the intended duration owing to technical issues. In conclusion, we analyzed the data of 28 trials from each participant in Study 1c. The data analyzed in this study were made available at the Open Science Framework (https://osf.io/cr4yx/).


Results


Study 1a (Animacy judgment)
The results of the analysis showed that participants tended to choose longer-shown faces as more animated faces in Study 1a (53.89%, 95% CI [51.89-55.89]; b = 0.34, z = 3.19, p < .001). This result suggests that gaze bias influenced both preferences and perceptions of animacy. The likelihoods of longer-shown stimuli chosen through Studies 1a to 1c are visualized in 
Figure 3
. The results of the analysis revealed that participants preferred the faces that were shown longer (57.03%, 95% CI [54.65-59.39]; b = 0.53, z = 4.21, p < .001). This indicates that we successfully replicated the effect of eye movement on preference judgment 
(Krajbich et al., 2010;
Saito et al., 2017;
Shimojo et al., 2003)
.


Study 1c (Roundness Judgment)
The results of the analysis indicated that participants did not tend to choose longer-shown faces as rounder faces in Study 1c 
(49.88%,
; b = -0.02, z = -0.08, p = .98). This result suggests that gaze bias specifically influenced both preferences and animacy perception rather than morphological perception (i.e., roundness judgment).


Discussion
Through Studies 1a to 1c, we observed that gaze manipulation influences animacy and preference judgments, not roundness judgments. These findings suggest the specificity of the effect of gaze manipulation on animacy and preference perceptions and that these perceptions might be affected by gaze manipulation through the exact mechanism. However, regarding the mechanism, it is unclear what aspect of gaze manipulation we used affected the perceptions because we manipulated the presentation duration (i.e., mere exposure) and arbitrary eye movements (i.e., orienting behavior). Furthermore, we did not directly compare the effects of gaze manipulation on animacy and roundness judgment. Therefore, Study 2 was designed to address these questions.


Study 2
In Study 2, we sought to solve the issues mentioned above by directly comparing the effects of (1) present duration (i.e., mere exposure) and arbitrary eye movements (i.e., orienting behavior) and (2) animacy and roundness judgment. To specify the factors of gaze manipulation on animacy perception, we used a paradigm in which participants' eye movements were fixed 
(Shimojo et al., 2003)
.


Method


Experimental Design
This study included two independent variables: the type of judgment (two levels: animacy and roundness) and gaze manipulation (two levels: arbitrary eye movement and fixed eye movement). These variables were between-participant factors. The dependent variable was the choice of stimulus.


Participants and Stimuli
We conducted a simulation-based power analysis using the SIMR package 
(Green & MacLeod, 2016)
 in R and the data from Study 1a to estimate the ideal sample size. This analysis determined the expected power to secure the fixed effect of gaze manipulation for various sample sizes. The results indicated the need for a sample size of 169 to achieve over 80% at an alpha level of 0.05. Considering that the average dropout rate of a typical web experiment is approximately 30% 
(Musch & Reips, 2000;
Zhou & Fishbach, 2016)
, we determined the sample size to be 220 participants (55 participants for each condition). We recruited participants using Lancers (https://www.lancers.jp), a crowdsourcing website in Japan. A total of participants were recruited for the study. After excluding participants who failed the attention check, data from 205 participants (63 women, 136 men, 6 preferred not to disclose; mean age, 41.98; SD of age, 8.66) were analyzed. The participants received a small monetary compensation for their participation. This study was approved by AsPredicted.org (https://aspredicted.org/492_915). Further, we used the same stimuli as in Studies 1a to 1c.


Procedure
The procedure was almost identical to those of the previous studies, except as noted in the following text. We conducted the study online through Qualtrics (https://www.qualtrics.com/jp/) because it was challenging to experiment in person due to the coronavirus disease 2019 pandemic at that time 
(October 18-25, 2021)
. At the beginning of each study, participants answered a question designed to check whether they read instructions as an attention check 
(Oppenheimer et al., 2009)
. In particular, participants had to ignore the standard response format and instead provide a confirmation that they had read the instruction in the question. Then, participants were randomly assigned to one of four conditions (two types of judgment: animacy, roundness × 2, gaze manipulation: arbitrary eye movement, and fixed eye movement). In Study 2, we established a fixed eye movement condition, where the stimuli face alternated at the center of the screen ( 
Figure 2B)
. Thus, the participants did not have to shift their gaze toward the visible face on the screen. After viewing each pair of faces, participants chose the face they perceived as having more animacy (animacy condition) or rounder (roundness condition) by pressing the corresponding keys. For instance, the "f" key for the face presented at last and the "j" key for the face presented before the last. In conclusion, 104 participants were assigned to the animacy judgment condition (53 in arbitrary eye movement, 51 in fixed eye movement), and 101 participants were further assigned to the roundness judgment condition (52 participants in arbitrary eye movement, 49 participants in fixed eye movement).


Statistical analysis
Study 2 used the preregistered analysis, which was a linear mixed model predicting the choice of one target (arbitrary eye movement condition: 1 = left-sided target, 0 = right-sided target; fixed condition: 1 = the last-presented target, 0 = before the last-presented target), with the target was shown for a long or short duration (presentation duration: 1 = shown longer, 0 = shown shorter), gaze manipulation (1 = arbitrary eye movement, 0 = fixed eye movement), types of judgment (1 = animacy, 0 = morphological perception). Further, the interactions were included as fixed effects, and participants and pairs of stimuli were included as random effects. We used the performance package 
(Lüdecke et al., 2021)
 in the R software to investigate the variance inflation factors (VIFs) and overdispersion.
In addition to the preregistered analysis, we conducted similar analyses to the previous three studies as exploratory analyses for analytical consistency across studies. For each condition, we conducted an analysis that was a mixed logistic model predicting the choice of one target (arbitrary eye movement condition: 1 = left-sided target, 0 = right-sided target; fixed condition: 1 = the lastpresented target, 0 = before the last presented target), with the target shown for a long or short duration (1 = shown longer, 0 = shown shorter), as a fixed effect. Further, participants and pairs of stimuli were included as a random slope and random intercept, respectively. 
Figure 4
 shows the likelihood of choosing longer-shown faces. Regarding the preregistered analysis, we confirmed that multicollinearity was not a problem by inspecting the VIFs (VIFs < 3.91). Further, overdispersion was not a problem in the overdispersion test (χ 2 = 7157.48, p = 1.00). The result from the preregistered analysis showed neither significant effects of presentation duration, gaze manipulation, and types of judgment nor those interactions 
(Table 2
).


Results


Stimulus Exposure Facilitates Perceived Animacy
[Insert 
Figure 4
 here] [Insert 
Table 2 here]
 Although we did not observe any significant results from the registered analysis, we conducted a mixed logistic model to predict the choice of one target for each condition, as in previous studies 
(Table 3
).
[Insert 
Table 3
 here]
In the arbitrary eye movement condition, we observed that participants tended to choose longer-shown faces when choosing more animate faces (54.86%, 95% CI [52.71-56.99]; b = 0.42, z = 2.77, p = .01) than when choosing rounder faces (50.48%, 95% CI [48.31-52.65]; b = 0.05, z = 1.14, p = .26). In the fixed eye movement condition, we also observed that participants tended to choose longer-shown faces when choosing more animate faces (53.43%, 95% CI [51.24-55.61]; b = 0.29, z = 2.28, p = .02) than when choosing rounder faces (50.71%, 95% CI [48.48-52.95]; b = 0.23, z = 0.61, p = .54).


Discussion
In Study 2, the preregistered analysis showed neither significant effects nor interactions between the experimental conditions. Therefore, we failed to elucidate the factors of gaze manipulation (i.e., mere exposure and orienting behavior) that influence animacy perception. However, subsequent exploratory analyses were consistent with Studies 1a to 1c, showing that gaze manipulation in arbitrary and fixed eye movement conditions influenced only animacy perception rather than the perception of roundness. These results suggest that mere exposure may be critical in facilitating animacy perception.


General discussions
Factors in a perceiver have not received sufficient attention regarding the factors that drive animacy perception. We tested whether one of the primary factors, visual attention toward stimuli, affects animacy perception. Across Studies one and two, the participants felt that cartoon faces were more animated when manipulating their gaze to look at the faces longer. This effect of biased exposure duration was also observed in preference judgments (Study 1b) rather than in lower-level perception (i.e., roundness judgments, Studies 1c and 2). Furthermore, in the preregistered online study (Study 2), it was found that arbitrary eye movements were not necessarily needed to increase animacy perception. However, exposure duration played a crucial role in influencing it.
Our results provide evidence that gazing behavior influences the perception of animacy. In this study, manipulating the exposure duration in arbitrary and fixed eye movement conditions facilitated animacy perception. This finding is inconsistent with the claim that gaze orienting is necessary to bias higher-level cognition, such as preference judgment 
(Shimojo et al., 2003)
. Instead, this finding is consistent with studies that show that gaze orienting is not a necessary condition for Visual Attention Facilitates Perceived Animacy forming higher-level cognition but instead demonstrates that a mere exposure effect underlies biased higher-level cognition by gaze manipulation 
(Bird, Lauwereyns, & Crawford, 2012;
Glaholt & Reingold 2009;
Glaholt & Reingold. 2011;
Nittono, & Wada, 2009)
.
There are several potential explanations for why the mere exposure effect derives animacy perceptions. First, along with aDDM 
(Krajbich et al., 2010)
, attention would have facilitated evidence of animacy and preference. Second, mere exposure may have changed several psychological constructs, as mere exposure increases familiarity and saliency 
(Montoya, Horton, Vevea, Citkowicz, & Lauber, 2017)
. Familiarity seemed to be a crucial construct in this study, given the uncanny valley theory, where unfamiliarity or strangeness hinders the perception of animacy 
(Mori et al., 2012)
. Moreover, an empirical study indicated that people attribute fundamental capacities of the mind, which is a concept strongly related to animacy, to preferred targets 
(Kozak et al., 2006)
. Examining the relationship between the mere exposure effect and animacy will likely be a pivotal issue for future work.
We have observed that the choice probabilities of longer-shown stimuli in the animacy condition were greater than chance. Nonetheless, it is important to note that in Study 2's preregistered analysis, we could not identify the gaze manipulation components that affected animacy perception. Given that the preregistered analysis did not reveal significant effects of judgment types and gaze manipulations on the choice probabilities, we cannot conclude that gaze manipulation uniquely affected animacy perception. Instead, we need to stress that the effect of gaze manipulation on animacy perception might be limited or relatively small. The degree and the uniqueness of the gaze manipulation effect on animacy perception should be further examined in future studies.
Future work would be needed to specify the relationship between visual attention and animacy perception in detail. Firstly, it is necessary to test whether the effect of gaze manipulation occurs for completely inanimate objects (e.g., simple geometrics). The facial stimuli in the present study seemed relatively animate; therefore, it is unclear whether the gaze manipulation effect can trigger animacy perception. Thus, testing whether exposure duration facilitates the perception of animacy, even when the targets are entirely inanimate, would be an interesting direction. It is crucial to inspect the underlying mechanisms biased by gaze manipulation directly influencing animacy perception. Notably, attentional bias results in changes in the target's characteristics, such as saliency, liking 
(Mrkva & Van Boven, 2020)
, and familiarity 
(Montoya et al., 2017)
. Therefore, future studies need to examine the psychological mechanisms that mediate the relationship between gaze manipulation and animacy perception.
This study tested whether exposure time plays a role in the perception of animacy. We found evidence that biased exposure time of targets facilitated both animacy perception and preference toward targets rather than lower-level perception (i.e., morphological judgment). The underlying mechanisms biased by gaze manipulation directly influencing animacy perception are not clear. However, our findings suggest that biasing visual attention toward targets facilitates animacy perception, possibly because mere exposure increases familiarity or preference. Note. OR: odds ratio.  Note. In Studies 1b, 1c, and 2, the instruction for decision-making was changed depending on the conditions [which did you prefer?] for Study 1b; and which did you perceive as rounder?; for Studies 1c and 2. (A) the arbitrary eye movement condition in Studies 1a-1c, 2 and (B) the fixed eye movement condition in Study 2.  Note. The dashed line represents the chance level (50%).


Visual Attention Facilitates Perceived Animacy
Figure 1 :
1
Examples of modified face images used in the studies Figure 2: Example of task flow in Studies 1a to 1c and Study 2.


Figure 3 :
3
The box plots of the likelihood of the longer-shown stimuli chosen by participants across Studies 1a to 1cNote. The dashed line represents the chance level (50%).


Figure 4 :
4
The box plots of the likelihood of the longer-shown stimuli chosen by participants in Study 2


Table 1 Stimulus Exposure Facilitates Perceived Animacy 2.2.2 Study 1b (Preference Judgment)
1
further shows the details of the results.
[Insert Figure 3 here]
[Insert Table 1 here]


Toshiki Saito :Table 1 .Table 2 .
Saito12
Conceptualization, Methodology, Investigation, Software, Formal Analysis, Writing -Original draft preparation. Kosuke Motoki: Conceptualization, Methodology, Investigation, Writing-Reviewing and Editing. Rui Nouchi: Methodology, Writing-Reviewing and Editing. Motoaki Sugiura: Supervision, Writing-Review and Editing. Fixed effects from the GLMM analyses through Studies 1a to 1c Fixed effects from the registered analysis predicting the choice in Study 2
Stimulus Exposure Facilitates Perceived
Animacy
Tables
Study Predictor
Predictor
β
β SE
SE z-value p-value z-value p-value OR
OR 95% (OR) 95% (OR)
Study 1a (Animacy) Intercept
-0.28
0.11
-2.57
.010
0.76 [0.61, 0.94]
Intercept
-0.13
0.19
-0.72
.473
0.87
[0.61, 1.26]
Presentation Duration
0.34
0.11
3.19
.001
1.40 [1.14, 1.72]
Presentation Duration
0.30
0.28
1.08
.282
1.35
[0.78, 2.35]
Study 1b (Preference) Intercept
-0.33
0.14
-2.41
.016
0.72 [0.55, 0.94]
Gaze manipulation
-0.12
0.26
-0.46
.643
0.89
[0.53, 1.49]
Presentation Duration
0.53
0.13
4.21
.001
1.71 [1.33, 2.19]
Type of choice
0.39
0.27
1.45
.148
1.47
[0.87, 2.48]
Study 1c (Roundness) Intercept
0.19
0.15
1.28
.202
1.20 [0.91, 1.60]
Presentation Duration × Gaze
0.14
0.40
0.34
.732
1.15
[0.53, 2.50]
Manipulation
Presentation Duration
-0.02
0.24
-0.08
.936
0.98 [0.61, 1.58]
Note. OR: odds ratio. Presentation Duration × Type of choice
-0.12
0.40
-0.30
.762
0.89
[0.40, 1.95]
Gaze manipulation × Type of choice
-0.35
0.38
-0.93
.353
0.70
[0.34, 1.48]
Presentation Duration × Gaze
-0.27
0.57
-0.47
.641
0.77
[0.25, 2.34]
Manipulation× Type of choice


Table 3 .Stimulus Exposure Facilitates Perceived Animacy Figure Captions
3
Fixed effects from the additional GLMM analyses of each condition in Study 2
Type
Condition
Predictor
β
SE
z-value p-value
OR
95% (OR)
Animacy Arbitrary
Intercept
-0.25
0.11
-2.35
.019
0.78 [0.63, 0.96]
Presentation Duration 0.42
0.15
2.82
.005
1.52 [1.14, 2.03]
Fixed
Intercept
-0.12
0.08
-1.50
.133
0.88 [0.75, 1.04]
Presentation Duration 0.28
0.13
2.23
.026
1.33 [1.04, 1.70]
Roundness Arbitrary
Intercept
-0.29
0.33
-0.88
.379
0.75 [0.40, 1.42]
Presentation Duration 0.03
0.52
0.06
.950
1.03 [0.38, 2.84]
Fixed
Intercept
0.25
0.23
1.12
.264
1.29 [0.83, 2.01]
Presentation Duration 0.21
0.35
0.59
.558
1.23 [0.62, 2.46]
Note. OR: odds ratio.


9. Data Availability StatementThe datasets analyzed for this study can be found in the Open Science Framework (https://osf.io/cr4yx/).








Conflict of Interest
The authors have no conflicts of interest to disclose. 


Stimulus Exposure Facilitates Perceived Animacy
 










Biasing simple choices by manipulating relative visual attention




K
C
Armel






A
Beaumel






A
Rangel








Judgm. Decis. Mak




3
















Does the design of a robot influence its animacy and perceived intelligence?




C
Bartneck






T
Kanda






O
Mubin






Al
Mahmud






A








Adv. Robot




1
















lme4: Linear mixed-effects models using Eigen and S4. R Package Version




D
Bates






M
Maechler






B
Bolker






Walker
S








1














The role of eye movements in decision making and the prospect of exposure effects




G
D
Bird






J
Lauwereyns






Crawford






M
T








Vis. Res




60
















Emotion expression modulates perception of animacy from faces




N
C
Bowling






M
J
Banissy








J. Exp. Soc. Psychol




71
















Animacy, perceptual load, and inattentional blindness




D
P
Calvillo






Jackson






R
E








Psychon. Bull. Rev




21
















Movement and mind: a functional imaging study of perception and interpretation of complex intentional movement patterns




F
Castelli






F
Happé






U
Frith






C
Frith








NeuroImage




12
















Eye tracking and pupillometry are indicators of dissociable latent decision processes




J
F
Cavanagh






T
V
Wiecki






A
Kochar






M
J
Frank








J. Exp. Psychol Gen




143
















The shaping of social perception by stimulus and knowledge cues to human animacy




E
S
Cross






R
Ramsey






R
Liepelt






W
Prinz






A
F D C
Hamilton




10.1098/rstb.2015.0075






Philos. Trans. R. Soc. B Biol. Sci




371














The psychophysics of chasing: A case study in the perception of animacy




T
Gao






G
E
Newman






B
J
Scholl








Cogn. Psychol




59
















Taking the intentional stance at 12 months of age




G
Gergely






Z
Nádasdy






G
Csibra






S
Bíró








Cognition




56
















Stimulus exposure and gaze bias: A further test of the Visual Attention Facilitates Perceived Animacy gaze cascade model




M
G
Glaholt






E
M
Reingold








Atten. Percept. Psychophys




71
















Eye movement monitoring as a process tracing methodology in decision making research




M
G
Glaholt






E
M
Reingold




10.1037/a0020692






J. Neurosci. Psychol. Econ




4
















An eye-tracking study on information processing in risky decisions: Evidence for compensatory strategies based on automatic processes




A
Glöckner






A
K
Herbold




10.1002/bdm.684






J. Behav. Decis. Mak




24
















SIMR: An R package for power analysis of generalized linear mixed models by simulation




P
Green






C
J
Macleod








Methods Ecol. Evol




7
















Impaired spontaneous anthropomorphizing despite intact perception and social knowledge




A
S
Heberlein






Adolphs






R








Proc. Natl. Acad. Sci. USA




101
















An experimental study of apparent behavior




F
Heider






M
Simmel








Am. J. Psychol




57
















Evolutionary relevance facilitates visual information processing




R
E
Jackson






D
P
Calvillo








Evol. Psychol




11
















What do I think you're doing? Action identification and mind attribution




M
N
Kozak






A
A
Marsh






D
M
Wegner








J. Pers. Soc. Psychol




90
















Accounting for attention in sequential sampling models of decision making




I
Krajbich








Cur. Opin. Psychol




29
















Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel








Nat. Neurosci




13
















The attentional drift-diffusion model extends to simple purchasing decisions




I
Krajbich






D
Lu






C
Camerer






A
Rangel








Front. Psychol




3














Multialternative drift-diffusion model predicts the relationship between visual fixations and choice in value-based decisions




I
Krajbich






A
Rangel








Proc. Natl. Acad. Sci. USA




108
















When facial expressions do and do not signal minds: The role of face inversion, expression dynamism, and emotion type




E
G
Krumhuber






Y
K
Lai






P
L
Rosin






K
Hugenberg








Emotion




19
















Attribution of dispositional states by 12-montholds




V
Kuhlmeier






K
Wynn






P
Bloom








Psychol. Sci




14
















The perception of causality in infants




A
M
Leslie








Perception




11
















The decision value computations in the vmPFC and striatum use a relative value code that is guided by visual attention




S
L
Lim






J
P
Doherty






A
Rangel








J. Neurosci




31
















The tipping point of animacy: How, when, and where we perceive life in a face




C
E
Looser






T
Wheatley








Psychol. Sci




21
















Performance: An R package for assessment, comparison and testing of statistical models




D
Lüdecke






M
Ben-Shachar






I
Patil






P
Waggoner






Makowski
D








J. Open Source Softw




6


3139














The Chicago face database: A free stimulus set of faces and norming data




D
S
Ma






J
Correll






B
Wittenbrink








Behav. Res. Methods




47
















Orbitofrontal cortex value signals depend on fixation location during free viewing




V
B
Mcginty






A
Rangel






W
T
Newsome








Neuron




90
















A reexamination of the mere exposure effect: The influence of repeated exposure on recognition, familiarity, and liking




R
M
Montoya






R
S
Horton






J
L
Vevea






M
Citkowicz






E
A
Lauber








Psychol. Bull




143
















The uncanny valley




M
Mori






K
Macdorman






N
Kageki












from the field










10.1109/mra.2012.2192811






IEEE Robot. Autom. Mag




19














Eye-tracking research on sensory and consumer science: A review, pitfalls, and future directions




K
Motoki






T
Saito






T
Onuma








Food Res. Int




145


110389














Salience theory of mere exposure: Relative exposure increases liking, extremity, and emotional intensity




K
Mrkva






L
Van Boven








J. Pers. Soc. Psychol




118
















A brief history of Web experimenting




J
Musch






U
D
Reips








Psychological experiments on the Internet




Academic Press














Category-specific attention for animals reflects ancestral priorities, not expertise




J
New






L
Cosmides






J
Tooby








Proc. Natl. Acad. Sci. USA




104
















Gaze shifts do not affect preference judgments of graphic patterns




H
Nittono






Y
Wada








Percept. Mot. Skills




109
















Attention and choice: a review on eye movements in decision making




J
L
Orquin






L
S
Mueller








Acta Psychol. (Amst.)




144




















P
Pärnamets






P
Johansson






L
Hall






C
Balkenius






M
J
Spivey






D
C
Richardson


















Biasing moral decisions by exploiting the dynamics of eye gaze






Proc. Natl. Acad. Sci. USA




112














Social connection modulates perceptions of animacy




K
E
Powers






A
L
Worsham






J
B
Freeman






T
Wheatley






T
F
Heatherton








Psychol. Sci




25
















It's alive! Animate motion captures visual attention




J
Pratt






P
V
Radulescu






R
M
Guo






R
A
Abrams








Psychol. Sci




21
















Young infants' sensitivity to movement information specifying social causality




P
Rochat






R
Morgan






M
Carpenter








Cogn. Dev




12
















Non-photorealistic rendering of portraits




P
L
Rosin






Y
K
Lai








Proc. Workshop Comput. Aesthet


Workshop Comput. Aesthet












Presented at the Istanbul Turkey. Goslar, DEU: Eurographics Association








The perception of animacy in young children with autism




M
D
Rutherford






B
F
Pennington






S
J
Rogers








J. Autism. Dev. Disord




36
















Social Perception: Detection and Interpretation of Animacy, Agency, and Intention




M
D
Rutherford






V
A
Kuhlmeier








MIT Press












R: A language and environment for statistical computing




R Core Team




















Happy = human: A feeling of belonging modulates the "expression-to-mind




T
Saito






S
Almaraz






K
Hugenberg








effect. Soc. Cogn










In press








Gaze bias in preference judgments by younger and older adults




T
Saito






R
Nouchi






H
Kinjo






R
Kawashima








Front. Aging Neurosci




9


285














The gaze bias effect in toddlers: Preliminary evidence for the developmental study of visual decision-making




T
Saito






R
Sudo






Y
Takano




10.1111/desc.12969






Dev. Sci




23


12969














Gaze bias both reflects and influences preference




S
Shimojo






C
Simion






E
Shimojo






C
Scheier








Nat. Neurosci




6
















Gaze bias differences capture individual choice behaviour




A
W
Thomas






F
Molter






I
Krajbich






H
R
Heekeren






P
N C
Mohr








Nat. Hum. Behav




3
















Perception of animacy from the motion of a single object




P
D
Tremoulet






J
Feldman








Perception




29
















Perceptual causality and animacy




B
J
Scholl






P
D
Tremoulet








Trends Cogn. Sci




4
















Early interactions between orienting, visual sampling and decision making in facial preference




C
Simion






S
Shimojo








Vis. Res




46
















Interrupting the cascade: Orienting contributes to decision making even in the absence of visual stimulation




C
Simion






S
Shimojo








Percept. Psychophys




69
















Human perception of animacy in light of the uncanny valley phenomenon




S
Wang






P
Rochat








Perception




46
















Distinct processing for pictures of animals and objects: Evidence from eye movements




J
Yang






A
Wang






M
Yan






Z
Zhu






C
Chen






Wang






Y








Emotion




12
















Attitudinal effects of mere exposure




R
B
Zajonc








J Pers Soc Psychol




9
















The pitfall of experimenting on the web: How unattended selective attrition leads to surprising (yet false) research conclusions




H
Zhou






A
Fishbach








J Pers Soc Psychol




111


4


493















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]