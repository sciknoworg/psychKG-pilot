You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
Decision-making is the process of choosing one option or course of action from a range of possibilities, guided by sensory information and personal preferences. Decisions have long been studied in economics and psychology. More recently, with the rise of cognitive neuroscience, the field of decision neuroscience has emerged (which is sometimes also called neuroeconomics; 
Glimcher & Fehr, 2013;
Loewenstein et al., 2008)
. Decision neuroscience integrates behavioral and computational approaches from economics and psychology with tools from neuroscience to study the neurocognitive mechanisms underlying decision-making in both humans and animals.
From a decision-neuroscience perspective, the concept of a decision often encompasses Changing Environment a b c 
Figure 1
. Understanding uncertainty. Decision-making takes place under uncertainty when information relevant to the decision is incomplete or imperfect. Here, we distinguish between three broad types of uncertainty with dissociable effects on decision-making: perceptual uncertainty, risk, and uncertainty as a consequence of environmental changes. a| Perceptual uncertainty is present when sensory information is ambiguous, either because external sensory information is ambiguous itself or because of sensory and neural noise in the decisionmaker's nervous system. For example, perceptual uncertainty occurs when we try to estimate the speed of a car to decide if we can quickly cross the street before the car drives past or if it would be safer to wait until the car is away. In such a scenario, it is usually impossible possible to perceive the exact speed, and a common measure of perceptual uncertainty is the variance of a Gaussian distribution. A higher variance would correspond to more uncertainty because the decision-maker considers a broader range of possible speeds to be plausible. b| Risk is present when the outcomes of a decision cannot be perfectly predicted and is usually defined by the variance of potential outcomes. For example, when changing lanes in traffic, risk would be present when it is 80 % likely that one can change lanes successfully but 20 % likely that it results in a near miss or even an accident. In this case, most people might act in a risk-averse manner and decide not to change lanes. c| Finally, we often encounter new environments in which outcome contingencies, perceptual uncertainty, or risk are systematically different. For optimal decision-making, it is required to adjust behavior adaptively to such changes. One example is that on quiet weekend days, changing lanes on a particular route is safer (e.g., 80 % likely to be safe) than on busy weekdays (e.g., 80 % likely to result in a dangerous situation).
a broader scope than what people typically consider in their everyday lives. One important branch is perceptual decision-making, which studies choices that are primarily guided by sensory information 
(Gold & Heekeren, 2014;
Gold & Stocker, 2017;
O'Connell & Kelly, 2021)
. Examples of perceptual choices include the identification of a familiar person among a group of people, judging distances of cars in traffic, identifying potential obstacles on the road, or deciding whether a sensation is painful or merely uncomfortable. Even though such decisions are made countless times and often automatically in everyday life, they involve intricate computational and neural mechanisms that we will sketch in this chapter.
In contrast, economic or value-based decision-making is potentially closer to everyday ideas of what a decision involves. These sorts of choices are based on subjective preferences and are generally made to obtain rewards and to avoid punishment 
(Platt & Huettel, 2008;
Rangel et al., 2008)
. Crucially, economic decision-making goes beyond the scope of financial decisions, such as considering what to get for lunch or choosing a university at which to study. In many cases, economic decisions are driven by subjective preferences that can considerably vary across individuals, for example, subjective food or risk preferences. The underlying mechanisms of economic and perceptual decision-making exhibit both shared and distinct characteristics that we will cover in this chapter.


Understanding Uncertainty
Perceptual and economic decision-making have in common that they often occur under uncertainty, which broadly refers to incomplete and imperfect information (K. F. 
Park & Shapira, 2017)
. Both types of decision-making involve multiple types of uncertainty with different origins and partly dissociable effects on behavior 
(Bach & Dolan, 2012)
. In perceptual decision-making, uncertainty is often due to ambiguous sensory information, which is referred to as perceptual uncertainty 
(Fig. 1a)
. For example, in traffic with poor visibility, estimating the distance to other cars can be quite challenging. Moreover, in economic decision-making, a ubiquitous form of uncertainty is risk, which is present when outcomes (reward or punishment) are variable and, therefore, not perfectly predictable 
(Fig. 1b)
. For instance, when considering whether or not to change lanes in traffic, the outcome of the maneuver may be successful or not, which cannot be predicted with certainty. Instead, it might only be possible to assign probabilities to the different outcome scenarios, such as 80 % likely to change lanes safely and 20 % likely to result in a near miss. Finally, decision-making often occurs in dynamic environments that change systematically, thereby increasing uncertainty 
(Fig. 1c
). For example, on some routes, overtaking another car might be safer (e.g., on average, 80 % likely to be safe) than on others (only 20 % likely to be safe), and safe driving behavior requires that one takes into account such changing circumstances. Here, we will distinguish between these three levels (perceptual uncertainty, risk, and uncertainty due to environmental changes) and resort to this framework of uncertainty throughout the chapter 
(Bruckner et al., 2022)
.
In the following, we will present an overview of perceptual and economic decisionmaking under uncertainty. For both kinds of decision-making, we will discuss common computational models and insights into the underlying neural mechanisms. Subsequently, we will discuss commonalities of perceptual and economic decision-making, illustrating that although they rely partly on different information, both types of choices have to be integrated for adaptive behavior in the real world.


Perceptual Decision-Making
Perceptual choices are categorical judgments about sensory evidence 
(Gold & Heekeren, 2014;
Gold & Stocker, 2017;
O'Connell & Kelly, 2021
). Here, one major source of uncertainty is perceptual uncertainty 
(Walker et al., 2023)
. On the one hand, this type of uncertainty can originate from neural noise or variability due to random influences on neural activity. On the other hand, perceptual uncertainty can come from ambiguous sensory information, for example, when trying to estimate the speed of a fast car under poor visibility. Perceptual decision-making research, with a long tradition rooted in psychophysics (e.g., 
Fechner, 1860;
Von Helmholtz, 1867;
E. H. Weber, 1851)
 
Figure 2
. Perceptual decision-making. Perceptual decisions are categorical judgments about sensory stimuli and can be thought of as an inference over the true underlying stimulus value. a| Signal-detection theory offers useful tools to translate observed sensory information corrupted by uncertainty into perceptual decisions. Within this framework, perceptual uncertainty can be quantified by the variance of a probability distribution over the true stimulus value. For instance, when deciding if an approaching car is slow enough to cross the street before the car, we might consider two categorical hypotheses about the state of the car (car slow vs. car fast illustrated by the two distributions), quantifying what sensory information we would expect to observe under these two hypotheses. We can then compare the plausibility of the two underlying hypotheses with respect to the observed sensory information (black vertical line) in order to evaluate which stimulus category is more likely. b| This comparison can be expressed by the belief state indicating the probability of the states (slow vs. fast) given the sensory information. In this example, state "car fast" would be more likely. c| In many situations, sensory information unfolds over time, allowing for dynamic accumulation of evidence about the underlying stimulus category. The sequential sampling approach describes a process for incorporating moment-to-moment sensory evidence into a dynamic decision variable that is used to make a perceptual choice. In this framework, each piece of imperfect momentary evidence is integrated into a decision variable that evolves over time (light traces), beginning at a "starting point" and culminating when the decision variable crosses one of two "decision boundaries" (upper and lower black lines). The "drift rate" of the process is related to the mean of the underlying distribution of momentto-moment evidence and thus governs the speed of evidence accumulation (here, examples of slow, medium, and fast accumulation are shown), whereas the decision boundary determines the amount of accumulated evidence necessary to translate a continuous belief into a categorical choice. valuable experimental methods for carefully controlling presented sensory information, such as signal strength and uncertainty, and for precisely measuring choices and response times. Additionally, the ability to control the temporal scale of information presentation allows for a detailed examination of how decisions unfold over time. This precise control over both the content and timing of sensory input is crucial for dissecting the intricate dynamics of decision-making.


Computational Models
Perceptual decision-making can be thought of as a form of inference about the stimuli or states of the environment given the available sensory information 
(Dayan & Daw, 2008;
Gold & Heekeren, 2014)
. The term inference refers to the act of drawing a conclusion about a variable of interest based on the currently available information 
(Bernardo & Smith, 2009)
. For instance, the state of the world could be the true but unknown speed of a car that is approaching. To infer the speed, the brain has to rely on all sorts of information imbued by uncertainty, such as neural activity in motion-sensitive areas or auditory information providing a hint about how quickly the car is approaching based on changes in the engine noise. In this section, we will present two common computational approaches to performing sensory inference: signal-detection theory and the sequential sampling framework.


Signal-Detection Theory
Signal-detection theory is an important pillar in perceptual decision-making under uncertainty, providing many useful tools to formalize how the brain performs sensory inference (D. M. 
Green & Swets, 1966)
. To illustrate signal-detection theory, we take the example of inferring whether one can cross the street before a car has driven past assuming discrete states and actions 
(Bruckner et al., 2020;
Dayan & Daw, 2008)
. We assume that the decision-maker or agent can either cross the street before the car (action a = 0) or wait until the car has driven by (action a = 1). Moreover, for simplicity, we assume that the car can assume two states (in the real world, there might, of course, be more states): in state s = 0, the car is slow, and it is safe to cross the street before the car; in state s = 1, the car is fast, and it would be dangerous to try to cross the street before. Crucially, the states are partially hidden from the agent and can only be inferred based on uncertain perceptual information about the car's speed, which we refer to as observation o here.
To formalize the perceptual choice process, it is necessary to specify the contingency between observations and hidden states ( 
Fig. 2a
). Here, we have
p(o|s) = N (o; µ s , σ 2 )
(1)
where p(o|s) denotes the probability of sensory observation o given the car's true state.
In signal detection, it is often assumed that such probabilities follow a Gaussian distribution, where the mean µ s would, in our example, indicate the car's true underlying speed for each of the two possible states (e.g., slow µ s=0 = 30 km/h; fast µ s=1 = 50 km/h). Crucially, this way of formalizing sensory observations yields a definition of perceptual uncertainty in terms of the variance of the observations, here denoted by σ 2 . In brief, we have just built a simple perceptual model of the mapping between partially hidden states of the world (state of the car) and a subject's uncertain perception of the situation (how fast do I think the car is driving).
The next step is mapping the subjective observation of the car's speed to perceptual decision-making, that is a categorical judgment about whether the car is too fast to cross the street or slow enough to quickly run to the other side. Signal detection distinguishes four contingencies between states and actions 
(Table 1)
. What we want to optimize is the number of "hits" and "correct rejections". In our example, we want to cross the street when the car is slow (hit), and we want to make sure that we wait when the car is too fast (correct rejection). At the same time, it is important to avoid "false alarms", that is, trying to cross the street when the car is fast. Finally, we would like to minimize "misses", which would correspond to situations in which we wait although the car is actually slow enough.


Actual State Action


Cross street Wait
Car slow Hit (crossing safely) Miss (waiting too long) Car fast False alarm (endangering Correct rejection yourself) (waiting appropriately) 
Table 1
. Signal-detection contingencies.
To compute the decision, we can rely on Bayesian inference. Ideally, we would like to know the true state of the car and decide accordingly. However, since the true state is not directly observable, we can rely on the so-called belief state that reflects the probability of the state based on the available uncertain sensory information 
(Fig. 2b)
. The belief state can be computed with Bayes' rule:
p(s|o) = p(o|s)p(s) p(o)
(2)
Here, we re-use eq. (1) as the "likelihood" indicating the probability of observing car speed o given the actual state of the car s and the degree of perceptual uncertainty σ 2 , which could for example be larger when it is dark and rainy. The other term in the numerator, p(s), is the prior probability of the state and regularizes to which extent the newly observed information influences the belief state. For example, when a person strongly expects that cars are mostly very fast, their belief state would favor the state "car fast" even when the currently observed car seems to be relatively slow based on the available sensory data. p(o) in the denominator is the marginal probability of the observation and is used to normalize the probability.
Based on the computed belief state, we can then make a decision. To do so, we can define a threshold on the belief state:
π = a = 0, if p(s = 0|o) ≥ θ a = 1, if p(s = 0|o) < θ
(3)
For example, we might only want to cross the street when we are quite certain that the car is slow and not being dangerous (a = 0), such as belief state for s = 0 (car slow) ≥ θ = 99 %. In other scenarios, such as a simple contrast-discrimination task in the laboratory, when stakes are lower, subjects may adopt a different threshold, for example, θ = 50 %, which would correspond to a choice strategy in which the option with the higher belief state is favored. More generally, we could define subjective values associated with the four possible contingencies and choose a value-maximizing threshold, which we discuss in more detail in the economic decision-making section below.
In summary, we can use signal-detection theory to formalize key computations underlying perceptual decision-making under uncertainty. So far, we have focused on these computations on the trial level without explicitly taking into account how a perceptual choice unfolds over time. Therefore, in the next section, we zoom into the temporal dynamics of perceptual decision-making from the perspective of a sequential sampling approach. One major conceptual advancement of sequential sampling models is that they capture the fundamental trade-off between speed and accuracy. Overall, perceptual choices become more accurate when the agent takes more time to sample sensory information, and choices become less accurate when responses are faster.


Sequential Sampling Models
Sequential sampling models propose that decision-makers accumulate evidence over time by sampling sensory information from the environment 
(Fig. 2c)
 
(Forstmann et al., 2016;
Ratcliff & Rouder, 1998;
Shadlen et al., 2006)
. These models assume that the signal-to-noise ratio of the uncertain (noisy) sensory information increases with sampling. Therefore, the more time one takes for sampling, the higher the signal-to-noise ratio of the sampled evidence tends to be. At the same time, sequential sampling models assume that waiting longer is costly, so the decision-maker has to balance the trade-off between speed and accuracy. This trade-off is navigated by a decision threshold determining when the sampling process stops, and the choice is reported. When the threshold is lower, the choice process is faster but also based on fewer samples, thereby decreasing accuracy. In contrast, a higher threshold is associated with longer response times, more samples, and higher accuracy. In summary, sequential sampling models share fundamental concepts with signal-detection theory and allow us to model the formation of belief states and perceptual choices from moment to moment in terms of a dynamic process of sensory evidence accumulation.


Behavior and Neuroscience
Perceptual decision-making has long been empirically investigated in humans and animals. In this section, we give a selective overview of research into the behavioral and neural mechanisms supporting the computational perspectives described above.


Sensory Evidence and Perceptual Uncertainty
The discovery that the brain seems to accumulate evidence, as suggested by sequential sampling models, is one of the most prominent contributions of decision neuroscience so far. Many of the pioneering studies in this domain have been conducted in monkeys performing the random-dot motion task ( 
Fig. 3a-c)
. In this task, the monkey observes a cloud of noisy dots that, on average, moves towards the left or right side. Perceptual uncertainty is present because of stochasticity in the dot motion, defined in terms of "coherence", which refers to the proportion of dots that move in the dominant direction, as opposed to relocating to a random position in a circle. This perceptual uncertainty makes it challenging to figure out the average movement direction and makes it useful to integrate information over multiple frames. The monkeys typically indicate their choices with a saccade toward the respective side on the presentation screen. Representations   
Britten et al., 1992)
. The psychometric curve indicates the relationship between movement coherence and choice performance, where higher coherence is associated with better performance. The neurometric curve indicates how well the activity of recorded neurons predicts movement direction. That is, at least in such coarse discrimination tasks, single neurons can show a similar "performance" as the monkey. e| Perceptual decision-making can also take place in changing environments, requiring the decision as to whether the state of the environment is the same as before or different. For example, in traffic, one often has to decide if a car at a crossing is just waiting and one can keep driving as usual (same state) or is suddenly crossing one's path, requiring a swift reaction (new state). f| Evidence in changing environments, therefore, switches between different states, and optimal evidence accumulation requires adjusting to such changes.
of sensory evidence have been primarily found in sensory areas. In perceptual choices about movement direction, the medial temporal area (MT), also known as V5, has been one focus of many studies 
(Britten et al., 1992
(Britten et al., , 1996
Newsome & Pare, 1988;
Newsome et al., 1989;
Salzman et al., 1990
Salzman et al., , 1992
. Motion-selective neurons in area MT track the movement direction of the cloud of dots and predict the monkey's choice behavior, showing that this area is involved in representing the sensory evidence in the service of motion judgments. In fact, neuronal responses to random-dot stimuli show a striking correspondence to the monkey's psychometric curve linking motion strength and choice behavior, emphasizing that relatively small populations of cells represent a considerable amount of choice-predictive evidence ( 
Fig. 3d
) 
(Britten et al., 1992)
. Microstimulation and pharmacological studies indicate that area MT is both necessary and sufficient for providing motion evidence in dot-motion decision-making tasks 
(Katz et al., 2016;
Salzman et al., 1990
Salzman et al., , 1992
. Although we focus on the visual system as a model of perceptual decision-making, similar results about the neural representations of sensory evidence have been obtained for somatosensory and auditory choices, where activity in the somatosensory and auditory cortex predict respective choice behaviors 
(Romo & Salinas, 2003;
Tsunada et al., 2015)
.
A key question that the brain faces in perceptual decision-making tasks is when to stop sampling and translate the read-out evidence into a choice. A wealth of studies on choice-selective activity has proven particularly illuminating about the link between perception and action, showing that motor association areas play a prominent role in the choice process. In the context of the random-dot motion task, in which monkeys usually indicate their choices via saccadic eye movements, the focus has been on oculomotor areas, playing a role in the control of eye movements. Several sensory-motor association brain areas, including the lateral intraparietal cortex (LIP), frontal eye field (FEF), and superior colliculus (SC), display neural responses consistent with translating sensory evidence into choices, much like the accumulation to bound that occurs in sequential sampling models 
(Ding & Gold, 2010
, 2012
Gold & Shadlen, 2000
Roitman & Shadlen, 2002)
. Experiments examining the roles of these brain regions in perceptual decision-making typically involve characterizing individual neurons to identify their so-called response fields. Response fields define regions of visual space that elicit high firing rates when the animal initiates a saccade to them. LIP, FEF, and SC include populations of neurons with response fields tiling visual space, providing a sort of population code that could initiate different saccade targets. To examine the neural correlates of evidence accumulation, one choice target is typically displayed in the response field for the recorded neuron, such that saccades for one of the two choices elicit high firing rates. However, a key finding is that such neurons tend to increase firing slowly over the course of motion viewing and in proportion to dot coherence as if they are integrating evidence into a single decision variable, quantifying the evidence for the "in-response-field" choice. This is in line with the idea that neurons tuned toward specific saccadic targets accumulate sensory evidence until reaching a threshold level of firing at which accumulated evidence is converted into an action, in this case, an eye movement toward the preferred choice target.
Human neuroimaging studies using functional magnetic resonance imaging (fMRI) often build on monkey work and seek to test mechanistic predictions derived from such studies. An influential study by 
Heekeren et al. (2004)
 suggests that representations of sensory evidence for decision-making can be found in sensory areas, similar to the monkey studies described above. In this study, human participants were asked to report categorical perceptual choices about faces versus houses. The authors exploited that different functionally specialized regions in the brain preferentially respond to faces (fusiform face area, FFA) and others to houses (parahippocampal place area, PPA) to examine how the human brain integrates sensory evidence 
(Epstein & Kanwisher, 1998;
Haxby et al., 1994;
Kanwisher et al., 1997)
. When images of faces that were easily identifiable (low perceptual uncertainty) were presented, the FFA showed greater responses than for faces that were hard to identify. Similarly, houses that could be easily identified evoked stronger responses in the PPA compared to houses plagued by perceptual uncertainty. In contrast to this, the FFA showed stronger responses to uncertain house stimuli, and so did the PPA for uncertain face stimuli. These results suggest that sensory regions are involved in the collection of sensory evidence for perceptual decisionmaking. In particular, stronger evidence for a choice (e.g., face) correlates with stronger activity in stimulus-specific areas (e.g., FFA), and more uncertainty is reflected in more distributed activity across these areas.
In human perceptual decision-making, the dorsolateral prefrontal cortex (dlPFC) and pre-motor areas have been suggested to be involved in evidence accumulation for a particular response based on the difference in sensory evidence from lower-level sensory areas (such as the FFA and PPA in the study above by 
Heekeren et al., 2004)
. One potential computational role of the dlPFC is the regulation of the speed with which evidence is integrated (which is sometimes referred to as the drift rate in sequential sampling models). For example, Philiastides et al. 
2011
applied transcranial magnetic stimulation (TMS) to the dlPFC, which reduced participants' choice accuracy and increased reaction times, suggesting that stimulation reduced the drift rate of evidence accumulation. Other work with patients with Parkinson's disease and an implanted deep brain-stimulation device (DBS) highlights the role of the subthalamic nucleus (N. 
Green et al., 2013)
. The authors asked subjects to discriminate the direction of motion in a random-dot task while being on and off DBS, which showed that DBS of the subthalamic nucleus increased performance for particularly difficult perceptual choices. There is further evidence that a cortico-basal ganglia network plays a role in the calibration of decision thresholds to different task demands in terms of speed versus accuracy 
(Bogacz et al., 2010)
. For example, studies suggest that lower thresholds increasing response speed are related to sustained activity in the pre-supplementary motor area (pre-SMA) and striatum 
(Forstmann et al., 2008
(Forstmann et al., , 2010
. Taken together, there is evidence that modulations of the speed-accuracy trade-off are related to activity in higher-order and pre-motor areas rather than in early sensory and primary motor areas.
Moreover, a fundamental aim of perceptual decision-making research is understanding where and how perceptual uncertainty is represented in the brain 
(Walker et al., 2023)
. As already suggested in the previous sections, there is evidence to suggest that neural representations of perceptual uncertainty are closely related to sensory brain areas. For example, Vilares et al. (2012) devised a perceptual estimation task in which subjects undergoing fMRI had to sequentially estimate the location of a hidden target that was signaled based on uncertain sensory information randomly distributed around the target. The study demonstrated that higher perceptual uncertainty yielded stronger responses in the occipital cortex that is involved in visual processing. Similarly, 
Michael et al. (2015)
 had subjects perform a categorization task (e.g., average color of a range of cues) based on uncertain sensory information (color of each cue differed to some extent) and found stronger brain activity in occipital areas when sensory information was more uncertain. These results are in line with further studies suggesting stronger activity in the occipital cortex under higher perceptual uncertainty, for example, when shapes are more incoherent 
(Murray et al., 2002)
 or when random-dot motion is more noisy 
(McKeefry et al., 1997)
.
Building upon the idea that neural representations of perceptual uncertainty are strongly related to sensory representations, several theoretical contributions developed computational models of the neural code of uncertainty representations in such areas 
(Beck et al., 2008;
Ma et al., 2006)
. One such perspective proposes that perceptual uncertainty is represented through probabilistic population codes. Accordingly, populations of neurons in sensory brain areas convey information about the most likely stimulus property (e.g., orientation of a grating) along with uncertainty about the stimulus property (e.g., probability over possible orientations). Consequently, neural populations inherently represent probability distributions based on which the brain can perform Bayesian inference, such as in the traffic example above.
First fMRI studies in humans have built upon the idea that neural populations code for perceptual uncertainty and examined whether this form of uncertainty can be decoded from neural activity. Van Bergen et al. (2015) conducted a perceptual decision-making study in which subjects were asked to report the orientation of grating stimuli. The authors of this study developed a model for decoding the grating orientation along with uncertainty over the orientation based on measured brain activity in areas V1-V3 (see also Van Bergen & Jehee, 2017). One highlight of this line of work was the finding that the decoded magnitude of perceptual uncertainty is related to the subjects' behavioral responses. In particular, when the decoded uncertainty was lower (i.e., the decoded orientation based on neural activity was more certain), participants' orientation ratings were more accurate, suggesting that more certain neural sensory representations are translated into more accurate perceptual choices. A more recent study building on this method suggests that subjective confidence ratings might, at least in part, be explained by the same principles of neural coding 
(Geurts et al., 2022)
.


Environmental Changes
So far, we have focused on how perceptual uncertainty affects choices based on sensory evidence, but it turns out that uncertainty related to environmental changes affects perceptual decision-making as well. For example, in traffic, it is crucial to quickly respond to suddenly appearing cars or cyclists, especially when they emerge from a crossing road or another unexpected source. A relatively recent line of work examines perceptual decision-making in changing environments. The crucial challenge in this scenario is distinguishing perceptual uncertainty and environmental changes and deciding if a new observation can be assigned to the same state as before or a new one 
(Fig. 3e)
. That is, depending on the current state of the environment, sensory evidence might be quite different, and flexible decision-making requires adjusting evidence accumulation accordingly 
(Fig. 3f
).
Research into perceptual decision-making in changing environments shows that decisionmakers dynamically adjust the integration of perceptual information to changes. To study auditory decision-making under perceptual uncertainty and in the face of changes, 
Krishnamurthy et al. (2017)
 developed a sound-localization task. The participants were asked to report the source of a played tone, where uncertainty came from noise in the exact location of the presented tone and occasional changes in the average sound source. Importantly, from a perceptual inference perspective, participants should accumulate sound information across trials as long as the average sound source is stable. This allows them to infer the most common sound source and to average out the noise in the signal over time. However, after a change in the average location of the tone, they should discard previous sensory information and restart the evidence accumulation process to accurately infer the new average location. The behavioral findings of this study supported this prediction, indicating that perceptual decision-making can be dynamically tuned to environmental contingencies.
Several additional studies in the visual domain similarly suggest that human subjects treat uncertain sensory information dependent on environmental changes 
(Drevet et al., 2022;
Purcell & Kiani, 2016)
. One such study provides evidence that subjects even dynamically adjust sensory information processing to the frequency of changes 
(Glaze et al., 2015)
. In one task of this work, subjects made choices about which of two sources generated a visual signal, which was uncertain due to noise. The results indicated that subjects adjusted their visual information processing to the different levels of changes in the task. In particular, in more stable environments, subjects accumulated sensory information over longer time scales compared to more frequently changing environments, in line with the predictions of a Bayesian perceptual inference model. Rats performing a comparable auditory decision-making task similarly adjust the timescale of evidence integration to the frequency of environmental change points 
(Piet et al., 2018)
. Moreover, the study by 
Sato and Kording (2014)
 provides crucial insights into the algorithmic foundations of how the brain learns about the amount of perceptual uncertainty in changing environments. In their experimental task, the quality of sensory inputs changed over time, and modeling analyses showed that subjects learned about perceptual uncertainty consistent with principles of Bayesian inference, suggesting that they nearly optimally adjusted perceptual choices to different degrees of uncertainty. Finally, theoretical perspectives 
(Yu & Dayan, 2005)
 and empirical findings 
(Krishnamurthy et al., 2017;
P. R. Murphy et al., 2021)
 suggest that adjustments to environmental changes are supported by arousal-linked brain dynamics, in particular, the norepinephrine system. Environmental changes elicit heightened arousal levels that co-occur with increased sensitivity to immediate sensory input, positioning arousal-linked neuromodulatory systems such as the locus coeruleous-norepinephrine (LC-NE) system 
(Joshi et al., 2016;
Reimer et al., 2016)
 to control the strength of bottom-up versus top-down influences on perceptual decisions. An active area of research is aimed at dissecting the causal nature of these relationships and mapping it onto exact biological circuitry, but to date, there remain a number of open questions.  a| Risk is commonly defined as the variance of the outcomes, making it impossible to precisely predict the outcome of a choice. For example, when two outcomes (0 and 1) are possible with a certain probability, risk would be greatest when both outcomes are equally likely (50-50 chance), indicating the outcomes are the least predictable. When outcomes are predictable with higher certainty, risk is lower. For example, when the outcome probability is p = 0.2, risk is σ 2 = 0.16. Likewise, when the outcome probability is p = 0.8, risk is also equal to 0.16. Finally, when outcomes can be perfectly predicted (probability p = 0 or 1), σ 2 = 0. In economics and psychology, it is usually assumed that the amount of risk is known to (decisions from description) or at least estimated by the decision-maker (decisions from experience). b| Estimation uncertainty refers to the decision-maker's incomplete knowledge of outcome probabilities and can also be quantified by the variance of a probability distribution. For example, the true but unknown outcome probability of an option might be p = 0.8, but the decision-maker considers multiple probabilities to be likely. When experience is limited, uncertainty might be higher than after multiple experiences.
Economic decisions are driven by subjective expected values that are related to expectations about reward or punishment following a choice 
(Platt & Huettel, 2008;
Rangel et al., 2008)
. A primary form of uncertainty in economic decision-making is risk. In economics, risk is generally defined in terms of the variability of possible outcomes (K. F. 
Park & Shapira, 2017)
. For example, imagine a simple coin-flipping game in which a player receives 2€ when the coin comes up heads and 0€ for tails. Assuming a fair coin, the chances for each outcome are 50 %, and the average, expected outcome would be 1€. In this situation, risk is present because the player cannot perfectly predict the outcome due to the outcome variance. When choosing between a coin toss or a sure outcome of 1€, a person would be considered risk-averse when they show a preference for the lower-variance option with the same expected value (1€ for sure).
Notably, the economic definition of risk seems to be quite different from a layperson's perspective on risk, as well as the usual conception in clinical practice 
(Schonberg et al., 2011)
. In everyday life, risk is more often described in terms of possible negative outcomes and without a direct reference to outcome variability. In clinical settings, risky behavior often refers to behavior that can harm oneself or others. Similarly, it is common to refer to risk factors that increase the likelihood of a disease or other negative health outcomes. To illustrate the difference between these two perspectives, we consider the variance of different outcome probabilities 
(Fig. 4a)
. From an economics perspective, the level of risk is greatest (variance σ 2 = 0.25) when the outcome probability is 50 %. That is, risk would be considered high when the outcome is the least predictable. In contrast, the better the events can be predicted, the lower the risk. For example, when a rewarding outcome has a chance of 20 % or 80 %, risk would be lower since the outcome can be predicted with higher certainty. Crucially, from a layperson's perspective, risk might be higher when the reward is only 20 % likely compared to 80 %. In this chapter, we will use the economic definition of risk in terms of outcome variance.
The literature in economics and psychology often distinguishes risk from (estimation) uncertainty. Accordingly, risk quantifies known or estimated outcome probabilities, such as in the coin-flipping example, when the player has some knowledge about the actual probability of heads and tails 
(Fig. 4a)
. In opposition to risk, estimation uncertainty quantifies the decision-maker's internal uncertainty about the outcome probabilities, often in terms of the variance over the possible outcome probabilities 
(Fig. 4b)
. When the decision-maker is unfamiliar with the outcome probabilities, their knowledge is imprecise, and estimation uncertainty tends to be higher. In contrast, estimation uncertainty is lower when the decision-maker has more substantial experience and a better estimate of the probabilities. We briefly note that other definitions regarding the distinction between risk and uncertainty exist, where uncertainty is sometimes interpreted as a lack of knowledge that cannot be quantified 
(Knight, 1921)
, which we, however, do not assume in this chapter.


Computational Models
Computational models of risky choice aim to explain how the presence of risk influences choice behavior and, in particular, individual risk attitudes 
(Frey et al., 2017)
. From an economics perspective, a person is considered risk-averse when preferring safe options (e.g., 1€) over risky options (e.g., 50 % chance of winning 2€) when both have the same expected value. In contrast, favoring the risky option would be considered risk-seeking behavior. In this section, we will present two common approaches to modeling risk preferences: expectation-based approaches that decompose preferences into outcomes and probabilities and mean-variance approaches that primarily consider the expected value (mean) and variance (risk) of outcome distributions.


Expectation-Based Approaches
Expectation-based approaches propose that choice options are evaluated based on the magnitude and probability of possible outcomes. A seminal concept of expectationbased approaches is the expected value, which can be computed by multiplying outcome magnitude and probability:  where one has the choice between winning 2€ if the coin lands heads and nothing otherwise or winning 0.9€ for sure. Most people would take the risky option (2€ with 50 % probability), in line with the idea that the average gain of 1€ is greater than that of the safe option. However, what happens when stakes are higher, for example, playing for 20.000€ when the coin comes up heads versus a safe 9.000€? In this case, most people prefer the safe option, which would be described as risk-averse. b| Expected-utility theory explains this choice pattern, proposing that the amount of money involved in the game is not perceived in an objective but rather subjective way, referred to as expected utility. Changes in the objective value in the lower range (e.g., 0-10€) are associated with a steeper increase in expected utility than changes in the higher range (e.g., 80-90€), which is often described as diminishing marginal utility. c| Prospect theory extends expected-utility theory, assuming that the translation from objective to subjective values occurs with respect to a reference point rather than the absolute value. Moreover, prospect theory assumes that the effects of losses are stronger than those of gains. For example, losing 20€ would be associated with a stronger change in subjective value than winning the same amount. d| Finally, prospect theory additionally assumes that objective probabilities are translated into subjective probabilities, where smaller probabilities tend to be overestimated, while larger probabilities tend to be underestimated.
EV (x, p) = p • x
(4)
where p denotes the probability and x outcome magnitude. A basic, risk-neutral choice rule is to choose the option that maximizes the expected value. For example, from this perspective, one should favor a risky choice with magnitude x = 2€ with probability p = 0.75, where EV = 1.5€ over a sure 1€. Two common theories have extended this approach by assuming subjective as opposed to objective values (expected-utility theory) and, in addition, subjective probabilities (prospect theory).
Expected-Utility Theory Expected-utility theory allows us to model individual risk attitudes by replacing the expected value with the concept of expected utility 
(Bernoulli, 1738
(Bernoulli, /1954
; see also 
Mata and Nagel, 2023)
. A useful example for illustrating the advantages of expected utility in a coin-flipping game is the following one ( 
Fig. 5a
): Imagine a person can choose between a sure outcome of 0.9€ and a risky bet for 2€ with a 50 % chance of winning and a 50 % chance of receiving 0€. Most people would choose the risky gamble, in line with the predictions of the expected-value theory, where the expected value for the risky option (EV = 1€) is greater than for the safe option (EV = 0.9€). Next, consider a similar coin-flipping game with magnitudes that are considerably higher. For example, instead of playing for 2€, the risky option might have a magnitude of 20.000€, and the safe option might be worth 9.000€. From the perspective of expected-value maximization, people should prefer the gamble since the expected value EV = 10.000€ is greater than that of the safe option. However, when stakes are high, like in the example, people generally prefer the safe option.
Expected-utility theory can successfully explain the emergence of risk aversion under high stakes 
(Fig. 5b)
. In particular, this approach replaces expected value with expected utility:
EU (x, p) = p • u(x)
(5)
where u(x) refers to the utility function that maps an individual's current wealth onto utility, thereby assuming that values guiding choices have a subject component that depends on the overall financial situation of the decision-maker. A common type of utility function is the log function. Here, the increase in subjective utility is greater at lower initial levels of wealth compared to higher initial levels, which is often referred to as diminishing marginal utility. For example, an increase from 0€ to 10€ would lead to a much larger increase in subjective utility than an increase from 80€ to 90€. Therefore, the same objective increase in wealth would psychologically be much higher in a poorer than a richer person.
We can apply these insights to explain why people tend to be risk-averse when stakes are higher. When choosing between a 50-50 chance of winning 20.000€ and a sure 9.000€, the expected utility of the safe option would be higher than that of the gamble: u(9.000) = 3.95 > u(20.000) • 0.5 = 2.15
This example aligns with the intuition that it seems to be a reasonable choice to prefer a smaller but safe amount of money, especially when the magnitude of both options is quite high. Prospect Theory While expected-utility theory proposes that objective values are transformed into subjective values, prospect theory additionally assumes that objective probabilities are transformed into subjective probabilities 
(Kahneman & Tversky, 1979;
Tversky & Kahneman, 1992)
. Prospect theory posits that low probabilities are subjectively overestimated, and high probabilities are underestimated 
(Fig. 5d)
. Accordingly, the subjective value of an option is defined by
SV (x, p) = w(p) • u(x)
(7)
Here, w(p) denotes the subjectively weighted probability, and u(x) measures the subjective utility of the option. Moreover, in contrast to expected-utility theory, prospect theory assumes that subjective values are evaluated compared to the decision-maker's current reference point rather than their wealth 
(Fig. 5c
). Finally, prospect theory famously states that losses loom larger than gains 
(Kahneman & Tversky, 1979)
, that is, a particular loss (e.g., -20€) is subjectively higher than the same amount in the gain domain (e.g., 20€).
These features of prospect theory accommodate a prominent fourfold pattern of risk attitudes related to the factors outcome domain (gain vs. loss) and outcome probability (high vs. low) governing human risk preferences 
(Table 2)
. When higher outcome probabilities are involved, people tend to underestimate such probabilities. For example, 80 % is subjectively perceived as 70 %. Consequently, in the gain domain, people tend to behave risk-averse (e.g., preferring safe over risky investments). In contrast, in the loss domain, people are predicted to behave risk-seeking (e.g., keeping a losing stock for too long). In contrast, people tend to overestimate lower probabilities. For example, 2 % is perceived as 5 %. Consequently, in the gain domain, people show risk-seeking (e.g., playing the lottery), but in the loss domain, risk-averse behavior (e.g., being over-insured against very unlikely events).


Mean-Variance Approaches
Mean-variance approaches decompose outcome distributions into the mean (expected value) and variance and optionally higher moments (e.g., skewness), where risk is measured by the variance. This perspective on risk emerged in finance and is often used in portfolio theory for investment decisions 
(Bodie et al., 2003;
Markovitz, 1959)
. Meanvariance approaches generally assume that decision-makers are risk-averse. In portfolio . Mean-variance approaches to economic decision-making. Mean-variance approaches assume that decision-makers are generally risk-averse. When two assets have the same expected value, investors will prefer the one with lower risk (lower variance), and options with more risk are only more attractive if they offer a higher expected return (risk premium). a| The indifference curve describes the options that are equally preferred by the decision-maker as a function of their expected value and risk. That is, each illustrated line shows different combinations of expected value and risk that would be associated with the same expected utility. The two curves showing risk-averse investors illustrate that higher expected gains can compensate for higher risk. Theoretically, a risk-neutral investor would not consider the amount of risk, and a risk-seeker would even prefer options with higher risk and lower expected returns. b| The coefficient of variation formalizes risk in terms of the standard deviation relative to the expected value of an option. While the standard deviation can remain constant across a range of expected values, the coefficient of variation decreases as a function of the value. Consequently, risk would tend to be higher for options with higher standard deviation and lower expected values compared to options with the same standard deviation but higher values.
choices, investors would penalize the expected value or return of a portfolio for the presence of risk. One way to express the risk-penalized utility of a choice option is
EU (x, σ) = EV (x) − A • σ 2
(8)
where EV (x) is the expected value of the portfolio, σ 2 is risk expressed as variance, and A denotes the decision-maker's risk-aversion. A useful way of illustrating this point is the indifference curve describing the options that have the same expected utility as a function of the expected value and risk 
(Fig. 6a)
. A risk-averse agent (with A > 0) would only choose a risky option over a safe option when the expected value of the option makes up for the associated risk, which is often called a risk premium in the financial literature. In the indifference curve, this is reflected in steeper curves, where a higher expected value is required to compensate for higher risk. In contrast, a risk-seeker would find higher-risk options more attractive and accept lower expected values.
Psychologists and economists have extended mean-variance models to better predict risky choice behavior of humans and animals. One such extension is to explicitly consider the skewness or asymmetry of outcomes 
(Seaman et al., 2017;
Spiliopoulos & Hertwig, 2019
Symmonds et al., 2011;
Wright et al., 2013)
. Moreover, another crucial extension has been the definition of risk in terms of the coefficient of variation instead of variance (E. U. Weber, 2010; E. U. 
Weber et al., 2004)
:
CV (x, σ) = σ EV (x)
(9)
where the standard deviation of outcomes σ is standardized by the expected value 
(Fig.  6b)
. To appreciate the advantage of the coefficient of variation, consider a risky option with EV = 10€ and standard deviation σ = 100€. Since the standard deviation of ±100€ is much larger than the expected value of 10€, this option might seem quite a risky business, leading to a coefficient of variation of CV = 10. In contrast, an option with a higher expected value (e.g., 100€) but the same standard deviation seems to be much less risky since the spread of outcomes relative to the expected value is considerably lower (CV = 1).


Learning To Make Economic Decisions under Uncertainty
Thus far, we have presented an overview of different approaches to decisions under risk, where it is generally assumed that outcome magnitudes and probabilities are known to, or at least accurately estimated by, the decision-maker. This domain is often referred to as decisions from description, but in the real world, decisions are frequently based on experience 
(Hertwig & Erev, 2009)
. For example, some types of financial choices might be based on statistics and established knowledge that accurately reflects risk, however, in many other cases, like founding a company or developing new products, subjective values and economic risk are uncertain and have to be learned from experience. In the next section, we present current approaches to modeling an individual's estimation uncertainty about outcomes and probabilities and how systematic environmental changes in outcome contingencies affect an individual's estimation uncertainty. Bayesian inference turns out to provide invaluable tools to achieve such quantification of uncertainty over the course of learning.
A useful way to model experience-driven learning about a subjective value v is the delta rule from reinforcement-learning theory 
(Daw, 2014;
Sutton & Barto, 1998)
:
v t+1 = v t + α t • (x t − v t )
(10)
where v refers to the subjective value, t denotes the current time point or trial, and (x t − v t ) =: δ t refers to the prediction error quantifying the difference between outcome x and subjective value v. α t indicates the learning rate that determines how strongly the decision-maker considers the prediction error for the adjustment of the subjective value (1 indicates a full consideration of the error; 0 means that the error is ignored altogether).
Bayesian inference allows us to model how an ideal decision-maker should learn to achieve maximally accurate performance 
(Dayan et al., 2000;
Yu & Dayan, 2005)
. From this perspective, uncertainty about the estimated value parameter, here referred to as estimation uncertainty, is a key factor that should govern how much the learning rate is adjusted 
(Bruckner et al., 2022;
Nassar et al., 2010
; Payzan-LeNestour & Bossaerts, . Experimental tasks and dynamic learning in economic decision-making. a| Example of a risky decision-making task where the participants choose between a risky and safe option with the same expected value. b| Example of an adaptive learning task 
(Nassar et al., 2019
). In the cannon task, subjects predict the location of cannon balls shot by a cannon. In training trials, subjects see the aim of the cannon, but in experimental trials, the cannon is hidden. Therefore, they have to infer the cannon's aim based on the observed cannon balls. c| On the one hand, learning tasks like the cannon task involve risk and estimation uncertainty due to outcome variance. That is, each cannon ball can deviate from the cannon's aim, making it impossible to predict outcomes exactly. On the other hand, the task involves changes because the cannon occasionally changes its aim. An optimal learning model would adjust predictions to both estimation uncertainty and changes. d| One key variable governing optimal learning performance is the learning rate, determining how strongly a prediction error (difference between cannon ball and expected cannon aim) influences learning. The learning rate peaks after larger prediction errors to adjust to potential changes and decreases as a function of estimation uncertainty about the cannon aim.
2011). Like risk, estimation uncertainty is defined by the variance of the variable. That is, we can use probability distributions to describe the probabilities of possible values that we aim to learn, such as an outcome probability 
(Fig. 4b)
. Consider the coinflipping game from above, but without knowing if the coin is fair (50-50 probability) or potentially biased (e.g., 70 % heads, 30 % tails). When observing multiple coin flips, one can use eq. (10) to estimate the probability of heads and tails using the prediction error. The learning rate determining the impact of the prediction error would decay over time, reflecting that estimation uncertainty decreases. Thus, lower estimation uncertainty indicates that the decision-maker has learned an accurate estimate of the value and risk of the coin, which would call for less learning.
Finally, we have so far focused on economic decision-making in stable environments. However, as also discussed for perceptual choices, outcome contingencies may change systematically. To make optimal economic decisions, agents have to constantly adjust their behavior to such environmental changes through learning. For example, when playing a coin-flipping game in which it is initially 80 % likely that the coin lands heads, but suddenly, tails are more likely, the decision-maker should adjust their choice behavior accordingly. Bayesian learning prescribes that such adjustments of subjective values (e.g., outcome probabilities in the game) should be initiated by ramping up the learning rate, assuring that the decision-maker strongly learns from the prediction error.
In many cases, risk, estimation uncertainty, and environmental changes are simultaneously present. For example, in the coin-flipping game, changes might be unsignalled, leading to uncertainty about whether a prediction error is due to a true change or just risk, especially when estimation uncertainty is high. If, for instance, the decision-maker's subjective value is v = 0.8 (80 % heads), and the coin lands tails, then the prediction error would be equal to -0.8. In this case, the decision-maker should consider the possibility that the unexpected outcome was due to risk (since 20 % tails are expected) or a systematic change (e.g., now tails have a chance of 80 %). Other examples include continuous predictive inference tasks such as the cannon task, where outcomes are shot by a hidden cannon 
(Fig. 7b)
 
(Nassar et al., 2019)
. The advantage of predictive inference tasks is that participants specify their beliefs directly, which can provide a more detailed picture of exactly how participants update their beliefs about the underlying variable, in this case, the aim of a hidden cannon 
(Nassar & Gold, 2013
). In the cannon task, risk is due to the imprecision of the cannon (the cannon ball shot from it will vary from trial to trial), and the aim of the cannon is reset occasionally on change points. Bayesian inference offers methods to compute the probability of a change, which is sometimes called unexpected uncertainty, surprise, or change-point probability, and is utilized to increase the learning rate in a manner that the higher the probability of a change, the more strongly the learning rate is scaled up 
(Fig. 7c,d
) 
(Behrens et al., 2007;
Mathys et al., 2014;
Meyniel et al., 2015;
Nassar et al., 2010;
O'Reilly et al., 2013;
Payzan-LeNestour & Bossaerts, 2011;
Yu & Dayan, 2005)
.


Behavior and Neuroscience
Economic decision-making has been the subject of extensive empirical research among both human and animal populations. In this section, we provide a focused review of studies exploring the behavioral and neural mechanisms that underpin the computational viewpoints outlined earlier in the context of economic choices.


Subjective Value and Risk
A considerable body of studies on economic decision-making has sought to identify the neural correlates of subjective value and risk, and we commence with a short overview of the former. The value system spans a collection of brain regions that are thought to represent subjective value on a common neural scale 
(Levy & Glimcher, 2012)
. That is, on a domain-general level so that primary rewards (e.g., food) and secondary rewards (e.g., money) are represented based on the same neural currency. This system includes the ventromedial prefrontal cortex (vmPFC), dorsomedial prefrontal cortex (dmPFC), dorsolateral prefrontal cortex (dlPFC), medial orbitofrontal cortex (mOFC), striatum, and insula 
(Bartra et al., 2013;
Newton-Fenner et al., 2023
). It appears that risk representations are, to a large extent, associated with the same set of brain areas.
Studies investigating decision-making under risk typically devise choice tasks featuring options with different magnitudes and outcome probabilities to manipulate expected values and risk, ideally dissociating reward magnitude, probability, expected value, and outcome variance 
(Fig. 7a
). For example, 
Tobler et al. (2007)
 presented subjects with visual objects that differed in the dimensions of shape (indicating reward magnitude) and color (indicating reward probability). That way, different stimuli can, for example, have the same expected value (e.g., 100 points) but different degrees of risk (higher vs. lower outcome variance). The results of this fMRI experiment showed that more risky stimuli elicited stronger activity in the lateral OFC. Moreover, in line with the above-described valuation system, striatal activity correlated with expected value across different combinations of magnitude and probability. Regions of the PFC responding to expected values differentially covaried with risk depending on participants' risk attitudes. In risk-seeking individuals, activity in these regions increased as a function of higher risk, while the opposite was observed for risk-averse individuals. In follow-up work, the same group reported that expected-value-related activity in the lateral PFC increases with risk in risk-seeking but decreases in risk-averse subjects, suggesting that both risk and value are integrated in this area 
(Tobler et al., 2009)
. Moreover, 
Preuschoff et al. (2006)
 used a card game where subjects gambled for monetary outcomes with orthogonal manipulations of expected value and risk in terms of outcome variance. fMRI results suggested that the ventral striatum encodes not only the expected value as described above but also risk. Finally, 
Mohr, Biele, Krugel, et al. (2010)
 used an investmentdecision task offering subjects the choice between a safe option and an investment that was presented as a stream of returns similar to a stock price. Subjects' subjectively perceived risk was associated with activity in the right anterior insula and the right OFC.
There is some evidence to suggest that the insula plays a crucial role in learning about the amount of risk. The study by 
Preuschoff et al. (2008)
 relied on a card game in which estimates of risk had to be updated over the course of a trial, leading to risk-prediction errors that can be used for learning about risk, in analogy to reward-prediction errors for learning about subjective values. The results showed that activity in the insula correlated with risk-related prediction errors as well as the degree of risk as such. Crucially, the two signals emerged on two different time scales. Risk-prediction errors were associated with a fast onset, in line with the idea that such errors drive learning about risk. In contrast, risk representations were considerably slower, potentially suggesting a role in the anticipation of risk after a choice.
More recent studies capitalized on multivariate decoding approaches to analyzing neural representations of subjective value and economic risk. A magnetoencephalography (MEG) study featuring a simple response task probed neurophysiological representations of subjective value and economic risk, showing that value and risk have dissociable neural representations 
(Bach et al., 2017)
. However, both types of representation emerged in parietal and frontal regions, including the OFC. Crucially, this work also provided evidence for representations of subjective value and economic risk in sensory (here visual) areas. Functional neuroimaging combined with decoding analyses can also be utilized to predict risky choices based on brain activity at a level of approximately 70 % accuracy 
(Helfinstein et al., 2014)
. One conclusion of this study was that these predictions are, to a large extent, driven by specific activity patterns in the neural networks responsible for cognitive control. These control regions exhibited higher levels of activation before subjects made safe as opposed to risky choices, implying that control systems play a significant role in suppressing risky decision-making.
Two systematic meta-analyses on risk have identified several key areas for risk processing that are generally in line with the example studies above 
Wu et al., 2021)
. Both confirmed that the anterior insula is involved in risk processing, primarily when choices involve potential losses. This finding is usually interpreted in terms of emotional processing and arousal, suggesting that risk processing has affective components. Moreover, risk was related to the ventral striatum, dmPFC, dlPFC, and parietal cortex, potentially related to the engagement of cognitive control and executive functions that generally concern decision-making, such as processing of outcome probability, expected-value calculation, and decision formation 
(Knutson & Huettel, 2015)
.
Finally, we turn to a discussion of potential behavioral and neural evidence for the two common modeling approaches to risky decision-making (expectation-based and meanvariance approaches). In general, it is challenging to distinguish the two approaches, primarily because they often make quite similar predictions and because most studies usually only follow one of the two approaches 
(Boorman & Sallet, 2009;
d'Acremont & Bossaerts, 2008;
Tobler & Weber, 2014;
Williams et al., 2021)
. Moreover, it is possible that humans employ both expectation-based computations (e.g., as proposed by prospect theory) and mean-variance approaches (e.g., risk-penalized expected values). d' 
Acremont and Bossaerts (2008)
 have argued that mean-variance decomposition might be faster to implement, while expectation-based computations are computationally more demanding. Therefore, depending on the situation, subjects may rely on a mixed strategy, and more recent evidence suggests that two such factors are task complexity and the way risk is revealed to subjects 
(Spiliopoulos & Hertwig, 2019)
. When risk was descriptively stated in a complex task with multiple options, prospect theory provided a better fit than mean-variance approaches, but vice versa when risk had to be learned from experience. Therefore, current work aims to develop integrated models that capture these mixed results 
(Spiliopoulos & Hertwig, 2023)
. The perspective that both expectation-based and mean-variance models depict elements of risky decision-making has recently also been supported by an fMRI study 
(Williams et al., 2021)
. Based on a model comparison between both approaches on the neural level, the study revealed that a mean-variance model (including skewness) best explained subjective-value correlates in the vmPFC and dlPFC. In contrast, prospect theory captured patterns in the striatum and parietal cortex better.
Moreover, another recent approach to dissociating models of risky decision-making was presented by 
Peterson et al. (2021)
, who combined a large-scale experiment and machine learning to explore a large range of choice models. The study included almost 15k participants and a broad range of features of the choice task, including reward probabilities. Regarding a comparison between expectation-based and mean-variance approaches (and many other models, including choice heuristics), the study favored expectationbased theories, in particular prospect-theory-based models. However, most importantly, this big-data approach yielded an extended contextual "mixture-of-theories" model that outperformed canonical prospect theory. This model included two utility functions and probability functions, and depending on the exact trial characteristics (e.g., maximum outcome, minimum outcome, and outcome variability), one such utility and probability function was selected. Importantly, such functions resembled prospect theory, specifically the differences between gains and losses (for a comparable utility function from prospect theory, see 
Fig. 5c
) as well as over-weighting of smaller probabilities and underweighting of larger probabilities (for a comparable probability function from prospect theory, see 
Fig. 5d
). Thus, currently, it seems that across a large set of risky choice problems, the basic tenets of prospect theory are well supported and it turns out that the exact shape of utility and probability transformations depends on the task features.


Description-Experience Gap
When risk is not described but instead learned from experience, risk attitudes are often substantially different than those discussed so far. In particular, in description-based choices, people generally overweight small probabilities. In contrast, in experience-based scenarios, people often underweight lower probabilities 
(Hertwig et al., 2004)
. This discrepancy is called the description-experience gap 
(Hertwig & Erev, 2009)
. One important factor explaining this gap is that decisions from description tend to be based on small samples, that is, limited experience 
(Hertwig et al., 2004)
. Therefore, unlikely events are often either not experienced at all or less frequently compared to the actual but unknown likelihood. This line of inquiry has put forward a fourfold pattern of knowledge states by a combination of description and experience 
(Table 3
; 
Hertwig and Wulff, 2022
  decisions are solely based on descriptive information, subjective probabilities follow the pattern as described by prospect theory (top left). However, when choices are only based on experience, this pattern often reverses, and people tend to underweight smaller probabilities (bottom right). 
Hertwig and Wulff (2022)
 further report that under some circumstances, people tend to overweight smaller probabilities. For example, the hotstove effect describes avoidance behavior after an extremely negative experience, such as a cat consistently avoiding stoves after a single negative experience. When both descriptive and experience-based information is available, both factors govern choices, but overall, the effect of experience seems to be stronger (top right). Finally, when decision-makers can neither draw on descriptive information nor relevant experience, they are in a state of maximal uncertainty or ambiguity, where people generally seem to be ambiguity-averse (bottom left; e.g., reviewed in 
Rangel et al., 2008;
Tobler & Weber, 2014)
.


Risk-Sensitive Value Learning
Following the previous point that risky options often have to be learned from experience, we now turn to the computational basics of learning under uncertainty. One way to accomplish this is through trial and error, as defined by the delta-rule (eq. (10)). Within the broader field of decision neuroscience, value learning through reinforcement holds a central position as one of its main branches. A key insight from more than 25 years of research is that subjective values are updated through prediction errors, implemented in the midbrain dopamine system and its targets, particularly in the striatum 
(Montague et al., 1996;
Schultz, 2016;
Schultz et al., 1997)
. In this chapter, we focus on the role that uncertainty plays in error-driven learning. For more details on the basics of dopamine and reinforcement learning, see 
Froemer and Nassar (2024)
 in this encyclopedia.
There is evidence to suggest that dopamine neurons signal prediction errors scaled by the range or standard deviation of reward magnitudes instead of the raw prediction error. In the study by 
Tobler et al. (2005)
, the authors presented reward-predicting stimuli that differed in terms of reward probability and magnitude while recording the activity of single dopamine neurons in the monkey midbrain. Crucially, the gain of prediction errors depended on the standard deviation of reward magnitudes. Adjusting the encoded prediction errors in relation to the standard deviation might optimize neural sensitivity for detecting smaller differences when the variability in prediction errors is reduced. Thus, the larger of two potential rewards always elicits the same increase in activity, and the smaller of the two elicits the same decrease in activity, regardless of absolute magnitude. This kind of adaptive coding scheme has more recently also been reported in humans, where error correlates in the striatum adapted to the probability of prediction errors (S. Q. 
Park et al., 2012)
.
Under some circumstances, range-adjusted prediction errors might help the nervous system learn subjective values more accurately than learning based on raw errors. In particular, when outcomes are generated by a continuous distribution (e.g., Gaussian distribution), where risk-generating outcome variability is independent of the average reward magnitude. For example, two Gaussians might have the same mean payout (e.g., mean µ = 100 points) but different variance parameters. A distribution with low variance (e.g., σ 2 = 10) would be considered less risky than a distribution with higher variance (e.g., σ 2 = 100) since outcomes can be predicted more reliably. At the same time, learning should be faster in the first case since each outcome provides more reliable, that is, less noisy, information about the mean. There is some evidence to suggest that human subjects compute scaled prediction errors during reinforcement learning accordingly. 
Diederen et al. (2016)
 had subjects perform a learning task with Gaussian outcome distributions with different degrees of risk (low, medium, and high standard deviation). Behaviorally, this study provided evidence that subjects scaled prediction errors driving learning according to the distribution's standard deviation, resulting in slower learning for more risky distributions. While performing the task, subjects underwent an fMRI session, and results suggested that prediction errors in the midbrain and the ventral striatum were stronger when risk was lower (smaller standard deviation). This finding is in line with the idea that humans adaptively adjust learning to the amount of risk in the environment.


Estimation Uncertainty and Environmental Changes
We can go one step further and flesh out what learning looks like from a Bayesian perspective to better understand how an ideal agent would learn under risk. Estimation uncertainty reflects the decision-maker's internal uncertainty about the learned subjective value and would tend to be higher over the course of learning when risk is higher, similar to the results by 
Diederen et al. (2016)
. However, a Bayesian perspective primarily focuses on the dynamic adjustment of learning rates rather than prediction errors and prescribes that learning rates should be lower under higher estimation uncertainty.
Several studies that combined risky outcomes and changing outcome contingencies provide evidence that learning rates in human subjects change dynamically as a function of estimation uncertainty (see 
Fig. 7a
,b for example tasks). One study used a gambling task with multiple risky options (yielding either a reward, a neutral outcome, or a loss), and computational modeling favored a Bayesian model with uncertainty-dependent learning rates 
(Payzan-LeNestour & Bossaerts, 2011)
. Moreover, results indicated that subjects flexibly adjusted to changes in reward probabilities, which increases estimation uncertainty. A neuroimaging study revealed that estimation uncertainty correlated with activity in the anterior cingulate cortex (ACC), extending into the dmPFC 
(Payzan-LeNestour et al., 2013)
. Environmental changes were associated with brainstem activity, most likely the locus coeruleus, suggesting the involvement of the norepinephrine system. In a related study by 
Meyniel and Dehaene (2017)
, the task included not only visual but also auditory stimuli. Changes in outcome probabilities were associated with sensory activity (auditory activity in the auditory version, visual activity in the visual case). Furthermore, estimation uncertainty (referred to as confidence) correlated with parietal activity, and the joint influence of change-related surprise and estimation uncertainty emerged in the inferior frontal gyrus. Finally, work by 
McGuire et al. (2014)
 similarly reported that change-point-driven learning is associated with sensory, in that case visual, brain activity, while uncertainty-driven learning was linked to the medial PFC and parietal areas. These regions were functionally connected to a larger constellation of brain regions (dlPFC, ACC, insula, intraparietal sulcus) that was linked to learning behavior, in particular the degree to which participants would update beliefs in response to a given prediction error, providing a potential mechanistic account for how detected change points and uncertainty contribute to online calibrations of learning.
Taken together, the emerging picture is that learning under risk and in changing environments recruits additional areas than decision-making under risk with stated outcome probabilities. These regions include sensory areas involved in the detection of changes, brainstem activity, potentially initiating surging learning rates after changes, and a frontoparietal network, including the medial PFC, calibrating learning in response to risk and estimation uncertainty. We close this section on learning in changing environments by highlighting recent developments incorporating simultaneous learning about risk and changes into learning models 
(Nassar et al., 2010;
Nassar et al., 2016;
Piray & Daw, 2021
). As we have seen in the sections on risky decision-making, humans seem to have distorted representations of risk and probabilities. Consistent with this, a recent study requiring dynamic learning suggested that some participants (about 30 % in their sample) were insensitive to risk during learning, while another subgroup was insensitive to change (also approximately 30 %). Consequently, these subjects showed maladaptive learning behavior compared to subjects that estimated risk and environmental changes more precisely 
(Piray & Daw, 2023)
.


Convergence of Perceptual and Economic Decision-Making
We conclude our chapter with a discussion of the commonalities of perceptual and economic decision-making. Most decisions involve perceptual categorization of sensory evidence (perceptual decision-making) and reward or motivational components (economic decision-making) 
(Summerfield & Tsetsos, 2012)
. Recall our initial example in the section on perceptual decision-making, where we alluded to a person who decides when to cross the street when a car is approaching. While this decision is clearly driven by the available sensory information, the decision-maker is also motivated to avoid an accident (i.e., punishment) and, since the stakes are high, most likely acts in a particularly riskaverse way. Similarly, in order to make an economic choice, we first have to process the available sensory information, for example, when deciding when to change lanes in traffic. Therefore, it is not surprising that different lines of research suggest partly overlapping neurocomputational mechanisms and an interplay of both types of decision-making.


Shared Computational Mechanisms
An overarching computational principle of both perceptual and economic decision-making is Bayesian inference 
(Daw, 2014;
Dayan & Daw, 2008;
Fiser et al., 2010)
. Throughout the chapter, we have touched upon this topic several times, for instance, concerning the current state in the environment by computing belief states, when computing the probability of a change to guide sensory evidence accumulation, or updates of the subjective value in economic choice. To recall what we covered earlier, Bayesian inference refers to drawing conclusions based on the currently available knowledge and is the key to reasoning under uncertainty 
(Bernardo & Smith, 2009;
K. P. Murphy, 2012)
. From this perspective, perceptual and economic decision-making (in particular, reward-based learning to find out what actions to take) rely on the same computational mechanisms but on at least two different time scales. Perceptual inference takes place rapidly and often concerns evidence within a trial, and reward inference often takes place more slowly, mostly across trials 
(Fiser et al., 2010)
. Therefore, it is worth highlighting some mechanisms for perceptual and economic choice that might seem disconnected in the first place but basically rely on similar computational principles. Perceptual uncertainty shares some interesting commonalities with risk. Our working definition of both types of uncertainty was directly related to the variance of outcome distributions. In the perceptual case, variance leads to noisy sensory information (e.g., speed of the car), while in the economic case, variance yields outcome noise or stochasticity (e.g., coin-flipping game). In fact, in both cases, these types of uncertainty lead to estimation uncertainty and should govern learning 
(Dayan et al., 2000;
Krishnamurthy et al., 2017;
Meyniel et al., 2015;
Nassar et al., 2010;
Payzan-LeNestour & Bossaerts, 2011;
Sato & Kording, 2014;
Vilares et al., 2012)
. Moreover, we have presented studies examining perceptual and economic choices in changing environments, where the probability of a change can be computed based on Bayesian inference 
(Drevet et al., 2022;
Glaze et al., 2015;
Meyniel et al., 2015;
P. R. Murphy et al., 2021;
Nassar et al., 2010;
Payzan-LeNestour & Bossaerts, 2011;
Sato & Kording, 2014;
Yu & Dayan, 2005)
. Hence, these examples emphasize that both types of decision-making under uncertainty share important principles that can be examined within a Bayesian framework.


Interplay of Perceptual and Economic Decision-Making
A growing number of studies elucidates the overlap and interplay of perceptual and economic choice computations. 
Polanía et al. (2014)
 developed a choice paradigm in which perceptual and economic choices could be probed based on the same stimuli and motor responses. The study also relied on electroencephalography (EEG) and a common computational sequential sampling framework as often used in perceptual decision-making (and further discussed in the context of economic choices in the chapter by 
Froemer and Nassar (2024)
). In both conditions, evidence accumulation was observed in parietal oscillations, and a corresponding frontal signal was specific to economic choices. The synchronization between these frontal and parietal signals was found to predict the accuracy of economic choices. These findings imply that parietal regions encode a shared decision variable for both types of choices, while frontal regions engage in an additional cognitive process unique to economic decision-making.
Moreover, reward-based learning often takes place under perceptual uncertainty. Research on this intersection between perceptual and economic decision-making asks whether humans and animals actively take into account perceptual uncertainty and belief states for optimizing reward-based learning. For example, in traffic, both perceptual uncertainty (poor visibility) and risk (unpredictable behavior of other drivers) are often present, and a Bayesian perspective calls for an integration of these two types of uncertainty 
(Bruckner et al., 2020;
Djurić & Huang, 2000)
. 
Bruckner et al. (2020)
 presents evidence to suggest that human subjects consider their belief states to reduce the learning rate when belief states are more uncertain. Subjects had to learn which economic choices maximize reward while being confronted with varying levels of perceptual uncertainty. Learning was captured by a Bayesian learning model that scaled learning according to the belief state in order to avoid corrupted learning due to misperceived stimuli. However, at the same time, people seem to differ in the extent to which they consider their belief states, with some ignoring belief-state uncertainty altogether and others showing a closer correspondence to Bayesian learning.
Further work suggested that subjects adaptively take into account perceptual uncertainty in changing environments 
(Drevet et al., 2022)
. This study relied on a perceptual choice task with occasional changes in the absence of reward uncertainty due to risk. Modeling suggested that subjects adjusted learning to perceptual uncertainty. However, instead of considering stimuli according to their reliability (which would be in line with an optimal Bayesian strategy), they were shown to only consider newly arriving sensory observations that were perceived as being sufficiently reliable. In contrast, when sensory information was deemed too uncertain, subjects ignored the stimulus altogether. Moreover, the study by Ez-Zizi et al. (2023) combined perceptual uncertainty, risk, and environmental changes. Across two experiments, the task featured conditions combining perceptual uncertainty and environmental changes, as well as risky decision-making with changing reward contingencies. Computational modeling favored a reinforcementlearning model that ignored perceptual uncertainty. While this ignorance of perceptual uncertainty seems sub-optimal, it might have led to an improved ability to adjust to changes in this specific task. Finally, work in animals based on a perceptual choice task with substantial perceptual uncertainty but no risk or environmental changes points to a neural mechanism that scales dopaminergic reward-prediction errors as a function of ambiguous belief states due to perceptual uncertainty 
(Lak et al., 2017
(Lak et al., , 2020
. Taken together, to date, several studies have examined the interplay of perceptual decisionmaking and reward-based learning. Both behavioral and neural evidence suggests that humans and animals consider perceptual uncertainty and belief states during learning. However, the exact mechanisms and factors that determine the strength or absence of this integration need to be further examined in future work.


Discussion and Conclusion
Decision-making is an important cognitive process involving choices based on sensory information and personal preferences. It has been studied extensively in economics and psychology. The emerging field of decision neuroscience, or neuroeconomics, integrates these disciplines with neuroscience to explore the neural mechanisms behind decisionmaking in humans and animals. This chapter presents an overview of decision-making under uncertainty and distinguishes perceptual choices based on sensory information from economic choices that are guided by subjective values. We have covered several established approaches to these two types of decision-making, including signal-detection theory, sequential sampling models, and approaches to risky decision-making and reinforcement learning. As an overarching perspective, we have referred to Bayesian inference, which offers a framework for both perceptual choices and reward-based learning.
Decision neuroscience explores many other effects and approaches to decision-making under uncertainty that go beyond the scope of this chapter. As briefly mentioned above, the exact definition of risk and risk-taking can be quite different between different scientific disciplines. We have adopted an economic definition in terms of outcome variance. However, from a clinical perspective and according to everyday conceptions, risk is more closely related to negative events, and several recent attempts offer promising approaches to bridging this gap 
(Gagne & Dayan, 2022;
Schonberg et al., 2011)
. Moreover, studies comparing different behavioral tasks like gambling paradigms mentioned above found relatively weak associations across tasks 
(Frey et al., 2017;
Frey et al., 2021)
. Similarly, correlations between behavioral measures and self-reported risk preferences based on questionnaires tend to be weak. These results raise questions as to whether risky decision-making tasks can be used to measure general risk preferences and whether they are useful predictors for real-life behavior, which is an ongoing topic of investigation 
(Hertwig et al., 2018)
.
Moreover, we would like to point to the emerging literature on sequential sampling in the context of economic decision-making and refer to chapter the chapter by 
Froemer and Nassar (2024)
 for more details. We have also not addressed social decision-making, where uncertainty is particularly complex 
(FeldmanHall & Nassar, 2021;
FeldmanHall & Shenhav, 2019)
. Finally, both perceptual and economic choices are often affected by biases that we have not considered here. Some biases arise under uncertainty across different tasks and might be partly linked to psychopathology, which is often investigated in computational psychiatry 
(Bruckner et al., 2022;
Huys et al., 2021)
.
To conclude, uncertainty almost always pervades decision-making in some form. Decision neuroscience studies different kinds of choices under uncertainty, including perceptual decision-making based on uncertain sensory evidence and economic choices based on subjective values and risk. Both interact in naturalistic circumstances and partly rely on shared neurobiological and computational mechanisms. Figures were created in Python 3.10 (Python Software Foundation). We used the matplotlib 
(Hunter, 2007)
, seaborn 
(Waskom, 2021)
, NumPy 
(Harris et al., 2020)
, SciPy 
(Virtanen et al., 2020)
, and pandas (McKinney, 2010; pandas development team, 2020) libraries. "Porsche" and "warning" icons ( 
Fig. 1
) by Icons8. "Coin-toss" icon ( 
Fig. 5)
 by Flaticon.
0%


Figure 4 .
4
Risk and estimation uncertainty. Risk and estimation uncertainty are two related but partly dissociable concepts.


Figure 5 .
5
Risk taking and expectation-based approaches to economic decision-making. a| Human risk-taking is often seemingly inconsistent across different choice situations. Consider a simple coin-flipping game,


Figure 6. Mean-variance approaches to economic decision-making. Mean-variance approaches assume that decision-makers are generally risk-averse. When two assets have the same expected value, investors will prefer the one with lower risk (lower variance), and options with more risk are only more attractive if they offer a higher expected return (risk premium). a| The indifference curve describes the options that are equally preferred by the decision-maker as a function of their expected value and risk. That is, each illustrated line shows different combinations of expected value and risk that would be associated with the same expected utility. The two curves showing risk-averse investors illustrate that higher expected gains can compensate for higher risk. Theoretically, a risk-neutral investor would not consider the amount of risk, and a risk-seeker would even prefer options with higher risk and lower expected returns. b| The coefficient of variation formalizes risk in terms of the standard deviation relative to the expected value of an option. While the standard deviation can remain constant across a range of expected values, the coefficient of variation decreases as a function of the value. Consequently, risk would tend to be higher for options with higher standard deviation and lower expected values compared to options with the same standard deviation but higher values.


Figure 7. Experimental tasks and dynamic learning in economic decision-making. a| Example of a risky decision-making task where the participants choose between a risky and safe option with the same expected value. b| Example of an adaptive learning task (Nassar et al., 2019). In the cannon task, subjects predict the location of cannon balls shot by a cannon. In training trials, subjects see the aim of the cannon, but in experimental trials, the cannon is hidden. Therefore, they have to infer the cannon's aim based on the observed cannon balls. c| On the one hand, learning tasks like the cannon task involve risk and estimation uncertainty due to outcome variance. That is, each cannon ball can deviate from the cannon's aim, making it impossible to predict outcomes exactly. On the other hand, the task involves changes because the cannon occasionally changes its aim. An optimal learning model would adjust predictions to both estimation uncertainty and changes. d| One key variable governing optimal learning performance is the learning rate, determining how strongly a prediction error (difference between cannon ball and expected cannon aim) influences learning. The learning rate peaks after larger prediction errors to adjust to potential changes and decreases as a function of estimation uncertainty about the cannon aim.


, offers
b a
Probability Belief State
Car Speed Signal Detection C a r S lo w C a r F a s t
c
Starting Point
Time Colored Lines: Drift Rate
Decision Boundary Slow Medium Fast


Examples of perceptual decision-making research. a| The
random-dot motion task is commonly used to examine perceptual decision-making. A cloud of moving dots is presented, and subjects have to indicate the average movement direction. In this example, the coherence is 0 %, i.e., all dots are moving in a random direction. b| This example shows 50 % coherence in the right direction. c| Example of 100 % coherence in the right direction. d| Schematic illustration of the psychometric and neurometric curve in a monkey experiment with single-cell recordings (e.g.,
a
Coherence
b
50% Coherence Right
c
100% Coherence Right
Proportion Correct
0.5 0.6 0.7 0.8 0.9 1.0 d
Psychometric Neurometric
e
Choice ? Changing Environment Same State New State
Evidence f
0.4
Coherence
Time
Figure 3.


4 Economic Decision-Making
a
0.20 0.25
b
Lower Uncertainty Higher Uncertainty True Probability
Risk (Variance)
0.10 0.15
Probability
0.05
0.00
0.0
0.2
0.4 Outcome Probability 0.6
0.8
1.0
0.0
0.2
0.4 Outcome Probability 0.6
0.8
1.0


Table 2 .
2
Prospect theory: Fourfold pattern of risk attitudes.
Probability Outcome Domain
Gain
Loss
High
Risk-averse: Preferring safe
Risk-seeking: Keeping losing
over risky financial investments
stocks for too long
Low
Risk-seeking: Playing the lottery Risk-averse: Being over-insured


Table 3 .
3
Description versus experience: Fourfold pattern of epistemic states.








Acknowledgments
We thank Muhammad Hashim Satti and Prashanti Ganesh for useful discussions and comments on a previous version of the chapter. R.B. was supported by DFG (Deutsche Forschungsgemeinschaft) grant 412917403. M.R.N was supported by NIMH R01 MH126971.






Conflict of interest disclosure
The authors declare no competing interests.
 










Whole-brain neural dynamics of probabilistic reward prediction




D
R
Bach






M
Symmonds






G
Barnes






R
J
Dolan




10.1523/JNEUROSCI.2943-16.2017








NeuroImage




37


14
















Knowing how much you don't know: A neural organization of uncertainty estimates




D
R
Bach






R
J
Dolan




10.1038/nrn3289








Nature Reviews Neuroscience




13


8
















The valuation system: A coordinatebased meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value




O
Bartra






J
T
Mcguire






J
W
Kable




10.1016/j.neuroimage.2013.02.063








NeuroImage




76
















Probabilistic population codes for Bayesian decision making




J
M
Beck






W
J
Ma






R
Kiani






T
Hanks






A
K
Churchland






J
Roitman






M
N
Shadlen






P
E
Latham






A
Pouget




10.1016/j.neuron.2008.09.021








Neuron




60


6
















Learning the value of information in an uncertain world




T
E J
Behrens






M
W
Woolrich






M
E
Walton






M
F S
Rushworth




10.1038/nn1954








Nature Neuroscience




10


9
















Bayesian Theory




J
M
Bernardo






A
F M
Smith




10.1002/9780470316870








John Wiley & Sons












Exposition of a new theory on the measurement of risk [translation by L. Sommer of D. Bernoulli, 1738, Specimen Theoriae Novae de mensura sortis




D
Bernoulli








Commentarii Academiae Scientiarum Imperialis Petropolitanae




5


















10.2307/1909829








Econometrica




22


1


















Z
Bodie






A
Kane






Marcus








Investments. McGrawHill
















The neural basis of the speed-accuracy tradeoff




R
Bogacz






E
J
Wagenmakers






B
U
Forstmann






S
Nieuwenhuis




10.1016/j.tins.2009.09.002








Trends in Neurosciences




33


1
















Mean-variance or prospect theory? The nature of value representations in the human brain




E
D
Boorman






J
Sallet




10.1523/JNEUROSCI.1876-09.2009








Journal of Neuroscience




29


25
















A relationship between behavioral choice and the visual responses of neurons in macaque MT




K
H
Britten






W
T
Newsome






M
N
Shadlen






S
Celebrini






J
A
Movshon




10.1017/S095252380000715X








Visual Neuroscience




13


1
















The analysis of visual motion: A comparison of neuronal and psychophysical performance




K
H
Britten






M
N
Shadlen






W
T
Newsome






J
A
Movshon




10.1523/JNEUROSCI.12-12-04745.1992








Journal of Neuroscience




12


12
















Understanding learning through uncertainty and bias




R
Bruckner






H
R
Heekeren






M
R
Nassar




10.31234/osf.io/xjkbg


















Belief states and categorical-choice biases determine reward-based learning under perceptual uncertainty




R
Bruckner






H
R
Heekeren






D
Ostwald




10.1101/2020.09.18.303495


















Neurobiological studies of risk assessment: A comparison of expected utility and mean-variance approaches. Cognitive, Affective




M
Acremont






P
Bossaerts




10.3758/CABN.8.4.363








& Behavioral Neuroscience




8
















Advanced reinforcement learning




N
D
Daw




10.1016/B978-0-12-416008-8.00016-4








Neuroeconomics: Decision Making and the Brain


P. W. Glimcher & E. Fehr




Academic Press










2nd edition








Decision theory, reinforcement learning, and the brain




P
Dayan






N
D
Daw




10.3758/CABN.8.4.429








Cognitive, Affective, & Behavioral Neuroscience




8


4
















Learning and selective attention




P
Dayan






S
Kakade






P
R
Montague




10.1038/81504








Nature Neuroscience




3


11
















Adaptive prediction error coding in the human midbrain and striatum facilitates behavioral adaptation and learning efficiency




K
M
Diederen






T
Spencer






M
D
Vestergaard






P
C
Fletcher






W
Schultz










Neuron




90


5
















Caudate encodes multiple computations for perceptual decisions




L
Ding






J
I
Gold




10.1523/JNEUROSCI.2894-10.2010








Journal of Neuroscience




30


47
















Neural correlates of perceptual decision making before, during, and after decision commitment in monkey frontal eye field




L
Ding






J
I
Gold




10.1093/cercor/bhr178








Cerebral Cortex




22


5
















Estimation of a Bernoulli parameter p from imperfect trials




P
M
Djurić






Y
Huang




10.1109/97.844638








IEEE Signal Processing Letters




7


6
















Efficient stabilization of imprecise statistical inference through conditional belief updating




J
Drevet






J
Drugowitsch






V
Wyart




10.1038/s41562-022-01445-0








Nature Human Behaviour




6


12
















A cortical representation of the local visual environment




R
Epstein






N
Kanwisher




10.1038/33402








Nature




392


6676
















Reinforcement learning under uncertainty: Expected versus unexpected uncertainty and state versus reward uncertainty




A
Ez-Zizi






S
Farrell






D
Leslie






G
Malhotra






C
J
Ludwig




10.1007/s42113-022-00165-y








Computational Brain & Behavior




6


















G
T
Fechner




Elemente der Psychophysik. Breitkopf u. Härtel
















The computational challenge of social learning




O
Feldmanhall






M
R
Nassar




10.1016/j.tics.2021.09.002








Trends in Cognitive Sciences




25


12
















Resolving uncertainty in a social world




O
Feldmanhall






A
Shenhav




10.1038/s41562-019-0590-x








Nature Human Behaviour




3


5
















Statistically optimal perception and learning: From behavior to neural representations




J
Fiser






P
Berkes






G
Orbán






M
Lengyel




10.1016/j.tics.2010.01.003








Trends in Cognitive Sciences




3


14
















Cortico-striatal connections predict control over speed and accuracy in perceptual decision making




B
U
Forstmann






A
Schäfer






A
Neumann






J
Brown






S






J






W
E
Bogacz






R
Turner






R




10.1073/pnas.1004932107








Proceedings of the National Academy of Sciences




107


36
















Striatum and pre-SMA facilitate decisionmaking under time pressure




B
U
Forstmann






G
Dutilh






S
Brown






J
Neumann






D
Y
Von Cramon






K
R
Ridderinkhof






E
J
Wagenmakers




10.1073/pnas.0805903105








Proceedings of the National Academy of Sciences




105


45
















Sequential sampling models in cognitive neuroscience: Advantages, applications, and extensions




B
Forstmann






R
Ratcliff






E.-J
Wagenmakers




10.1146/annurev-psych-122414-033645








Annual Review of Psychology




67


1
















Risk preference shares the psychometric structure of major psychological traits




R
Frey






A
Pedroni






R
Mata






J
Rieskamp






R
Hertwig




10.1126/sciadv.1701381








Science Advances




3


10














Identifying robust correlates of risk preference: A systematic approach using specification curve analysis




R
Frey






D
Richter






J
Schupp






R
Hertwig






R
Mata




10.1037/pspp0000287








Journal of Personality and Social Psychology




120


2
















Belief updates, learning and adaptive decision making




R
Froemer






M
R
Nassar




10.1016/b978-0-12-820480-1.00059-0








Reference Module in Neuroscience and Biobehavioral Psychology. Elsevier
















Peril, prudence and planning as risk, avoidance and worry




C
Gagne






P
Dayan




10.1016/j.jmp.2021.102617








Journal of Mathematical Psychology




106


102617














Subjective confidence reflects representation of Bayesian probability in cortex




L
S
Geurts






J
R
Cooke






R
S
Van Bergen






J
F
Jehee




10.1038/s41562-021-01247-w








Nature Human Behaviour




6


2
















Normative evidence accumulation in unpredictable environments. eLife, 4, e08825




C
M
Glaze






J
W
Kable






J
I
Gold




10.7554/eLife.08825


















Neuroeconomics: Decision Making and the Brain




P
W
Glimcher






E
Fehr








Academic Press












Neural mechanisms for perceptual decision making




J
I
Gold






H
R
Heekeren




10.1016/B978-0-12-416008-8.00019-X








Neuroeconomics: Decision Making and the Brain


P. W. Glimcher & E. Fehr




Academic Press










2nd edition








Representation of a perceptual decision in developing oculomotor commands




J
I
Gold






M
N
Shadlen




10.1038/35006062








Nature




404


6776
















The influence of behavioral context on the representation of a perceptual decision in developing oculomotor commands




J
I
Gold






M
N
Shadlen




10.1523/JNEUROSCI.23-02-00632.2003








Journal of Neuroscience




23


2
















Visual decision-making in an uncertain and dynamic world




J
I
Gold






A
A
Stocker




10.1146/annurev-vision-111815-114511








Annual Review of Vision Science




3
















Signal Detection Theory and Psychophysics




D
M
Green






J
A
Swets








Wiley


New York












Reduction of influence of task difficulty on perceptual decision making by STN deep brain stimulation




N
Green






R
Bogacz






J
Huebl






A
K
Beyer






A
A
Kühn






H
R
Heekeren




10.1016/j.cub.2013.07.001








Current Biology




23


17
















Array programming with NumPy




C
R
Harris






K
J
Millman






S
J
Van Der Walt






R
Gommers






P
Virtanen






D
Cournapeau






E
Wieser






J
Taylor






S
Berg






N
J
Smith






R
Kern






M
Picus






S
Hoyer






M
H
Van Kerkwijk






M
Brett






A
Haldane






J
F
Del Río






M
Wiebe






P
Peterson






.
.
Oliphant






T
E




10.1038/s41586-020-2649-2








Nature




585


7825
















The functional organization of human extrastriate cortex: A PET-rCBF study of selective attention to faces and locations




J
V
Haxby






B
Horwitz






L
G
Ungerleider






J
M
Maisog






P
Pietrini






C
L
Grady




10.1523/JNEUROSCI.14-11-06336.1994








Journal of Neuroscience




14


11
















A general mechanism for perceptual decision-making in the human brain




H
R
Heekeren






S
Marrett






P
A
Bandettini






L
G
Ungerleider




10.1038/nature02966








Nature




431


7010
















Predicting risky choices from brain activity patterns




S
M
Helfinstein






T
Schonberg






E
Congdon






K
H
Karlsgodt






J
A
Mumford






F
W
Sabb






T
D
Cannon






E
D
London






R
M
Bilder






R
A
Poldrack




10.1073/pnas.1321728111








Proceedings of the National Academy of Sciences




7


1111
















Decisions from experience and the effect of rare events in risky choice




R
Hertwig






G
Barron






E
U
Weber






I
Erev




10.1111/j.0956-7976.2004.00715.x








Psychological Science




15


8
















The description-experience gap in risky choice




R
Hertwig






I
Erev




10.1016/j.tics.2009.09.004








Trends in Cognitive Sciences




13


12
















A description-experience framework of the psychology of risk




R
Hertwig






D
U
Wulff




10.1177/17456916211026896








Perspectives on Psychological Science




17


3
















Three gaps and what they may mean for risk preference




R
Hertwig






D
U
Wulff






R
Mata




10.1098/rstb.2018.0140








Philosophical Transactions of the Royal Society B: Biological Sciences




374














Matplotlib: A 2d graphics environment




J
D
Hunter




10.1109/MCSE.2007.55








Computing in Science & Engineering




9


3
















Advances in the computational understanding of mental illness




Q
J M
Huys






M
Browning






M
P
Paulus






M
J
Frank




10.1038/s41386-020-0746-4








Neuropsychopharmacology




46


1
















Relationships between pupil diameter and neuronal activity in the locus coeruleus, colliculi, and cingulate cortex




S
Joshi






Y
Li






R
M
Kalwani






J
I
Gold




10.1016/j.neuron.2015.11.028








Neuron




89


1
















Prospect theory: An analysis of decision under risk




D
Kahneman






A
Tversky




10.2307/1914185








Econometrica




47


2
















The fusiform face area: A module in human extrastriate cortex specialized for face perception




N
Kanwisher






J
Mcdermott






M
M
Chun




10.1523/JNEUROSCI.17-11-04302.1997








Journal of Neuroscience




17


11
















Dissociated functional significance of decision-related activity in the primate dorsal stream




L
N
Katz






J
L
Yates






J
W
Pillow






A
C
Huk




10.1038/nature18617








Nature




535


7611


















F
H
Knight




Risk, Uncertainty and Profit


Cambridge




Houghton Mifflin














The risk matrix




B
Knutson






S
A
Huettel




10.1016/j.cobeha.2015.10.012








Current Opinion in Behavioral Sciences




5
















Arousal-related adjustments of perceptual biases optimize perception in dynamic environments




K
Krishnamurthy






M
R
Nassar






S
Sarode






J
I
Gold




10.1038/s41562-017-0107








Nature Human Behaviour




1


6


107














Midbrain dopamine neurons signal belief in choice accuracy during a perceptual decision




A
Lak






K
Nomoto






M
Keramati






M
Sakagami






A
Kepecs




10.1016/j.cub.2017.02.026








Current Biology




27


6
















Dopaminergic and prefrontal basis of learning from sensory confidence and reward value




A
Lak






M
Okun






M
M
Moss






H
Gurnani






K
Farrell






M
J
Wells






C
B
Reddy






A
Kepecs






K
D
Harris






M
Carandini




10.1016/j.neuron.2019.11.018








Neuron




105


4
















The root of all value: A neural common currency for choice




D
J
Levy






P
W
Glimcher




10.1016/j.conb.2012.06.001








Current Opinion in Neurobiology




22


6




















G
Loewenstein






S
Rick






J
D
Cohen




10.1146/annurev.psych.59.103006.093710








Neuroeconomics. Annual Review of Psychology




59
















Bayesian inference with probabilistic population codes




W
J
Ma






J
M
Beck






P
E
Latham






A
Pouget




10.1038/nn1790








Nature Neuroscience




9


11
















Portfolio Selection: Efficient Diversification of Investments




H
M
Markovitz








John Wiley












On an unknown early version of Daniel Bernoulli's Specimen Theoriae Novae de mensura sortis




R
Mata






F
Nagel




10.31234/osf.io/49f6s


















Uncertainty in perception and the Hierarchical Gaussian Filter




C
D
Mathys






E
I
Lomakina






J
Daunizeau






S
Iglesias






K
H
Brodersen






K
J
Friston






K
E
Stephan




10.3389/fnhum.2014.00825








Frontiers in Human Neuroscience




8


825














Functionally dissociable influences on learning rate in a dynamic environment




J
T
Mcguire






M
R
Nassar






J
I
Gold






J
W
Kable




10.1016/j.neuron.2014.10.013








Neuron




84


4
















The activity in human areas V1/V2, V3, and V5 during the perception of coherent and incoherent motion




D
J
Mckeefry






J
D G
Watson






R
S J
Frackowiak






K
Fong






S
Zeki




10.1006/nimg.1996.0246








NeuroImage




5


1
















Data structures for statistical computing in Python




W
Mckinney




10.25080/Majora-92bf1922-00a








Proceedings of the 9th Python in Science Conference


the 9th Python in Science Conference






445














Brain networks for confidence weighting and hierarchical inference during probabilistic learning




F
Meyniel






S
Dehaene




10.1073/pnas.1615773114








Proceedings of the National Academy of Sciences


the National Academy of Sciences






114














The sense of confidence during probabilistic learning: A normative account




F
Meyniel






D
Schlunegger






S
Dehaene




10.1371/journal.pcbi.1004305








PLoS Computational Biology




11


6














Unreliable evidence: 2 sources of uncertainty during perceptual choice




E
Michael






V
De Gardelle






A
Nevado-Holgado






C
Summerfield




10.1093/cercor/bht287








Cerebral Cortex




25


4
















Neural processing of risk




P
N
Mohr






G
Biele






H
R
Heekeren




10.1523/JNEUROSCI.0003-10.2010








Journal of Neuroscience




30


19
















Neural foundations of risk-return trade-off in investment decisions




P
N
Mohr






G
Biele






L
K
Krugel






S
C
Li






H
R
Heekeren




10.1016/j.neuroimage.2009.10.060








NeuroImage




49


3
















A framework for mesencephalic dopamine systems based on predictive Hebbian learning




P
R
Montague






P
Dayan






T
J
Sejnowski




10.1523/JNEUROSCI.16-05-01936.1996








Journal of Neuroscience




16


5
















Machine Learning: A Probabilistic Perspective




K
P
Murphy










MIT Press












Adaptive circuit dynamics across human cortex during evidence accumulation in changing environments




P
R
Murphy






N
Wilming






D
C
Hernandez-Bocanegra






G
Prat-Ortega






T
H
Donner




10.1038/s41593-021-00839-z








Nature Neuroscience




24


7
















Shape perception reduces activity in human primary visual cortex




S
O
Murray






D
Kersten






B
A
Olshausen






P
Schrater






D
L
Woods




10.1073/pnas.192579399








Proceedings of the National Academy of Sciences




99


23
















Statistical context dictates the relationship between feedback-related EEG signals and learning. eLife, 8, e46975




M
R
Nassar






R
Bruckner






J
Frank






M




10.7554/eLife.46975


















An approximately Bayesian delta-rule model explains the dynamics of belief updating in a changing environment




M
R
Nassar






R
C
Wilson






B
Heasly






J
I
Gold




10.1523/JNEUROSCI.0822-10.2010








Journal of Neuroscience




30


37
















Age differences in learning emerge from an insufficient representation of uncertainty in older adults




M
R
Nassar






R
Bruckner






J
I
Gold






S.-C
Li






H
R
Heekeren






B
Eppinger




10.1038/ncomms11609








Nature Communications




7














A healthy fear of the unknown: Perspectives on the interpretation of parameter fits from computational models in neuroscience




M
R
Nassar






J
I
Gold




10.1371/journal.pcbi.1003015








PLoS Computational Biology




9


4














Neuronal correlates of a perceptual decision




W
T
Newsome






K
H
Britten






J
A
Movshon




10.1038/341052a0








Nature




341


6237
















A selective impairment of motion perception following lesions of the middle temporal visual area (MT)




W
T
Newsome






E
B
Pare




10.1523/JNEUROSCI.08-06-02201.1988








Journal of Neuroscience




8


6
















Economic value in the brain: A meta-analysis of willingness-to-pay using the Becker-DeGroot-Marschak auction




A
Newton-Fenner






D
Hewitt






J
Henderson






H
Roberts






T
Mari






Y
Gu






O
Gorelkina






T
Giesbrecht






N
Fallon






C
Roberts






A
Stancak




10.1371/journal.pone.0286969








PLoS ONE




18


7














Neurophysiology of human perceptual decision-making. Annual Review of Neuroscience




O'connell &
Kelly




10.1146/annurev-neuro-092019-100200








44














Dissociable effects of surprise and model update in parietal and anterior cingulate cortex




J
X
O'reilly






U
Schüffelgen






S
F
Cuell






T
E J
Behrens






R
B
Mars






M
F S
Rushworth




10.5281/zenodo.3509134








Proceedings of the National Academy of Sciences


the National Academy of Sciences






110








Pandas-dev/pandas: Pandas (Version latest)








Risk and uncertainty




K
F
Park






Z
Shapira




10.1057/978-1-349-94848-2_250-1








The Palgrave Encyclopedia of Strategic Management


M. Augier & D. J. Teece


















Adaptive coding of reward prediction errors is gated by striatal coupling. Proceedings of the National Academy of Sciences




S
Q
Park






T
Kahnt






D
Talmi






J
Rieskamp






R
J
Dolan






H
R
Heekeren




10.1073/pnas.1119969109








109














Risk, unexpected uncertainty, and estimation uncertainty: Bayesian learning in unstable settings




E
Payzan-Lenestour






P
Bossaerts




10.1371/journal.pcbi.1001048








PLoS Computational Biology




7


1














The neural representation of unexpected uncertainty during value-based decision making




E
Payzan-Lenestour






S
Dunne






P
Bossaerts






J
P
Doherty




10.1016/j.neuron.2013.04.037








Neuron




79


1
















Using large-scale experiments and machine learning to discover theories of human decision-making




J
C
Peterson






D
D
Bourgin






M
Agrawal






D
Reichman






T
L
Griffiths




10.1126/science.abe2629








Science




372


6547
















Causal role of dorsolateral prefrontal cortex in human perceptual decision making




M
G
Philiastides






R
Auksztulewicz






H
R
Heekeren






F
Blankenburg




10.1016/j.cub.2011.04.034








Current Biology




21


11
















Rats adopt the optimal timescale for evidence integration in a dynamic environment




A
T
Piet






A
El Hady






C
D
Brody




10.1038/s41467-018-06561-y








Nature Communications




1


9














A model for learning based on the joint estimation of stochasticity and volatility




P
Piray






N
D
Daw




10.1038/s41467-021-26731-9








Nature Communications




12


1


6587














Computational processes of simultaneous learning of stochasticity and volatility in humans




P
Piray






N
D
Daw




10.31234/osf.io/kz5ua


















Risky business: The neuroeconomics of decision making under uncertainty




M
L
Platt






S
A
Huettel




10.1038/nn2062








Nature Neuroscience




11


4
















Neural oscillations and synchronization differentially support evidence accumulation in perceptual and value-based decision making




R
Polanía






I
Krajbich






M
Grueschow






C
C
Ruff




10.1016/j.neuron.2014.03.014








Neuron




82


3
















Neural differentiation of expected reward and risk in human subcortical structures




K
Preuschoff






P
Bossaerts






S
Quartz




10.1016/j.neuron.2006.06.024








Neuron




51


3
















Human insula activation reflects risk prediction errors as well as risk




K
Preuschoff






P
Bossaerts






S
Quartz




10.1016/j.neuron.2006.06.024








Journal of Neuroscience




28


11
















Hierarchical decision processes that operate over distinct timescales underlie choice and changes in strategy




A
Purcell






R
Kiani




10.1073/pnas.1524685113








Proceedings of the National Academy of Sciences


the National Academy of Sciences






113














A framework for studying the neurobiology of value-based decision making




A
Rangel






C
Camerer






P
R
Montague




10.1038/nrn2357








Nature Reviews Neuroscience




9


7
















Modeling response times for two-choice decisions




R
Ratcliff






J
N
Rouder




10.1111/1467-9280.00067








Psychological Science




9


5
















Pupil fluctuations track rapid changes in adrenergic and cholinergic activity in cortex




J
Reimer






M
J
Mcginley






Y
Liu






C
Rodenkirch






Q
Wang






D
A
Mccormick






A
S
Tolias




10.1038/ncomms13289








Nature Communications




7


1


13289














Response of neurons in the lateral intraparietal area during a combined visual discrimination reaction time task




J
D
Roitman






M
N
Shadlen




10.1523/JNEUROSCI.22-21-09475.2002








Journal of Neuroscience




22


21
















Flutter discrimination: Neural codes, perception, memory and decision making




R
Romo






E
Salinas




10.1038/nrn1058








Nature Reviews Neuroscience




4


3
















Cortical microstimulation influences perceptual judgements of motion direction




C
D
Salzman






K
H
Britten






W
T
Newsome




10.1038/346174a0








Nature




346


6280
















Microstimulation in visual area MT: Effects on direction discrimination performance




C
D
Salzman






C
M
Murasugi






K
H
Britten






W
T
Newsome




10.1523/JNEUROSCI.12-06-02331.1992








Journal of Neuroscience




12


6
















How much to trust the senses: Likelihood learning




Y
Sato






K
P
Kording




10.1167/14.13.13.








Journal of Vision




13


14
















Mind the gap: Bridging economic and naturalistic risk-taking with cognitive neuroscience. Trends in Cognitive sciences




T
Schonberg






C
R
Fox






R
A
Poldrack




10.1016/j.tics.2010.10.002








15














Dopamine reward prediction-error signalling: A two-component response




W
Schultz




10.1038/nrn.2015.26








Nature Reviews Neuroscience




17


3
















A neural substrate of prediction and reward




W
Schultz






P
Dayan






P
R
Montague




10.1126/science.275.5306.1593








Science




275


5306




















K
L
Seaman






J
K
Leong






C
C
Wu






B
Knutson






G
R
Samanez-Larkin












Individual differences in skewed financial risk-taking across the adult life span












Affective
Cognitive






Behavioral Neuroscience




10.3758/s13415-017-0545-5






17














The speed and accuracy of a simple perceptual decision: A mathematical primer




M
N
Shadlen






T
D
Hanks






A
K
Churchland






R
Kiani






T
Yang




10.7551/mitpress/9780262042383.003.0010








Bayesian Brain: Probabilistic Approaches to Neural Coding


K. Doya, S. Ishii, A. Pouget, & R. P. N. Rao




MIT Press Scholarship Online
















Nonlinear decision weights or moment-based preferences? A model competition involving described and experienced skewness




L
Spiliopoulos






R
Hertwig




10.1016/j.cognition.2018.10.023








Cognition




183
















Variance, skewness and multiple outcomes in described and experienced prospects: Can one descriptive model capture it all




L
Spiliopoulos






R
Hertwig




10.1037/xge0001323








Journal of Experimental Psychology: General




152


4
















Building bridges between perceptual and economic decision-making: Neural and computational mechanisms




C
Summerfield






K
Tsetsos




10.3389/fnins.2012.00070








Frontiers in Neuroscience




6














Reinforcement Learning: An Introduction




R
S
Sutton






A
G
Barto








MIT Press












Deconstructing risk: Separable encoding of variance and skewness in the brain




M
Symmonds






N
D
Wright






D
R
Bach






R
J
Dolan




10.1016/j.neuroimage.2011.06.087








NeuroImage




58


4
















Adaptive coding of reward value by dopamine neurons




P
N
Tobler






C
D
Fiorillo






W
Schultz




10.1126/science.110537








Science




307


5715
















Reward value coding distinct from risk attitude-related uncertainty coding in human reward systems




P
N
Tobler






J
P
O'doherty






R
J
Dolan






W
Schultz




10.1152/jn.00745.2006








Journal of Neurophysiology




97


2
















Risk-dependent reward value signal in human prefrontal cortex




P
N
Tobler






J
P
O'doherty






R
J
Dolan






W
Schultz




10.1073/pnas.0809599106








Proceedings of the National Academy of Sciences


the National Academy of Sciences






106














Valuation for risky and uncertain choices




P
Tobler






E
Weber




10.1016/B978-0-12-416008-8.00009-7








Neuroeconomics: Decision Making and the Brain


P. W. Glimcher & E. Fehr




Academic Press










2nd edition








Causal contribution of primate auditory cortex to auditory perceptual decision-making




J
Tsunada






A
S K
Liu






J
I
Gold






Y
E
Cohen




10.1038/nn.4195








Nature Neuroscience




19


1
















Advances in prospect theory: Cumulative representation of uncertainty




A
Tversky






D
Kahneman




10.7554/eLife.46331








Journal of Risk and Uncertainty




5
















Modeling correlated noise is necessary to decode uncertainty




R
S
Van Bergen






J
F
Jehee




10.1016/j.neuroimage.2017.08.015








NeuroImage




180
















Sensory uncertainty decoded from visual cortex predicts behavior




R
S
Van Bergen






W
J
Ma






M
S
Pratte






J
F M
Jehee




10.1038/nn.4150








Nature Neuroscience




18


12
















Differential representations of prior and likelihood uncertainty in the human brain




I
Vilares






J
D
Howard






H
L
Fernandes






J
A
Gottfried






K
P
Kording




10.1016/j.cub.2012.07.010








Current Biology




22


8
















Contributors, S. 1. 0. (2020). SciPy 1.0: Fundamental algorithms for scientific computing in Python




P
Virtanen






R
Gommers






T
E
Oliphant






M
Haberland






T
Reddy






D
Cournapeau






E
Burovski






P
Peterson






W
Weckesser






J
Bright






S
J
Van Der Walt






M
Brett






J
Wilson






K
Jarrod Millman






N
Mayorov






A
R J
Nelson






E
Jones






R
Kern






E
Larson




10.1038/s41592-019-0686-2








Nature Methods




17














Handbuch der physiologischen Optik: mit 213 in den Text eingedruckten Holzschnitten und 11 Tafeln




Von
Helmholtz






H








Voss


9












Studying the neural representations of uncertainty




E
Y
Walker






S
Pohl






R
N
Denison






D
L
Barack






J
Lee






N
Block






W
J
Ma






F
Meyniel




10.1038/s41593-023-01444-y








Nature Neuroscience




26
















Seaborn: Statistical data visualization




M
L
Waskom




10.21105/joss.03021








Journal of Open Source Software




6


60


3021














Die Lehre vom Tastsinne und Gemeingefühle auf Versuche gegründet




E
H
Weber








Friedrich Vieweg und Sohn












On the coefficient of variation as a predictor of risk sensitivity: Behavioral and neural evidence for the relative encoding of outcome variability




E
U
Weber




10.1016/j.jmp.2010.03.003








Journal of Mathematical Psychology




54


4
















Predicting risk sensitivity in humans and lower animals: Risk as variance or coefficient of variation




E
U
Weber






S
Shafir






A
R
Blais




10.1037/0033-295X.111.2.430








Psychological Review




111


2
















Testing models at the neural level reveals how the brain computes subjective value




T
B
Williams






C
J
Burke






S
Nebe






K
Preuschoff






E
Fehr






P
N
Tobler




10.1073/pnas.2106237118








Proceedings of the National Academy of Sciences




118


43














Dissociable influences of skewness and valence on economic choice and neural activity




N
D
Wright






M
Symmonds






S
Morris






L
Dolan






R
J




10.1371/journal.pone.0083454








PloS ONE




8


12














Better the devil you know than the devil you don't: Neural processing of risk and ambiguity




S
Wu






S
Sun






J
A
Camilleri






S
B
Eickhoff






R
Yu




10.1016/j.neuroimage.2021.118109








NeuroImage




236














Uncertainty, neuromodulation, and attention




A
J
Yu






P
Dayan




10.1016/j.neuron.2005.04.026








Neuron




46


4

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]