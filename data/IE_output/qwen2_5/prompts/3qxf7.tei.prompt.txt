You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1â€“3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



The Autocorrelated Bayesian Sampler: A Rational Process for Probability Judgments, Estimates, Confidence Intervals, Choices, Confidence Judgments, and Response Times
Human judgment and decision making has been studied using a wide variety of measures. Participants are asked to provide probability judgments (e.g., 
Sloman et al., 2004;
Fox & Rottenstreich, 2003;
Costello & Watts, 2014;
Dasgupta, Schultz, & Gershman, 2017;
, estimates of physical quantities (e.g., 
Gilden et al., 1995;
Jazayeri & Movshon, 2007)
 with associated confidence intervals (e.g., 
Juslin & Olsson, 1997;
Juslin, Winman, & Hansson, 2007)
, and choices (e.g., 
Tversky & Kahneman, 1974;
Usher & McClelland, 2004;
Fehr & Rangel, 2011)
 with their associated responses times (e.g., 
Ratcliff & Rouder, 1998;
Krajbich & Rangel, 2011;
Ratcliff & Starns, 2009;
Blurton et al., 2020)
 and confidence judgments (e.g., 
Baranski & Petrusic, 1998;
Juslin et al., 2007;
Li & Ma, 2020;
Pleskac & Busemeyer, 2010
). Yet while each measurement has been subject to an enormous amount of empirical and modeling work in psychology, a unified theoretical framework that can provide an integrated account of human performance across all six measures (i.e., probability judgments, estimates, confidence intervals, choices, confidence judgments, and response times) is currently lacking.
Theorists have taken steps towards a unified model from two starting points, normative and descriptive. Existing normative models are elegant, parsimonious and are easily extendable to all six measures. But these models fail to provide a satisfactory account of many qualitative effects that have been observed in empirical data. By contrast, various descriptive models, which systematically deviate from normative assumptions, capture the empirical effects both qualitatively and quantitatively for up to three of these six measures, but no single model makes predictions across all measures.
Here, we develop a simple and consistent process that can account for a surprising variety of qualitative findings across all six measures. To achieve this goal, we build on a strong normative foundation for all six measures, rooted in a sampling approximation to Bayesian inference. This approach also implies a radical shift in viewpoint concerning the nature of the decision-making process and the origin of variability in human behavior. In the perceptual decision-making literature, existing normative models generally operate on noisy sensory information and evaluate the relative probability that this noisy information is generated by the different hypotheses (corresponding to choice options) (e.g., 
Green & Swets, 1966;
Ratcliff & Rouder, 1998)
.
Our starting point is that exact Bayesian computations are generally intractable; and hence a Bayesian brain can, at best, only approximate these computations. One of the most widely used approach to such approximation in statistics and machine learning assumes that the brain draws samples from posterior probabilities. Inspired by this approach, many theorists in the Bayesian tradition have argued that the cognitive processes thus operate over these samples, rather than representations of probabilities 
(Griffiths, Vul, & Sanborn, 2012;
Vul et al., 2014;
Sanborn & Chater, 2016;
Lieder et al., 2018;
Dasgupta et al., 2017;
. But this process of sampling will inevitably be noisy-different samples will be drawn on different occasions. Thus, in this type of model, the main source of variability does not arise from sensory noise, but from computational noise caused by the process of sampling. That is, instead of evaluating evidence from the sensory system or memory, we propose that the cognitive system operates on stochastically generated hypotheses.
Our aim in this paper is to outline a general process that can be applied to a wide variety of measures and tasks, when equipped with a task-specific representation. Our focus is to show that this process provides a unified framework which captures a wide range of qualitative phenomena across measures and tasks, rather than to produce a comprehensive quantitative model of a particular task. The following sections are structured as follows. First, we review the traditional probabilistic view of normative decision making and note its limitations in explaining psychological data. Then we propose an alternative sampling-based approximation approach to alleviate the computational burden associated with the normative models, which in turn suggests a shift in the target problem of normative concern from accumulating sensory data to integrating stochastic hypotheses. We demonstrate the unifying power of the perspective shift by applying a rational process model across the six behavioral measures, emphasizing on qualitative model behaviors. Finally, we explore how to create these complete models after exploring the general judgement and decision-making process in detail.


Overview of Probabilistic Decision Making
The idea that human decision-making process is an optimal, perhaps Bayesian, process is attractive because given a problem description it prescribes the best behavior, and can therefore be justified as an ultimate state of evolution and/or learning 
(Green & Swets, 1966;
Ratcliff & Rouder, 1998;
Gold & Shadlen, 2002;
Pleskac & Busemeyer, 2010;
Bogacz et al., 2006;
Moran, 2015;
Drugowitsch et al., 2019;
Hawkins & Heathcote, 2021;
Tickle et al., 2021)
. There are also a wide variety of task-specific Bayesian models in psychology, but in the area of cognitive and perceptual decision making, they are often elaborations of the general decision process of Signal Detection Theory (SDT), which describes how sensory evidence can be transformed into optimal behavior 
(Green & Swets, 1966)
.
To illustrate our discussion, we shall consider the following trial in a perceptual task as a running example: a cloud of 24 dots briefly appears on-screen (i.e., stimulus, ) 1 . Participants might be asked to report a probability that the number of dots falls within a certain window (i. probability judgments). They may also be asked to estimate the exact number of dots (ii. estimates) or to provide a confidence interval for the estimate (iii. confidence interval). Alternatively, participants could be asked to decide whether the number of dots was greater or smaller than some predefined boundary (iv. choices) and the elapsed times for making such decision (vi. response times), for example, by asking participants whether or not there were greater than 25 dots on the screen. Finally, it is also possible to elicit their confidence rating for either of these responses (v. confidence in the decision). 
Figure 1
. Illustrations of the scope of behavioral measures for a single task. After the presentation of sensory stimulus, people can be asked a wide range of questions and their responses lead to corresponding behavioral measures.
Importantly, while this choice of example of numerosity judgment is intended to provide a simple and concrete illustration, and one that connects naturally to existing models such as SDT, the general approach applies quite generally. For a wide range of tasks, the six behavioral economics (e.g., 
Tversky & Kahneman, 1974)
, which has largely developed as a separate tradition.


Sensory stimulus Asking people a question Behaviour
< l a t e x i t s h a 1 _ b a s e 6 4 = " A Z I m S 7 T r 9 p j i 3 z 2 Z n P z T 0 z + L 6 O U = " > A A A B + X i c b V D L S g N B E J y N r x h f q x 6 9 D A b B U 9 g N Q b 0 I A S 8 e I 5 g H J M s y O + k k Q 2 Y f z P Q G w 5 I / 8 e J B E a / + i T f / x k m y B 0 0 s a C i q u u n u C h I p N D r O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O O T l o 5 T x a H J Y x m r T s A 0 S B F B E w V K 6 C Q K W B h I a A f j u 7 n f n o D S I o 4 e c Z q A F 7 J h J A a C M z S S b 9 v a 7 y E 8 Y Y Y q h d l t t e b b Z a f i L E D X i Z u T M s n R 8 O 2 v X j / m a Q g R c s m 0 7 r p O g l 7 G F A o u Y V b q p R o S x s d s C F 1 D I x a C 9 r L F 5 T N 6 Y Z Q + H c T K V I R 0 o f 6 e y F i o 9 T Q M T G f I c K R X v b n 4 n 9 d N c X D j Z S J K U o S I L x c N U k k x p v M Y a F 8 o 4 C i n h j C u h L m V 8 h F T j K M J q 2 R C c F d f X i e t a s W 9 q t Q e a u V 6 N Y + j S M 7 I O b k k L r k m d X J P G q R J O J m Q Z / J K 3 q z M e r H e r Y 9 l a 8 H K Z 0 7 J H 1 i f P 5 I 7 k 5 I = < / l a t e x i t >
s true = 24
The number of dots exceeds 25. What is the probability that this proposition is correct?
How many dots appeared onscreen? Give the smallest interval which you are 60% certain includes the number of dots appeared onscreen?
Is the number of dots greater than 25? How confident are you that your answer is correct?
Probability Judgments


Estimates Confidence Intervals
Choices & Response Times Confidence Judgments behaviors above can be collected and modelled. So, for example, participants might be asked memory-based questions about how much their last grocery bill was (e.g., "Your last grocery bill exceeded Â£150. What is the probability that this proposition is correct?"), or even asking participants about one-off future events such as how many years they expect to live. Thus, while we use the numerosity example in 
Figure 1
 because it is simple and straightforward to relate to SDT, our approach applies to cognitive as well as perceptual tasks, as we will see below.
More formally, in the SDT, we wish to choose between option A and B, based on a total of units of sensory input ( ! , " , â€¦ , # ) typically assumed to be accumulated over time.
Assuming that both options are equally likely a priori (i.e., ( ) = ( )), the key variable is the summed log-likelihood ratio over the evidence from each individual unit of sensory input:
( ) = , log ( $ | ) ( $ | ) # $%!
(1)
where ( $ | ) is the likelihood of sensory evidence $ when option is the correct choice (similarly for ( $ | )). The probability of choosing over should be a function of the summed log likelihood ratios. Provided with imperfect evidence (e.g., detecting a ship on a noisy radar image), SDT is a principled way to filter out irrelevant sensory noise to pick out the useful signal (e.g., whether the image contains ship). The approach can be applied to a wide range of domains in psychology, including memory, perception, and reasoning 
(Kellen et al., 2021;
Rotello, 2018;
Trippas et al., 2018;
McCarley & Benjamin, 2013)
.
SDT, however, makes no explicit commitment on the time course of how evidence is generated and/or collected, and so makes no predictions for response time. This issue can be addressed with a dynamic extension of SDT: the sequential probability ratio test (SPRT), which postulates that the stream of sensory evidence arrives steadily and sequentially over time 
(Edwards, 1965;
Laming, 1968;
Bogacz et al., 2006)
. To deal optimally with the incoming sensory evidence in, for example, binary choice, the evidence should be continuously integrated into the log-likelihood ratio between the two options until a fixed threshold is reached, and response times are predicted to depend on the amount of evidence accumulated. More formally, the log-likelihood ratio for choosing option over is recursively updated after the arrival of each new piece of sensory evidence ( # ):
( ) = ( âˆ’ 1) + log ( # | ) ( # | )
(2)
Once the log-likelihood ratio reaches a threshold (assuming symmetric thresholds: ( ) > Î´ or ( ) < âˆ’Î´), the evidence accumulation process stops and the response depends on whether the positive or negative threshold is reached. Increasing the magnitude of the threshold (Î´) produces a slower but more accurate response as more sensory evidence, on average, is accumulated before either threshold is reached. The SPRT is optimal in the sense that the expected amount of evidence (i.e., ) is minimized for any fixed probability of deciding incorrectly 
(Wald & Wolfowitz, 1948)
. In other words, following the SPRT allows for the fastest response time for a particular error rate. Because the sensory inputs are assumed to be independent of one another, the SPRT is a random walk model whose starting point is (0) = 0 and with two absorbing states: âˆ’Î´ and Î´ (see 
Figure 2A
). A Sequential Probability Ratio Test sample from sensory representation < l a t e x i t s h a 1 _ b a s e 6 4 = " A Z I m S 7 T r 9 p j i 3 z 2 Z n P z T 0 z + L 6 O U = " > A A A B + X i c b V D L S g N B E J y N r x h f q x 6 9 D A b B U 9 g N Q b 0 I A S 8 e I 5 g H J M s y O + k k Q 2 Y f z P Q G w 5 I / 8 e J B E a / + i T f / x k m y B 0 0 s a C i q u u n u C h I p N D r O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O O T l o 5 T x a H J Y x m r T s A 0 S B F B E w V K 6 C Q K W B h I a A f j u 7 n f n o D S I o 4 e c Z q A F 7 J h J A a C M z S S b 9 v a 7 y E 8 Y Y Y q h d l t t e b b Z a f i L E D X i Z u T M s n R 8 O 2 v X j / m a Q g R c s m 0 7 r p O g l 7 G F A o u Y V b q p R o S x s d s C F 1 D I x a C 9 r L F 5 T N 6 Y Z Q + H c T K V I R 0 o f 6 e y F i o 9 T Q M T G f I c K R X v b n 4 n 9 d N c X D j Z S J K U o S I L x c N U k k x p v M Y a F 8 o 4 C i n h j C u h L m V 8 h F T j K M J q 2 R C c F d f X i e t a s W 9 q t Q e a u V 6 N Y + j S M 7 I O b k k L r k m d X J P G q R J O J m Q Z / J K 3 q z M e r H e r Y 9 l a 8 H K Z 0 7 J H 1 i f P 5 I 7 k 5 I = < / l a t e x i t > s true = 24 stimulus B < l a t e x i t s h a 1 _ b a s e 6 4 = " A Z I m S 7 T r 9 p j i 3 z 2 Z n P z T 0 z + L 6 O U = " > A A A B + X i c b V D L S g N B E J y N r x h f q x 6 9 D A b B U 9 g N Q b 0 I A S 8 e I 5 g H J M s y O + k k Q 2 Y f z P Q G w 5 I / 8 e J B E a / + i T f / x k m y B 0 0 s a C i q u u n u C h I p N D r O t 1 X Y 2 N z a 3 i n u l v b 2 D w 6 P 7 O O T l o 5 T x a H J Y x m r T s A 0 S B F B E w V K 6 C Q K W B h I a A f j u 7 n f n o D S I o 4 e c Z q A F 7 J h J A a C M z S S b 9 v a 7 y E 8 Y Y Y q h d l t t e b b Z a f i L E D X i Z u T M s n R 8 O 2 v X j / m a Q g R c s m 0 7 r p O g l 7 G F A o u Y V b q p R o S x s d s C F 1 D I x a C 9 r L F 5 T N 6 Y Z Q + H c T K V I R 0 o f 6 e y F i o 9 T Q M T G f I c K R X v b n 4 n 9 d N c X D j Z S J K U o S I L x c N U k k x p v M Y a F 8 o 4 C i n h j C u h L m V 8 h F T j K M J q 2 R C c F d f X i e t a s W 9 q t Q e a u V 6 N Y + j S M 7 I O b k k L r k m d X J P G q R J O J m Q Z / J K 3 q z M e r H e r Y 9 l a 8 H K Z 0 7 J H 1 i f P 5 I 7 k 5 I = < / l a t e x i t >  
Beta(2,
1)
 Beta 
(2,
2)
 Beta 
(3,
2)
 Beta 
(3,
3)
 Beta 
(4,
3)
 Beta 
(5,
3)
 Autocorrelated Bayesian Sampler 26 24 27 22 23 autocorrelated samples < l a t e x i t s h a 1 _ b a s e 6 4 = " E 4 j 4 + s O K T a j a R h v H g + + P x b U o K D c = " > A A A B 6 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V J J S 1 G P B i 8 c q 9 g P a U D b b S b t 0 s w m 7 G 6 G E / g M v H h T x 6 j / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k d u 5 3 n l B p H s t H M 0 3 Q j + h I 8 p A z a q z 0 k F Q G p b J b d R c g 6 8 T L S R l y N A e l r / 4 w Z m m E 0 j B B t e 5 5 b m L 8 j C r D m c B Z s Z 9 q T C i b 0 B H 2 L J U 0 Q u 1 n i 0 t n 5 N I q Q x L G y p Y 0 Z K H + n s h o p P U 0 C m x n R M 1 Y r 3 p z 8 T + v l 5 r w x s + 4 T F K D k i 0 X h a k g J i b z t 8 m Q K 2 R G T C 2 h T H F 7 K 2 F j q i g z N p y i D c F b f X m d t G t V 7 6 p a v 6 + X G 7 U 8 j g K c w w V U w I N r a M A d N K E F D E J 4 h l d 4 c y b O i / P u f C x b N 5 x 8 5 g z + w P n 8 A T o 6 j R 8 = < / l a t e x i t > p( < l a t e x i t s h a 1 _ b a s e 6 4 = " w J B D 9 U f t o 2 0 h y 4
v d v j h H S W 5 f O 6 4 = " > A A A B 6 n i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D 0 E n Z D U I 8 R L x 4 j m g c k S 5 i d 9 C Z D Z m e X m V k h x H y C F w + K e P W L v P k 3 T p I 9 a G J B Q 1 H V T X d X k A i u j e t + O y u r a + s b m 7 m t / P b O 7 t 5 + 4 e C w o e N U M a y z W M S q F V C N g k u s G 2 4 E t h K F N A o E N o P h z d R v P q L S P J Y P Z p S g H 9 G + 5 C F n 1 F j p / u n 6 v F s o u i V 3 B r J M v I w U I U O t W / j q 9 G K W R i g N E 1 T r t u c m x h 9 T Z T g T O M l 3 U o 0 J Z U P a x 7 a l k k a o / f H s 1 A k 5 t U q P h L G y J Q 2 Z q b 8 n x j T S e h Q F t j O i Z q A X v a n 4 n 9 d O T X j l j 7 l M U o O S z R e F q S A m J t O / S Y 8 r Z E a M L K F M c X s r Y Q O q K D M 2 n b w N w V t 8 e Z k 0 y i X v o l S 5 q x S r 5 S y O H B z D C Z y B B 5 d Q h V u o Q R 0 Y 9 O E Z X u H N E c 6 L 8 + 5 8 z F t X n G z m C P 7 A + f w B 1 i G N d w = = < / l a t e x i t > |A)
< l a t e x i t s h a 1 _ b a s e 6 4 = " 0 r
S D K Z J C c T m E o w / I U d t n j o K n s y I = " > A A A B 6 n i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D 0 E n Z D U I 9 B L x 4 j m g c k S 5 i d 9 C Z D Z m e X m V k h x H y C F w + K e P W L v P k 3 T p I 9 a G J B Q 1 H V T X d X k A i u j e t + O y u r a + s b m 7 m t / P b O 7 t 5 + 4 e C w o e N U M a y z W M S q F V C N g k u s G 2 4 E t h K F N A o E N o P h z d R v P q L S P J Y P Z p S g H 9 G + 5 C F n 1 F j p / u n 6 v F s o u i V 3 B r J M v I w U I U O t W / j q 9 G K W R i g N E 1 T r t u c m x h 9 T Z T g T O M l 3 U o 0 J Z U P a x 7 a l k k a o / f H s 1 A k 5 t U q P h L G y J Q 2 Z q b 8 n x j T S e h Q F t j O i Z q A X v a n 4 n 9 d O T X j l j 7 l M U o O S z R e F q S A m J t O / S Y 8 r Z E a M L K F M c X s r Y Q O q K D M 2 n b w N w V t 8 e Z k 0 y i X v o l S 5 q x S r 5 S y O H B z D C Z y B B 5 d Q h V u o Q R 0 Y 9 O E Z X u H N
E c 6 L 8 + 5 8 z F t X n G z m C P 7 A + f w B 1 6 a N e A = = < / l a t e x i t >


|B)
< l a t e x i t s h a 1 _ b a s e 6 4 = " E 4 j 4 + s O K T a j a R h v H g +
+ P x b U o K D c = " > A A A B 6 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V J J S 1 G P B i 8 c q 9 g P a U D b b S b t 0 s w m 7 G 6 G E / g M v H h T x 6 j / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k d u 5 3 n l B p H s t H M 0 3 Q j + h I 8 p A z a q z 0 k F Q G p b J b d R c g 6 8 T L S R l y N A e l r / 4 w Z m m E 0 j B B t e 5 5 b m L 8 j C r D m c B Z s Z 9 q T C i b 0 B H 2 L J U 0 Q u 1 n i 0 t n 5 N I q Q x L G y p Y 0 Z K H + n s h o p P U 0 C m x n R M 1 Y r 3 p z 8 T + v l 5 r w x s + 4 T F K D k i 0 X h a k g J i b z t 8 m Q K 2 R G T C 2 h T H F 7 K 2 F j q i g z N p y i D c F b f X m d t G t V 7 6 p a v 6 + X G 7 U 8 j g K c w w V U w I N r a M A d N K E F D E J 4 h l d 4 c y b O i / P u f C x b N 5 x 8 5 g z + w P n 8 A T o 6 j R 8 = < / l a t e x i t > p( < l a t e x i t s h a 1 _ b a s e 6 4 = " g y o Y K M 7 D 7 m p W w 7 E o d K 5 K Y 2 u c x V U = " > A A A B 6 H i c b V D L S g N B E O y N r x h f U Y 9 e B o M g C G E 3 B P U Y 8 O I x A f O A Z A m z k 9 5 k z O z s M j M r h J A v 8 O J B E a 9 + k j f / x k m y B 0 0 s a C i q u u n u C h L B t X H d b y e 3 s b m 1 v Z P f L e z t H x w e F Y 9 P W j p O F c M m i 0 W s O g H V K L j E p u F G Y C d R S K N A Y D s Y 3 8 3 9 9 h M q z W P 5 Y C Y J + h E d S h 5 y R o 2 V G l f 9 Y s k t u w u Q d e J l p A Q Z 6 v 3 i V 2 8 Q s z R C a Z i g W n c 9 N z H + l C r D m c B Z o Z d q T C g b 0 y F 2 L Z U 0 Q u 1 P F 4 f O y I V V B i S M l S 1 p y E L 9 P T G l k d a T K L C d E T U j v e r N x f + 8 b m r C W 3 / K Z Z I a l G y 5 K E w F M T G Z f 0 0 G X C E z Y m I J Z Y r b W w k b U U W Z s d k U b
A j e 6 s v r p F U p e 9 f l a q N a q l W y O P J w B u d w C R 7 c Q A 3 u o Q 5 N Y I D w D K / w 5 j w 6 L 8 6 7 8 7 F s z T n Z z C n 8 g f P 5 A 2 + j j K g = < / l a t e x i t > + < l a t e x i t s h a 1 _ b a s e 6 4 = " E 4 j 4 + s O K T a j a R h
v H g + + P x b U o K D c = " > A A A B 6 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V J J S 1 G P B i 8 c q 9 g P a U D b b S b t 0 s w m 7 G 6 G E / g M v H h T x 6 j / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k d u 5 3 n l B p H s t H M 0 3 Q j + h I 8 p A z a q z 0 k F Q G p b J b d R c g 6 8 T L S R l y N A e l r / 4 w Z m m E 0 j B B t e 5 5 b m L 8 j C r D m c B Z s Z 9 q T C i b 0 B H 2 L J U 0 Q u 1 n i 0 t n 5 N I q Q x L G y p Y 0 Z K H + n s h o p P U 0 C m x n R M 1 Y r 3 p z 8 T + v l 5 r w x s + 4 T F K D k i 0 X h a k g J i b z t 8 m Q K 2 R G T C 2 h T H F 7 K 2 F j q i g z N p y i D c F b f X m d t G t V 7 6 p a v 6 + X G 7 U 8 j g K c w w V U w I N r a M A d N K E F D E J 4 h l d 4 c y b O i / P u f C x b N 5 x 8 5 g z + w P n 8 A T o 6 j R 8 = < / l a t e x i t > p(
< l a t e x i t s h a 1 _ b a s e 6 4 = " w J B D 9 U f t o 2 0 h y 4
v d v j h H S W 5 f O 6 4 = " > A A A B 6 n i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D 0 E n Z D U I 8 R L x 4 j m g c k S 5 i d 9 C Z D Z m e X m V k h x H y C F w + K e P W L v P k 3 T p I 9 a G J B Q 1 H V T X d X k A i u j e t + O y u r a + s b m 7 m t / P b O 7 t 5 + 4 e C w o e N U M a y z W M S q F V C N g k u s G 2 4 E t h K F N A o E N o P h z d R v P q L S P J Y P Z p S g H 9 G + 5 C F n 1 F j p / u n 6 v F s o u i V 3 B r J M v I w U I U O t W / j q 9 G K W R i g N E 1 T r t u c m x h 9 T Z T g T O M l 3 U o 0 J Z U P a x 7 a l k k a o / f H s 1 A k 5 t U q P h L G y J Q 2 Z q b 8 n x j T S e h Q F t j O i Z q A X v a n 4 n 9 d O T X j l j 7 l M U o O S z R e F q S A m J t O / S Y 8 r Z E a M L K F M c X s r Y Q O q K D M 2 n b w N w V t 8 e Z k 0 y i X v o l S 5 q x S r 5 S y O H B z D C Z y B B 5 d Q h V u o Q R 0 Y 9 O E Z X u H N E c 6 L 8 + 5 8 z F t X n G z m C P 7 A + f w B 1 i G N d w = = < / l a t e x i t > |A)
< l a t e x i t s h a 1 _ b a s e 6 4 = " 0 r
S D K Z J C c T m E o w / I U d t n j o K n s y I = " > A A A B 6 n i c b V D L S g N B E O z 1 G e M r 6 t H L Y B D 0 E n Z D U I 9 B L x 4 j m g c k S 5 i d 9 C Z D Z m e X m V k h x H y C F w + K e P W L v P k 3 T p I 9 a G J B Q 1 H V T X d X k A i u j e t + O y u r a + s b m 7 m t / P b O 7 t 5 + 4 e C w o e N U M a y z W M S q F V C N g k u s G 2 4 E t h K F N A o E N o P h z d R v P q L S P J Y P Z p S g H 9 G + 5 C F n 1 F j p / u n 6 v F s o u i V 3 B r J M v I w U I U O t W / j q 9 G K W R i g N E 1 T r t u c m x h 9 T Z T g T O M l 3 U o 0 J Z U P a x 7 a l k k a o / f H s 1 A k 5 t U q P h L G y J Q 2 Z q b 8 n x j T S e h Q F t j O i Z q A X v a n 4 n 9 d O T X j l j 7 l M U o O S z R e F q S A m J t O / S Y 8 r Z E a M L K F M c X s r Y Q O q K D M 2 n b w N w V t 8 e Z k 0 y i X v o l S 5 q x S r 5 S y O H B z D C Z y B B 5 d Q h V u o Q R 0 Y 9 O E Z X u H N E c 6 L 8 + 5 8 z F t X n G z m C P 7 A + f w B 1 6
a N e A = = < / l a t e x i t >


|B)
< l a t e x i t s h a 1 _ b a s e 6 4 = " E 4 j 4 + s O K T a j a R h
v H g + + P x b U o K D c = " > A A A B 6 X i c b V B N S 8 N A E J 3 4 W e t X 1 a O X x S L 0 V J J S 1 G P B i 8 c q 9 g P a U D b b S b t 0 s w m 7 G 6 G E / g M v H h T x 6 j / y 5 r 9 x 2 + a g r Q 8 G H u / N M D M v S A T X x n W / n Y 3 N r e 2 d 3 c J e c f / g 8 O i 4 d H L a 1 n G q G L Z Y L G L V D a h G w S W 2 D D c C u 4 l C G g U C O 8 H k d u 5 3 n l B p H s t H M 0 3 Q j + h I 8 p A z a q z 0 k F Q G p b J b d R c g 6 8 T L S R l y N A e l r / 4 w Z m m E 0 j B B t e 5 5 b m L 8 j C r D m c B Z s Z 9 q T C i b 0 B H 2 L J U 0 Q u 1 n i 0 t n 5 N I q Q x L G y p Y 0 Z K H + n s h o p P U 0 C m x n R M 1 Y r 3 p z 8 T + v l 5 r w x s + 4 T F K D k i 0 X h a k g J i b z t 8 m Q K 2 R G T C 2 h T H F 7 K 2 F j q i g z N p y i D c F b f X m d t G t V 7 6 p a v 6 + X G 7 U 8 j g K c w w V U w I N r a M A d N K E F D E J 4 h l d 4 c y b O i / P u f C x b N 5 x 8 5 g z + w P n 8 A T o 6 j R 8 = < / l a t e x i t > p( < l a t e x i t s h a 1 _ b a s e 6 4 = " g y o Y K M 7 D 7 m p W w 7 E o d K 5 K Y 2 u c x V U = " > A A A B 6 H i c b V D L S g N B E O y N r x h f U Y 9 e B o M g C G E 3 B P U Y 8 O I x A f O A Z A m z k 9 5 k z O z s M j M r h J A v 8 O J B E a 9 + k j f / x k m y B 0 0 s a C i q u u n u C h L B t X H d b y e 3 s b m 1 v Z P f L e z t H x w e F Y 9 P W j p O F c M m i 0 W s O g H V K L j E p u F G Y C d R S K N A Y D s Y 3 8 3 9 9 h M q z W P 5 Y C Y J + h E d S h 5 y R o 2 V G l f 9 Y s k t u w u Q d e J l p A Q Z 6 v 3 i V 2 8 Q s z R C a Z i g W n c 9 N z H + l C r D m c B Z o Z d q T C g b 0 y F 2 L Z U 0 Q u 1 P F 4 f O y I V V B i S M l S 1 p y E L 9 P T G l k d a T K L C d E T U j v e r N x f + 8 b m r C W 3 / K Z Z I a l G y 5 K E w F M T G Z f 0 0 G X C E z Y m I J Z Y r b W w k b U U W Z s d k U b A j e 6 s v r p F U p e 9 f l a q N a q l W y O P J w B u d w C R 7 c Q A 3 u o Q 5 N Y I D w D K / w 5 j w 6 L 8 6 7 8 7 F s z T n Z z C n 8 g f P 5 A 2 + j j K g = < / l a t e x i t > + < l a t e x i t s h a 1 _ b a s e 6 4 = " q o I C b 8 8 Y t + 9 Z E r w 3 j q 5 f V b n R 8 A I = " > A A A B 6 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B U 0 h K U Y 8 F L x 4 r 2 g 9 o Q 9 l s J + 3 S z S b s b o R S + h O 8 e F D E q 7 / I m / / G b Z u D t j 4 Y e L w 3 w 8 y 8 M B V c G 8 / 7 d g o b m 1 v b O 8 X d 0 t 7 + w e F R + f i k p Z N M M W y y R C S q E 1 K N g k t s G m 4 E d l K F N A 4 F t s P x 7 d x v P 6 H S P J G P Z p J i E N O h 5 B F n 1 F j p w X X d f r n i u d 4 C Z J 3 4 O a l A j k a / / N U b J C y L U R o m q N Z d 3 0 t N M K X K c C Z w V u p l G l P K x n S I X U s l j V E H 0 8 W p M 3 J h l Q G J E m V L G r J Q f 0 9 M a a z 1 J A 5 t Z 0 z N S K 9 6 c / E / r 5 u Z 6 C a Y c p l m B i V b L o o y Q U x C 5 n + T A V f I j J h Y Q p n i 9 l b C R l R R Z m w 6 J R u C v / r y O m l V X f / K r d 3 X K v V q H k c R z u A c L s G H a 6 j D H T S g C Q y G 8 A y v 8 O Y I 5 8 V 5 d z 6 W r Q U n n z m F P 3 A + f w B K A o 0 b < / l a t e x i t > ...
< l a t e x i t s h a 1 _ b a s e 6 4 = " u 3 X o Z l 1 K + a R 4 A I t e 6 + + 0 F j u n
L d E = " > A A A B 6 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y G o B 4 D X j x G M I m Q L G F 2 M p s M m c c y M y u E J b / g x Y M i X v 0 h b / 6 N s 8 k e N L G g o a j q p r s r S j g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p G p V q Q j t E c a U f I 2 w o Z 5 J 2 L L O c P i a a Y h F x 2 o u m t 7 n f e 6 L a M C U f 7 C y h o c B j y W J G s M 2 l A V f j Y b X m 1 / 0 F 0 D o J C l K D A u 1 h 9 W s w U i Q V V F r C s T H 9 w E 9 s m G F t G e F 0 X h m k h i a Y T P G Y 9 h 2 V W F A T Z o t b 5 + j C K S M U K + 1 K W r R Q f 0 9 k W B g z E 5 H r F N h O z K q X i / 9 5 / d T G N 2 H G Z J J a K s l y U Z x y Z B X K H 0 c j p i m x f O Y I J p q 5 W x G Z Y I 2 J d f F U X A j B 6 s v r p N u o B 1 f 1 5 n 2 z 1 m o U c Z T h D M 7 h E g K 4 h h b c Q R s 6 Q G A C z / A K b 5 7 w X r x 3 7 2 P Z W v K K m V P 4 A + / z B x M p j j k = < / l a t e x i t > log
< l a t e x i t s h a 1 _ b a s e 6 4 = " u 3 X o Z l 1 K + a R 4 A I t e 6 + + 0 F j u n
L d E = " > A A A B 6 3 i c b V D L S g N B E O y N r x h f U Y 9 e B o P g K e y G o B 4 D X j x G M I m Q L G F 2 M p s M m c c y M y u E J b / g x Y M i X v 0 h b / 6 N s 8 k e N L G g o a j q p r s r S j g z 1 v e / v d L G 5 t b 2 T n m 3 s r d / c H h U P T 7 p G p V q Q j t E c a U f I 2 w o Z 5 J 2 L L O c P i a a Y h F x 2 o u m t 7 n f e 6 L a M C U f 7 C y h o c B j y W J G s M 2 l A V f j Y b X m 1 / 0 F 0 D o J C l K D A u 1 h 9 W s w U i Q V V F r C s T H 9 w E 9 s m G F t G e F 0 X h m k h i a Y T P G Y 9 h 2 V W F A T Z o t b 5 + j C K S M U K + 1 K W r R Q f 0 9 k W B g z E 5 H r F N h O z K q X i / 9 5 / d T G N 2 H G Z J J a K s l y U Z x y Z B X K H 0 c j p i m x f O Y I J p q 5 W x G Z Y I 2 J d f F U X A j B 6 s v r p N u o B 1 f 1 5 n 2 z 1 m o U c Z T h D M 7 h E g K 4 h h b c Q R s 6 Q G A C z / A K b 5 7 w X r x 3 7 2 P Z W v K K m V P 4 A + / z B x M p j j k = < / l a t e x i t > log log likelihood ratio 1 log likelihood ratio 2 decision making choice A (less than 25 dots) physical times L(0) L(1) L(2) L(3) L(4) L(5)
< l a t e x i t s h a 1 _ b a s e 6 4 = " Y + H a I B 6 s b I 5 z O K e t z R n F N 0 3 J 8 s E = "
> A A A B 7 X i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B g 5 R E i n o s e P F Y w X 5 A G 8 p m s 2 n X b r J h d y K U 0 v / g x Y M i X v 0 / 3 v w 3 b t s c t P X B w O O 9 G W b m B a k U B l 3 3 2 y m s r W 9 s b h W 3 S z u 7 e / s H 5 c O j l l G Z Z r z J l F S 6 E 1 D D p U h 4 E w V K 3 k k 1 p 3 E g e T s Y 3 c 7 8 9 h P X R q j k A c c p 9 2 M 6 S E Q k G E U r t X o h l 0 j 7 5 Y p b d e c g q 8 T L S Q V y N P r l r 1 6 o W B b z B J m k x n Q 9 N 0 V / Q j U K J v m 0 1 M s M T y k b 0 Q H v W p r Q m B t / M r 9 2 S s 6 s E p J I a V s J k r n 6 e 2 J C Y 2 P G c W A 7 Y 4 p D s + z N x P + 8 b o b R j T 8 R S Z o h T 9 h i U Z R J g o r M X i e h 0 J y h H F t C m R b 2 V s K G V F O G N q C S D c F b f n m V t C 6 r 3 l W 1 d l + r 1 C / y O I p w A q d w D h 5 c Q
x 3 u o A F N Y P A I z / A K b 4 5 y X p x 3 5 2 P R W n D y m W P 4 A + f z B 4 3 c j w 8 = < / l a t e x i t > < l a t e x i t s h a 1 _ b a s e 6 4 = " o t C
v / s j l j t j Q B + L k + T i 8 7 F i q / W c = " > A A A B 7 n i c b V B N S 8 N A E J 3 U r 1 q / q h 6 9 L B b B g 5 Z E i n o s e P F Y w X 5 A G 8 p m M 2 m X b j Z h d y O U 0 h / h x Y M i X v 0 9 3 v w 3 b t s c t P X B w O O 9 G W b m B a n g 2 r j u t 1 N Y W 9 / Y 3 C p u l 3 Z 2 9 / Y P y o d H L Z 1 k i m G T J S J R n Y B q F F x i 0 3 A j s J M q p H E g s B 2 M 7 m Z + + w m V 5 o l 8 N O M U / Z g O J I 8 4 o 8 Z K 7 c t e i M L Q f r n i V t 0 5 y C r x c l K B H I 1 + + a s X J i y L U R o m q N Z d z 0 2 N P 6 H K c C Z w W u p l G l P K R n S A X U s l j V H 7 k / m 5 U 3 J m l Z B E i b I l D Z m r v y c m N N Z 6 H A e 2 M 6 Z m q J e 9 m f i f 1 8 1 M d O t P u E w z g 5 I t F k W Z I C Y h s 9 9 J y B U y I 8 a W U K a 4 v Z W w I V W U G Z t Q y Y b g L b + 8 S l p X V e + 6 W n u o V e o X e R x F O I F T O A c P b q A O 9 9 C A J j A Y w T O 8 w p u T O i / O u / O
x a C 0 4 + c w x / I H z + Q P 4 D I 9 G < / l a t e x i t > estimate confidence interval 23 using the last sample as estimate 60% empirical quantiles as 60% CI 
[23,
26]
 choice B (greater or equal than 25 dots) confidence < l a t e x i t s h a 1 _ b a s e 6 4 = " A g e
v U K P h J E Q w B Q E F / m u v U N a W k w k = " > A A A C F H i c b Z B N S w M x E I a z f l u / V j 1 6 C R Z B q J R d K e p F U H r x W M H a Q r e W b D q r w W x 2 S W b F s v R H e P G v e P G g i F c P 3 v w 3 p r W I W l 8 I P L w z w 2 T e M J X C o O d 9 O B O T U 9 M z s 3 P z h Y X F p e U V d 3 X t 3 C S Z 5 l D n i U x 0 M 2 Q G p F B Q R 4 E S m q k G F o c S G u F 1 d V B v 3 I A 2 I l F n 2 E u h H b N L J S L B G V q r 4 5 Y C h F v M q 4 m K + p 1 j e k i D S D O e w 0 X Q B Y m s n / u l b + 6 4 R a / s D U X H w R 9 B k Y x U 6 7 j v Q T f h W Q w K u W T G t H w v x X b O N A o u o V 8 I M g M p 4 9 f s E l o W F Y v B t P P h U X 2 6 Z Z 0 u j R J t n 0 I 6 d H 9 O 5 C w 2 p h e H t j N m e G X + 1 g b m f 7 V W h t F B O x c q z R A U / 1 o U Z Z J i Q g c J 0 a 7 Q w F H 2 L D C u h f 0 r 5 V f M p o I 2 x 4 I N w f 9 7 8 j i c 7 5 b 9 v X L l t F I 8 2 h n F M U c 2 y C b Z J j 7 Z J 0 f k h N R I n X B y R x 7 I E 3 l 2 7 p 1 H 5 8 V 5 / W q d c E Y z 6 + S X n L d P z 0
e e n g = = < / l a t e x i t >
Conf A = e 1 + e
choice RT choosing A < l a t e x i t s h a 1 _ b a s e 6 4 = " / / m A j k a B J X T L L A b 3 I w 5 X k + T 6 K 7 U = " > A 
A A C A X i c b V D L S g M x F M 3 4 r P U 1 6 k Z w M 1 i E F q T M S F G X B T c u R 7 A P a I e S S T O d 0 E w S k o x Q p n X j r 7 h x o Y h b / 8 K d f 2 P a z k J b D w Q O 5 9 z L z T m h o E R p 1 / 2 2 V l b X 1 j c 2 C 1 v F 7 Z 3 d v X 3 7 4 L C p e C o R b i B O u W y H U G F K G G 5 o o i l u C 4 l h E l L c C o c 3 U 7 / 1 g K U i n N 3 r k c B B A g e M R A R B b a S e f e y X 4 7 G q d I X k Q n P H L 6 t x X D F a p W e X 3 K o 7 g 7 N M v J y U Q A 6 / Z 3 9 1 + x y l C W Y a U a h U x 3 O F D j I o N U E U T 4 r d V G E B 0 R A O c M d Q B h O s g m y W Y O K c G a X v R F y a x 7 Q z U 3 9 v Z D B R a p S E Z j K B O l a L 3 l T 8 z + u k O r o O M s J E q j F D 8 0 N R S h 2 T d V q H 0 y c S I 0 1 H h k A k i f m r g 2 I o I d K m t K I p w V u M v E y a F 1 X v s l q 7 q 5 X q 5 3 k d B X A C T k E Z e O A K 1 M E t 8 E E D I P A I n s E
4 = " l o N 7 P L x U f D N A d c v Y w g c Q / J o x h 5 Q = " > A A A B 7 3 i c b V D L S g N B E O z 1 G e M r 6 t H L Y B A 8 S N g N Q b 0 I A T 1 4 j G A e k C x h d j K b D J m d X W d 6 h R D y E 1 4 8 K O L V 3 / H m 3 z h J 9 q C J B Q 1 F V T f d X U E i h U H X / X Z W V t f W N z Z z W / n t n d 2 9 / c L B Y c P E q W a 8 z m I Z 6 1 Z A D Z d C 8 T o K l L y V a E 6 j Q P J m M L y Z + s 0 n r o 2 I 1 Q O O E u 5 H t K 9 E K B h F K 7 U 6 t 1 w i v S 5 3 C 0 W 3 5 M 5 A l o m X k S J k q H U L X 5 1 e z N K I K 2 S S G t P 2 3 A T 9 M d U o m O S T f C c 1 P K F s S P u 8 b a m i E T f + e H b v h J x a p U f C W N t S S G b q 7 4 k x j Y w Z R Y H t j C g O z K I 3 F f / z 2 i m G V / 5 Y q C R F r t h 8 U Z h K g j G Z P k 9 6 Q n O G c m Q J Z V r Y W w k b U E 0 Z 2 o j y N g R v 8 e V l 0 i i X v I t S 5 b 5 S r J 5 n c e T g G E 7 g D D y 4 h C r c Q Q 3 q w E D C M 7 z C m / P o v D j v z s e 8 d c X J Z o 7 g D 5 z P H 1 P O j 3 I = < / l a t e x i t > = 2
< l a t e x i t s h a 1 _ b a s e 6 4 = " x e J J P e D U y m 0 6 Q r 
I p I 8 D y V A a p m q w = " > A A A B 8 H i c b V B N S w M x E J 2 t X 7 V + V T 1 6 C R b B g 5 b d U t S L U N C D x w r 2 Q 9 q l Z N N s G 5 p k l y Q r l K W / w o s H R b z 6 c 7 z 5 b 0 z b P W j r g 4 H H e z P M z A t i z r R x 3 W 8 n t 7 K 6 t r 6 R 3 y x s b e / s 7 h X 3 D 5 o 6 S h S h D R L x S L U D r C l n k j Y M M 5 y 2 Y 0 W x C D h t B a O b q d 9 6 o k q z S D 6 Y c U x 9 g Q e S h Y x g Y 6 X H 7 i 3 l B l + f V 3 r F k l t 2 Z 0 D L x M t I C T L U e 8 W v b j 8 i i a D S E I 6 1 7 n h u b P w U K 8 M I p 5 N C N 9 E 0 x m S E B 7 R j q c S C a j + d H T x B J 1 b p o z B S t q R B M / X 3 R I q F 1 m M R 2 E 6 B z V A v e l P x P 6 + T m P D K T 5 m M E 0 M l m S 8 K E 4 5 M h K b f o z 5 T l B g + t g Q T x e y t i A y x w s T Y j A o 2 B G / x 5 W X S r J S 9 i 3 L 1 v l q q n W V x 5 O E I j u E U P L i E G t x B H R p A Q M A z v M K b o 5 w X 5 9 3 5 m L f m n G z m E P 7 A + f w B v
d A M O x n Z q n u 7 x z 4 M d 1 3 5 g Z E = " > A A A B / H i c b V D L S s N A F J 3 4 r P U V 7 d L N Y B H E R U m k P p Y F N y 6 r 9 A V N K J P p t B 0 6 y Y S Z G z G E + i t u X C j i 1 g 9 x 5 9 8 4 b b P Q 1 g M X D u f c y 7 3 3 B L H g G h z n 2 1 p Z X V v f 2 C x s F b d 3 d v f 2 7 Y P D l p a J o q x J p Z C q E x D N B I 9 Y E z g I 1 o k V I 2 E g W D s Y 3 0 z 9 9 g N T m s u o A W n M / J A M I z 7 g l I C R e n b J A / Y I 2 X 1 j g r 1 Y y R g k v u j Z Z a f i z I C X i Z u T M s p R 7 9 l f X l / S J G Q R U E G 0 7 r p O D H 5 G F H A q 2 K T o J Z r F h I 7 J k H U N j U j I t J / N j p / g E 6 P 0 8 U A q U x H g m f p 7 I i O h 1 m k Y m M 6 Q w E g v e l P x P 6 + b w O D a z 3 g U J 8 A i O l 8 0 S A Q 2 L 0 6 T w H 2 u G A W R G k K o 4 u Z W T E d E E Q o m r 6 I J w V 1 8 e Z m 0 z i v u Z a V 6 V y 3 X z v I 4 C u g I H a N T 5 K I r V E O 3 q I 6 a i K I U P a N X 9 G Y 9 W S / W u / U x b 1 2 x 8 p k S + g P r 8 w d t j p S O < / l a t e x i t > RT / 5 < l a t e x i t s h a 1 _ b a s e 6 4 = " 5 u r o Z 2 B W R 6 l c N N 6 d b R f z D Y M t A m 4 = " > A A A C B H i c b V C 7 S g N B F J 2 N r x h f q 5 Z p B o M g F m F X o q Y R I m k s I 5 g H J C H M T m a T I b O z y 8 x d M S x b 2 P g r N h a K 2 P o R d v 6 N k 0 e h i Q c u H M 6 5 l 3 v v 8 S L B N T j O t 5 V Z W V 1 b 3 8 h u 5 r a 2 d 3 b 3 7 P 2 D h g 5 j R V m d h i J U L Y 9 o J r h k d e A g W C t S j A S e Y E 1 v V J 3 4 z X u m N A / l H Y w j 1 g 3 I Q H K f U w J G 6 t n 5 D r A H S K q h 9 N P e N b 7 C H V 8 R m p y n S T n t 2 Q W n 6 E y B l 4 k 7 J w U 0 R 6 1 n f 3 X 6 I Y 0 D J o E K o n X b d S L o J k Q B p 4 K l u U 6 s W U T o i A x Y 2 1 B J A q a 7 y f S J F B 8 b p Y / 9 U J m S g K f q 7 4 m E B F q P A 8 9 0 B g S G e t G b i P 9 5 7 R j 8 c j f h M o q B S T p b 5 M c C Q 4 g n i e A + V 4 y C G B t C q O L m V k y H x K Q A J r e c C c F d f H m Z N M 6 K 7 k W x d F s q V E 7 n c W R R H h 2 h E + S i S 1 R B N 6 i G 6 o i i R / S M X t G b 9 W S 9 W O / W x 6 w 1 Y 8 1 n D t E f W J 8 / L z K X u w = = < / l a t e x i t > Conf A = 5 8
probability judgment with a prior on responses of < l a t e x i t s h a 1 _ b a s e 6 4 = " 
T g E N h W Z k D c 4 V W 5 A r F f X z x v t Z 7 x Y = " > A A A C A H i c b V D L S s N A F J 3 4 r P U V d e H C z W A R x E V J p G o 3 Q s W N y w r 2 A U 0 I k + m k H T p 5 M H M j l J C N v + L G h S J u / Q x 3 / o 3 T N g t t P X D h c M 6 9 3 H u P n w i u w L K + j a X l l d W 1 9 d J G e X N r e 2 f X 3 N t v q z i V l L V o L G L Z 9 Y l i g k e s B R w E 6 y a S k d A X r O O P b i d + 5 5 F J x e P o A c Y J c 0 M y i H j A K Q E t e e a h M y S Q N X P v B l 9 j J 5 C E Z h d 5 V s 8 9 s 2 J V r S n w I r E L U k E F m p 7 5 5 f R j m o Y s A i q I U j 3 b S s D N i A R O B c v L T q p Y Q u i I D F h P 0 4 i E T L n Z 9 I E c n 2 i l j 4 N Y 6 o o A T 9 X f E x k J l R q H v u 4 M C Q z V v D c R / / N 6 K Q R 1 N + N R k g K L 6 G x R k A o M M Z 6 k g f t c M g p i r A m h k u t b M R 0 S n Q L o z M o 6 B H v + 5 U X S P q / a l 9 X a f a 3 S O C v i K K E j d I x O k Y 2 u U A P d o S Z q I Y p y 9 I x e 0 Z v x Z L w Y 7 8 b H r H X J K G Y O 0 B 8 Y n z / L 1 p X V < / l
f u g T 0 T h 7 R B o u 8 = " > A A A B + X i c b V D L S g N B E J y N r x h f q x 6 9 L A Y h i o T d E N R j 0 I v H C O Y B y R J m J 7 3 J k N k H M 7 3 B s O R P v H h Q x K t / 4 s 2 / c Z L s Q R M L G o q q b r q 7 v F h w h b b 9 b e T W 1 j c 2 t / L b h Z 3 d v f 0 D 8 / C o q a J E M m i w S E S y 7 V E F g o f Q Q I 4 C 2 r E E G n g C W t 7 o b u a 3 x i A V j 8 J H n M T g B n Q Q c p 8 z i l r q m W Y X 4 Q n T W 0 A 6 L V U u n f O e W b T L 9 h z W K n E y U i Q Z 6 j 3 z q 9 u P W B J A i E x Q p T q O H a O b U o m c C Z g W u o m C m L I R H U B H 0 5 A G o N x 0 f v n U O t N K 3 / I j q S t E a 6 7 + n k h p o N Q k 8 H R n Q H G o l r 2 Z + J / X S d C / c V M e x g l C y B a L / E R Y G F m z G K w + l 8 B Q T D S h T H J 9 q 8 W G V F K G O q y C D s F Z f n m V N C t l 5
6 p c f a g W a x d Z H H l y Q k 5 J i T j k m t T I P a m T B m F k T J 7 J K 3 k z U u P F e D c + F q 0 5 I 5 s 5 J n 9 g f P 4 A Q 2 2 S s Q = = < / l a t e x i t > Beta(2, 1) < l a t e x i t s h a 1 _ b a s e 6 4 = " z r a k p r + u 7 m F C F Q M U e + V c f t 6 8 h 0
Q = " > A A A C E H i c b V D L S g M x F M 3 U V 6 2 v U Z d u g k W s I m V G 6 m N Z E M F l l b 6 g U 0 o m T d v Q T G Z I 7 o h l 6 C e 4 8 V f c u F D E r U t 3 / o 3 p Y 6 G t B w I n 5 9 x 7 k 3 v 8 S H A N j v N t p R Y W l 5 Z X 0 q u Z t f W N z S 1 7 e 6 e q w 1 h R V q G h C F X d J 5 o J L l k F O A h W j x Q j g S 9 Y z e 9 f j f z a P V O a h 7 I M g 4 g 1 A 9 K V v M M p A S O 1 7 E M P 2 A M k d + U h 9 j Q P 8 O R 6 r Q S R 3 W H u 7 M Q T Z l a b H L X s r J N 3 x s D z x J 2 S L J q i 1 L K / v H Z I 4 4 B J o I J o 3 X C d C J o J U c C p Y M O M F 2 s W E d o n X d Y w V J K A 6 W Y y X m i I D 4 z S x p 1 Q m S M B j 9 X f H Q k J t B 4 E v q k M C P T 0 r D c S / / M a M X Q u m w m X U Q x M 0 s l D n V h g C P E o H d z m i l E Q A 0 M I V d z 8 F d M e U Y S C y T B j Q n B n V 5 4 n 1 d O 8 e 5 4 v 3 B a y x e N p H G m 0 h / Z R D r n o A h X R D S q h C q L o E T 2 j V / R m P V k v 1 r v 1 M S l N W d O e X f Q H 1 u c P R s 6 c p w = = < / l a t e x i t > RT â‡  Erlang(5, )
which 24 dots were briefly presented on-screen as the stimulus. The SPRT draws sequential samples from the noisy sensory representation (e.g., corrupted images), while the ABS draws autocorrelated samples of hypotheses (e.g., numbers of dots).  
Figure   2B
. Here, the sampler was automatically terminated when 5 samples were generated, while the dashed lines denote potential future samples if continued. Samples were compared to a decision boundary of 25 (red dots: evidence for lower than 25 dots, blue dots: evidence for greater than or equal to 25). The 5 samples were then integrated with a prior on responses (here used an asymmetric prior, Beta(2,1)), reaching a posterior of Beta(5,3). The mean of this posterior on responses was then used to generate probability judgments or confidence judgments in decision-making.
While intuitive and simple, the framework of the SPRT also makes imperfect decisions that take time, as people do, which is an advantage over SDT in modeling empirical data. Indeed, the SPRT can produce human-like speed accuracy tradeoffs: requiring faster decisions reduces accuracy, while requiring more accurate decisions reduces speed. This is captured in the model by assuming that people control the magnitude of the thresholds to suit their objectives. In response to experimental emphasis on speed (accuracy), people are assumed to be able to decrease (increase) the decision threshold; the model's guarantee of optimal performance implies that these two measures will trade off against one another.
Unfortunately, the SPRT does not easily explain other psychological relationships between choice and response times. In binary choice, for example, the SPRT predicts identical response time distributions for choosing either of the two options (assuming an unbiased starting point, (0) = 0, and symmetric thresholds), contradicting the empirical observation that mean response times differ for correct and incorrect decisions 
(Stone, 1960;
Ratcliff & Rouder, 1998)
. This is far from the only issue: 
Table 1 summarizes several
 qualitative effects of choice, response time, and confidence, the majority of which cannot be accommodated by the SPRT. These stylized facts have been used to motivate descriptive models, including the family of models known as Drift Diffusion Models (DDMs) that relaxes the normative SPRT framework to better describe human data, specifically regarding three key measures: choice, response time, and confidence. While such approaches have been highly successful, our focus here remains on approaches closely tied to normative depictions of behavior, though we return to DDMs and other common descriptive models below.


A Representation for Producing Estimates and Confidence Intervals
The categorical-hypotheses representations used in SPRT can produce choice, response time, and confidence measures, but are not fine-grained enough to produce probability judgments (e.g., judge the probability that the number of dots was greater than 25), estimates (e.g., how many dots are there on the screen), or confidence intervals (e.g., placing a 95% confidence interval around the estimate). What is needed is an extension of the hypothesis space beyond the categorical hypotheses used when making a choice. In principle, within a Bayesian framework, this is straightforward, although the resulting model looks very different. Instead of simply using two categorical hypotheses (e.g., whether or not there are more than 25 dots on the screen), the model can instead represent the fine-grained hypotheses relevant for estimates (e.g., the exact number of dots on the screen). With such a representation, estimates and confidence intervals can simply be a function (e.g., the mean and quantiles respectively) of this distribution. The probabilities of categorical hypotheses used to produce choices, confidence judgments, and response times can be calculated simply by summing up the posterior probability of the fine-grained hypotheses that are consistent with each choice (e.g., summing the probability of all the hypotheses in which the number of dots is more than 25). This representational change, however, does not allow a probabilistic model to account for many empirical effects found with estimates and confidence intervals. For estimates, anchoring effects demonstrate a dependence on preceding choices even when the choice question transparently contains no information 
(Tversky & Kahneman, 1974)
.
Moreover, estimated confidence intervals are empirically far too narrow and are strikingly different depending on whether participants produce or evaluate them 
(Juslin et al., 2007)
. In addition, a long line of empirical work shows that probability judgments are systematically biased and incoherent (e.g., subadditivity, conjunction fallacies, partition dependence), which argues against all purely probabilistic models (e.g., 
Tversky & Kahneman, 1983;
Tversky & Koehler, 1994;
Tentori et al., 2013;
Dasgupta et al., 2017;
Zhu et al., 2020)
.
Exact probabilistic models also show fundamental mismatches with the results of recent investigations into the source of noise in human judgment and decision making. While probabilistic models assume a noise-free inference process using precise probabilities, there is growing empirical evidence suggesting that much, or even most, variability in decision making in fact arises from "computational noise" (i.e., variability in precision and approximation used to perform inference) rather than "sensory noise" (i.e., variability in relevant sensory features) or "decision noise" (i.e., variability associated with action selection) 
(Drugowitsch et al., 2016;
Findling & Wyart, 2021;
StengÃ¥rd & van den Berg, 2019)
. Clearly, then, there are problems with the descriptive adequacy of all probabilistic models, including SDT and the SPRT, which may stem from the psychologically implausible assumption of exact calculation of probabilities and the lack of mechanism to account for the stochasticity arising from the inference process. In the next section, we propose how to address these fundamental problems, before evaluating how far the proposed solution produces a better qualitative match to a wide range of regularities in human behavior.


A Sampling-based Approximation Perspective for Rational Decision Making
Assuming imprecise probabilities does not necessarily mean abandoning probabilistic models. While exact Bayesian computation is often out of reach for real-world computational mechanisms, including the human brain 
(Anderson, 1991;
Aragones et al., 2005;
Kwisthout et al., 2011)
, computer scientists and statisticians have devised a number of sophisticated, general-purpose approximations for producing useful answers with a more reasonable amount of computational time and effort. It is therefore interesting to explore whether the brain has hit on similar solutions. One major family of general-purpose approximations in computer science and statistics are sampling techniques 2 .
Following the Bayesian approach, we propose that people solve cognitive tasks by building an internal model and posterior distribution over fine-grained hypotheses, which can support the responses for all of the aforementioned six behavioral measures. But, because the exact representation of the posterior probabilities of hypotheses is typically computationally intractable, we further hypothesize that the posterior probability distribution is not computed exactly, but is approximated by drawing representative samples from that distribution.
Sampling-based approximations to the posterior are appealing as a psychological mechanism because (i) some sampling algorithms (e.g., MCMC: Brooks et al., 2011) need only local knowledge of the target posterior distribution and can represent only one or a few hypotheses at a time, lending these algorithms psychological plausibility 
(Anderson, 1991;
Sanborn, Griffiths, & Navarro, 2010)
, (ii) sampling algorithms show much of the same behavioral variability and deviations from ideal probabilistic inference as observed in people across a range of domains 
(Griffiths, Vul, & Sanborn, 2012;
Sanborn & Chater, 2016;
Dasgupta et al., 2017;
Lieder et al., 2018;
Vul et al., 2014;
Zhu et al., 2022b)
, and (iii) the variability of sampling algorithms has been found to match neural variability in the cortex 
(Hoyer & Hyvarinen, 2003;
Haefner et al., 2016;
Fiser et al., 2010)
. These suggest that the samplingbased explanations can connect with all three of 
Marr's (1982)
 celebrated explanatory levels: computational (through implementing Bayesian inference), algorithmic (via a tractable 
2
 We do not further consider other general-purpose approximation algorithms, such as variational inference, in which a simpler distribution is used to approximate a more complex one, and the statistical distances between the two distributions are minimized by optimisation algorithms. Such algorithms provide an alternative source of explanations for human behaviour 
(Gershman & Beck, 2017;
Sanborn, 2017)
. computational mechanism), and implementational (through potentially mapping on to neural activity).
Taking a sampling-based approximation perspective to model choices suggests decision-making should be conceptualized as the problem of integrating a sequence of stochastic hypotheses into categorical decisions. The key distinction with other probabilistic models such as SDT and the SPRT is that we specifically define the 'evidence' as samples of hypotheses, abstracting away from noisy sensory percepts or memory traces (see 
Figure 2B)
 and implying that it is computational noise in the inference process that is the primary source of variability in behavior.


The Autocorrelated Bayesian Sampler
Here we outline a rational process for producing probability judgments, estimates, confidence intervals, choices, confidence judgments, and response times based on a sampling approximation of the posterior probability of fine-grained hypotheses, which we call the Autocorrelated Bayesian Sampler (ABS). Our key theoretical contributions are links between the sampling process and each of the six behavioral measures. This is possible because samples of the fine-grained hypotheses contain all of the relevant information to produce these (and indeed many other) aspects of behaviors.
Continuing our numerosity example (see 
Figure 1
 and 2), the ABS produces behavior based on the posterior probability of the hypotheses, (â„Ž| ), which is calculated using Bayes rule:
(â„Ž| ) = ( |â„Ž) (â„Ž) ( )
(3)
where â„Ž is a hypothesis, is a stimulus, ( |â„Ž) is the likelihood of a stimulus given a hypothesis, (â„Ž) is the prior probability of a hypothesis 3 , and ( ) is the overall probability of observing the stimuli across all possible hypotheses included in the internal model. In the numerosity task, for example, the hypothesis space reflects all possible numbers of dots that may have appeared on-screen, while the posterior distribution could be represented as a This general framework applies far beyond our numerosity task illustration. For example, it can be applied to intuitive physics when â„Ž is a complete object trajectory and is the initial movement of an object (e.g., 
Hamrick et al., 2015;
Battaglia, Hamrick, & Tenenbaum, 2013;
Sanborn, Mansinghka, & Griffiths, 2013)
, language production when â„Ž is the next word in a sentence and are the preceding words (e.g., 
Chater & Manning, 2006;
Levy, Reali, & Griffiths, 2008)
, and common-sense reasoning when â„Ž is a social goal of other agents and is a sequence of actions performed by those agents (e.g., 
Baker, Saxe, & Tenenbaum, 2009;
Baker, Goodman, & Tenenbaum, 2008)
. Similarly, Bayesian models have also been successfully implemented in explaining effects in other areas of psychology such as vision (e.g., 
Yuille & Kersten, 2006)
, motor control 
(Kording & Wolpert, 2004)
, causal reasoning (e.g., 
Abbott & Griffiths, 2011;
Bramley et al., 2017)
, and learning (e.g., 
Courville & Daw, 2007;
Gershman, Blei, & Niv, 2010
).
3 Note that this prior reflects the prior knowledge of the hypothesis space and therefore should be amenable to feedback and experimental instructions about the hypothesis space. For the running numerosity example, the experimenter could explicitly inform participants, or they could learn through experiences, that the numbers of dots appearing on-screen across trials are uniformly distributed in the range of 
[21,
30]
. Indeed, previous work has shown that participants can quickly acquire an accurate prior from feedback in a numerosity task 
(Sanborn & Beierholm, 2016)
. In this case, for simplicity, we should use a uniform distribution as the prior for hypotheses.
Next, a set of hypotheses are sampled from the fine-grained posterior distribution, and these samples directly and straightforwardly support all six of our measures ( 
Figure 2B
).
Probability judgments are based on the relative proportion of the samples (e.g., the number of samples with numerosities greater than 25). Estimates are based on a summary statistic of the samples (e.g., the mean sampled numerosity or the value of the latest sample). Confidence intervals are based on the quantiles of the samples (e.g., ordering five samples and using the numerosities of the 2 nd and 4 th sample as the bounds of a 60% confidence interval). Choices are based on the preponderance of the samples (e.g., depending on whether more than half the samples have numerosities greater than 25). Confidence judgments are (like probability judgments) based on the relatively proportion of the samples that agree with the choice.
Response times are a function of the number of samples drawn (e.g., on average drawing four samples takes longer than three).
To generate concrete predictions from the model, and assess the match with human behavior, we need to outline three further aspects of the model: the choices of sampling algorithm, prior on responses, and stopping rule, to which we now turn.


The Sampling Algorithm
We assume that the mind conducts sampling-based approximations by drawing samples of hypotheses in proportion to the posterior probabilities associated with each hypothesis (e.g., 
Griffiths, Vul, & Sanborn, 2012;
Vul et al., 2014;
Dasgupta et al., 2017;
Zhu et al., 2020;
Chater et al., 2020)
. Rather than reviewing the extensive literature on sampling algorithms in statistics and computer science (see 
Andrieu et al., 2003
 for an overview), we focus on algorithms that have been previously shown to match human behavior in some domains of psychology.
The simplest sampling algorithm is direct sampling in which independent and identically distributed (i.i.d.) samples are drawn (e.g., 
Vul et al., 2014)
. However, a lot must be known about the target distribution to draw i.i.d. samples: people would have to (at least implicitly) know the posterior probability of every hypothesis, which fails to alleviate the intractability problem that motivates the need for sampling approximations. Another difficulty with for direct sampling is descriptive. Human hypothesis generation is not a process of drawing independent samples, as the direct sampling requires. Instead, what comes to mind now depends on what came to mind in the past 
(Gilden et al., 1995;
Dasgupta et al., 2017;
Zhu et al., 2022c)
.
In light of this, researchers have recently started to explore a family of more sophisticated sampling algorithms called Markov Chain Monte Carlo (MCMC; 
Robert & Casella, 2004)
. MCMC algorithms explore the hypothesis space using only local knowledge about the probability distribution, greatly reducing the knowledge required to generate samples. The key idea of MCMC is that, in its simplest form, it represents only a single hypothesis at a time, and probabilistically transitions between hypotheses in proportion to their posterior probabilities. The local transitions induce a serial dependence between samples, akin to the local transitions in human hypothesis generation 
(Bramley et al., 2017;
Franken, Theodoropoulos, & Bramley, 2022)
.
In our own work, we have found that an extension of MCMC, named MC 3 , provides a close match to the dynamics of repeated human judgement, capturing the observed longrange autocorrelations between estimates, as well as the heavy-tailed distribution of changes between responses 
(Zhu, Sanborn, & Chater, 2019;
Zhu et al., 2022c;
Zhu et al., 2021;
Spicer et al., 2022)
. We therefore use MC 3 as the sampling algorithm in the present model, though the specific mechanics of this algorithm beyond dependencies between samples are not necessary for almost all of the behaviors targeted here (see Appendix A for algorithmic details). That is, with the exception of explaining the cross-trial autocorrelation results which requires quantitative characterizations of the dependence in samples, the key condition for a sampler to reproduce the qualitative model behaviors (e.g., comparing average model behaviors between experimental conditions) is simply that sampling is local and autocorrelated. Thus, most model predictions can be replicated using many other MCMC sampling algorithms, including the widely-used Random Walk Metropolis algorithm, and many others, so long as the generated samples are positively correlated across time.
Using dependent samples influenced our choice for how the ABS produces estimates.
In past work, estimates have been based on the most recently generated sample or by averaging over samples 
(Vul et al., 2014;
Lieder et al., 2018)
. While the mean of a set of independent samples is clearly a better estimate of the underlying mean than a single sample, with dependent samples, earlier samples are more likely to be biased by the starting point than later samples. For this reason, we chose to use the last sample as our estimate. However, these two approaches do not predict qualitatively different behavior on aggregate (see Appendix E for details).
Producing confidence intervals, however, requires more than a single sample, and instead can reflect statistics of the entire set of samples: for example, the 2.5% and 97.5% quantiles of the samples can represent a 95% confidence interval of the target distribution.
This approach can only be applied directly for large samples. With small samples, we produce more fine-grained intervals by following 
Juslin et al. (2007)
 and use linear interpolation to fill in the gap between the two quantiles of the samples.
We also assume that sampling takes time. For simplicity, we model the time necessary to produce samples as a Poisson process: while time taken to produce a new sample is random, the samples are generated at a constant rate ( samples per sec). In a Poisson process, the waiting time between samples is exponentially distributed, and the time necessary to generate samples follows an Erlang distribution:
( ) ~ Erlang( , )
(4)
The mean and variance of RT for a sample size of are then defined as
[ ] = & ' and [ ] = & '
! respectively. Using a Poisson process allowed us to more closely link our approach to existing models such as the Poisson random walk model 
(Blurton et al., 2020;
discussed below)
, though the results in this paper would be qualitatively the same under a wide variety of assumptions of how long it takes to generate each additional sample. This is because many empirical results only require assuming the samples were generated sequentially and the time to generate a sample is non-zero. Exponential waiting times are assumed here to explain the shape of RT distributions, particularly the observation that the response times for probability judgments (which we assume to have been produced using a fixed number of samples) have heavy tails (see Appendix F) 4 .


The Bayesian Monte Carlo Prior on Responses
Samples of the fine-grained hypotheses generated from our sampling algorithm can be readily used to make a choice. In our numerosity example, if asked to decide whether the number of dots that appeared on-screen is greater than 25, the hypothesis space should be partitioned into two subspaces with 25 on the boundary line. Samples that indicate greater than 25 dots or not should be categorized as supporting evidence for the corresponding hypotheses. That is, evidence is directly translated from the samples, here taking one of two values. And also, unlike the evidence used in SPRT, there is no inherent uncertainty about which alternative each sample supports. For the numerosity example, the generated sample can denote any number of dots in the hypothesis space, but it can only support one alternative in decisions: if the sample was 23, it only supports the hypothesis that there were less than 25 dots on screen.
Similarly for M-alternative choices ( > 2), the hypothesis space should be partitioned into M subspaces with hypothesis samples from each subspace supporting the corresponding alternative.
These samples implicitly carry information about the probability that each choice alternative is correct. For example, when asked about the probability that the number of dots is greater than 25, the relative frequency of evidence in favor of the event should inform the probability estimate. But, as explored in Zhu et al. 
2020
, people should not directly use the relative frequency of the hypotheses as a probability estimate. This is especially true when sample sizes are small because the relative frequency tends to be extreme. Indeed, a single sample would lead to a probability estimate of either 0 or 1. This problem can be solved by incorporating a prior on responses to temper the relative frequency in the estimates of the probability that each choice alternative is correct, an approach that in statistics is called Bayesian Monte Carlo 
(Gelman et al., 2013;
Rasmussen & Ghahramani, 2002)
 5 . The Bayesian Sampler model of Zhu et al. (2020) used a fixed prior on responses, and for mathematical simplicity, this was chosen to be a Beta distribution, because this is the conjugate prior for probability estimates. The Beta distribution is bounded by 0 and 1, and has two parameters, ( and ! , which determine its shape: when both parameters exceed 1, 
5
 The Bayesian Monte Carlo prior on responses is different from the prior on hypothesis in Equation 3. Specifically, the Bayesian Monte Carlo prior should capture full or partial information about the frequencies of the relevant behavioral outcomes in past trials. Consider again the binary choice in the numerosity example where people were asked to judge whether the number of dots is greater than 25. In this case, the prior on responses should reflect, to some extent, prior belief in different probabilities that each response is correct; and this prior knowledge could be acquired through feedback of correctly choosing greater-than-25 and of correctly choosing the alternative lessor-equal-than-25. An additional difference is that when knowledge of the probabilities is precise, even if there is uncertainty in the hypotheses, the effect of the Bayesian Monte Carlo prior reduces. Thus, in Equation 5, as the sample size, N, approaches infinity then " ( ) tends to ( ).
the Beta distribution is unimodal with a peak in the middle of the range (i.e., at
) " *! ) # +) " *" );
when both parameters equal 1, it is uniform; and when both parameters are less than 1, it is bimodal with peaks at both 0 and 1. Most critically, using the Beta distribution as the prior enables evidence to act as pseudocounts in the parameters. For ( ) pieces of evidence of event A, (Â¬ ) of event not-A, and a Beta( ( , ! ) prior, people will have a posterior distribution for probability estimates that is distributed according to Beta( ( + ( ), ! + (Â¬ )). The Bayesian Sampler model used the expected value of this posterior distribution as its probability estimate, which is also simple to calculate:
O ( ) = ( + ( ) ( + ( ) + ! + (Â¬ ) = ( + ( ) + ( + !
(5)
where = ( ) + (Â¬ ) denotes the total amount of samples that were generated and translated into evidence. Both the prior parameters (which affect ( , ! ) and the sampling process (which affects ( ) and ) affect the expected value. As the prior parameters are defined to be non-negative (i.e., ( , ! â‰¥ 0), the Bayesian Sampler's estimated probabilities tend to avoid extreme values and regress to the mean of the prior (i.e., ( /( ( + ! )).
Here, we generalize the prior on responses used in the original Bayesian Sampler in two ways. The first is to make it multivariate: in many situations, people can be asked to judge a multivariate event where the hypothesis space should be partitioned into many subspaces. For example, when asked "what is the probability that the hottest day of the week will be Sunday?", there are seven comparable events for the seven days in a week ("Sunday hottest", "Monday hottest", and so on). In this case, the Dirichlet distribution, a multivariate generalization of the Beta distribution, is the natural conjugate prior. For an -variate Dirichlet prior, Dir( ), with = ( ( , ! , â€¦ , ,*! ), people report the mean posterior distribution as their probability estimates:
O ( ) = ( + ( ) + âˆ‘ - ,*! -%(
(6)
This view of probability estimates implies an indifference point (when the underlying probability and the estimated probability matches) that depends on the number of alternatives (see 
Figure 4A
). Indifference points were directly reported by the data analyses in 
Fox & Rottenstreich (2004)
, 
Bardolet, Fox, & Lovallo (2004)
, 
and Varey, Mellers, & Birnbaum (1990)
, and were inferred from the regression in 
Attneave (1953)
.
The second way in which we generalize the prior on responses of the Bayesian Sampler is to allow it to adapt to experience (e.g., the trial history in an experiment). In Bayesian data analysis, when no prior information is available, a default prior is typically recommended 
(Gelman et al., 2013)
. However, for many real-world applications and especially for everyday cognitive tasks, historical data (e.g., past experiences of the same A B
task, data from similar previous tasks or from observing others' performing the task) are available which can help people can construct an appropriate prior. For example, if repeatedly choosing between the same two alternatives, historical choice data should provide useful information such as the base rate, which in turn can help construct a prior on responses to guide future decisions. How to construct an adaptive prior based on historical data is a topic of debate in statistics and computer science because it is difficult to determine how much to generalize previous experience to new situations 
(Ibrahim et al., 2015;
Chen et al., 2000;
Diaconis & Ylvisaker, 1979)
 6 . For simplicity, we assume that people only use information from the immediately previous trial to develop their adaptive prior for the present trial: in binary choice, a non-informative, uniform prior (Beta(1,1)) is adjusted to favor the option the feedback indicated was correct, becoming either Beta(2,1) or Beta(1,2).
The adaptive prior on responses, in conjunction with the generated samples, then determines the model's estimated probability of a categorical alternative being correct. This estimated probability is used both as the model's probability estimate and its confidence judgment in whether a choice is correct 7 . The equivalence between the two is not unique to our model-it has been previously posited as the Bayesian Confidence Hypothesis 
(Mamassian, 2016;
Kepecs & Mainen, 2012;
Pouget et al., 2016)
, and has attracted both support (Calder-Travis et al., 2020) and criticism 
(Li & Ma, 2020
).
6 Incorporating historical information into new situations is known as power prior in the statistics literature, which is also closely related to the ideas of meta-learning (or learning-to-learn) and hierarchical Bayesian modeling.
7 Confidence judgments are often made on various ordinal rather than probability scales, though analyses of confidence judgments often just assume that they are monotonically related 
(Li & Ma, 2020;
Shekhar & Rahnev, 2021a
), as we do here. For comparability across different ordinal scales we present all of the model predictions on the probability scale rather than specifying those relationships.


The Stopping Rule
Any model of judgment or decision that depends on the sequential accumulation of evidence needs a rule determining at what point to stop collecting evidence and make a decision. When to stop drawing samples should depend on both the costs (e.g., metabolic, opportunity, etc.) of sampling as well as the task-specific benefits of additional samples for providing a good response. For probability judgments, estimates, and confidence intervals, in the absence of a reason to do otherwise, we make the simplest possible assumption: that a fixed number of samples are drawn to answer each question.
A fixed number of samples will allow the model to produce indifferent probability judgments (e.g., judging a binary event to have a probability of 0.5) as is often observed in the human data 8 . However, for making decisions a fixed sample is likely to be too simple. If the samples so far leave the evidence finely balanced regarding which decision to make, then it is likely that more data will be collected. While it is possible in principle to derive an optimal stopping rule for the sampling process in this model, unlike with the SPRT, the optimal rule is not analytically tractable and can instead only be computed using dynamic programming (see Appendix C). So, again for simplicity, we use a well-known heuristic stopping rule instead: the max-minus-next rule, which counts the difference in evidence between the top two hypotheses, and terminates the sampling process whenever the accumulated difference exceeds a threshold. This simple heuristic stopping rule has also been shown to approach the performance of an optimal SPRT even in multi-alternative settings 
(Dragalin et al., 1999;
2000)
. For binary choices, this reduces to just the difference in the number of samples in favor of each alternative, which has been proposed in past work 
(Hamrick et al, 2015;
Vul et al, 2014)
. The decision-making panels of 
Figure 2B
 demonstrates the max-minus-next stopping rule with a threshold value of 2.
While the choice of stopping rule does not change how samples are used to produce the different measures, it does influence the content of the samples and the variability of the sample size and hence responses times. So, for example, in our model, while the response times for a probability judgment which assumes fixed sample sizes will follow an Erlang distribution (see Appendix F for further justification), response times for a choice (which assumes optional stopping) will follow a mixture of Erlang distributions (see Appendix B for details). 
The initial hypothesis used by the autocorrelated sampler will often be the comparison value used in the decision task (i.e., the anchored hypothesis). Moreover, the samples used to reach the decision are assumed to be reused in the estimation task. People are more confident in conditions in which they take more time to make a choice. 
Vickers & Packer (1982)
 The decision threshold is greater in the accuracy condition than in the speed condition, so choices will take longer while the greater difference in sample counts at threshold leads to higher confidence. We now demonstrate the explanatory power of the ABS. We focus on behavioral results that deviate from the Bayesian ideal embodied in models like the SPRT (see 
Table 1
), simulating these using a consistent set of parameters (detailed in Appendix A). To facilitate understanding of the active ingredients of the model, we also show results from three restricted variants of the full ABS model. The no-prior variant removes the adaptive prior (i.e., equivalent to fixing the prior to Beta(0,0)) while keeping the remaining components.


Confidence Intervals
The direct-sampling variant uses independent samples instead of the autocorrelated samples while keeping the remaining components. The fixed-sample-size variant always uses a fixed number of samples (N=5) to form behaviors while keeping the remaining components.


Biases in Probability Judgments
Biases in probability judgments are perhaps the most direct evidence against purely normative probabilistic models. We find that the prior on responses and local sampling algorithm of the ABS, which help to reduce the computational burden of the model by reusing old and useful computations and by using only local knowledge of the posterior distribution respectively, suffice to produce many of these biases. In the ABS, there are no biases in the underlying posterior probabilities; biases arise solely from the algorithmic process by which the posterior is sampled and judgments and decisions are generated.
Using prior knowledge to temper the probability estimates was the basis of the Bayesian Sampler model 
(Zhu et al., 2020)
. The ABS works in the same way, except that it uses autocorrelated, rather than independent, samples 9 . As shown in 
Figure 4A
, the prior in the Bayesian Sampler produces a linear bias toward conservative judgments 
(Zhu et al., 2020)
 where people avoid the extremes in their probability judgments 
(Fiedler, 1991;
Peterson & Beach, 1967;
Erev, Wallsten, & Budescu, 1994)
. This type of conservatism captures the results of a series of probabilistic identities investigated by Costello, Watts, and colleagues 
(Costello & Watts, 2014;
Costello, Watts, & Fisher, 2018)
, which were constructed by adding and subtracting various mean judgments across combinations of events. While all these identities would equal zero if participants reported coherent probabilities (even if just on average), mean judgments were zero for some identities and substantially different from zero for others. The results from the entire set of identities,
including conditional probability judgments of dependent events, were well fit by the Bayesian Sampler's linear conservatism bias 
(Zhu et al., 2020)
. As the average behavior of the ABS is approximated by the Bayesian Sampler especially when the effects of local sampling are not strong (e.g., random initializations of the local sampler), the ABS will produce these results as well.
The sample size and prior on responses of the ABS can be dissociated by examining the mean-variance relationship in probability judgments. When probability judgments are 
9
 The autocorrelation of the samples does not qualitatively alter the overall model predictions for probability judgments (with the exception of implicit subadditivity and implicit superadditivity, discussed below) because autocorrelated sample sizes can be corrected to produce the effective sample size of independent samples using the following equation:
!"" = # $%& âˆ‘ ( ! " !#$
where ) is the degree of autocorrelation at lag . For the parameters we used in the simulations, the effective sample size is on average 16.80% of the autocorrelated sample size (95% CI, [16.40%, 17.21%]). In addition, in the studies we refer to, there is very rarely any feedback. Without feedback, we assume the ABS prior does not change from trial to trial, making it identical to the fixed prior of the Bayesian Sampler for binary events.
based on sampled outcomes, the relationship between the mean probability estimates and the variance of the estimates will constitute an inverse U-shaped ("rainbow-shaped") curve (see 
Figure 5A
). The prior on responses then constrains the range of possible probability estimates that an agent can produce, thereby lowering the relative variance and pulling the curve both inward and downward (see 
Figure 5B
). For example, for a binary event with a uniform prior, if a single sample is drawn, probability judgments will be either 0.33 or 0.67, and total variance will be relatively lower than for the pure proportions of sampled outcomes (taking now account of the prior on responses). Overall, the Bayesian Sampler predicts a shrinkage of the mean-variance curve for probability judgments, and this was empirically validated in four experiments 
(Sundh et al., 2021)
. For the same reasons as the Bayesian Sampler, the ABS model predicts this shrinkage of the mean-variance curve as well (see 
Figure 5B
). Moreover, the phenomenon of explicit subadditivity in probability judgments also occurs as a direct consequence of using the prior on responses. Explicit subadditivity is when the estimated probability of an event ( ( ) is lower than the sum of estimated probabilities for events ( ! , " , â€¦ , ,. ) where ( is the disjunction of those â€² mutually exclusive events.
That is:
O ( ( ) < O ( ! ) + O ( " ) + â‹¯ + O ( ,. )
(7)
where probability theory requires that these should be equal. An explicit subadditivity bias was observed generally in between-participant designs in which participants were asked explicitly to judge the probability of each of the â€² events and their disjunction, ( , so that a total of â€² + 1 probability estimates were recorded (e.g., 
Tversky & Koehler, 1994;
Tversky & Fox, 1994;
Fox et al., 1994)
. According to the sampling account, for each query, because participants do not know the full range of questions that are asked, they will treat the event to be judged as a binary event; that is, participants will sample instances and non-instances of that event (that is, -vs. not--), thus requiring a Beta prior on responses. The resulting estimate of each ( -) will therefore be inflated by regression to the mean. The regressionto-mean effect then applies multiple times on aggregate to the right-hand side of Equation 7
and only once to the left-hand-side, predicting a subadditivity bias for low probability events.
As a corollary, more probability judgments queried on the right-hand-side of Equation 7 should associate with a greater degree of subadditivity bias. For M' component hypotheses, the predicted difference between the sum of the M' probability estimates and the probability estimates of the disjunction can be derived as follows:
O ( ! ) + O ( " ) + â‹¯ + O ( , $ ) âˆ’ O ( ( ) = , X + 2 ( ( -) + ( + 2 ( Y , $ -%! âˆ’ X + 2 ( ( ( ) + ( + 2 ( Y = ( . âˆ’ 1) ( + 2 (
where the assumptions were fixed sample size ( ) and symmetric prior on responses, Beta( ( , ( ). Indeed, the empirical findings suggest a positive relationship between M' and the degree of explicit subadditivity bias, and the Bayesian Sampler correctly captures the relationship (see 
Figure 6
). Moreover, when the disjunction of M' mutually exclusive events was exactly 1, participants were sometimes asked to only judge the probabilities of M'
component hypotheses but not their disjunction. In this case, model predictions can be analytically approximated as ( â€² âˆ’ 2)
) # &+") #
under the same assumption as before. This prediction also matches the empirical pattern known as the binary complementarity: on average, no subadditivity bias was observed for mutually exhaustive events when . = 2 
(Tversky & Koehler, 1994
). The ABS model inherits these predictions from the Bayesian Sampler. Similarly, this regression-to-mean effect predicts the conjunction fallacy 
(Costello & Watts, 2016;
Zhu et al., 2020)
. The conjunction fallacy arises where the estimated probability for a conjunctive event is greater than that for its constituent events O ( ( â‹‚ ! ) â‰¥ O ( ( ), whereas the probability theory requires the probability of conjunctive events to be less or equal with their constituents, ( and ! 
(Tversky & Kahneman, 1983)
. The conjunction fallacy occurs in the Bayesian Sampler when the regression-to-mean applies more to the conjunctive event than to the constituent events. Specifically, it is assumed that fewer samples of the more-complex conjunctive events can be generated or tallied in a fixed amount of time; and the prior produces a greater regression-to-mean effect for smaller sizes (see Equation 6). This allows the Bayesian Sampler to predict above-chance levels of conjunction fallacies when the conjunction and constituent event both have low probability 
(Zhu et al., 2020)
, as is often the case in empirical work 
(Costello & Watts, 2016
). The ABS model also inherits this prediction from the Bayesian Sampler.
In contrast with the explicit judgments of M'+1 probabilities above, both subadditivity and its opposite effect, superadditivity, have been observed in so-called implicit experimental designs. In implicit designs, only two probability judgments are made: one for the unpacked descriptor (e.g., "baby bottles and other bottles made of glass") and one for the simple disjunctive descriptor (e.g., "bottles made of glass") 
(Dasgupta et al., 2017;
Sloman et al., 2004)
. Unpacking to typical examples (e.g., a baby bottle in the category of bottles made of glass) leads to subadditivity:
O ( ( ) â‰¤ O ( ! âˆ© " âˆ© â€¦ âˆ© , )
, whereas unpacking to atypical examples (e.g., a shampoo bottle in the category of bottles made of glass) leads to 
(Dasgupta et al., 2017;
Sloman et al., 2004)
.
superadditivity: O ( ( ) â‰¥ O ( ! âˆ© " âˆ© â€¦ âˆ© , )
Again, since ( was unpacked into mutually exclusive events ( ( = ! âˆ© " âˆ© â€¦ âˆ© , ), probability theory requires the two probability estimates to be equal. Previous work with autocorrelated sampling models 
(Dasgupta et al., 2017;
Sanborn & Chater, 2016)
 accounted for this effect by assuming that the descriptor influenced the local sampler's starting point:
typical unpacking initializes the sampler in a high probability region of the hypothesis space, while atypical unpacking initializes it in a low probability region. As a result, the proportion of hypotheses supporting the event's occurrence will be highest for typical unpacking, intermediate for the simple disjunctive descriptor (assuming it results in a random starting point), and lowest for atypical unpacking. We believe that the ABS will inherit this prediction because it produces autocorrelated samples, though we do not reproduce it here because auxiliary assumptions about the locations and probabilities of hypotheses are needed to do so.
This explanation of implicit subadditivity and superadditivity depends on local sampling.
They cannot be predicted by the Bayesian Sampler model 
(Zhu et al., 2020
; see a similar argument against a "regressive model" in 
Tversky and Koehler, 1994)
, which assumes independent sampling.
Interestingly, people's probability estimates are also found to exhibit so-called "partition dependence." That is, they regress to ! , where is the number of alternatives that people are encouraged to consider (see 
Figure 4B
 for a summary; 
Attneave,1953;
Fox & Rottenstreich, 2003;
Bardolet et al., 2004;
Varey et al., 1990)
. For example, asking
"what is the probability that Sunday will be hotter than any other day next week?" encouraged participants to treat the event as binary, and their estimates were observed to be biased toward ! " , while asking, "what is the probability that the hottest day of the week will be Sunday?", encouraged participants to consider seven possible outcomes, and estimates were observed to be biased toward ! / 
(Fox & Rottenstreich, 2003)
. In ABS, framing the probability query as judging an M-variant event invokes a Dirichlet prior with M parameters,
Dir(Î± ( , Î± ! , â€¦ , Î± ,*! )
, which for a binary event reduces to a Beta prior, Beta(Î± ( , Î± ! ). Partition dependence effects can be explained by assuming that people have no a priori reason to believe one event occurs more often than another event: ( = ! = â‹¯ = ,*! and so probability estimates are predicted to be biased toward
) # âˆ‘ ) % &'" ()# = !
, (see 
Figure 4A
). In the ABS, the impact of this non-informative prior should be more pronounced in situations where people are less knowledgeable about the probability estimation task or less confident in a learning context (reflecting fewer samples), matching the empirical results 
(Fox & Rottenstreich, 2006)
.


Choice Accuracy and Response Times
The Bayesian Monte Carlo process for choice and RT correctly predicts four key relationships between choice and RT. First, and in common with many other evidence accumulation models, the ABS predicts a trade-off between accuracy and speed where increasing decision thresholds lead to, on average, more evidence being accumulated (and thus higher accuracy) as well as longer response times. This trade-off between accuracy and speed has been widely documented in the literature 
(Garrett, 1922;
Johnson, 1939;
Pachella, 1974;
Wickelgren, 1977;
Ratcliff & Rouder, 1998)
.
Second, unlike many models, the ABS predicts that correct and incorrect responses have unequal average response times. The empirical result is that, when accuracy is emphasized (or in difficult tasks), errors are usually slower than correct responses. By contrast, when speed is emphasized (or in easy tasks), errors are usually faster 
(Luce, 1986;
Swensson, 1972;
Ratcliff & Rouder, 1998;
Ratcliff, Thapar, & McKoon, 2003)
. This empirical pattern is surprisingly difficult to match for models that accumulate relative evidence to symmetric bounds: these models predict that the response time distributions for correct responses and errors will always be the same, regardless of choice accuracy 
(Link & Heath, 1975;
Vickers, 1979)
. To produce slow errors, the usual route is to add variability to the strength of the "signal", or the drift rate in DDMs 
(Ratcliff & Rouder, 1998)
. While both strong signals and weak signals will produce equal mean response times, weak signals are both more error-prone and slower. So, with an equal mixture of strong and weak signals, there will be more slow errors and more fast correct responses.
The ABS produces slow errors in a different way. Instead of adding cross-trial variation to the signal strength, or independent within-trial variation to the signal strength 
(Diederich & Oswald, 2016)
, slow errors result from the local sampling algorithm producing autocorrelated samples. For example, if the sampling algorithm begins far above the decision boundary (e.g., the red subspace in the posterior of hypotheses illustrated in 
Figure 2B
), then the initial samples will almost all favor the correct response, while if the sampling algorithm begins far below the decision boundary (e.g., the blue subspace in the posterior of hypotheses) then the proportion of correct samples will almost all favor the incorrect response. Slow errors also require optional stopping, because with a fixed stopping rule the response distribution is itself fixed. This can be seen in the simulation in 
Figure 7B
: both autocorrelation and optional stopping (i.e., the no prior variant) are needed to produce errors that are on-average slower than correct responses.
Fast errors, often found in easy tasks, are produced in a different way. The usual route to producing fast errors is to assume variability in the starting point of the evidence accumulation process 
(Laming, 1968;
Ratcliff & Rouder, 1998;
Ratcliff et al., 2003)
. In the ABS, the adaptive prior on responses is assumed to change in response to the outcomes of the preceding trial. This encourages repeating past successes, but also introduces cross-trial variability in the starting point of the accumulator. This is because the accumulator will be biased toward whichever response was correct on the last trial, and assuming that (as is usual in experiments) the correct response randomly varies between trials, it will sometimes be closer to the correct threshold and sometimes closer to the error threshold. For those latter trials, the amount of evidence required to reach the error threshold is reduced, leading to a shortened mean response times for errors. As with slow errors, optional stopping is also necessary: only with both the adaptive prior on responses and optional stopping (i.e., the direct sampling variant) do fast errors appear in the stimulation in 
Figure 7D
.
The differences between the simulations of the 'difficult-accuracy' condition ( 
Figure   7B
) and the 'easy-speed' condition ( 
Figure 7D
) track the conditions in which slow errors and fast errors are found. We assume that: (i) greater emphasis on accuracy causes the threshold to be higher, and consequentially more pieces of evidence are needed to terminate the sampling algorithms, and (ii) easier stimuli makes the evidence more homogenous (e.g., samples are more likely to point to the same response) 10 . As a result, the 'easy-speed' condition involves integration over homogenous but smaller amounts of evidence than in the 'difficult-accuracy' condition. In other words, the starting point of the accumulator has more influences, while the degree of autocorrelation has less influence, on determining the predicted behavior in the 'easy-speed' condition than in the 'difficult-accuracy'. Across 
Figure 7B
 and 7D, only the full ABS model matches the empirical observations that slow errors are more common in the 'difficult-accuracy' condition, while fast errors are more common in the 'easy-speed' condition. 10 A reduction in trial difficulty can lead to either less variable posterior of hypotheses (e.g., people are more certain about the number of dots), the decision boundary that partitions the hypothesis space moving to one extreme (e.g., people are asked to judge whether the number of dots are less than 1000 while only 24 dots appeared onscreen), or both. Overall, these model implications of the difficulty reduction all contribute to an increase in proportions of samples that support the correct response. an RT distribution that becomes more positively skewed and spread out with an increase in decision threshold. Empirical data were adapted from 
Ratcliff, Thapar, and McKoon (2003)
.
As in other models (e.g., 
Blurton et al., 2020)
, the assumptions of exponential waiting time between consecutive samples and the optional stopping rule correctly reproduce many distributional properties of RTs including (i) that there tends to be one mode in the distribution and (ii) distributions with higher means more positively skewed. Further regularities in the shapes of RT distributions were stressed by Ratcliff et al. (2015) using quantile-quantile (Q-Q) plots (see 
Figure 8A
). Plotting the quantiles of RT from one difficulty condition against the quantiles from another difficulty condition, the empirical Q-Q plots reveals near-linear relationships and a fan shape: increasing task difficulty has its greatest impact on the tails of the distribution with the near linearity suggesting similar RT distribution shapes across difficulty conditions. As shown in 
Figure 8B
, the ABS captures the fan shape and near-linear regularity. The direct-sampling variant shows results that are closer to linear, as would be expected if the autocorrelation in samples causes the upper tails in RT distributions to spread out even more in harder tasks. Also of interest is the fixed-sample-size variant, which because it always collects the same number of samples for all difficulty levels, produces identical quantiles between RTs from one level of difficulty and those from another, and thus doesn't match the empirical data.  
Ratcliff, Thapar, and McKoon (2003)
. One difficulty level was selected to compute its quantiles and then quantiles of the other four difficulty levels were plotted against the first condition. The rank of a condition depends on its mean RTs. (B) Q-Q plots of RT distributions produced by the ABS model and its variants.


Confidence in Decisions
From a Bayesian perspective, it is natural to map decision confidence onto the posterior probability that the decision is correct, a mapping which has been called the Bayesian Confidence Hypothesis 
(Mamassian, 2016;
Kepecs & Mainen, 2012;
Pouget et al., 2016)
. For the SPRT, posterior probability is updated as sensory samples are observed, and its posterior probability at the time of choice is simple: it is the posterior probability when the threshold is reached, because as evidence collection stops once this occurs (see 
Figure 2A
 confidence).
The SPRT thus predicts that decision confidence only relates to the threshold values, because the threshold captures the amount of evidence favoring one hypothesis or the other. Given that the threshold value is fixed prior to, and independent of, the characteristics of a particular trial, this means that confidence will be the same for all trials on which the same hypothesis is chosen 11 .
Unlike the SPRT, the ABS does not have direct access to its posterior probability that a response is correct (i.e., its confidence). Instead it needs to estimate this probability given a set of samples (see 
Figure 2B confidence)
. Fortunately, the form of the adaptive prior on responses (a Beta distribution in the case of binary choice) makes this estimate easy to update as samples are sequentially generated. At the start of the trial, the adaptive prior on responses reflects the prior belief in different probabilities that each response is correct. Using the binary choice example, assume a prior for choice A of Beta( , ) (and a prior for choice B of Beta( , )). When coming to a decision, samples in favor of each response, ( ) and ( ), are sequentially collected until the decision process is terminated by the stopping rule. The confidence after samples (i.e., N= ( ) + ( )) is then
Conf 1 = ( ) + + + , in Conf 2 = ( ) + + + , in .
(8)
The max-minus-next heuristic stopping rule terminates the sampling algorithm when the quantity of evidence favoring one choice exceeds a threshold, âˆ†= | + ( ) âˆ’ ( + ( ))| > 0. The final decision confidence can then be rewritten as follows:
Conf 1 = 1 âˆ’ Conf 2 = + + + âˆ† 2( + + ) , if was chosen (9)
11 While this characterizes an SPRT that stops at the threshold (e.g., as discussed in 
Pleskac and
Busemeyer, 2010, and
Vickers, 1979)
, there are variants that would make different predictions. For example, the boundaries do not necessarily have to be symmetric, or they could collapse. Also, it is possible that the SPRT's confidence would reflect not just the threshold but the posterior probability of the all the sensory samples that were observed before stopping, with confidence then being greater than or equal to the threshold confidence. All these variants would produce variable posterior probabilities and hence variable confidence judgments. However, none of these variants would produce estimates, confidence intervals, or other judgments that are generated by the ABS, but which are beyond the scope of the SPRT.
where the confidence judgments predicted by the ABS are decided by both the threshold values (âˆ†) and the amount of evidence accumulated ( ; this is same as the number of samples generated because evidence is directly mapped from hypothesis samples; for example, a sample of 27 dots will be converted into a piece of evidence for the proposition that the number of dots are greater than 25): the greater the number of samples generated before a decision is reached, the lower the confidence in that decision. This is because the ABS embodies a prior over the strength of signal in the Bayesian Monte Carlo process, and the longer the sampling process continues, the more likely the signal is weak, and so the posterior probability that the decision is correct correspondingly decreases. This is in contrast to the SPRT: in the SPRT, confidence does not change with additional sampling because its confidence is determined by a fixed decision threshold.
The decreasing decision confidence of the ABS with an increasing number of samples allows it to capture four key empirical phenomena which are not accommodated by the SPRT described above: the positive relationship between confidence and the discriminability of the stimuli 
(Baranski & Petrusic, 1998;
Vickers, 1979;
Vickers & Packer, 1982,
 
Figure 9A
), the "resolution of confidence" effect 
(Ariely et al., 2000;
Baranski & Petrusic, 1998;
Vickers, 1979;
Garrett, 1922;
Vickers, 2014;
Vickers & Packer, 1982,
 
Figure 9B
), so-called "metacognitive inefficiency" 
(Shekhar & Rahnev, 2021a
; 2021b, 
Figure 9C)
, and the complex relationship between RT and confidence 
(Baranski & Petrusic, 1998;
Vickers & Packer, 1982,
 
Figure 9D
).  Each dot denotes a level of difficulty. Empirical data adapted from 
Vickers & Packer (1982)
.
Error bars denote 95% confidence intervals of the model simulations.
The first of these effects, the positive relationship between confidence and stimulus discriminability, follows from the strength of the signal in the ABS. More discriminable stimuli will result in more homogenous evidence supporting one alternative (i.e., samples will more consistently support one response alternative over the other), and because decision confidence is a transformation of the proportion of samples that support the chosen response, more discriminable stimuli will on average produce higher confidence judgments (see Equation 8). Conversely, on more difficult trials, the evidence will be more heterogeneous and so the ABS predicts lower average decision confidence. 
Figure 9A
 shows this qualitative effect arising in ABS model simulations, in which confidence is expressed on a probability scale which is ordinally related to the scale with which the empirical data were collected, and it is produced by all model variants (see 
Table 2
).
Second, average confidence ratings tend to be higher for correct responses than for incorrect responses (e.g., 
Ariely et al., 2000;
Baranski & Petrusic, 1998;
Vickers, 1979;
Vickers, 2014;
Vickers & Packer, 1982)
. This so-called "resolution-of-confidence" effect also holds true even if stimulus difficulty is held constant 
(Baranski & Petrusic, 1998)
 and even if choice and confidence are simultaneously elicited from participants 
(Ratcliff & Starns, 2009;
Van Zandt, 2000;
Kiani et al., 2014)
. Once again, the SPRT cannot properly explain this effect given that its thresholds are fixed prior to, and independently from, the characteristics of particular trials (e.g., it is constant across all trials or randomly drawn from a fixed distribution). However, if we make the assumption that people have the correct generative model of the task (i.e., the probability of generating a sample that supports the correct alternative is the largest among all other alternatives), the ABS predicts that correct responses will on average be made with higher confidence. This is tied to the explanation for slower errors above: autocorrelations cause errors to be slower on average, and slower responses produce lower confidence judgments (see Equation 9). Therefore, the ABS predicts a resolution-of-confidence effect in experimental conditions that produce slow errors (see 
Figure 9B
). As this effect requires both optional stopping and autocorrelated samples, as also are required to produce slow errors, only the full model and the no prior variant produce it (see 
Table 2
).
Third, studies have shown that the meta-cognitive judgments in confidence ratings generally carry less information about the accuracy of a decision than would be predicted by a purely normative account like the SPRT. Thus, there seems to be a systematic deficit in "metacognitive efficiency" 
(Shekhar & Rahnev, 2021a;
2021b)
. To give an intuition, imagine a participant is asked to make a decision whether to respond A or B to a stimulus. The participant's ability to discriminate between the alternatives (i.e., . ) can be calculated, based on SDT, by using the percentage of A stimuli that are correctly identified (i.e., hits) and the percentage of B stimuli that are incorrectly identified as A stimuli (i.e., false alarms). This standard . measure can also be extended to metacognition by choosing a confidence criterion and recalculating the hit and false alarm rates from confidence judgments that exceed this criterion to produce a meta_d' 12 . SDT predicts that . equals meta_d' for any confidence criterion and so predicts that metacognitive judgments are always efficient (while 12 Informativeness of choices and confidence ratings are measured as stimulus sensitivity d' and meta_d' respectively 
(Maniscalco & Lau, 2012;
Fleming & Lau, 2014)
. More specifically, * = +$ (hit rate) âˆ’ +$ (false alarm rate) where +$ is the inverse of the cumulative Gaussian distribution. meta_d' is calculated in the same manner but with the hit rate and the false alarm rate tallied according to a criterion value that partitions confidence ratings. More specifically, the hit rate is the proportion of trials in which participants reported high confidence given a correct response, whereas the false alarm rate is the proportion of trials in which participants reported high confidence given an incorrect response; and the confidence criterion value determines whether a confidence judgment is considered high or low.
the SPRT predicts constant confidence judgments and so cannot be evaluated using this measure). By contrast, a value of _ â€²/ â€² < 1 would indicate that information available for the decision is lost in part of in whole when making confidence judgments. Empirically, metacognition has been found to be inefficient, and moreover meta_d' decreases relative to
. as the confidence criterion increases, meaning that higher confidence ratings are less informative than lower confidence ratings 
(Shekhar & Rahnev, 2021a;
2021b)
. Metacognitive inefficiency has been explained by adding additional noise to confidence judgments 
(Shekhar & Rahnev, 2021a)
.
While it would be straightforward to add noise to the ABS confidence judgments, surprisingly this additional noise is not necessary to produce such metacognitive inefficiency;
in fact, there are multiple routes for the ABS to produce this effect already offered in the current specification. A first route derives from more informed decisions being overall less confident decisions. For example, imagine using a stopping rule with âˆ†= 2 and a symmetric Beta(1,1) prior on responses. If a decision is made based on only a total of 2 samples, then both will have to be in favor of the chosen response and confidence will be 75% (i.e.,
plugging these values in Equation 8:
"+! "+" = 75%). However, if a decision is made based on a total of 100 samples then only 51 can have supported the chosen alternative (because the stopping rule requires âˆ†= 51 âˆ’ 49 = 2) and confidence will be about 51% (i.e., plugging these values in Equation 8:
3!+! !((+" â‰ˆ 51%). Thus, with optional stopping, lower confidence decisions will be based on more samples (and so have longer RTs) and hence will be more informative (see Equation 9). A second route derives from basing confidence judgments on discrete samples of hypothesis counts rather than the Gaussian distributed sensory evidence assumed by SDT; this applies even if samples are independent, a fixed number of samples are generated, and no prior is used (see Appendix D). Therefore, the ABS predicts decreasing metacognitive efficiency for more extreme confidence judgments not only for the full model (see 
Figure 9C
) but also for all its variants (see 
Table 2
).
Finally, confidence is empirically observed to systematically vary with RTs, with positive (cross-condition) and negative (cross-trial) relationships between confidence and RTs (see 
Figure 9D)
. When people are forced to respond more quickly in a particular experimental condition, their confidence reduces, which is in line with the standard speed-accuracy tradeoff, assuming the confidence positively co-varies with accuracy 
(Vickers & Packer, 1982;
Irwin et al., 1956)
. Both the SPRT and the ABS can capture the positive (cross-condition) relationship simply by varying the threshold according to experimental conditions:
emphasizing accuracy moves the threshold further away from the starting point of the accumulator (and the opposite is true for the speed condition). Higher threshold values in the SPRT lead to more extreme final log odds and therefore higher confidence readouts. Higher threshold values in the ABS (i.e., larger âˆ†) naturally lead to higher confidence as shown in Equation 9.
However, within a condition, people are more confident in decisions they reach quickly -intuitively, the "easy" trials are decided quickly and with high confidence 
(Baranski & Petrusic, 1998;
Vickers & Packers, 1982)
. Crucially, the SPRT cannot explain this because the strength of evidence at which a decision is made depends only on the threshold, which is determined prior to, and hence independently from, the characteristics of any particular trial.
The ABS can explain this negative (cross-trial) relationship because earlier termination (for a fixed threshold âˆ†) implies that there will be a higher proportion of evidence supporting the chosen alternative. As a result, the ABS predicts that within a condition, faster decisions will be given with higher confidence.


Confidence Intervals
So far, we have considered confidence in decisions. But confidence reports can also be elicited for estimates by asking for confidence intervals. Commonly a participant is given a probability first and then asked to produce an interval (by giving upper and lower bounds) that correspond to the probability (e.g., 'give the smallest interval which you are 60% certain to include the number of dots which appeared onscreen: between ____ and ____ dots').
However, this procedure can also be reversed: participants can be shown an interval of some quantity of interest and then asked to evaluate the probability of that interval (e.g., 'what is the probability that the number of dots which appeared onscreen falls in the range of 23 to 25?'; 
Juslin & Persson, 2002)
.
In the ABS, confidence interval production and evaluation both are driven by very similar mechanisms to those underlying the naÃ¯ve intuitive statistician model of 
Juslin, Winman, & Hansson (2007)
. Taking a set of samples, a confidence interval can be produced by using the lower and upper bounds of the sample coverage (i.e., empirical quantiles of the samples) as the lower and upper bounds of the confidence interval. When the values of the quantiles are not explicitly represented in the sample (e.g., deriving a 93% CI based on 5 samples), linear interpolation was assumed to fill in the gap between the samples 
(Juslin et al., 2007)
. This mechanism correctly predicts the considerable overconfidence in interval production found empirically (see 
Figure 10A
 dots; 
Juslin et al., 2003;
Juslin et al., 2007)
. This is because for small sample sizes, the empirical quantile of the sample will have a shorter range than the confidence interval from the posterior because distributional tails tend to be underrepresented within a few samples. Therefore, the proportion generated from the sample will be too small, producing an overconfident interval in our simulations (see 
Figure   10B
 dots). One might then question why interval production overconfidence is not corrected in the same manner described for probability judgments above where useful prior knowledge is incorporated -this lack of correction for confidence interval production is what was "naÃ¯ve" about the naÃ¯ve intuitive statistician model. Corrections for intervals, however, depend on the functional form of the distribution, so that a general correction process is difficult to establish in the ABS. While the standard computation of a confidence interval assumes a Gaussian distribution, for unknown distributions confidence intervals are usually produced by bootstrapping. For the purposes of producing the confidence interval for a sample, as opposed to producing the confidence interval for a mean, bootstrapping is essentially what the ABS does.
In contrast to confidence interval production, confidence interval evaluation shows very different empirical results: here there is little to no overconfidence with only a small degree of conservatism at the extremes of the subjective probability (see 
Figure 10A
 squares; 
Juslin et al., 2003)
. This arises in the ABS (see 
Figure 10B
 squares), using the simplest possible assumption (and following 
Juslin et al., 2007
) that people answer this question by generating samples and calculating the proportion that fall within the provided interval. As noted by 
Juslin et al., (2007)
, this proportion is an unbiased estimator, and hence shows good
calibration 13 .
13 There is only slight overconfidence predicted by the naÃ¯ve intuitive statistican model when the internal generative model does not perfectly describe the data generating process 
(Juslin et al., 2007)
, and the ABS would show the same effect with an imperfect model of the data generating process. 
Figure 10
. (A) Empirical data for interval evaluation (i.e., probability judgment) and interval production, adapted from 
Juslin et al. (2003)
. Interval evaluations were relatively well calibrated while substantial overconfidence was observed in interval production. The dashed line illustrates perfect calibration. (B) ABS predictions of confidence interval production and evaluation: strong overconfidence in interval production (blue dots) and no overconfidence in interval evaluation (red squares). The horizontal axis indicates either the requested interval coverage (production) or the judged probability of the interval (evaluation), while the vertical axis indicates the empirical proportion of events covered by the interval.


Decisions Affecting Later Estimates
Besides eliciting confidence judgments after choices, experimenters have often asked participants to provide separate secondary responses to the same stimulus. One example is the decision-estimation task where people were asked to first choose, say, whether the number of dots which appeared on-screen was greater or smaller than 25, and then are asked, immediately following the choice, to estimate the number of dots. In this setting, an estimate can be influenced by the preceding choice (e.g., 
Tversky & Kahneman, 1974;
Jazayeri & Movshon, 2007)
. In cognitive judgments, estimate have often been observed to be pulled towards a preceding arbitrary value-a phenomenon better known as the anchoring bias 
(Tversky & Kahneman, 1974;
Epley & Gilovich, 2006)
. For example, in the famous study of 
Tversky and Kahneman (1974)
, participants were first asked to choose whether the percentage of African countries in the United Nations was higher or lower than a value (â„Ž * ),
and then give an estimate of that percentage. The comparison value used in the choice, â„Ž * , was generated randomly and so should have been irrelevant to the distribution of hypotheses (and thus irrelevant to the estimate too), but estimates were biased toward â„Ž * .
However, in an almost identical paradigm of decision-estimation tasks, perceptual judgments showed the opposite effect: estimates of aspects such as dot orientation or direction of motion have been observed to be pushed away from â„Ž * 
(Jazayeri & Movshon, 2007;
Zamboni et al., 2016;
Luu & Stocker, 2018)
. The phenomenon is better known as the repulsion effect found in perceptual tasks.
Existing models of anchoring cannot predict the repulsion effect and vice versa. This is because they only predict one direction of bias (e.g., 
Tversky & Kahneman, 1974;
Strack & Mussweiler, 1997;
Jazayeri & Movshon, 2007;
Luu & Stocker, 2018)
, and thus fail to capture the co-occurrence of anchoring and repulsion. While this would be tenable if anchoring and repulsion were each specific to their respective (cognitive or perceptual) domains, a recent empirical investigation suggests otherwise 
(Spicer et al., 2022)
. In this work, we noted that the location of the comparison value, â„Ž * , relative to the distribution of hypotheses has not typically been the same across cognitive and perceptual paradigms. Indeed, it was found empirically that the relative location of â„Ž * determines whether the subsequent estimates will be pulled toward or pushed away in both cognitive and perceptual tasks. Specifically, estimates are drawn towards distant values of â„Ž * (replicating the anchoring effect) but pushed away from nearby values of â„Ž * (replicating the repulsion effect; 
Spicer et al., 2022)
. This finding is consistent with a common general-purpose algorithm underlying decision-making in both cognition and perception.
The anchoring effect, the repulsion effect, and their dependence on the relative position of â„Ž * are captured by the ABS assuming that the set of samples generated to make the choice is then reused to produce the estimate. To explain anchoring, the ABS follows the approach of 
Lieder et al. (2018)
 and assumes that local sampling algorithm uses â„Ž * as an initial hypothesis. For a small number of iterations, the local sampler will then be biased toward the initial hypothesis. Anchoring is then produced in our simulations for the full model and all variants except the direct sampling variant (see 
Figure 11
 and 
Table 2
).
To explain repulsion, we first note that in the ABS â„Ž * effectively partitions the hypothesis space into two binary response regions. The sampling algorithm is adaptively terminated when a sufficient number of samples support one alternative over the other, with the amount determined by the threshold parameter (i.e., âˆ†). This adaptive stopping rule produces a repulsion bias if the estimate is also based on the same set of samples 
(Zhu et al., 2019)
, because the sampling process will terminate when the weight of evidence favors one hypothesis rather than when the evidence is finely balanced: In effect, optional stopping for choice biases the subsequent estimate away from indifference (i.e., the decision boundary).
Thus, repulsion is produced by the full model and all of the variants except for the fixed sample size variant (see 
Figure 11
 and 
Table 2
). sampling with means in the range of 
[21,
30]
 were shown in black solid lines, which were vertically rescaled by a factor of 1/4 to aid visualization.


Cross-trial Autocorrelations in Estimates and RTs
Substantial cross-trial autocorrelations are an important, and often unexplained, aspect of human behavior. For example, long-range dependencies in estimates and in RTs known as 1/f noise have been observed in many cognitive and perceptual tasks and can explain more variance in behavior than the experimental manipulations 
(Gilden et al., 1995;
Gilden, 2001;
Wagenmakers et al., 2004)
 14 . In these tasks, participants were instructed to repeatedly
14 1/f noise goes under various names in different literatures (e.g., pink noise and flicker noise). Besides cognition, diverse complex processes have also been found to exhibit this type of estimate fixed physical quantities (e.g., a 1-sec temporal interval or a 1-inch spatial interval) or to repeatedly choose between two options. The statistical features of the time series produced by participants were analyzed in the frequency domain, with the high-frequency components corresponding to trials that are close together, whereas low-frequency components correspond to trials that are well separated. The power of each of these components for explaining the time series are then calculated (i.e., in a spectral density analysis; 
Sheu & Ratcliff, 1995;
Gilden et al., 1995;
Gilden, 2001
). Standard statistical processes show different relationships between frequency and power: in a random walk the power falls off with 1/f 2 noise (i.e., a slope of -2 in log-log power spectra), whereas white noise (also called independent sampling or direct sampling) has a flat power spectrum (i.e.,
1/f 0 noise and a slope of 0). In a time-series containing long-range serial dependence, as has been found in human data, power spectra typically have a slope between -1.5 and -0.5, and are thus categorized as 1/f noise. The long-range autocorrelations in 1/f noise are not straightforward to produce, generally requiring complex processes to do so 
(Gardner, 1978)
.
Further complicating the picture, while time-series of estimates have long-range autocorrelations that are classed as 1/f noise 
(Gilden et al., 1995;
Gilden, 2001;
Wagenmakers et al., 2004;
Zhu et al., 2021)
, RT time series fluctuate as 1/f noise but with a log-log slope that is shallower than that of estimates 
(Van Orden et al., 2003;
Wagenmakers et al., 2004)
.
As shown in 
Figure 12
, the ABS qualitatively reproduces the observed autocorrelations in time series of RTs and estimates. The cross-trial autocorrelation in estimates is predicted by the cross-trial carryover of the sampler's location in the autocorrelated MC 3 algorithm 
(Zhu et al., 2018;
Zhu et al., 2022c)
: the initial location of the sampler for the present trial is the long-range dependence. For example, MEG and EEG data from human brains, and indeed classical music, all exhibit 1/f-like fluctuations 
(Novikov et al., 1997;
Linkenkaer-Hansen et al., 2001)
 last sample for the preceding trial. In comparison, the RT time series is predicted to be less autocorrelated because samples generated by the MC 3 are accumulated to a threshold to produce the RT; this is a non-linear transformation of autocorrelated samples which "whitens" the power spectrum. Simulations of the full model demonstrate both these effects, and as it is driven by the MC 3 algorithm it occurs for all variants except for the direct sampling variant (see 
Figure 12
 and 
Table 2
). predicts independent estimates and RTs and thus exhibits a flat line (i.e., the power spectrum of white noise). (Right) The ABS model predicts autocorrelations in estimates and RTs with the latter displaying flatter slopes than the former (i.e., the power spectra of 1/f noise). 


Summary
Using a consistent set of parameter values, we have shown that the ABS qualitatively captures empirical results and relationships observed across probability judgments, estimates, confidence intervals, choices, confidence judgments, and response times (see 
Table 2
). The wide range of predicted behaviors is based on an internal probabilistic model using a finegrained set of hypotheses. The process of inferring the posterior probability of the hypotheses is governed by Bayes' rule and approximated using an autocorrelated sampling algorithm.
While the autocorrelation in the sampling algorithm is motivated as making the sampling process computationally efficient, it is crucial for explaining many empirical effects such as slow errors, anchoring, and cross-trial autocorrelations. Assuming each sample generated is costly, turning these samples into choices relies on an optional stopping rule that trades the benefits of larger samples against the cost of sampling. In turn, the optional stopping rule helps explain empirical effects such as the repulsion effect, the resolution of confidence, and metacognitive inefficiency. The probabilistic model also learns from trial history, using the adaptive prior. This prior helps explain effects such as conservatism, the conjunction fallacy, partition dependence, and fast errors. In sum, this rational process is fruitful for understanding a wide assortment of human behavior. 
N/A âœ“ âœ— âœ“ âœ“ âœ“ Mean-variance relationship N/A âœ“ âœ— âœ“ âœ“ âœ“ Explicit subadditivity N/A âœ“ âœ— âœ“ âœ“ âœ“ Conjunction fallacy N/A âœ“ âœ— âœ“ âœ“ âœ“ Implicit subadditivity in typical unpacking N/A âœ— âœ“ âœ— âœ“ âœ“ Implicit superadditivity in atypical unpacking N/A âœ— âœ“ âœ— âœ“ âœ“ Partition dependence N/A âœ“ âœ— âœ“ âœ“ âœ“ Decisions Affecting Later Responses Anchoring N/A N/A âœ“ âœ— âœ“ âœ“ Repulsion N/A N/A âœ“ âœ“ âœ— âœ“ Accuracy and Response Times Speed-accuracy trade- off âœ“ N/A âœ“ âœ“ âœ“ âœ“ Slow errors âœ— N/A âœ“ âœ— âœ— âœ“ Fast errors âœ— N/A âœ— âœ“ âœ— âœ“ Near-linear relationship of RT quantiles with a fan shape âœ“ N/A âœ“ âœ“ âœ— âœ“


Confidence in Decisions
Positive relationship between confidence and stimulus discriminability 
âœ“ N/A âœ“ âœ“ âœ“ âœ“ Resolution of confidence âœ— N/A âœ“ âœ— âœ— âœ“ Metacognitive inefficiency âœ— N/A âœ“ âœ“ âœ“ âœ“
âœ— N/A âœ“ âœ— âœ— âœ“
Note. N/A denotes that the model is non-applicable to the empirical effect because it does not produce the relevant behavioral measure.


Comparison with Competing Models
There are many models that can produce at least a subset of the empirical effects that the ABS does, and many were briefly mentioned in the text above. Here we compare the ABS first to other models of probability judgments and then to drift-diffusion models of choice, response time, and confidence.


Models of Probability Judgments
Intensive modeling efforts have also been directed at explaining human probabilistic reasoning, spurred on by the identification of biases, particularly those summarized in 
Table   1
, demonstrating that people's judgments do not conform with the rules of probability theory (e.g., 
Peterson & Beach, 1967;
Nilsson et al., 2009;
Costello & Watts, 2014;
Dasgupta et al., 2017;
Zhu et al., 2020;
Tversky & Koehler, 1994;
Hilbert, 2012)
. Many models have assumed that probability judgments follow a deterministic process, albeit one that violates the rules of probability theory. For example, one type of model, geared toward accounting for conjunction fallacies, assumes that probability estimates of conjunctions are the weighted average of the probabilities of their constituent events, which produces above-chance conjunction fallacy rates and can reproduce several probabilistic identities 
(Fantino, Kulik, Stolarz-Fantino, & Wright, 1997;
Nilsson, Winman, Juslin, & Hansson, 2009;
Nilsson, Juslin, & Winman, 2016)
. However, these models require additional mechanisms to match the empirically observed combination of above-chance and below-chance rates of conjunction fallacies that the ABS can produce 
(Nilsson et al., 2009;
Fisk & Pidgeon, 1996)
.
A different type of deterministic approach that has been used to explain conjunction fallacies is based on quantum probability. Here probabilities are based on projections of event subspaces. If the events are compatible, probability judgments are indistinguishable from classical probability theory, but if the events are incompatible then interference produces probability judgments that deviate from classical probability theory. These deviations are such conjunction and disjunction fallacies will occur at rates above chance, and in this way, quantum probability can produce both above-chance and below-chance conjunction fallacies depending on how the events are represented 
(Busemeyer et al., 2011)
. Quantum probability has explained a wide range of probabilistic biases, including some not covered here 
(Pothos & Busemeyer, 2022)
. However, there are also probabilistic identities that quantum probability cannot reproduce, that are predicted by sampling-based models, including the ABS 
Zhu et al., 2020)
.
A third deterministic approach is support theory, which was developed to explain subadditivity biases. The core assumption of support theory is that the probability of event descriptions is evaluated rather than the probability of the events themselves and does not incorporate the probabilities of events that are not immediately available (e.g., those not mentioned in the descriptor of events). This approach elegantly explains both a range of implicit subadditivity results, as well as explaining why subadditivity does not occur for mutually exclusive binary events. However, it does not produce the later finding that an atypical unpacking of events produces implicit superadditivity 
(Sloman et al., 2004)
, and requires additional mechanism such as an "ignorance prior" which pulls probability judgments towards indifference between the available responses 
(Fox & Rottenstreich, 2003)
.
These different mechanisms have echoes in the ABS. In the ABS, a hypothesis is "available" only if it has been sampled, and the event description influences the starting point of the local sampler. Further, the prior on responses is a principled version of the ignorance prior, one that is uncertain about the underlying probabilities because often only a small number of samples is available.
Recent approaches have rejected purely deterministic approaches and explored the alternative possibility that stochastic mechanisms explain the biases in probability judgments.
For example, simple unbiased response noise has been shown to produce subadditivity 
(Bearden, Wallsten, & Fox, 2007;
Brenner, 2003)
. However, unbiased response noise alone does not explain why subadditivity still occurs for median judgments. A more promising alternative is to consider corruptive noise in memory or evidence accumulation, which can produce stronger biases (e.g., 
Costello & Watts, 2014;
Erev et al., 1994;
Hilbert, 2012)
. In a leading stochastic model, Probability Theory plus Noise (PT+N), people are assumed to first draw independent samples from a probabilistic representation, and unbiased "counting noise"
is added to individual samples to reflect an error-prone cognitive system 
(Costello & Watts, 2014
). This counting noise pulls probability judgments towards indifference and allows the PT+N to capture empirical results such as explicit subadditivity, the conjunction fallacy, and a wide range of probabilistic identities 
(Costello & Watts, 2014;
. The PT+N has impressive empirical coverages, although it has recently been argued that it does not fully reproduce all the mean-variance relationship in probability judgments 
(Sundh et al., 2021)
: while it will produce the inverted U-shaped relationship between the mean and variance of judgments, the curve will not be pulled inward as is with the empirical data and as the ABS predicts. This mean-variance relationship also stands as a challenge to deterministic models because it is not easily produced by simply adding response noise to a deterministic model.


Drift-Diffusion Models
One family of models that deserves more extensive discussion is the family of Drift-Diffusion Models (DDMs; 
Ratcliff et al., 2016;
Gold & Shadlen, 2007;
Krajbich & Rangel, 2011;
. While there are many members of this family, they all describe decision making as a stochastic process similar to that of a biased random walk (or a biased diffusion process, in continuous time) in which the path of the accumulator is, on average, biased by the drift rate 
(Ratcliff & McKoon, 2008;
Bogacz et al., 2006)
. For binary choices, this is determined by the difference in the evidence signals supporting for the two alternatives. In line with the stopping rule of the SPRT, the threshold reached in the DDM decides the choice and the time taken to do so the response time. However, unlike the static summation process of log-likelihood ratios in the SPRT, the accumulator in the DDM also diffuses because the accumulator is corrupted by noise, typically white noise. In perceptual tasks, the drift rate is related to which choice is objectively correct 
(Ratcliff & McKoon, 2008
), whereas in high-level cognitive tasks where people are choosing their preferred option the drift rate is assumed to be related to the relative appeal of the alternatives 
(Krajbich, Armel, & Rangel, 2010;
Krajbich & Rangel, 2011
).
There are generally strong theoretical links between these models and the normative framework of the SPRT: in the continuous limit, the SPRT converges on the DDM and the drift rate and the corruptive noise in the DDM can jointly mimic calculation of likelihood ratios in the SPRT 
(Bogacz et al., 2006)
. However, implementing an optimal statistical decision test in the form of the DDM also generates a number of useful theoretical and empirical insights that were not originally part of the SPRT. First, the psychologically implausible assumption that people are required to have global knowledge of the generative model of the task to calculate the exact likelihoods (e.g., ( $ | ) or ( $ | )) is implicitly relaxed by the DDM because the drift rate and diffusion noise are free parameters that are recovered from fitting to behavioral data. Thus, the DDM does not need to calculate with the exact cumulative differences in evidence as supposed by the SPRT, greatly improving the DDM's computational plausibility, given that the exact likelihood ratios are almost always impractical to compute in real time except in simple toy problems.
Second, extensions of the DDM can also account for empirical features such as those noted above which are not accounted for by the SPRT. For example, slow and fast errors 
(Ratcliff & Rouder, 1998;
Townsend & Ashby, 1983)
 can be produced by further assuming that model parameters are variable across trials 
(Laming, 1968;
Rouder, 1996;
Ratcliff, 1981;
Ratcliff & Rouder, 1998)
. In particular, varying the drift rates trial-by-trial generates slow errors, while varying the starting point of the accumulator predicts fast errors 
(Laming, 1968;
Ratcliff & Rouder, 1998
). The ABS model works in a similar fashion, as autocorrelation acts like variability in drift rates and a biased prior of evidence acts like variability in the starting point of the accumulator.
Moreover, the benefits of using the DDM instead of the SPRT also apply to explaining confidence judgments. The SPRT predicts the confidence ratings to be identical between correct and incorrect responses because, for a fixed symmetric threshold, there will always be the same level of evidence difference accumulated favoring the selected option, 15 and the probability that the chosen option is correct is simply read out from the final state of the accumulator. As outlined above, such predictions are contradicted by empirical data in which choice accuracy and confidence are positively related 
(Baranski & Petrusic, 1998;
Dougherty, 2001;
Vickers, 1979;
Yeung & Summerfield, 2014)
. To reconcile the confidence data with the SPRT, one kind of DDM introduced another assumption in which the same drift-diffusion process continues to run for a period of times after the choice has been made
15 Regardless of trial-by-trial variability in drift-rates and/or starting points.
but before the confidence judgments 
(Pleskac & Busemeyer, 2010)
. As the accumulator has a bias toward the correct choice, this continued accumulation after the choice and before the confidence judgment, no longer bounded by the fixed threshold of the decision, will drive the confidence ratings towards supporting the correct choice. Hence, with this additional assumption, this DDM can correctly predict that people should report higher confidence in correct responses than in errors, and moreover that the resolution of confidence effect grows with the delay between choosing and reporting confiden"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]