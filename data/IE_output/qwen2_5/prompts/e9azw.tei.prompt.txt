You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
When you go to your favorite restaurant, do you always get the same thing (the pizza you know and love), or are you ever tempted by something else (the ravioli you've never tried)? Exploiting an old favorite guarantees the reward of a good meal, but is uninformative (you already know the pizza is good). On the other hand, exploring something new brings no guarantees about the quality of the meal, but does guarantee that you learn something (in this case, whether you like the ravioli or not). This is an example of the explore-exploit dilemma, a behavioral dilemma that occurs any time our desire for information conflicts with our need for reward 
[1,
2,
3,
4,
5,
6]
.
Outside of the contrived examples at the start of explore-exploit papers, the exploreexploit dilemma is ubiquitous. It is faced by birds in the sky as they forage for food 
[7]
 and fish in the sea as they decide where to hunt 
[8]
. Monkeys face it when navigating changing environments 
[9]
 and rats face it all the time in the lab 
[10]
. Even slime molds, without a brain but with a rudimentary ability to process information and a drive to find food, confront the explore-exploit dilemma 
[11]
. As humans we face it when we travel to work 
[12]
, decide where to fish 
[13]
, or pick out food to order online 
[14]
. As scientists we face it when choosing the next experiment to run. And as experts on explore-exploit decisions, the authors of this paper face it every time we introduce the dilemma to a new audience in our papers and talks: should we exploit the tried-and-trusted restaurant examples we have used before 
[15]
, or branch out and explore something new?
Given the ubiquity of the explore-exploit dilemma, an obvious question is: How do we solve it? Based on recent literature in psychology and neuroscience, we argue that humans and animals combine two major (but not mutually exclusive) strategies for exploration: information-seeking (directed exploration) and behavioral variability (random exploration). These strategies are associated with different neural correlates and the natural balance between them changes over the lifespan. Ultimately, we argue that a holistic model of human exploration must account for this duality and we review recent progress in developing such models. We end by highlighting some of the major open questions in the field.


Directed and random strategies for exploration
Optimal solutions to the explore-exploit dilemma are intractable in all but the simplest cases 
[16,
17,
18,
19]
. The reason for this difficulty is that optimal solutions require us to perform massive simulations of the future -considering how choices impact future outcomes and how those outcomes will impact future choices. Because of this computational complexity, most theoretical work has turned to approximate methods. While there are literally hundreds of such approximate algorithms 
[20]
, across all of these approaches, two general strategies have proven to be especially effective: an explicit bias for information, 'directed exploration' 
[16,
17]
, and the randomization of choice, 'random exploration' 
[21,
22,
2]
 
(Figure 1
).  : Illustration of a simple explore-exploit task and algorithms that attempt to solve it. (a) In this 'bandits task,' participants choose between three slot machines, or 'onearmed bandits,' loosely based on those in a casino. In this case the bandits pay out rewards sampled from Gaussian distributions whose mean is different for each machine. Participants are not told these mean payoffs and so must explore in order to learn which bandit is best. However, because they receive the reward from the bandit they choose, they also face pressure to exploit the bandit they currently believe to be best. After several plays, participants can have quite different information about each bandit, which can be summarized as a posterior distribution over the mean payoff from each option, (b). In this case, the participant has the most information about the red option, which they also believe to be best (narrow distribution with highest mean), some information about the blue distribution (wide distribution, lower mean), and no information about the yellow option (uniform distribution). (cf) Different algorithms make use of the information in different ways. (c) A purely exploitative algorithm sets the value of each option, Q(a), deterministically to the mean of the posterior, r(a). This algorithm always exploits the option with highest r(a), in this case choosing the red option with 100% probability. (d) A purely directed algorithm (in this case the Upper Confidence Bound algorithm, 
[23]
) adds a deterministic information bonus, set to twice the standard deviation of the posterior distribution for each bandit, to the value of each option. This information bonus is largest for the yellow option and the algorithm chooses this exploratory option with 100% probability. (e) A simple random strategy for exploration is to add random noise to the value of all options 
[22]
. This algorithm is not deterministic, and any option can be chosen. However, because the values still include the expected payoff, this option is most likely to choose the option it believes to be best, the red option. (f) A more sophisticated random exploration strategy is Thompson sampling 
[21]
. In this algorithm the value of each option is sampled randomly from the posterior distribution over the mean payoff from each option. The mean of this sampled value is still equal to the expected reward, but its variability -i.e. the decision noise -scales with the uncertainty in each option. Thus random exploration in Thompson sampling is highest when the algorithm is uncertain and reduces to zero when the payoff structure is fully known.
In directed exploration, exploration is 'directed' towards more informative options by a deterministic 'information bonus,' which increases the value of informative options. Mathematically, one way to implement this strategy is by increasing the value of informative options such that the value of taking action a
Q(a) = r(a) + IB(a)
(1)
where r(a) is how good we expect option a to be and IB(a) is the information bonus for each action. In this simple model, the choice is made by picking the option with the highest Q(a). Different algorithms have different forms for the information bonus. One popular approach, epitomized by the 'Upper Confidence Bound' (or UCB) algorithm 
(Figure 1c)
, is to set the information bonus proportional to the uncertainty about the expected payoff from each option 
[23]
. In some situations the performance of this strategy can be close to optimal despite having a fraction of the computational cost. In random exploration, random decision noise drives exploration by chance. Mathematically, one way to implement random exploration is by adding noise to the computation of value Q(a) = r(a) + η(a)
where η(a) is zero-mean random noise sampled from some probability distribution and again the choice is the action with largest Q(a). The exact flavor of random exploration is determined by the form of the noise distribution. For example, adding logisticiallydistributed random noise to values will yield the famous softmax choice function ( 
Figure  1d
). Random forms of exploration can perform quite well in many environments and other noise distributions can solve other problems. For example, annealing algorithms reduce the noise over time, while an algorithm called Thompson Sampling scales the noise with the agent's uncertainty. Both approaches lead to high levels of random exploration when the environment is unknown, but reduce random exploration later on allowing the agent to exploit what it has learned and leading to near optimal performance in some cases ( 
Figure 1e
) 
[21,
24]
. Of course, directed and random exploration are not mutually exclusive and it is possible to use both strategies at once. In fact, there is strong evidence that humans and animals use both strategies; how exactly this holistic strategy could be implemented is a question we address towards the end.


The existence of directed and random exploration in behavior
While the success of directed and random exploration in artificial systems suggests that they may be good strategies for humans and animals, identifying these strategies in behavior proved difficult because of a number of psychological confounds. For example, directed exploration is often opposed by risk and ambiguity aversion 
[25,
26]
, while random exploration is difficult to disentangle from boredom or disengagement from the task. As a result, early work looking for directed exploration led to mixed results (e.g. 
[27,
28]
), and the interpretation of choice variability as random exploration has been controversial 
[29,
30,
31]
.
A key advance in proving the existence of directed and random exploration was the design of tasks that manipulate how valuable it is to explore, independent of confounding factors. This approach builds on normative models, which identify the environmental features that should influence exploration because they alter the utility of new information. By manipulating these environmental features, we create conditions where exploration has value and conditions where it does not. We then identify directed and random exploration by looking for changes in information seeking and behavioral variability between these conditions.
Manipulations that increase the value of exploration include: increasing the time horizon 
[32,
15]
, increasing the uncertainty participants have about different options 
[33]
, and adding completely novel options that participants have not seen before 
[34,
35,
36,
37,
38]
. Conversely, manipulations that increase the value of exploitation include raising the stakes of a one-off decision and decoupling information from choice 
[30]
. In all of these cases, information seeking and behavioral variability increase when it is valuable to explore and decrease when it is valuable to exploit, providing strong evidence for the existence of both directed and random exploration in behavior.


The existence of directed and random exploration in the brain
Findings from neuroscience support the existence of directed and random exploration and further suggest that the neural processes underlying them may be dissociable.
Directed exploration, but not random exploration, has been associated with several prefrontal structures and systems, including activity in frontal pole 
[39,
40]
, mesocorticolimbic regions 
[36,
37]
, frontal theta oscillations 
[41]
, and prefrontal dopamine 
[28,
35,
42,
43]
. A causal role for frontal regions in directed exploration is suggested by 
[44]
, who showed that continuous theta-burst transcranial magnetic stimulation to frontal pole abolishes horizon-dependent directed exploration, but leaves random exploration untouched. Building on a long literature in navigation and foraging 
[45]
, Johnson and colleagues 
[46]
 proposed that hippocampus should also play a key role in directed exploration.
The unique neural correlates of random exploration are less circumscribed. A number of studies have suggested that increased neural variability as a mechanism for generating exploratory noise. For example, random exploration is associated with a sudden increase in neural variability and a loss of choice tuning in decision-making circuits in monkeys 
[47]
. Likewise, increased neural variability in motor related circuits in both humans 
[40]
, rodents 
[48]
, and birds 
[49,
50]
 is also related to the use of random exploration. However, choice tuning and changes in neural variability have also been associated with directed exploration 
[51]
 and could reflect other computations 
[31]
.
There is also some evidence that random exploration may be modulated by catecholamines norepinephrine and dopamine. Norepinephrine levels and related measures, like pupil size 
[52,
53]
, predict increased noise in behavior 
[54,
55,
56,
57]
 and the brain 
[58,
31]
. However, results from systemic pharmacological studies tend to be more mixed 
[59,
60]
, and one study even found that blocking norepinephrine only affected exploration of completely novel options, a form of directed exploration 
[38]
, that is also modulated by dopamine 
[35]
. Dopamine has been also been associated with random exploration, with decreased tonic dopamine associated increased behavioral variability 
[61]
 in rats, and dopaminergic neurons being found to modulate song variability in song birds 
[62]
.


Directed and random exploration develop differently over the lifespan
Multiple lines of evidence show that directed and random exploration develop differently over the lifespan. Even infants and preschoolers recognize uncertainty in their environment and make exploratory choices to deconfound variables 
[63]
, resolve belief violations 
[64,
65]
, and reduce ambiguity in intuitive theories 
[66]
. Traditional bandits tasks reveal that the trade-off between exploration and exploitation shifts over development. Preschoolers are more likely to engage in directed exploration than 7-9 year-olds who are more directed than adults 
[67,
68]
.
In naturalistic tasks, preschoolers are sensitive to reward expectation and balance this against factors like whether information is decoupled from reward 
[69,
70]
. However, in more cognitively-demanding tasks, factors like horizon appear to more weakly influence directed exploration for young teens (age 10-12), and grow in influence through adoles-cence and adulthood (early 20s) 
[71]
, remaining stable into old age 
[72]
.
Conversely, random exploration as behavioral variability, (e.g. noise over choice behavior) is prevalent in preschoolers and decreases through adulthood 
[67,
68,
73]
. However, horizon-dependent random exploration appears more constant over adolescence and young adulthood 
[71]
, though is also reduced in healthy older adults 
[72]
. Taken together, these results suggest that some forms of directed and random exploration may be most prevalent in early childhood and diminish with age, but that sensitivity to factors like horizon may follow different trajectories, highlighting the dissociability of the different types of exploration.


Integrating directed and random exploration
Although directed and random exploration rely on dissociable cognitive and neural systems, it is clear that both are used in behavior. In this section we discuss holistic models for how directed and random exploration could be combined.
Perhaps the simplest holistic strategy is to combine the information bonus and decision noise into one equation to estimate the value of choosing a particular option 
[15,
6]
 Q(a) = r(a) + IB(a) + n(a)
In this case, directed and random exploration have additive effects on value, with exploration occurring whenever the information bonus or decision noise tips the balance away from the exploitative choice. Another approach would be to mix the distinct strategies for directed exploration, random exploration, and exploitation over time. In this case, a higher-order process decides when to explore (and perhaps also whether to use a directed or random strategy), while the decision of what to choose is driven by component processes of exploitation, and directed and random exploration. Consistent with this separation of what and when, several studies argue for dissociable exploratory and exploitative states, on the basis of qualitative differences in behavior and neural activity 
[74,
75,
53,
36]
. Further, directed exploration can occur at random times, an observation that is difficult to reconcile with a unified mechanism for deciding when and what to explore 
[76]
.
A third approach to combining directed and random exploration, contends that the two strategies emerge as different behavioral facets of a unified algorithm known in the machine learning literature as Deep Exploration 
[77]
. In this model 
[78]
, the exploreexploit choice is made by mental simulation of a small number of plausible futures that are 'deep,' in that they extend multiple time steps into the future, but narrow, in that the number of simulations used is small. Random exploration arises from this model because the simulations are stochastic. More subtly, directed exploration also arises from Deep Exploration if the mental simulations extend multiple time steps into he future and include lose-shift behavior, i.e. mentally simulating a switch away from an explore option if the simulated outcome is bad. Such lose-shift simulations limit the simulated downside of ex-ploring, which boosts the simulated value of exploring and hence biases the exploration towards informative options.
Beyond the existence of directed and random exploration, Deep Exploration also accounts for the horizon dependence, uncertainty dependence and feedback dependence of directed and random exploration. Moreover, it predicts that there should be a tradeoff between directed and random exploration. As people use more simulations to make their decision they should exhibit more directed exploration and less random exploration, a prediction that holds both across the population and within subject 
[78]
.


Open questions
What should we continue to exploit?
There are outstanding issues in almost every section above and much future work will involve exploiting these ideas. Open questions include: What are the neural mechanisms of directed and random exploration? And how do they relate to other cognitive processes such as working memory 
[79]
 and motor control 
[47,
40,
48,
49,
50]
? How does explore-exploit behavior in general (and directed and random exploration in particular) vary across species and cultures? Are individual differences in directed and random exploration stable traits? Do directed and random exploration change in mental illness 
[80,
81,
82,
83,
84,
85]
? And is modifying explore-exploit, with neural stimulation or behavioral therapy, a potential therapeutic target 
[86,
44]
?
In regard to the computations underlying explore-exploit decisions: Are they really made by mental simulation as implied by Deep Exploration? And if Deep Exploration is really at play, how can this unifying theory explain the dissociation between directed and random exploration? Are there separate decision processes for 'when' versus 'what' to explore? And, more generally, are exploration and exploitation distinct behavioral states or are they drives that work together in a more continuous fashion?
What is left to explore?
There are a number of more open-ended questions we should explore, although this is by no means an exhaustive list.


How does explore-exploit behavior relate to other constructs?
Because we still lack precise operational definitions, there is perennial confusion about the relationship between explore-exploit behavior and a number of other related constructs. These include 'classic' measures in behavioral economics such as risk taking, ambiguity attitude, and loss aversion, as well as measures from ecology such as foraging, stopping problems, and search 
[19]
. The relationship with foraging and search has been questioned empirically 
[87]
 and whether these are distinct behaviors or share some variance is a key question.
Outside of the physical world, explore-exploit problems may also occur in the mental domain. Indeed, mental search and theory change has framed learning as an exploreexploit problem in which we choose between exploiting our current beliefs about the world or mentally exploring for new hypotheses (see, e.g. 
[88,
89,
90,
91]
). The degree to which the processes of mental search align with those in the physical world remain a topic for future work; additionally behavioral methods to tease apart directed versus random search in mental space remain elusive.
Finally, it is an open question how explore-exploit behavior relates to emotions such as curiosity, interest, and affect 
[92,
93,
94,
95,
96,
97]
. While these concepts are thought to inspire or inhibit exploration or exploitation, the relationship between them and exploreexploit behavior has not been sufficiently explored. There is a conceptual bias that exploration is an intrinsically appetitive act, intended to maximize future rewards and minimize future losses. However, depending on the decision context and choice outcomes exploring could be construed as aversive and avoided. By examining directed and random exploration in both appetitive and aversive environments we can understand how explore-exploit decisions differ from simpler approach-avoidance behaviors.


How do we explore complex environments?
Many explore-exploit papers begin in the real-world, with a motivating example like the restaurant example in this paper, but they almost always end up in the lab, with participants performing highly controlled tasks with few options and simple probability distributions over rewards. The real world does not look like this, and the obvious question is whether that matters for explore-exploit behavior or not?
That is, are directed and random exploration enough for the complexity of real-world explore-exploit problems? Or are we missing something fundamental from the theory? A new type of exploration perhaps 
[38]
? Or exploration based on stereotyped behaviors, that are not based on information or randomization, but are nevertheless effective 
[98]
?
Relatedly, does the complexity of the real world, make implementing the more sophisticated algorithms for directed and random exploration too difficult? For example, Thompson Sampling and Deep Exploration require the ability to simulate future outcomes, a computation that gets more difficult as the complexity of those outcomes increases. Conversely, simpler strategies such as a fixed bias for novel stimuli 
[99]
 or adding decision noise that is not tuned to simulated outcomes may perform well enough in more complex settings that a more difficult computation is not justified.
Towards this end of understanding how directed and random exploration are implemented in more complex settings, is recent work by 
[100]
 who used a task with hundreds of options and a complex reward structure. While this increased complexity required a new model of learning to explain behavior, the decision process, based on an information bonus and decision noise, did not. Similarly, work on exploration using online food orders found evidence for uncertainty driven exploration in this real-world case 
[14]
. As impressive as this work is, we have only just begun to scratch the surface of the complexity of the real world and there is, quite literally, a whole world out there left to explore!
Figure 1
1
) = r(a) + (a) (a) ~ Logistic(0, s)








Acknowledgements
This work was supported by grants from the National Institute on Aging (R01AG061888 to RCW), the National Science Foundation (SES #1627971 to EB), the McDonnell Foundation (to EB and to RCW), the Jacobs Foundation (to EB), a Brain and Behavior Foundation Young Investigator Award (#27298 to RBE) and an Unfettered Research Grant from the Momental Foundation (to RBE).






Highlighted papers ** 
[30]
 Demonstrates that most noise in reinforcement learning tasks is learning noise that has autocorrelation over time. However, the noise used for random exploration is different and appears to have no autocorrelation. 
 










Reinforcement learning: A survey




Leslie
Pack Kaelbling






Andrew W
Michael L Littman






Moore








Journal of artificial intelligence research




4
















Reinforcement learning: An introduction




S
Richard






Andrew
G
Sutton






Barto








MIT press












Should i stay or should i go? how the human brain manages the trade-off between exploitation and exploration




Jonathan D Cohen






M
Samuel






Angela
J
Mcclure






Yu








Philosophical Transactions of the Royal Society B: Biological Sciences




362
















Exploration versus exploitation in space, mind, and society




T
Thomas






Hills






M
Peter






David
Todd






David
Lazer






Iain
D
Redish






Cognitive
Couzin






Search Research






Group








Trends in cognitive sciences




19


1
















Unpacking the exploration-exploitation tradeoff: A synthesis of human and animal literatures. Decision




Katja
Mehlhorn






R
Ben






Newell






M
Peter






Todd






D
Michael






Kate
Lee






Morgan






A
Victoria






Daniel
Braithwaite






Klaus
Hausmann






Cleotilde
Fiedler






Gonzalez








2


191












The algorithmic architecture of exploration in the human brain




Eric
Schulz






Samuel J Gershman








Current opinion in neurobiology




55
















Test of optimal sampling by foraging great tits




Alejandro
John R Krebs






Peter
Kacelnik






Taylor








Nature




275


5675
















Scaling laws of marine predator search behaviour




W
David






Emily
J
Sims






Nicolas
E
Southall






Graeme
C
Humphries






Hays






J
A
Corey






Jonathan
W
Bradshaw






Alex
Pitchford






James






Z
Mohammed






Andrew
S
Ahmed






Mark
A
Brierley






Hindell








Nature




451


7182
















Anthropogenic influences on the time budgets of urban vervet monkeys




R
Harriet






Colleen
T
Thatcher






Nicola
F
Downs






Koyama








Landscape and Urban Planning




181
















Many paths to the same goal: balancing exploration and exploitation during probabilistic route planning




J
Brian






Gusti
Lulu
Jackson






Sujean
Fatima






David
H
Oh






Gire








Eneuro




7


3


2020












Slime mold uses an externalized spatial "memory" to navigate in complex environments




Tanya
Chris R Reid






Audrey
Latty






Madeleine
Dussutour






Beekman








Proceedings of the National Academy of Sciences




109


43
















The benefits of forced experimentation: striking evidence from the london underground network




Shaun
Larcom






Ferdinand
Rauch






Tim
Willems








The Quarterly Journal of Economics




132


4
















Disturbance modifies payoffs in the explore-exploit trade-off




O'
Shay






James
N
Farrell






Orr
Sanchirico






Maxime
Spiegel






Alan
C
Depalle






Haynie






A
Steven






Larry
Murawski






Andrew
Perruso






Strelcheck








Nature communications




10


1
















Structured, uncertainty-driven exploration in real-world consumer choice




Eric
Schulz






Rahul
Bhui






C
Bradley






Bastien
Love






Brier






T
Michael






Samuel
J
Todd






Gershman








Proceedings of the National Academy of Sciences


the National Academy of Sciences






116














Humans use directed and random exploration to solve the explore-exploit dilemma




Andra
Robert C Wilson






Geana






M
John






White






A
Elliot






Jonathan
D
Ludvig






Cohen








Journal of Experimental Psychology: General




143


6


2074














A problem in the sequential design of experiments




Richard
Bellman








Sankhyā: The Indian Journal of Statistics




16


3/4
















Bandit processes and dynamic allocation indices




C
John






Gittins








Journal of the Royal Statistical Society: Series B (Methodological)




41


2
















Forgetful bayes and myopic planning: Human learning and decision-making in a bandit setting




Shunan
Zhang






Angela
Yu








Advances in neural information processing systems


















Theory of choice in bandit, information sampling and foraging tasks




B
Bruno






Averbeck








PLoS computational biology




11


3
















Sébastien
Bubeck






Nicolo
Cesa-Bianchi




arXiv:1204.5721


Regret analysis of stochastic and nonstochastic multi-armed bandit problems










arXiv preprint








On the likelihood that one unknown probability exceeds another in view of the evidence of two samples




William R Thompson








Biometrika




25


3/4
















Learning from delayed rewards




Christopher John Cornish Hellaby
Watkins








King's College, Cambridge






PhD thesis








Finite-time analysis of the multiarmed bandit problem




Peter
Auer






Nicolo
Cesa-Bianchi






Paul
Fischer








Machine learning




47


2-3
















Analysis of thompson sampling for the multiarmed bandit problem




Shipra
Agrawal






Navin
Goyal








Conference on learning theory


















Risk, ambiguity, and the savage axioms. The quarterly journal of economics




Daniel
Ellsberg




















Recent developments in modeling preferences: Uncertainty and ambiguity




Colin
Camerer






Martin
Weber








Journal of risk and uncertainty




5


4
















Cortical substrates for exploratory decisions in humans




D
Nathaniel






Daw






P
John






Peter
O'doherty






Ben
Dayan






Raymond J
Seymour






Dolan








Nature




441


7095
















Prefrontal and striatal dopaminergic genes predict individual differences in exploration and exploitation




J
Michael






Frank






B
Bradley






Jen
Doll






Francisco
Oas-Terpstra






Moreno








Nature neuroscience




12


8


1062














Taming the beast: extracting generalizable knowledge from computational models of cognition. Current opinion in behavioral sciences




R
Matthew






Michael J
Nassar






Frank








11














Computational noise in reward-guided learning drives behavioral variability in volatile environments




Charles
Findling






Vasilisa
Skvortsova






Remi
Dromnelle






Stefano
Palminteri






Valentin
Wyart








Nature neuroscience


















Control of entropy in neural models of environmental state




H
Timothy






Muller






B
Rogier






Timothy
E
Mars






Jill X O'
Behrens






Reilly








Elife




8


39404














Studies of foraging behaviour and time budgeting in great tits (Parus major)




Alejandro
Kacelnik












University of Oxford






PhD thesis








Deconstructing the human algorithms for exploration. Cognition




J
Samuel






Gershman








173














Striatal activity underlies novelty-based choice in humans




Nathaniel
D
Bianca C Wittmann






Ben
Daw






Raymond J
Seymour






Dolan








Neuron




58


6
















Dopamine modulates novelty seeking behavior during decision making. Behavioral neuroscience




D
Vincent






Valery
L
Costa






Janita
Tran






Bruno
B
Turchi






Averbeck








128


556












Subcortical substrates of explore-exploit decisions in primates




D
Vincent






Andrew
R
Costa






Bruno
B
Mitz






Averbeck








Neuron




103


3
















Primate orbitofrontal cortex codes information relevant for managing explore-exploit tradeoffs




D
Vincent






Costa






Bruno B Averbeck








Journal of Neuroscience




40


12


















Magda
Dubois






Johanna
Habicht






Jochen
Michely






Rani
Moran






Ray
Dolan






Tobias
Hauser




Noradrenaline modulates tabula-rasa exploration. bioRxiv
















Rostrolateral prefrontal cortex and individual differences in uncertainty-driven exploration




David
Badre






B
Bradley






Nicole
M
Doll






Michael J
Long






Frank








Neuron




73


3
















Dissociable neural correlates of uncertainty underlie different exploration strategies




S
Momchil






Tomov






Q
Van






Truong






A
Rohan






Samuel
J
Hundia






Gershman








Nature communications




11


1
















Frontal theta reflects uncertainty and unexpectedness during exploration and exploitation




F
James






Christina
M
Cavanagh






Figueroa






X
Michael






Michael J
Cohen






Frank








Cerebral cortex




22


11
















Dopaminergic genes are associated with both directed and random exploration




J
Samuel






Gershman






Bastian Greshake Tzovaras








Neuropsychologia




120
















Dopaminergic modulation of the exploration/exploitation trade-off in human decision-making. Elife




Karima
Chakroun






David
Mathar






Antonius
Wiehler






Florian
Ganzer






Jan
Peters








9


51260












A causal role for right frontopolar cortex in directed, but not random, exploration. Elife, 6:e27430




Malgorzata
Wojciech K Zajkowski






Robert C
Kossut






Wilson


















The hippocampus as a cognitive map




O'
John






Lynn
Keefe






Nadel








Clarendon Press


Oxford












The hippocampus and exploration: dynamically evolving behavior and neural representations




Adam
Johnson






Zachary
Varberg






James
Benhardus






Anthony
Maahs






Paul
Schrater








Frontiers in human neuroscience




6


216














Exploration disrupts choicepredictive signals and alters dynamics in prefrontal cortex




Eddy
Becket Ebitz






Tirin
Albarran






Moore








Neuron




97


2
















Distinct sources of deterministic and stochastic components of action timing decisions in rodent frontal cortex




Masayoshi
Murakami






Hanan
Shteingart






Yonatan
Loewenstein






Zachary
F
Mainen








Neuron




94


4
















The role of variability in motor learning




Maurice
A
Ashesh K Dhawale






Bence
Smith






Pölveczky








Annual review of neuroscience




40
















The avian basal ganglia are a source of rapid behavioral variation that enables vocal motor exploration




Satoshi
Kojima






H
Mimi






Allison
J
Kao






Michael
S
Doupe






Brainard








Journal of Neuroscience




38


45
















Rule adherence warps decision-making




Jiaxin
Cindy
Becket Ebitz






Benjamin Y
Tu






Hayden








BioRxiv
















Pupil size as a window on neural substrates of cognition




Siddhartha
Joshi






Joshua
I
Gold








Trends in Cognitive Sciences
















Both a gauge and a filter: Cognitive modulations of pupil size




R
Becket Ebitz






Tirin
Moore








Frontiers in neurology




9


1190














Pupil diameter predicts changes in the exploration-exploitation trade-off: Evidence for the adaptive gain theory




Marieke
Jepma






Sander
Nieuwenhuis








Journal of cognitive neuroscience




23


7
















Behavioral variability through stochastic choice and its gating by anterior cingulate cortex




D
G
Tervo






M
Proskurin






M
Manakov






M
Kabra






A
Vollmer






K
Branson






A
Y
Karpova








Cell




159


1
















Neural and sympathetic activity associated with exploration in decision-making: further evidence for involvement of insula




Hideki
Ohira






Naho
Ichikawa






Kenta
Kimura






Seisuke
Fukuyama






Jun
Shinoda






Jitsuhiro
Yamada








Frontiers in behavioral neuroscience




8


381














Pupil size and social vigilance in rhesus macaques




John
M
Becket Ebitz






Michael L
Pearson






Platt








Frontiers in neuroscience




8


100














Coordinated forms of noradrenergic plasticity in the locus coeruleus and primary auditory cortex




Ana
Raquel






O
Martins






Robert C Froemke








Nature neuroscience




18


10
















The effect of atomoxetine on random and directed exploration in humans




M
Christopher






Warren






C
Robert






Wilson






J
Nic






Eric
J
Van Der Wee






Giltay






Jonathan
D
Martijn S Van Noorden






Sander
Cohen






Nieuwenhuis








PloS one




12


4


176034














The role of the noradrenergic system in the explorationexploitation trade-off: a pharmacological study




Marieke
Jepma






Erik T Te
Beek






Eric-Jan
Wagenmakers






Joop
Van Gerven






Sander
Nieuwenhuis








Frontiers in human neuroscience




4


170














Dopamine blockade impairs the exploration-exploitation trade-off in rats




François
Cinotti






Virginie
Fresno






Nassim
Aklil






Etienne
Coutureau






Benoît
Girard






Alain
R
Marchand






Mehdi
Khamassi








Scientific reports




9


1
















Dopaminergic modulation of basal ganglia output through coupled excitation-inhibition




Agata
Budzillo






Alison
Duffy






Kimberly
E
Miller






Adrienne
L
Fairhall






David
J
Perkel








Proceedings of the National Academy of Sciences




114


22
















Serious fun: preschoolers engage in more exploratory play when evidence is confounded




E
Laura






Elizabeth
Baraff
Schulz






Bonawitz








Developmental psychology




43


4


1045














Children balance theories and evidence in exploration, explanation, and learning




Elizabeth
Baraff Bonawitz






Tessa Jp Van
Schijndel






Daniel
Friel






Laura
Schulz








Cognitive psychology




64


4
















Observing the unexpected enhances infants' learning and exploration




E
Aimee






Lisa
Stahl






Feigenson








Science




348


6230
















Children with more immature intuitive theories seek domain-relevant information




J
Wang






Y
Yang






C
Macias






E
Bonawitz








in revision








Searching for rewards like a child means less generalization and more directed exploration. Psychological science




Eric
Schulz






Charley
M
Wu






Azzurra
Ruggeri






Björn
Meder








30














Development of directed and random exploration in children




Björn
Meder






Charley
M
Wu






Eric
Schulz






Azzurra
Ruggeri


















Choosing to learn: Evidence evaluation for active learning and teaching in early childhood




Elizabeth
Bonawitz






Ilona
Bass






Elizabeth
Lapidow








Active Learning from Infancy to Childhood




Springer
















Explore-exploit: Ambiguity, expectation, and information gain influence preschooler's choices in exploration




E
Lapidow






E
Bonawitz








in review








Charting the expansion of strategic exploratory behavior during adolescence




H
Leah






Stephanie
F
Somerville






Megan
C
Sasse






Andrew
T
Garrad






Nadine
Abi
Drysdale






Catherine
Akar






Robert C
Insel






Wilson








Journal of experimental psychology: general




146


2


155
















Siyu
Jack-Morgan Mizell






Alec
Wang






Lily
Frisvold






Alex
Alvarado






Waitsang
Farrell-Skupny






Mark
H
Keung






Mary-Kathryn
Sundman






Ying-Hui
Franchetti






Gene
E
Chou






Robert
C
Alexander






Wilson




Differential impacts of healthy cognitive aging on directed and random exploration












Probability learning: Changes in behavior across time and development




Jacqueline
M
Rista C Plate






Kristin
Fulvio






Shawn
Shutts






Seth
D
Green






Pollak








Child development




89


1
















A bayesian analysis of human decision-making on bandit problems




Mark
Steyvers






D
Michael






Eric-Jan
Lee






Wagenmakers








Journal of Mathematical Psychology




53


3
















Psychological models of human and optimal performance in bandit problems




Shunan
Michael D Lee






Miles
Zhang






Mark
Munro






Steyvers








Cognitive Systems Research




12


2
















Tonic exploration governs both flexibility and lapses




Brianna
J
Becket Ebitz






Sleezer






P
Hank






Charles
W
Jedema






Benjamin Y
Bradberry






Hayden








PLoS computational biology




15


11


1007475














Deep exploration via bootstrapped dqn




Ian
Osband






Charles
Blundell






Alexander
Pritzel






Benjamin
Van Roy








Advances in neural information processing systems


















Deep exploration as a unifying account of explore-exploit behavior




Robert
Wilson






Siyu
Wang






Hashem
Sadeghiyeh






Jonathan
D
Cohen


















Should we control? the interplay between cognitive control and information integration in the resolution of the exploration-exploitation dilemma




Irene
Cogliati Dezza






Axel
Cleeremans






William
Alexander








Journal of Experimental Psychology: General




148


6


977














Uncertainty about mapping future actions into rewards may underlie performance on multiple measures of impulsivity in behavioral addiction: Evidence from parkinson's disease




Atbin
Bruno B Averbeck






Djamshidian






S
Sean






Charlotte
R
O'sullivan






Jonathan
P
Housden






Andrew J
Roiser






Lees








Behavioral neuroscience




127


2


245














Deficits in positive reinforcement learning and uncertainty-driven exploration are associated with distinct aspects of negative symptoms in schizophrenia




P
Gregory






Strauss






J
Michael






James
A
Frank






Zuzana
Waltz






Ellen
S
Kasanova






James M
Herbener






Gold








Biological psychiatry




69


5
















Attenuated directed exploration during reinforcement learning in gambling disorder




Antonius
Wiehler






Karima
Chakroun






Jan
Peters








BioRxiv




823583














Noveltyseeking impairment in addiction




Irene
Cogliati Dezza






Xavier
Noel






Axel
Cleeremans






Angela
Yu








BioRxiv
















Differential effects of psychotic illness on directed and random exploration




J
A
Waltz






R
C
Wilson






M
A
Albrecht






M
J
Frank






J
M
Gold








Computational Psychiatry
















Increased random exploration in schizophrenia is associated with inflammation. bioRxiv




Flurin
Cathomas






Federica
Klaus






Karoline
Guetter






Hui-Kuan
Chung






Anjali
Raja
Beharelle






Tobias
Spiller






Rebecca
Schlegel






Erich
Seifritz






Matthias
Hartmann-Riemer






Philippe
N
Tobler


















Transcranial stimulation over frontopolar cortex elucidates the choice attributes and neural mechanisms used to resolve exploration-exploitation trade-offs




Rafael
Anjali Raja Beharelle






Polanía






A
Todd






Christian C
Hare






Ruff








Journal of Neuroscience




35


43
















Foraging, exploration, or search? on the (lack of) convergent validity between three behavioral paradigms




Rui
Bettina Von Helversen






Mata






R
Gregory






Andreas
Samanez-Larkin






Wilke








Evolutionary Behavioral Sciences




12


3


152














Probabilistic models, learning algorithms, and response variability: sampling in cognitive development




Elizabeth
Bonawitz






Stephanie
Denison






L
Thomas






Alison
Griffiths






Gopnik








Trends in cognitive sciences




18


10
















Win-stay, lose-sample: A simple sequential algorithm for approximating bayesian inference




Elizabeth
Bonawitz






Stephanie
Denison






Alison
Gopnik






Thomas L
Griffiths








Cognitive psychology




74
















Sticking to the evidence? a behavioral and computational case study of micro-theory change in the domain of magnetism




Elizabeth
Bonawitz






D
Tomer






Sophie
Ullman






Alison
Bridgers






Joshua
B
Gopnik






Tenenbaum








Cognitive science




43


8


12765














Theory learning as stochastic search in the language of thought




Tomer D Ullman






D
Noah






Joshua
B
Goodman






Tenenbaum








Cognitive Development




27


4
















Curiosity and exploration




E
Daniel






Berlyne








Science




153


3731
















The psychology and neuroscience of curiosity




Celeste
Kidd






Y
Benjamin






Hayden








Neuron




88


3
















Towards a neuroscience of active sampling and curiosity




Jacqueline
Gottlieb






Pierre-Yves
Oudeyer








Nature Reviews Neuroscience




19


12
















Boredom, information-seeking and exploration




Andra
Geana






Robert
Wilson






Nathaniel
D
Daw






Jonathan
D
Cohen




CogSci
















The four-phase model of interest development




Suzanne
Hidi






Ann
Renninger








Educational psychologist




41


2
















Awesome play: Awe increases preschooler's exploration and discovery




Joseph
Colantonio






Elizabeth
Bonawitz


















Variability in velocity profiles during freeair whisking behavior of unrestrained rats




Blythe
Towal






Mitra Jz
Hartmann








Journal of neurophysiology




100


2
















The short-latency dopamine signal: a role in discovering novel actions?




Peter
Redgrave






Kevin
Gurney








Nature reviews neuroscience




7


12
















Generalization guides human exploration in vast decision spaces




C
M
Wu






E
Schulz






M
Speekenbrink






J
D
Nelson






B
Meder








Nature human behaviour




2


12

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]