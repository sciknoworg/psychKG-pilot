You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
For over half a century, computational modeling has been instrumental in exploring decision-making dynamics. With the challenges of directly manipulating and observing the brain, models play a crucial role in formalizing and evaluating mechanistic hypotheses regarding decision-making processes. They enable us to explore questions such as how individuals process information over time, adapt their caution levels across diverse contexts, or navigate through complex choice landscapes with multiple alternatives and attributes. Such questions often prove elusive through observation or statistical analysis alone. Models offer a robust method to indirectly investigate these questions by comparing the anticipated data patterns predicted by models to experimental findings.
One prominent category of models in this realm are Evidence Accumulation Models (EAMs). EAMs model decision outcomes by simulating the processes involved in making a choice. For instance, the commonly used Diffusion Decision Model 
(DDM)
 posits that individuals probabilistically sample information over time, incrementally accumulate evidence based on this information, and reach a decision upon reaching a critical evidence threshold. Such models, including variants, are often represented mathematically through stochastic differential equations (SDEs). A notable advantage of this model family lies in its ability to model both the decisions made and the time taken to reach them, commonly referred to as Choice-Response Time (choice-RT) data.
Crucially, the duration of decision-making offers valuable insights into the properties of underlying cognitive processes.
Evidence Accumulation Models (EAMs) are widely recognized in cognitive psychology for their effectiveness. They accurately capture various aspects of decision-making and response times, including the trade-off between speed and accuracy, the right skew in human response time distributions, the relationship between average response times and their variability, and distinctions between quick and slow errors 
(Brown & Heathcote, 2008;
Ratcliff, 1978;
Ratcliff & Rouder, 1998;
Ratcliff, Zandt, & McKoon, 1999;
Usher & McClelland, 2001)
. Additionally, they find application in diverse areas such as learning processes 
(Evans, Brown, Mewhort, & Heathcote, 2018;
Fontanesi, Gluth, Spektor, & Rieskamp, 2019)
, categorization tasks 
(Nosofsky, Little, Donkin, & Fific, 2011;
Nosofsky & Palmeri, 1997)
, memory mechanisms 
(Osth & Farrell, 2019;
Ratcliff, 1978)
, language comprehension 
(Lerche, Christmann, & Voss, 2018;
Wagenmakers, Ratcliff, Gomez, & McKoon, 2008)
, consumer decision-making 
(Busemeyer, Gluth, Rieskamp, & Turner, 2019;
Evans, Holmes, & Trueblood, 2019)
, development and aging 
(Ratcliff, Thapar, & McKoon, 2001;
van Wouwe et al., 2016;
Wieschen, Makani, Radev, Voss, & Spaniol, 2023)
, and personality and mood 
(White, Ratcliff, Vasey, & McKoon, 2010)
. Researchers have also begun to integrate EAMs with psychophysiological data, such as neural recordings 
(Turner et al., 2013;
Turner, Rodriguez, Norcia, McClure, & Steyvers, 2016;
Turner, van Maanen, & Forstmann, 2015)
, motor performance data 
(Servant, White, Montagnini, & Burle, 2016)
, eye movements 
(Krajbich, Armel, & Rangel, 2010)
, functional magnetic resonance imaging 
(Forstmann, van den Wildenberg, & Ridderinkhof, 2008;
White et al., 2014)
, electromyography 
(Servant, White, Montagnini, & Burle, 2015)
, and electroencephalography 
(Kelly & O'Connell, 2013;
Philiastides, Heekeren, & Sajda, 2014;
Servant et al., 2016)
.
Their popularity and success has led to the proposal of numerous modifications to the original DDM concept. Such proposals have modified the drift rate 
(Cisek, Puskas, & El-Murr, 2009;
Dendauw et al., 2024;
Ditterich, 2006;
Smith, 1995;
Ulrich, Schröter, Leuthold, & Birngruber, 2015)
, the diffusion rate 
(Cisek et al., 2009;
Trueblood, Heathcote, Evans, & Holmes, 2021)
, and the shape of the decision thresholds 
(Churchland, Kiani, & Shadlen, 2008;
Ditterich, 2006;
Evans & Hawkins, 2019;
Evans, Hawkins, & Brown, 2020;
Hanks, Mazurek, Kiani, Hopp, & Shadlen, 2011;
Hawkins, Forstmann, Wagenmakers, Ratcliff, & Brown, 2015;
Palestro, Weichart, Sederberg, & Turner, 2018;
Voskuilen, Ratcliff, & Smith, 2016)
, with the intention of exploring decision mechanisms beyond those encoded in the standard DDM. Though the PARAMETER RECOVERY 5 introduction of these additional features into the EAM framework substantially increases its investigative breadth, it also presents challenges. One of the prime values of EAMs over the decades has been their interpretability. They encode interpretable mechanistic features and by fitting them to data researchers can understand how factors of interest impact those features. These features are encoded in the model's structure and parameterization and interpretation often requires analysis of the parametric behavior of the model. Encoding more complex model features is however known to make such parametric analyses more challenging and less robust 
(Boehm et al., 2018;
Dutilh et al., 2019;
Evans, Trueblood, & Holmes, 2020;
Holmes & Trueblood, 2018;
White, Servant, & Logan, 2018)
. Thus there is a tension. More complex models may facilitate investigation of wider ranges of questions and phenomena, but that expansiveness may come at the expense of interpretability.
A number of works have sought to address this question of estimation and model interpretability through parameter recovery studies. The general approach taken is to 1) choose a subset of models to explore, 2) simulate data from the models using a set of known parameters, 3) generate a mathematical representation of the model, then 4) fit the model representation to the simulated data to determine if the input model parameters can be recovered. Among others, 
Lerche and Voss (2016)
 and 
Boehm et al. (2018)
 explored the parameter recoverability of the DDM; 
Evans, Trueblood, and Holmes (2020)
 explored the parameter recovery of the DDM in addition to models containing time changing thresholds and drift rates; 
Trueblood et al. (2021)
 focused specifically on the recovery of the Urgency Gating Model, an EAM with non-constant drift and diffusion rate; 
White et al. (2018)
 explored the recoverability of EAMs modeling conflict tasks; van 
Ravenzwaaij and Oberauer (2009)
  Probability Density Approximation 
(Holmes, 2015;
Turner & Sederberg, 2014)
 and
Quantile Maximation 
(Heathcote, Brown, & Mewhort, 2002;
Ratcliff & Tuerlinckx, 2002)
) while others rely on probabilistic methods (e.g. PyDDM 
(Shinn, Lam, & Murray, 2020)
, fast-dm 
(Voss & Voss, 2007)
 and PyBEAM 
(Murrow & Holmes, 2024))
 Some analyses are preformed using full distributional representations of the predictions of models (likelihood functions) while others compress those representations into summary statistics (RT quantiles, for example). Further, as methods evolve over time, it is unclear how those findings translate using current best practices and methods. One of the goals of this article is to unify this body of literature, and to do so using the best currently available computational methods.
In this work, we seek to address this gap in the literature. We explore the parameter recoverability of a wide number of commonly used EAMs that vary in their implementation of the drift rate, diffusion rate, and decision thresholds. To do so, we use the recently developed Python package PyBEAM, a tool which uses Bayesian methods to fit these models to full choice-RT data 
(Murrow & Holmes, 2024)
. We are using the best available modeling approach and applying it uniformly to these models to assess their qualities. We identify the specific challenges associated with fitting each model to data, then A) explore how to improve their parameter recoverability and B) provide recommendations for how to use them. The intent of this paper is to act as a single resource for the analysis of a suite of common binary choice EAMs, and to provide practical recommendations for best use to researchers who may be interested in studying them. That said, this is not a comprehensive assessment of such models. The analysis of a model should always be tied to the structure of the data available and the scientific purpose of using that model. The results and approaches here-in can however serve as a starting point for such analyses.


PARAMETER RECOVERY 7


Models
In this section, we first introduce the general structure of the models explored in this work. Next, we introduce the specific implementation details for each model. Lastly, we discuss our approach to performing numerical experiments to test the parameter recovery of each model and provide recommendations for practical use.


Two threshold, binary evidence accumulation models
Evidence accumulation models (EAMs) hypothesize that, during a decision, information is stochastically sampled from the stimulus, then additively accumulated until a critical level of evidence is reached. In this article, we specifically focus on the class of two threshold, binary evidence accumulation models discussed in the Though the thresholds in this figure are constant in value, they can also vary with time, either expanding or collapsing from their initial location. The separation between thresholds indicates the level of caution a exhibited by the decision maker. If the thresholds are far apart (near), the decision process will be slower (faster), resulting in more (less) accurate decisions.
Evidence accumulation begins at the start point z, indicated by the blue dot on the left of the panel. The start point can be located anywhere between the upper and lower thresholds and corresponds to an initial bias towards one of the two choices prior to stimulus presentation. For convenience, the start point is often written as a ratio of the threshold separation. This new parameter is referred to as the relative start point, and is given by w = z/(2a). Noisy accumulation proceeds from the start point and continues until one of the two decision thresholds have been reached. If the upper  (lower) threshold is reached first, then choice one (two) is chosen and the time at which the choice occurs is the threshold crossing time. The rate at which evidence accumulates is referred to as the drift rate, indicated by the upwards pointing arrow.
Time ⟹ Evidence Upper Decision Threshold (b 1 (t)) Lower Decision Threshold (b 2 (t)) Start (z) Caution (a) Drift (v(x, t)) A) −2 −1 0 1 2 Time (s) 0.
An additional parameter t nd is added to the final choice-RT value which encodes non-decision related behaviors such as stimulus encoding and motor movement.
EAMs of this type can be written as the following Stochastic Differential Equation where x(t) is the total evidence accumulated at time t and v(x, t) is the rate of evidence accumulation, referred to as the drift rate. The function D(x, t) is the diffusion rate, and it is commonly fixed for scaling purposes. Lastly, W (t) is the standard Wiener process. Once evidence x(t) ≥ b 1 (t) or x(t) ≤ b 2 (t), a choice is triggered.
(SDE), dx(t) = v(x, t)dt + D(x, t)dW (t),
(1)
In this article, we consider a variety of models which differ in their assumptions about the drift rate, diffusion rate, and decision threshold behavior. The drift rate v(x, t), diffusion rate D(x, t), and thresholds b i (t) are free to vary as functions of time and/or evidence. Here, we consider several models of this type commonly applied in the literature: the Simple DDM, EAMs with leaky integration, EAMs with changing thresholds (either Weibull, exponential, or linear), the Urgency Gating Model, and the Diffusion Model of Conflict, all of which are described in detail below.


Simple DDM
The first model we examine, the Simple DDM (sDDM), is the simplest EAM we examine and the basis of all upcoming models. We use this model as the baseline by which to gauge recovery. The sDDM is similar to the Ratcliff Diffusion Decision Model (DDM) 
(Ratcliff, 1978;
, but excludes across-trial variabilities in the start point, non-decision time, and drift rate. The sDDM assumes that the drift rate, decision thresholds, start point, and non-decision time are all fixed quantities throughout the decision process. Thus, it contains four parameters: non-decision time experiments. Note that all EAMs we use going forwards keep the same value for the diffusion rate, with only a small modification for the Urgency Gating Model.
t nd ; drift rate v(x, t) = µ,


Leaky Integration Model
The leaky integration model, referred to as "Leakage" from here on, is an extension of the sDDM with leaky integration added to the drift rate. This model is also referred to in the literature as an Ornstein-Uhlenbeck process. Leakage is used to more realistically describe the accumulation process by modeling the decay of excitatory currents in decision neurons 
(Usher & McClelland, 2001)
. Leaky integration changes the drift rate from a constant to the following,
v(x, t) = µ(t) − L x(t),
(2)
where µ(t) is the stimulus strength (allowed to vary with time) and L is the leakage strength. Addition of the leakage parameter causes old information to decay over a scale approximately equal to 1/L, leading to the favorable property of evidence decaying to zero when the stimulus is removed. This property has led it to being proposed as a mechanism for preference reversals under time pressure 
(Busemeyer & Townsend, 1993)
. If leakage is large, evidence is rapidly lost from the accumulator.
Conversely, small leakage values imply that accumulated evidence is retained for longer periods of time, making the accumulator less sensitive to novel stimulus information.
The leakage parameter can be difficult to recover, so we follow the lead of 
Evans, Trueblood, and Holmes (2020)
 and 
Trueblood et al. (2021)
 and run numerical PARAMETER RECOVERY 11 simulations with two different drift rate implementations: fixed information and changing information. In the fixed information case, the stimulus strength is a constant,
given by µ(t) = µ, where µ is the strength of stimulus information. For the changing information case, 
Trueblood et al. (2021)
 proposed an experiment with time changing information implemented via a grid of pixels flashing one of two colors (blue / orange).
They altered the fraction of each color on the screen at a given time while a decision was being made such that, as an example, early in the decision process, the grid may be 55 percent blue, while later it might be 55 percent orange. This is implemented by allowing the stimulus strength to change with time, given by,
µ(t) =          µ if t < t 0 , −µ if t ≥ t 0 ,
(3)
where, as in the fixed information case, µ 0 is the strength of stimulus information, while t 0 is the time where stimulus information changes, referred to as the flip time. In the context of the above example, at t < t 0 , the grid would be predominately blue (corresponding to positive µ), while for t ≥ t 0 , the grid would be mainly orange (corresponding to negative µ).


Time changing decision thresholds
We next examine EAMs which have time changing decision thresholds (CT). In the case of CT, the first three parameters of the sDDM are retained unmodified: the non-decision time t nd , the relative start point w, and the drift rate v(x, t) = µ. However, the thresholds b i (t) now are a function of time. Though in principle they are free to increase or decrease from their starting value, most interest in the literature has been directed towards thresholds which collapse from their starting point towards zero.
Psychologically, CTs encode dynamic changes in decision strategy. They allow for the subject to optimize the degree of caution they exhibit as time progresses to best meet the demands of the decision task. Thresholds which specifically collapse were shown to provide a mechanism that maximizes the reward rate in decision tasks with unpredictable information 
(Drugowitsch, Moreno-Bote, Churchland, Shadlen, & Pouget, PARAMETER RECOVERY 12 2012;
Thura, Beauregard-Racine, Fradet, & Cisek, 2012)
. In addition, collapsing thresholds provide a natural way to optimize decision behavior when experimental instructions include deadlines or emphasize speed of responding. For example, if a response time deadline is given to a subject, a fixed threshold strategy forces the subject to decrease the entire threshold location. Though this guarantees that the decision is completed by the deadline, it does so at the expense of accuracy early in the decision process. Conversely, collapsing thresholds allow the subject to keep thresholds distant early in the decision process to emphasize accuracy, then decrease the thresholds near the deadline to increase decision speed. For an in depth discussion, see 
Malhotra, Leslie, Ludwig, and Bogacz (2018)
, who developed a theoretical framework which explores in depth the conditions which favor changing thresholds.
Time changing thresholds also provide an alternate cause for the discrepancy in the average error and correct choice-RT. It is known that, in general, the average error choice-RT is not equal to the average correct choice-RT 
(Luce, 1991;
Swensson, 1972)
.
This behavior is most commonly accounted for via the addition of across-trial variability in the drift rate, as in the DDM 
(Ratcliff, 1978;
.
Changing thresholds provide an alternate mechanism to explain this behavior, predicting error RTs that are slower than the correct RTs 
(Ditterich, 2006)
.
Lastly, it has been shown that, in certain circumstances, primates implement changing thresholds in order to optimize their decision process 
(Hawkins et al., 2015)
.
Though it is still a matter of debate (beyond the scope of this article) whether humans routinely exhibit changing decision thresholds, exploration into this question is an active area of research 
(Evans & Hawkins, 2019;
Evans, Hawkins, & Brown, 2020;
Hawkins et al., 2015;
Palestro et al., 2018)
.
The principal threshold we study here is the Weibull threshold. This threshold uses a Weibull cumulative distribution function to model the decision threshold behavior. It is a commonly used threshold due to its flexibility in behavior 
(Hawkins et al., 2015)
 and has been used in a number of studies 
(Evans, Hawkins, & Brown, 2020;
Hawkins et al., 2015;
Palestro et al., 2018)
. The threshold is given by,
b 1 (t) = −b 2 (t) = b 0 − b 0 (1 − c) 2   1 − exp   − t λ κ     .
(4)
Here, b 0 is the initial threshold location. Parameter λ is referred to as the scale parameter, and approximately sets the time at which the threshold expands or collapses. Parameter κ is referred to as the shape parameter and indicates if the threshold is of exponential-like shape (κ < 1) or logistic-like shape (κ > 1). The remaining parameter, c, is the collapse ratio, and indicates how much the thresholds expand or collapse. If c = −1, the thresholds collapse to zero; if −1 < c < 1, the thresholds collapse to somewhere between their initial location b 0 and zero; if c = 1, no threshold collapse occurs; and if c > 1, the threshold expands away from b 0 . Generally, it is assumed that decision thresholds collapse, and thus c < 1. For a more detailed discussion of this threshold's behavior, we refer the reader to the PyBEAM publication 
(Murrow & Holmes, 2024)
 and 
Hawkins et al. (2015)
.
In addition to the Weibull threshold, we also examine several simpler thresholds containing fewer parameters. The first of these, the Reduced Weibull threshold, is identical to the Weibull threshold in Equation (4), with the exception that the collapse parameter is fixed at c = −1. This causes the threshold to always collapse to zero, constraining the behavior of the model and reducing the number of parameters it adds to the sDDM to two. The Reduced Weibull threshold has been applied in this or a similar form in 
Hawkins et al. (2015)
 and 
Evans, Hawkins, and Brown (2020)
.
The next two simpler CTs we examine are the linear and exponential thresholds which each contain a single additional threshold parameter. The first, linear, defines the decision thresholds as,
b 1 (t) = −b 2 (t) = b 0 − mt,
(5)
where b 0 indicates the threshold location at time zero and m is the thresholds' slope.
The second, exponential, defines the decision thresholds as,
b 1 (t) = −b 2 (t) = b 0 exp(−t/τ ),
(6)
where b 0 is, as before, the decision threshold location at time zero and τ describes the rate of threshold collapse.


Urgency Gating Model
The Urgency Gating Model (UGM) and other similar urgency based models propose an alternate, yet related, account for decision making behavior 
(Cisek et al., 2009)
. Unlike EAMs which posit that accumulation proceeds through gradual accumulation and integration of stimulus information, urgency models suggest that a time-varying gain function is the principal means by which the decision state is updated. In the context of two threshold binary choice, the simplest implementation of urgency is given by,
y(t) = g • E(t) • u(t),
(7)
where y(t) is the decision state, g is a scalar gain term, E(t) is the strength of the momentary evidence, and u(t) is a gain function which describes an increasing urgency to make a response. A common choice for the urgency u(t) is a linear function, given by,
u(t) = b + mt,
(8)
where b represents a baseline urgency, and m describes the rate of urgency increase over time.
The UGM is a specific implementation of this class which hypothesizes that the decision variable y(t) is affected by two main factors: the time dependent urgency function u(t) discussed above, and a low pass filtered representation of integrated stimulus information x(t), implemented via leaky integration. The decision variable is given by,
y(t) = x(t)u(t)
(9)
while the integrated stimulus information is,
dx(t) = (E(t) − Lx)dt + σdw,
(10)
where E(t) is the evidence signal, u(t) is the linear urgency signal introduced above, and L is the rate of leaky integration introduced in the leakage model. As shown by 
Trueblood et al. (2021)
, when an appropriate non-dimensional variable is used, models of this kind can be written in a form identical to that of Equation (1). Doing so modifies the drift rate of Equation 
1
to, v(x, t) = E(t)(1 + kt) +   k 1 + kt − L   x.
(11)
where x is, in this case, a non-dimensionalized decision variable, and k = m/b and represents an urgency ratio. In short, the urgency ratio describes the strength of urgency in the system, with k = 0 implying no urgency is present, and large k implying an urgency dominated system. In addition to altering the drift rate, the UGM introduces a modified diffusion rate, given by,
D(x, t) = σ(1 + kt),
(12)
where k is again the urgency ratio, σ is the scaling parameter from the sDDM and, as for the sDDM, it is set to one.
Similarly to the leakage model, the UGM has well known recovery problems for the leakage, urgency, and threshold parameters. Thus, as we did for the leakage model, we follow the lead of 
Trueblood et al. (2021)
 and implement two versions of E(t): fixed information and changing information. In the fixed information version, we assume that the evidence signal is constant, given by E(t) = E 0 . In the changing information case, we allow the evidence signal to change with time, given by,
E(t) =          E 0 if t < t 0 , −E 0 if t ≥ t 0 .
(13)
where E 0 is the strength of stimulus information and t 0 is, as with the leakage model, the time at which stimulus information changes.
Urgency signal models are motivated by many of the same questions as CT models. However, unlike CTs, urgency signals propose that strategic manipulation is implemented via the drift and diffusion rates instead of the threshold function. Recent work has demonstrated that these accounts of decision making are in fact equivalent 
(Smith & Ratcliff, 2022)
, an observation that we expand upon in the "Results" section.


Diffusion Model of Conflict
The Diffusion Model of Conflict (DMC) is an EAM used to describe conflict tasks 
(Ulrich et al., 2015)
. Conflict tasks are decision scenarios where conflicting evidence is present for the correct response. Classic examples of conflict tasks are the Stroop task 
(Stroop, 1935)
, where a written color word can conflict with the color it is written in;
the flanker task 
(Eriksen & Eriksen, 1974)
, where flanking items conflict with the target item; and the Simon task 
(Simon & Small, 1969)
, where the stimulus location can conflict with the response. The DMC was developed to model all three.
Its structure is based off the sDDM introduced earlier, and maintains three of its parameters: the non-decision time t nd , the relative start point w, and the decision thresholds b 1 (t) = −b 2 (t) = b. The original implementation of the DMC also includes across-trial variability in the non-decision time and start point, but we exclude them in this work for simplicity. The drift rate, however, deviates from the assumption of the sDDM, and posits that evidence accumulation is a combination of early automatic processing and late controlled processing. The early activation is modeled via a scaled gamma function, which provides strong manipulation of the drift rate at early times, and weakens as time progresses. In the context of the flanker task, this early activation is driven by the flanking non-target arrows and is given by,
v a = Ae −t/τ te τ (α − 1) α−1 α − 1 t − 1 τ ,
(14)
where A is the amplitude of the early activation, equaling a positive value for congruent tasks and negative value for incongruent tasks. Parameter τ sets the scale of the early activation, while α sets the shape of the early activation.
The controlled drift rate µ c is assumed to be constant as in the case of the sDDM, and dominates the drift as time progresses. In the context of the flanker task, for example, this models the shift from early activation driven by the flankers to the late activation driven by the target arrow. The total drift rate is the sum of the automatic and controlled process,
v(x, t) = v a + v c .
(15)
The DMC lacks a simple analytic solution, leading to it being only analyzed using simulation studies and quantile maximization approaches. A study has been performed to study parameter recovery of the DMC 
(White et al., 2018)
, but, to our knowledge, here is the first time that the DMC will be examined using the entire likelihood function and Bayesian methods. We also seek to answer two other unexplored questions: can the DMC parameters still be recovered when the response bias parameter w is included, and does the inclusion of multiple drift rate conditions meaningfully improve parameter recovery?


Choosing parameter sets
The general procedure used in this study is 1) generate a wide range of parameter sets representative of realistic model behavior, 2) simulate data from each parameter set, and 3) fit each model to the simulated data using PyBEAM, then analyze parameter recovery reliability by comparing the input and best fit parameter sets. In this section, we discuss our approach to each of these steps. To obtain a complete assessment of each model's identifiability, we generate a large number of parameter sets across a wide range of values, displayed for each model in 
Table 1
. Additionally, we generate parameter sets across a range of simulation set sizes N to determine the practical data set sizes needed for recovery.
The process used to generate parameter sets (for all models but the DMC) is as follows. First, for each model and N value, we randomly generate parameter sets from the ranges listed in 
Table 1
 using a Latin Hypercube Sampling design (LHS). We choose LHS over random sampling to ensure that the entire parameter space is evenly explored, something random sampling struggles with in high dimensional parameter space. Next, we filter out parameter sets which produce atypical choice-RT distributions. Our goal with this filter is to censor out parameter sets which produce data unlike that seen in experiment. To do so, we first simulate N of data for each parameter set using the methodology discussed below in section "Simulating data."
Then, we eliminate sets that do not fit certain distributional criteria 
(Evans, Trueblood,
 whose simulated data meets the following standards: mean and median response times between 0.4 and 2.5 seconds; interquartile range between 0.1 and 2 seconds; minimum RT below 1.5 seconds and maximum RT above 0.5 seconds; and less than five RTs for either decision. We randomly generate a sufficient number of parameter sets such that, after filtering, we are left with 1000 total parameter sets for each sample size.
An additional filter is used for the models with time varying information. The information change must occur at a meaningful time in the decision making process. If it occurs too early, no accumulators will have reached threshold before the flip occurs. If too late, most or all accumulators will have reached the decision threshold prior to the flip. To address this, we constrain the flip times to be between the first and third quartiles of the choice-RT distribution and eliminate parameter sets which do not fit this.
For the DMC, we used the parameter ranges given by 
White et al. (2018)
. In their work, these parameter ranges were constrained sufficiently that filtering was unnecessary, so we do not filter out any parameter sets for this model. Additionally, since the DMC is slower to run, we only use 100 unique parameter sets per experiment.


Simulating data
Data for each parameter set is simulated using the Python package PyBEAM 
(Murrow & Holmes, 2024)
, discussed in detail in the "Introduction". PyBEAM contains pre-coded versions of each model and simulates the models by integrating Equation 
1
using the Euler-Maruyama method 
(Kloeden & Platen, 1992)
,
x n = x n−1 + v(x n−1 , t n−1 )∆t + D(x n−1 , t n−1 )∆W √ ∆t,
(16)
where x n is the accumulated evidence at time step n, x n−1 is the accumulated evidence at time step n − 1, and t n−1 is the time at time step n − 1.
Functions v(x n−1 , t n−1 ) and D(x n−1 , t n−1 )
are, as in Equation 
1
, the drift and diffusion rates, respectively, evaluated at accumulated evidence x n−1 and time step t n−1 . Term ∆W simulates the Wiener process W (t) from Equation (1) by drawing a random number from a normal sDDM
t nd w µ b 0.1-0.6 0.3-0.7 -5-5 0.25-1.5 Leakage t nd w µ L t 0 b 0.1-0.6 0.3-0.7 -5-5 1-10 0.2-2 0.1-1 FWeibull t nd w µ b λ κ c 0.1-0.6 0.3-0.7 -5-5 0.25-1.5 1-10 0.4-10 -1.0-0.5 RWeibull t nd w µ b λ κ 0.1-0.6 0.3-0.7 -5-5 0.25-1.5 1-10 0.4-10 Linear t nd w µ b m 0.1-0.6 0.3-0.7 -5-5 0.25-3.0 0.1-2.5 Exp. t nd w µ b τ 0.1-0.6 0.3-0.7 -5-5 0.25-3.0 0.1-10 UGM t nd w µ L k t 0 b 0.1-0.6 0.3-0.7 -5-5 0.1-10 0.1-10 0.2-2 0.1-3 DMC t nd w A τ α µ c b
0.27-0.4 0.5 0.12-0.32 0.02-0.12 1.5-4.5 1.6-6.3 0.36-0.63 distribution with mean zero and standard deviation one at each integration step. The final term is the integration time step ∆t, which sets the time at step n via t n = n∆t.
The simulation ends when a decision threshold has been crossed, given by
x n ≥ b 1 (t n ) or x n ≤ b 2 (t n ).
The choice of ∆t is dependent upon model, with models with shorter time scales requiring smaller time steps. For this numerical experiment, our goal is to isolate parameter identifiability, so we choose conservatively small ∆t values to reduce the noise added to the system via simulation error. For all models but the DMC, we use ∆t = 1.0e − 4 seconds, while for the DMC we use ∆t = 1.0e − 6 seconds. We choose a smaller time step for the DMC since its dynamics occur on a scale nearly an order of magnitude faster than that of the other models.


Fitting models to data
Once we have simulated data for our parameter sets, we next fit each model to the simulated data. To do so, we again utilize the Python package PyBEAM 
(Murrow & Holmes, 2024)
. 
∂p(x, t) ∂t = − ∂ [v(x, t)p(x, t)] ∂x + 1 2 ∂ 2 [D(x, t) 2 p(x, t)] ∂x 2 ,
(17)
where p(x, t) is the probability of accumulated evidence x at time t, and v(x, t) and
D(x, t) are the drift and diffusion rates discussed earlier. This equations provides the probability at a given time t of having accumulated evidence quantity x. Then, to determine the probability f i (t) of crossing a decision threshold b i at time t, it calculates from Equation (17) the probability flux at the threshold, given by
J(x, t) = v(x, t)p(x, t) − 1 2 ∂ [D(x, t) 2 p(x, t)] ∂x .
(18)
This is the probability flux at point (x, t) and the likelihood of crossing threshold b i is
f i (t) = J(b i (t), t).
PyBEAM uses the likelihood function to measure the level of agreement between a model with given parameters and data. This log-likelihood is used in a Bayesian framework to fit these models to data and obtain approximate posterior distributions for their parameters. The computed log-likelihood is then used by PyBEAM to perform Bayesian parameter estimation with the Python package PyMC 
(Salvatier, Wiecki, & Fonnesbeck, 2016
), a robust, highly supported package built specifically for Markov chain Monte Carlo based inference. Though slower than other optimization methods like max log-likelihood or chi-squared statistics, we choose the above approach for fitting these models to data for several reasons. First, the use of PyBEAM allows access to rapidly generated, high resolution likelihood functions for all models with little to no modification. Most previous parameter recovery studies are restricted to Quantile Maximization approaches generated through simulation, which compress the information contained in the likelihood function. Second, the Bayesian inference algorithms of PyBEAM provide access to the entire distribution of parameter space rather than just the best fit parameters, giving us a more comprehensive way to analyze our model recoverability. This becomes particularly relevant in our "Results" section for our analysis of over-parameterized models.


Results
In this section, we present the findings of our numerical experiments. We examine the quality of fit for the five models discussed in "Methods": the sDDM, EAMs with leaky integration, EAMs with CTs, the UGM, and the DMC. We choose to include the sDDM since it is the basis of the more complex EAMs we examine and thus serves as a useful baseline to compare the other models to. The remaining are commonly used models (introduced in "Methods") which have, to our knowledge, not been comprehensively examined using the full likelihood function with Bayesian methods.
There are of course numerous other models and variants that we do not consider here, but we hope this process and the reference scripts provided online in the PyBEAM documentaion (https://pybeam-documentation.readthedocs.io/en/latest/) will facilitate similar study of other models where useful.


Simple DDM (sDDM)
We start with our parameter recovery experiments for the sDDM. For this numerical experiment, we choose simulated data set sizes of N = 100, 250, 500, 1000, and 10, 000 points. For each N , we use LHS to generate 1, 000 unique parameter sets, leading to a total of 5, 000 parameter sets. Data is simulated from the model using PyBEAM, which itself implements Equation 
16
discussed in "Methods".
We then fit the sDDM to each generated data set. We display the results of this in  We find that, regardless of N , recovery for the Simple DDM parameters is very good. Recovery is stable for as few as N = 100 samples, with near perfect recovery achieved once N = 1, 000 is reached. The most difficult parameter to recover is the relative start point, which struggles relative to the other parameters for small N . We also find that b is relatively difficult to recover when it is large (approximately b > 1).
This has several likely causes. First, when threshold starts are large, choice-RT distributions are dominated by the drift rate, resulting in fewer error RTs. This can make it more difficult for the precise value of the threshold to be narrowed down.
Second, when thresholds are large, small deviations from the simulated thresholds result in only tiny errors since they are a smaller percentage of the threshold location. This model is well studied, many of these observations have been made, and we include here mainly as a starting point and baseline to compare future models with.


Leaky integration (Leakage)
In this section, we report the results of our parameter recovery experiments for the Leakage model. We display the first set of results in values indicating the quality of fit of the data to the line. Each row displays the results for N = 1, 000 data points.
In row A1, we display results for fixed information (FI) with a single drift rate condition, while in row A2, we display results for FI with two drift rate conditions. In row B1, we display results for changing information (CI) with a single drift rate condition, while in row B2, we display results for CI with two drift rate conditions. The two drift rate conditions are used for a similar reason to that of the CI, being that leakage is a difficult parameter to recover. Thus, we simulate a slightly more complicated data set in rows A2 and B2 to see if it has a meaningful impact on recovery: a smaller µ and a larger µ. This is used to model an experiment where both a low quality and high quality stimulus are shown to the participant. In the context of the random dot kinematogram discussed earlier, this corresponds to a low coherence and a high coherence stimulus, respectively. The fits of both drift rate conditions are still displayed in the "Drift µ" column of 
Figure 3
.
We find that, in the FI case, it is very difficult to recover the leakage parameter.
Both in the one and two drift condition cases, the leakage parameter is mostly unidentifiable, with a small improvement present when two drift conditions are used. In the single condition case (A1), all other parameters are well recovered, with the exception of the the threshold b which struggles to be recovered for large values.
Addition of the second drift rate condition slightly improves recovery of w and µ, and significantly improves the recovery of b, especially for large values.
Conversely, in the CI case, we find that the leakage parameter is well recovered, with substantially better R 2 values than that of FI. The remaining parameters are also well recovered, with the exception of large drift rates. Small drift rates (µ < 3) are well recovered for CI, but larger drift rates exhibit substantially more variance, particularly in the single condition case (B1). Lastly, moving from a single to two drift rate conditions (B2) provided a large improvement in the recovery of b, with R 2 jumping from 0.92 to 1 when a second drift condition is added.
We next examine how parameter recovery scales with the number of samples. We perform the same experiment presented in row B1 of 
Figure 3
 with fixed information and a single drift rate condition. However, we report results for N = 100, 250, 500, 1000, and 10, 000 data points to demonstrate how recovery scales with simulation set size. We report the results of this in 
Figure 4
. For N = 10, 000 we find that recovery is excellent for all parameters. The N = 1, 000 results are the same as 
Figure 3
 which shows good recovery for each parameter. However, as N decreases, recovery becomes increasingly worse, with L unrecoverable for N = 500, and the remaining parameters difficult to recover for N = 250 and N = 100 data points. Thus, when attempting to recover leakage, it is necessary to use as many data points as possible to ensure good recovery of all parameters. Additionally, it is preferred to use A1) FI 1 Cond. R 2 = 1.00 R 2 = 0.96 R 2 = 0.99 R 2 = 0.10 R 2 = 0.85 A2) FI 2 Cond.
R 2 = 1.00 R 2 = 0.98 R 2 = 1.00 R 2 = 0.19 R 2 = 0.90 B1) CI 1 Cond.
R 2 = 1.00 R 2 = 0.96 R 2 = 0.98 R 2 = 0.47 R 2 = 0.92 0.1 0.4 0.7 Nd. Time (t nd ) B2) CI 2 Cond. The correlation coefficient R 2 indicates the quality of fit to the red line. Rows A1 and A2 show the results for the fixed information (FI) experiments for one and two drift rate conditions, respectively. Rows B1 and B2 show the results for the changing information (CI) experiments for one and two drift rate conditions, respectively. more than one experimental condition as well. Though in 
Figure 3
 we used two drift rate conditions, other condition types, such as caution manipulations, could also prove highly useful.   when CI is used. Additionally, recovery of non-leakage parameters improved when a second drift condition was added to the experiment, with the largest increase in the threshold b. Thus, we recommend that if the leakage parameter is your target, always use CI. It may also be helpful to include multiple flip times into your experiment or another novel modification of the stimulus strength. Further, it is highly recommended to use multiple drift rate conditions (or other types of experimental conditions) to help to mitigate this effect, especially with small sample size N .


Changing thresholds (CT)
We now explore the effect of time changing thresholds and urgency signals on parameter recovery. We seek to answer three main questions. 1) First, are the parameters of the Full Weibull model recoverable. If so, how many data points are necessary? 2) Are alternative threshold models with fewer parameters equally capable of describing data while achieving better parameter recovery? 3) Is it possible to distinguish between time changing threshold models when applied to human data?
Full Weibull recovery. We begin by testing parameter recovery of the Full Weibull model discussed in "Methods". To do so, we follow a similar procedure to that discussed in sections "Methods" and "sDDM". We first generate 1, 000 parameter sets using LHS, filtering out parameter sets which do not produce reasonable choice-RT distributions. Then, we simulate N = 1, 000 choice-RT data points for each parameter set. Lastly, we use PyBEAM to fit the Full Weibull model to the simulated data. The effect of data set size on this model will be discussed in a subsequent simulation experiment.
The result of this numerical experiment is shown in 
Figure 5
. Panels A1-A7 display scatter plots of the true versus best fit Full Weibull parameters. Note that we report the log 10 of the shape (λ) and scale (κ) parameters. Both λ and κ have large functional parameter ranges, making them difficult to sample directly using Bayesian methods. To address this, PyBEAM samples from the log base 10 of these parameters, so we report their log here as well. Panel A8 displays the threshold error (TE), calculated as,
TE = RTmax RT min b 1,true (t) − b 1,f it (t) dt RTmax RT min b 1,true (t) dt × 100%,
(19)
where RT min and RT max are the minimum and maximum choice-RTs from the simulated data set, respectively, and b 1,true (t) and b 1,f it (t) are the true and best fit upper thresholds, respectively. This metric calculates the area between the true and best fit upper thresholds, then divides it by the area under the true upper threshold to approximate provide a normalized measure of error in the threshold. If TE is high (low), then there is a large (small) distance between the true and best fit thresholds, implying a poor (good) fit. Note that we only integrate between RT min and RT max since the threshold location is relevant only when data is present.
We find that, for N = 1, 000 data points, recovery is very good for the non-decision time (t nd ), relative start point (w), and drift rate (µ). The threshold start parameter (b) is poorly recovered, while the shape (λ), scale (κ), and collapse (c)
parameters are completely unrecoverable. The Full Weibull threshold is over-parameterized, causing its parameters to be highly correlated and thus poorly recoverable individually 
(Gutenkunst et al., 2007;
Holmes & Trueblood, 2018
).
However, even though the threshold parameters are unrecoverable, the threshold itself is highly recoverable, with a TE = 5.2%. For reference, applying this metric to the sDDM threshold gives a median TE = 1.6% for N = 1, 000 data points.
To more clearly illustrate the results presented in 
Figure 5
, we provide an example fit for the Full Weibull model in 
Figure 6
. This example is chosen to represent an "average" fit, one which contains features common to many simulated data sets. Panels True parameters Fit parameters A1-A7 report the posteriors for each Full Weibull parameter. Panel B compares the true threshold to the best fit threshold and reports its TE = 4.5% (approximately the median TE from 
Figure 5
). The dotted black line is RT min for this data set, while RT max is the upper x-limit of the graph. Panel C is a histogram of the choice-RT data, with upper threshold crossings in positive time and lower threshold crossings in negative time. The likelihood functions for the true and best fit parameter sets are plotted, displayed in a solid blue and dotted red line, respectively. The panel also contains the log-likelihood values for the true and best fit parameter sets. 
Figure 6
 illustrates several features of the Full Weibull model. 1) Even in scenarios where parameters are not recovered, the fit quality is still high and in this case the recovered parameters produce a more favourable log-likelihood than even the generating parameters (Panel C).
2) The threshold parameter indeterminacy does not interfere with recovery of the relative start point or the drift rate. Both fits align closely with their true values, and the posteriors are Normally distributed. 3) However, the non-decision time parameter is underestimated and its posterior is skewed left. While in this case the mis-fit is relatively small (∼ 10% of true value), this is a systematic problem with the Full Weibull model. While the true and fit thresholds agree well on the range of observed RTs (Panel B), they diverge substantially for t < RT min . This results in a non-decision time that is smaller than that of the true parameter set. Thus, caution must be applied when interpreting the non-decision time predicted by the Full Weibull model. If this is of significant concern, recent work has presented alternate ways to constrain the non-decision time through the use of electro-myographical activity 
(Weindel, Gajdos, Burle, & Alario, 2021)
 or non-parameterized non-decision functions 
(Verdonck & Tuerlinckx, 2016)
.
We last explore the effect of simulated data set size N on the Full Weibull model's recovery quality. For this experiment, we follow the same procedure discussed in "sDDM". We first generate 1, 000 parameter sets using Latin Hypercube Sampling for N = 100, 250, 500, 1000, and 10, 000 points, leading to a total of 5, 000 parameter sets. As with the sDDM, we generate unique parameter sets for each N to eliminate  parameter sets which produce few or no error RTs. We then fit the Full Weibull model to each simulated data set. The results of this numerical experiment are shown in 
Figure 7
. Since threshold parameters are not recoverable themselves, we only report the threshold error (TE) and not the parameters themselves. Input parameters


Fit parameters
We find that parameter recovery is generally good, with excellent recovery starting at N = 500 data points. Similarly to the Simple DDM, the relative start point w is challenging to recover for small N and has the weakest recovery of all parameters.
As discussed earlier in 
Figure 6
 and clearly visible for N = 10, 000 data points, the non-decision time is systematically underestimated; thus, caution should be applied when interpreting the non-decision time in the Full Weibull model. Lastly, threshold recovery is good, with median TE's highest for N = 100 at TE= 9.3%, steadily decreasing to TE= 3.3% for N = 10, 000 data points. To address this, we first follow a similar procedure to that of the sDDM and Full Weibull models discussed above. We simulate N = 1, 000 data points for 1000 randomly generated parameter sets for each of the three alternative models: linear, exponential, and Reduced Weibull. Next, we fit the threshold models to their respective data sets.
This allows us to compare the recoverability of simpler thresholds to that of the Full Weibull threshold. We display a summarized set of results for this in 
Figure 8
, and the full set of results in the Supplementary Information.
We find that the simpler threshold models are more recoverable than the the Full Weibull threshold. The non-decision time t nd , relative start w, and drift rate µ have approximately equal recovery to that of the Full Weibull, but the threshold error is notably better. The Linear model (Supplement 
Figure 1)
 has the most recoverable threshold with a median threshold error TE = 3%, while the exponential threshold (Supplement 
Figure 2
) produces the worst recovery with a median TE = 4.6%. The Reduced Weibull (Supplement 
Figure 3
) fell in the middle with a median TE of TE = 4.2%.
We next examine if the alternate threshold models are capable of replicating the Full Weibull threshold's dynamics. We start by simulating N = 1, 000 data points for the 1000 Full Weibull parameter sets of 
Figure 5
. Then, we fit the four alternate models discussed in "Methods" to this data: the sDDM, the Linear threshold model, the Exponential threshold model, and the Reduced Weibull threshold model. The sDDM fit is used to determine if, on average, data generated from a time changing threshold model can be accurately described using a flat threshold. The other three are the same alternate time changing threshold models used in 
Figure 8
 which are candidates to replace the Full Weibull threshold.
The results of this numerical experiment are shown in 
Figure 9
. In Panel A, The  From 
Figure 9A
, we see that, on average, the sDDM performs the worst of all four alternate models, with a median LL D = 6.6. This suggests we cannot approximate a As with Panel A, this suggests that, of all alternate models, the Reduced Weibull is preferred.
We make a brief note about the magnitude of the LL D observations here, which are on the order of 1 − 10 in size. From an inference perspective, a LL D of 5 − 10 will often be considered as weak or moderate evidence in support of a conclusion. Thus from this perspective, the magnitude of these log-likelihood differences are relatively small. We note however that we are simulating data sets from random parameter sets using the full Weibull threshold. This threshold is capable of producing a wide array of threshold shapes, including flat, exponential, and linear. Thus, it is likely that many of the simulated data sets we use for this experiment are well mimicked by these other thresholds and should not generate substantial LL D . Thus, the illustrated differences between models are likely averaging results from parameter sets that do illustrate distinctive signatures of changing thresholds with sets that do not. In summary, the Reduced Weibull is sufficiently flexible to capture most threshold behaviors of the Full Weibull while being parametrically simpler and more easily recoverable. Further, it has nearly the same capacity to detect the presence of time varying thresholds when compared against the sDDM. While linear and exponential thresholds may have usefulness in some circumstances, based on these analyses, they do not have the same capacity as the full and reduced Weibull models if inferring the presence of time varying thresholds is intended.
Fitting changing threshold models to human data. Overall, our simulated results from 
Figure 7
 and 
Figure 9
 suggest that the best way to distinguish between time changing and flat thresholds is by using the Reduced Weibull threshold. However, since human data is always messier than simulated data, we next ask whether or not it is possible to distinguish between thresholds when applied to human experiments.
In 
Figure 10
, we fit the sDDM and changing threshold models to human choice-RT data 
Evans, Hawkins, and Brown (2020)
. This data is comprised of three different random dot kinematogram experiments where participants made decisions about direction of dot motion. Four coherences are used for each: 0%, 5%, 10%, and 40%. In experiment one, 63 participants were instructed to maximize reward rate with a cutoff time of 5 seconds; in experiment two, 71 participants were given a decision deadline of 1.3 seconds; and in the third experiment, one 154 participants were instructed to emphasize decision speed with the same 5 second cutoff of experiment one.
On average, Experiment 1 has N = 381 data points per subject, Experiment 2 has N = 348 per subject, and Experiment 3 has N = 191 per subject. Our goal in this work is to fit each data set to models with and without changing thresholds, then compare quality of fit to determine A) if it is possible to distinguish between flat and changing decision thresholds, and B) if it is possible, which thresholds is it possible for? We note that our goal here is not to retest previous conclusions of Evans 
, Hawkins, and Brown (2020)
. Rather, we are simply using this as a useful benchmark data set.
We display the results of these fits in 
Figure 10
. Panels A, B, and C contain boxplots for Experiments 1, 2, and 3, respectively, displaying the log-likelihood  
Figure 10
 . Boxplots of the log-likelihood difference (LL D ) between models when fit to data collected by 
Evans, Hawkins, and Brown (2020)
 For Experiment 1, we find that, on average, only the Full Weibull threshold has strong evidence for fitting the data better than the sDDM. Both the linear and exponential thresholds show almost no evidence for a better fit, while the Reduced Weibull provides weak evidence for fitting the data better. For Experiment 2, we find that all thresholds have very strong evidence for fitting the data better than the sDDM, with the strongest evidence for the Full Weibull and Reduced Weibull models. Lastly, for Experiment 3, no model shows significant evidence for changing thresholds. The Full and Reduced Weibull thresholds shows very weak evidence for fitting the data better than the sDDM, while the linear and exponential thresholds show functionally zero evidence for it.
In 
Evans, Hawkins, and Brown (2020)
 and the refit of their data in 
Murrow and Holmes (2024)
 using PyBEAM, the Reduced Weibull threshold was used. Both found that only Experiment 2 showed significant evidence for CT, while Experiments 1 and 3 only did so for some participants. We see similar results in this work, with only Experiment 2 in panel B of 
Figure 10
 showing clear evidence for all CT. Additionally, Experiment 3 closely matches the previous results, with most CT fitting the data similarly to the flat threshold. Experiment 1 tells a slightly different story. Like the previous fits, the Reduced Weibull shows little evidence for fitting the data better than the sDDM. Additionally, the simpler linear and exponential CTs also fit the data roughly similar to that of the sDDM. The Reduced Weibull fits the data slightly better than the linear and exponential fits since it can model both early and late collpase, whereas the linear and exponential models can only describe early collapse. The Full Weibull model, however, indicates a clearly better fit when compared to the sDDM. This occurs because the Full Weibull threshold allows collapse anywhere between the initial threshold location b 0 and zero, and the Experiment 1 data benefits greatly from this flexibility. When plotted, the principal threshold type that results from the Full Weibull fits is a threshold that looks similar to a step function. It starts at a constant level b 0 , then later rapidly collapses to another constant level somewhere between zero and b 0 .
This suggests strongly that a simple step function will fit the Experiment 1 data as well as the more complex Full Weibull. To demonstrate this, we fit the Evans Experiment 1 data using a smoothed step function as the threshold. The smoothed step function is implemented by using the Full Weibull model and setting the shape parameter κ = 10. We report the results of this in 
Figure 11
. We find that the step function fits nearly as well as the Full Weibull model and significantly better than the other CTs. Thus, the underlying CT behavior for this is very likely a simple step function, and it is unnecessary to use a complex Weibull threshold to accomplish this much simpler fit.


Full Weibull
Step  


Urgency Gating Model (UGM)
We next report the results of the UGM. As discussed in the methods, this model is equivalent to a changing threshold model with the addition of leaky integration. We display the results of our numerical experiments in 
Figure 12
. Plotting conventions are similar to prior simulation studies.
Row A of 
Figure 12
 displays the results for the FI experiment. We find that recovery of only the drift rate is acceptable, while all other parameters experience fair to poor recovery. Row B displays the results of the CI information experiment. Recovery for all parameters is substantially better than that of the FI case with the exception of the relative start point w. We find that, in some cases, the start point is completely improvement is in the urgency ratio (k), which is one of the primary parameters one  would be interested in for this model. Interestingly, the leakage is well recovered independent of the time at which the evidence change occurs, within the constraints of this test.
In summary, fixed information does not produce good recovery of the UGM parameters. Changing information improves recovery substantially, particularly if the change occurs relatively early relative to typical response times for the task. Though not shown in this section, following the lead of the Leakage model results, it is likely that the introduction of multiple drift rate or caution conditions will further improve recovery of the leakage and urgency parameters.
Equivalence of changing thresholds and urgency models. As discussed in "Methods", Urgency models are motivated by the same theoretical questions which led to the introduction of collapsing thresholds. However, unlike collapsing thresholds, urgency models propose that strategic manipulation exists principally in the choice of u(t). It has long been known that changing thresholds and urgency signals produce similar behavior 
(Drugowitsch et al., 2012)
, with more recent work by 
Trueblood et al. (2021)
 and 
Smith and Ratcliff (2022)
 explicitly demonstrating this. 
Smith and Ratcliff (2022)
 showed that they result in mathematically identical likelihood functions under the correct conditions. Specifically, a CT is equivalent to a UGM when the threshold
b i (t) is given by, b 1 (t) = −b 2 (t) = b 0 /u(t),
(20)
where b 0 is the initial threshold location. One can also do the reverse, and use a UGM to model a CT when Equation 
20
is solved for u(t),
u(t) = ±b 0 /b(t),
(21)
where it is positive if the thresholds collapses and negative if the threhsold expands (though this later case is infrequently used).
Thus, when leakage L = 0, we can directly compare the results of CTs and UGMs.
Specifically, we can determine if the UGM's choice of urgency function is an appropriate choice. Since the UGM is equivalent to a CT, we approach this in the same way as in the previous section. We fit it to the data collected by 
Evans, Hawkins, and Brown (2020)
, then compare it to the fits of the other thresholds. So that the models are directly comparable, we set the leakage rate L to zero.
We report the results of these fits in 
Figure 13
. As with 
Figure 10
, the boxplots display the log-likelihood difference LL D between the best UGM and sDDM fits. If positive, the UGM is preferred, while if negative, the sDDM is preferred. We find that for Experiments 1 and 3, as with the other thresholds there is no evidence for the UGM fitting the data better than the sDDM, fitting similarly to the linear and exponential thresholds. For Experiment 2, as with the other CT models, the UGM shows clear preference over the sDDM; however, of all the CT models, it has the smallest LL D , suggesting that it has the least power to determine if a collapsing threshold is present.
Overall, the UGM urgency functions appears equivalent to or worse than the linear and exponential thresholds for detecting collapsing thresholds in human data. This is unsurprising since the UGM "threshold" determined via Equation 
20
has a very similar shape to that of the exponential CT, another threshold whose shape and simplicity causes it to struggle at detecting CTs in human data. This suggests that the linear urgency function employed by the UGM may in fact be a poor choice when used for detecting changing thresholds/urgency signals in data, and that more model power may be achieved through the use of different urgency models. These could include the Reduced Weibull "urgency" function from the previous section calculated via Equation 
21
, or the logistic urgency function of 
Ditterich (2006)
. 


Diffusion Model of Conflict
We last explore the parameter recovery of the Diffusion Model of Conflict (DMC).
Though parameter recovery of the DMC has been studied in the past using simulation quantile methods 
(White et al., 2018)
, our work is the first time the DMC has been studied using Bayesian methods with the full likelihood distribution. We report our results in 
Figure 3
. Simulation study methods and plotting conventions are similar to prior studies. Each simulated data set here included N = 1, 000 simulated data points.
The primary model feature of interest with the DMC is the time changing drift rate function and its associated parameters. We thus follow a similar procedure used in the time changing threshold section. To assess the ability of the model to recover accurate dynamics from data, we both examine 1) parameter recovery and 2) the quality of recovery of the drift rate function as a function of time. For this second point, we quantify Drift Error, given by,
DE = RTmax t nd v true (t) − v f it (t) dt RTmax t nd v true (t) dt × 100%,
(22)
where v true is the true drift rate and v f it is the best fit drift rate. We integrate from the non-decision time t nd to RT max to capture the drift rate for the entire choice-RT distribution. Similar to the threshold error of Equation 
19
introduced in the changing thresholds section, this metric calculates the area between the true and best fit drift rate, then divides it by the area under the true drift rate to provide a normalized measure of error in the drift. If DE is high (low), then there is a large (small) distance between the true and best fit thresholds, implying a poor (good) fit. We use this metric for much the same reason as the changing thresholds. Due to parameter degeneracy in the DMC drift rate, it is possible to fit the drift function without recovering the exact parameters. The DE provides a way to calculate recovery of the drift rate independent of the fit parameters. have a two condition experiment, one congruent and one incongruent. This corresponds to giving the subject N = 500 congruent trials and N = 500 incogruent trials as part of the total of 1, 000 simulated data points. We find that mixing both congreuncies into a single experiment provides substantially better recovery, with all parameters receiving some degree of recoverability. Additionally, the DE is very low, suggesting that the recovery of the drift rate function is good.
The last row, D, provides results for a four condition experiment. In this case, we have the same congruent and incongruent setup as row C, but in addition, we have two conditions for the controlled drift rate µ c . As noted by 
Ulrich et al. (2015)
, this is an easy experimental manipulation to make, and an obvious candidate for improving parameter recovery of the DMC. We find that, in general, all parameters fit nearly as well or better, with the largest gains seen in α. Parameter τ fits slightly worse in this data set, but we expect that this is likely due to random variation in the sampled parameter sets. In summary, there may be gains in recovery for this scenario when additional conditions are added, but they are marginal and the interested researcher should determine whether this manipulation provides value for experimental time.
In 
Figure 15
, we provide an example DMC fit from the two condition experiment of row C in 
Figure 14
. In column A, we show the drift rate recovery for the congruent (row 1) and incongruent (row 2) conditions, with the true drift rate in the solid blue line and the recovered drift rate in the dashed red line. We provide the drift error above the curves equaling DE = 4.2%. We specifically chose a fit with DE value approximately equal to the median of row C in 
Figure 14
 to provide context for what that degree of error looks like. In row B, we provide the fit of the likelihood function to the simulated data set. The solid blue line corresponds to the true likelihood function, while the dashed red line corresponds to the best fit likelihood function. The grey histogram is the simulated data. Both the best fit and true likelihood fit the data well, demonstrating that recovery is effective at fitting the input data.
We last display results for a DMC with variable relative start point w in 16. All work on the DMC to this point has assumed no bias, and thus the relative start parameter is fixed at w = 0.5. Here we determine if this parameter is recoverable. We find that the non-decision time t nd , relative start point w, controlled drift rate µ c , and threshold parameters are all recovered with high accuracy. Recovery of the remaining parameters is however impaired, and the total drift error, though not substantially higher than the fixed start point case, has a larger variance. This level of drift rate recovery error is unlikely to change conclusions drawn from its shape 
(Figure 15
 shows a 4% error and the errors here are 7-10%). Thus, if there is reason to believe a bias may be present, the models recovery characteristics are reasonable with it included. 


Discussion
Evidence Accumulation Models comprise an ever expanding class of models used to explore evidence accumulation and temporal aspects of decision making. In recent years, the use of more complex variants of these models has become more common.
However, with this complexity comes added modeling challenges. How well posed are these models relative to the data they are being challenged with? Are model parameters recoverable and therefore interpretable? What experimental structures are sufficient to constrain these models? How can and should one judge the quality of these models mimicry of data? These questions are of paramount importance when working with these more complex models. Researchers have investigated these questions in past research 
(Boehm et al., 2018;
Evans, Trueblood, & Holmes, 2020;
Lerche & Voss, 2016;
Trueblood et al., 2021;
van Ravenzwaaij & Oberauer, 2009;
White et al., 2018)
. However this research has been a patchwork of investigations with different groups analyzing different models with different modeling approaches. Here, we address this (partially at least) by using a state-of-the-art Bayesian modeling methodology to investigate the methodological properties of a family of commonly used EAMs.
In this work, we considered a variety of EAMs which differed in their assumptions about the drift rate, diffusion rate, and decision threshold behavior. Specifically, we examined four types of models: the Simple DDM, EAMs with leaky integration, EAMs with changing thresholds (including the Urgency Gating Model), and the Diffusion Model of Conflict. While we have investigated each of these models using a unified modeling framework, this is not a one-size fits all approach. Some of these models have different variations and each comes with their own challenges. Thus while the general approach to investigating these is similar, the specific analyses performed and approaches vary to best address each class of models.
This investigation was performed using the Python package PyBEAM, an accurate and efficient method for Bayesian choice-RT modeling of a broad class of binary choice EAMs using the full likelihood function 
(Murrow & Holmes, 2024)
. This methodology improves on simulation based methodologies -including Quantile Maximization 
(Heathcote et al., 2002;
Ratcliff & Tuerlinckx, 2002)
, Probability Density Approximation (PDA) 
(Holmes, 2015;
Turner & Sederberg, 2014)
, and distribution summary statistics 
(Wagenmakers, Van Der Maas, & Grasman, 2007)
 -and is more powerful than methods that produce point parameter estimates such as PyDDM 
(Shinn et al., 2020)
. It thus allows us to provide a more comprehensive analysis of these models properties than prior studies. We also note that, to our knowledge, this is the first investigation of the DMC using Bayesian methods. We briefly summarize the results of investigations into each of these models. Some of these results have been found in prior studies and are acknowledged in the preceding text. Others are, to our knowledge, new observations.
Results from the Simple DDM (sDDM) reflect those from numerous prior investigations (included mainly for comparison) and illustrate that this model has good parameter recovery with as few as N = 100 data points. For the leaky integration model which adds leakage L to the sDDM's drift rate, recovery of the leakage parameter was poor when fixed information was used. However, when changing information was used, recovery of the leakage and threshold parameters improved, and improved even more when multiple drift rate conditions were used.
For the changing threshold models, we found that recovery for the relative start and drift rate parameters is always good. The non-decision time parameter is generally recoverable, though the Full Weibull model systematically underestimates it by a small amount. The threshold parameters for the Full and Reduced Weibull models are not recoverable for any simulation size N ; however, the threshold shape is recoverable for both models. Thus while structural inferences can be made from these models, one needs to take care when making inferences based on parameters. For the linear and exponential models, recovery of the threshold parameters is much better, with the linear threshold providing the best recovery of all.
Use and interpretation of these different caution / threshold models when applied to human data is more murky. In some cases these different threshold models will lead to similar structural conclusions (presence or absence of time varying caution). In others they can lead to different conclusions. More details of these results are in the main text. Given this murkiness, extra caution is recommended when using these models. For example, one could use multiple threshold models and examine consistency between results. Interpretation of results using these models will likely require problem specific approaches however and we hope the approach illustrated in this paper may provide a jumping off point to doing so.
While the Urgency Gating Model was originally discussed as a distinct model from other standard EAMs, recent work 
(Smith & Ratcliff, 2022)
 has shown that the UGM is a variation on the just discussed changing threshold model. Given this history, we analyze this model both in its own right and as a member of the family of changing threshold models. Our analysis shows that, as with the leakage model, recovery is poor when information is fixed. However, when changing information is used, recovery is excellent and improved further when multiple conditions are used. Further, parameter recovery is best when the time of evidence change is early relative to typical response times, especially if the relative start point is of interest to the experimenter.
Under an appropriate coordinate transformation, the UGM with linear urgency becomes a collapsing threshold model with a particular threshold function. We thus assess this model in comparison to the changing threshold models discussed previously.
This model performs similarly to the exponentially decaying threshold model. This is expected since the changing threshold in the transformed UGM behaves like an exponential decay (they look visually very similar). Thus the strengths (parameter identify-ability) and weaknesses (inability to model late changes in thresholds) are shared.
Lastly, we found that recovery for the Diffusion Model of Conflict is good, provided the congruent and incongruent conditions are fit simultaneously. We also found that addition of a second drift rate condition slightly improved recovery of the drift rate, but not to a substantial effect. This is in contrast to prior models where the addition of distinct trial types substantially improved matters. Finally, we found that recovery of the relative start point is possible with this model, though it decreases the PARAMETER RECOVERY 55 recoverability of the drift rate parameters related to the automatic process.
Overall, this work is, to our knowledge, the most comprehensive analysis of complex EAMs using A) the full choice-RT distributions (using full likelihood functions), and B) Bayesian inference. That said, a model should always be analyzed in the context of the question of interest and data available. Our hope is that this article is more than just a bullet point list of observations. We intend it to illustrate different approaches of analyzing complex choice-RT models in the context in which they may be used, while also providing practical suggestions for future studies which require models of this type.
Supplementary Information.


Changing thresholds
0.1 0.4 0. Fit Parameters True Parameters 
Figure 3
 . Quality of fit for the exponential CT for N = 1, 000 simulated data points.
Horizontal axes indicate the true simulated parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficients R 2 above each panel indicate the quality of fit to the red line.
explored the DDM, the Linear Ballistic Accumulator Model, and the Leaky Competing Accumulator Model; and Evans et al. (2019) explored the recoverability of EAMs of multi alternative multi attribute choice. Though comprehensive, these studies have been piecemeal in nature. Different groups investigate different models using different computational methods. Some PARAMETER RECOVERY 6 studies use point estimate methods (maximize some cost function) while others use Bayesian methods. Some rely on brute force stocahstic simulations of models (e.g.


"
Introduction." EAMs of this type take the general form shown in Panel A of Figure 1. The horizontal axis of this panel is elapsed time from stimulus presentation, while the vertical axis provides the total accumulated evidence x at time t. Two thresholds are present, an upper, positive valued function (b 1 (t), solid line) and lower, negative valued function (b 2 (t), dashed line), each corresponding to one of the two choices available.


Figure 1 .
1
Figure captionon next page.


Figure 1
1
. A) Schematic of an EAM. Evidence is accumulated (black line) starting from an initial bias z (black dot) until one of the two decision thresholds, b 1 (t) or b 2 (t), is reached (red dot), triggering a decision. Though the thresholds are constant in this plot, their position can vary as a function of time. The distance between thresholds indicates the degree of caution (a) exhibited by the decision maker, which can remain constant or change as a function of time if the thresholds are not constant. This process is described mathematically by Equation (1). B) Example of data simulated from an EAM via Equation (1) (grey bars) with likelihood functions overlaid. Data for the upper decision threshold crossing is shown on the positive time axis, while data for the lower threshold crossing is shown on the negative time axis. The solid black line corresponds to the likelihood function for the upper decision threshold, while the dashed black line gives the likelihood function for the lower decision threshold. The probability of making a choice at any time is given on the vertical axis.


where µ is the stimulus strength; relative start point w; and flat, symmetric decision thresholds b 1 (t) = −b 2 (t) = b. The diffusion rate D(x, t) acts as the model scaling parameter and is fixed at D(x, t) = 1 for all our numerical


As discussed in the Introduction, PyBEAM is a fast, accurate method for Bayesian modeling of full choice-RT distributions. Specifically, PyBEAM fits models to data by calculating the model's first passage time distribution, commonly referred to as the likelihood function. The likelihood function gives the probability of crossing either decision threshold at time t, and thus gives the probability of a making a choice at time t. An example of the likelihood function overlaid on a simulated data set is shown in Panel B of Figure 1. The horizontal axis displays the time coordinate, while the vertical axis gives the probability of making a choice. For convenience, we place the lower threshold crossing data in negative time, and the upper threshold crossing data in positive time. Discussed in detail in the package publication, PyBEAM generates the likelihood function in two main steps. First, it converts the SDE formalism of Equation (1) to the probabilistic Fokker-Planck equation,


Figure 2 .
2
Each column corresponds to one of the four Simple DDM parameters: the non-decision time (t nd ), the relative start point (w), the drift rate (µ), and the threshold location (b) (where a = 2b is the threshold separation / caution). The column which corresponds to each parameter is indicated along the bottom of the figure. Each row corresponds to the number of simulated data points N in each numerical experiment, ranging from N = 100 to N = 10, 000. The horizontal axis corresponds to the true parameters input to each simulation, while the vertical axis displays the best fit parameter sets, given by the parameter set with the maximum sum log-likelihood. The R 2 values give the quality of fit, with points which fall along the red lines indicating perfect parameter recovery.


Figure 2 .
2
Quality of fit for the sDDM for N = 100, 250, 500, 1000, and 10, 000 simulated data points. Horizontal axes indicate the true simulated parameter values, while the vertical axes indicate the parameter values which best fit the simulated data.The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficients R 2 indicate the quality of fit to the red line.


Figure 3. Each column corresponds to a different parameter, noted beneath the bottom row of panels. The horizontal axes provide the simulated input parameters, while the vertical axes display the fit parameters determined from the max log-likelihood of the posteriors. The red line on each panel indicates where the input and fit parameters are equal, with the R 2


Figure 3 .
3
Quality of fit for the leakage model with N = 1, 000 simulated data points for each numerical experiment. Horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot are where the simulation and fit parameters are equal.


Figure 4 .
4
Figure captionon next page.


Figure 4 .
4
Quality of fit for the single condition, CI leakage model for N = 100, 250, 500, 1000, and 10, 000 simulated data points. Horizontal axes indicate the true simulated parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficients R 2 indicate the quality of fit to the red line.


Figure 5 .
5
Quality of fit for the Full Weibull model with N = 1, 000 simulated data points each. For scatter plots, horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot are where the simulation and fit parameters are equal. The correlation coefficient R 2 indicates the quality of fit to the red line. The boxplot in panel A8 indicates the percent error between the true and fit threshold (TE) calculated using Equation 19. The percentage of outliers (those parameter sets that do not fit within the box and whisker) are listed above the boxplot, while the median value is noted on the right side of the boxplot in red.


Figure 6 .
6
Example fit for a Full Weibull model. Parameter set chosen to be representative of the median behavior. Panel group A show the posteriors for the model parameters, with red lines indicating the best fit parameter based on max log-likelihood and blue line corresponding to the true parameter value. Panel B displays the threshold recovery, with the true threshold in blue, fit threshold in red, and minimum RT value the vertical dashed black line. The TE is displayed on the bottom of the panel. Panel C displays the fit to data, with data displayed in the grey histogram, the true likelihood in the blue line, and the best fit likelihood in the red dashed line. The log-likelihood values of the true and best fit parameters are displayed as well in LLH T rue and LLH F it , respectively.


Figure 7 .
7
Quality of fit for the Full Weibull model for N = 100, 250, 500, 1000, and 10, 000 simulated data points. For scatter plots, horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficient R 2 indicates the quality of fit to the red line. Boxplots indicate the percent error between the true and fit thresholds TE as calculated using Equation (19) The percentage of outliers are listed above the boxplots, and the median values are listed next to the boxplots in red.


Figure 8 .Figure 9 .
89
Quality of fit for the alternate thresholds models Linear, Exponential (Exp.), and Reduced Weibull (Red. Weib.) with N = 1, 000 simulated data points for each. For scatter plots, horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot are where the simulation and fit parameters are equal. The correlation coefficient R 2 indicates the quality of fit to the red line. The boxplots in the final rows indicate the percent error between the true and fit threshold (TE) calculated using Equation 19. The percentage of outliers (those parameter sets that do not fit within the box and whisker) are listed above the boxplot, while the median value is noted in red in the panel title. In Panel B, the boxplots display the LL D between the alternate model and the sDDM. Unlike Panel A, this is calculated as the log-likelihood of the alternate model minus the log-likelihood of the sDDM, meaning that positive values favor the alternate model (listed on the horizontal axis) over the sDDM. These figures allow use to determine whether each of these models can infer presence of a changing threshold when compared against the sDDM. Boxplots of the log-likelihood difference (LL D ) models. A) LL D between the Full Weibull and alternate models, calculated as max log-likelihood of Full Weibull minus the max log-likelihood of the alternate model, shown on the horizontal axis. If positive, Full Weibull preferred; if negative, alternate model preferred. Outlier percentage and median value displayed near each boxplot. B) LL D between the sDDM and alternate models, calculated as max log-likelihood of sDDM minus the max log-likelihood of the alternate model, shown on the horizontal axis. If positive, sDDM preferred; if negative, alternate model preferred. Outlier percentage and median value displayed near each boxplot in red.


Full
Weibull threshold with a flat threshold. The next two models, linear and exponential, perform similarly to each other, with median LL D = 2.4. The median provides only weak evidence for distinguishing between the alternate and Full Weibull thresholds. The last model, the Reduced Weibull, fits the Full Weibull data best. It has a median log-likelihood difference of LL D = 0.4, making it nearly indistinguishable from the Full Weibull. This suggests that the Reduced Weibull is a suitable replacement for the Full Weibull model, especially considering its better parameter recoverability.Panel B tells a similar story. The Full Weibull model shows clear evidence of describing data better than the sDDM, with a median LL D = 6.6. The Linear and Exponential thresholds have only weak evidence for better fitting the data than the sDDM, with medians of approximately LL D = 3. Lastly, the Reduced Weibull model has strong evidence for fitting the data better than the sDDM, with a median LL D = 5.


difference (LL D ) between the sDDM and CT model listed beneath it for each participant. The LL D values are calculated by taking the max log-likelihood of the changing threshold model minus the max log-likelihood of the sDDM; thus, if LL D is positive, the CT model is preferred, and if negative, the sDDM is preferred. Red lines display the median LL D across all participants, with the value listed above the boxplots.


. The LL D between the sDDM and alternate models, calculated as max log-likelihood of sDDM minus the max log-likelihood of the alternate model, is shown on the horizontal axis. If positive, alternate model preferred; if negative, sDDM preferred. The median value is displayed above each boxplot. Panel A, B, and C show the results for Experiments 1, 2, and 3 from Evans, respectively.


Figure 11 .
11
Boxplots of the log-likelihood difference (LL D ) between the sDDM and changing threshold model listed on the horizontal axis when fit to Experiment 1 data collected by Evans, Hawkins, and Brown (2020). The LL D is between the sDDM and Full Weibull and stepwise models, calculated as max log-likelihood of the sDDM minus the max log-likelihood of the alternate model, and is shown on the horizontal axis. If positive, alternate model preferred; if negative, sDDM preferred. The median value is displayed above each boxplot.


unrecoverable in spite of the remaining parameters closely matching their true values. This inability to recover the start point is an artifact of choosing evidence change times that are too large relative to the typical response time. To demonstrate this, we plot two different data sets in row B of Figure 12: one with large change times in black circles, and one with small change times in cyan triangles. Specifically, the black circles correspond to data sets where the flip time t 0 > 0.35 × M data , where M data is the median of the generated data set. The cyan triangles plot data where t 0 ≤ 0.35 × M data . When small flip times are used, recovery is better for all parameters. We display the correlation coefficient for large flip time as R 2 and small flip time as R 2 st 0 . The largest improvement in recovery is present for the relative start point w. The most important


Figure 12 .
12
Quality of fit for the UGM. Horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. Red lines on each scatter plot indicate where input and fit parameters are equal. Correlation coefficients for the fit of the data to the red line are displayed above each panel. A) Fit with fixed information for N = 1, 000 data points. B) Fit with changing information for N = 1, 082 data points. The black circles are for fits with t 0 ≥ 0.35 * M data and have N = 946 points, while the cyan triangles are for fits with t 0 ≤ 0.35 * M data and have N = 136 points. Correlation coefficient R 2 corresponds to the black points, while R 2 st 0 corresponds to the cyan triangles.


Figure 13 .
13
Boxplots of the log-likelihood difference (LL D ) between the UGM and sDDM for the data collected by
Evans, Hawkins, and Brown (2020)
. LL D between the UGM and sDDM is calculated as max log-likelihood of UGM minus the max log-likelihood of the sDDM. If positive, UGM preferred; if negative, sDDM preferred.Median values displayed above each boxplot. Results for Experiments 1, 2, and 3 are shown in panels A, B, and C respectively.


Figure 14 Figure 14 .
1414
contains four rows with different sets of experimental conditions. In row A, only congruent samples are generated, whereas in row B, only incongruent samples are present. For each, we recieve good recovery of the non-decision time t nd , controlled process drift rate µ c , and threshold b; however, recovery for remaining drift rate parameters is poor. Further, the DE is high, and though slightly better for the incongruent than congruent condition, these give little power to extract meaningful information fromt the data. Quality of fit for the DMC with N = 1, 000 simulated data points each.Horizontal axes indicate the true parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot are where the simulation and fit parameters are equal. The correlation coefficient R 2 indicates the quality of fit to the red line. The box plots in the final column indicate the Drift Error for each experiment, with the median displayed in red in the title. Row A shows results for Congruent data only. Row B shows the results for Incongruent data only. Row C shows the results for half Congruent and half Incogruent data.


FigureFigure 15 .
15
Example fit for the DMC taken from the two condition experiment from row C ofFigure 14. Column A displays the drift rate recovery, with the DE displayed above the curves. The true drift rate is the solid blue line, while the fit drift rate is the dashed red line. Column B shows the likelihood functions fit to the choice-RT data (grey histogram). The true likelihood is the solid blue line, while the dashed red line is the fit likelihood function.


Figure 16 .
16
Fit of DMC to N = 1, 000 data points with variable relative start w. Two conditions, one congruent and one incongruent, are used. The input parameters are displayed on the horizontal axis, while the fit parameters are on the vertical axis. The red line is the location where the true and fit parameters are equal. The r and R 2 values above each panel are the correlation and coefficient of determination for each fit to the red line. The final panel displays the drift error, with the median DE shown above the panel.


Figure 1 .Figure 2 .
12
Quality of fit for the linear CT for N = 1, 000 simulated data points.Horizontal axes indicate the true simulated parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficients R 2 above each panel indicate the quality of fit to the red line. Quality of fit for the exponential CT for N = 1, 000 simulated data points.Horizontal axes indicate the true simulated parameter values, while the vertical axes indicate the parameter values which best fit the simulated data. The red lines on each scatter plot denote the location where the simulation and fit parameters are equal. The correlation coefficients R 2 above each panel indicate the quality of fit to the red line.


Table 1
1
Parameter
ranges used for each model: the Simple DDM (sDDM), the leaky integration model (Leakage), the Full Weibull CT (FWeibull), the Reduced Weibull CT (RWeibull), the Linear CT (Exp.), the Exponential CT (Exp.), the Urgency Gating Model (UGM), and the Diffusion Model of Conflict (DMC).


threshold versus alternative thresholds.
In summary, model recovery for the Full Weibull model is generally good, but there are a few key issues to be aware of. First, parameter recovery of the relative start point and drift rate are excellent, but require substantially more samples than the sDDM. Second, while threshold parameters are not recoverable, the threshold shapes themselves, which are the source of inference, are well recovered. Third, the non-decision time exhibits a small but systematic underestimation. As discussed above, the Full Weibull parameter recovery is generally good, but struggles in a few key areas. To address this, we explore the second question: can simpler thresholds be a better alternative to the Full Weibull model? Can they replicate the dynamics of the Full
Weibull Weibull model while also giving improved parameter recovery? Additionally, which
threshold models are most effective at determining whether a given data set provides
evidence of changing versus fixed thresholds?


boxplots display the log-likelihood difference LL D between the best fit parameters of the Full Weibull and alternate threshold models (shown on the horizontal axis). This is calculated as the log-likelihood of the Full Weibull model minus the log-likelihood of the alternate model. Thus, if LL D is positive, the Full Weibull model is preferred, whereas
if the log-likelihood difference is negative, the alternate model is preferred. These figures allow us to determine whether the Full Weibull model is distinguishable from the simpler candidates.


To summarize, when data contains a clear signature of changing thresholds with early collapse (as was shown for Experiment 2), all threshold models are capable ofdetecting this. If late collapse is present, the Full and Reduced Weibull models are capable of capturing the data. When evidence is more mixed, different threshold models generate different conclusions. In light of this, we recommend that researchers fit multiple thresholds of varying complexity to their data, then closely analyze their fit quality to best determine if CTs are present. If all threshold types provide evidence forCTs, there is a high probability they are present in that data set. If the Full Weibull and Reduced Weibull only fit the data well, then there is likely a mixture of early and late collapsing subject in your data set. If all thresholds indicate no collapse, no collapse is likely present. And lastly, if different thresholds provide different results, one should be careful not to draw strong conclusions from ambiguous supporting evidence.


& Holmes, 2020;
Trueblood et al., 2021)
. Specifically, we keep only parameter sets


















U
Boehm






J
Annis






M
J
Frank






G
E
Hawkins






A
Heathcote






D
Kellen














Estimating across-trial variability parameters of the diffusion decision model: Expert advice and recommendations




E.-J
Wagenmakers




10.1016/j.jmp.2018.09.004








Journal of Mathematical Psychology




87
















The simplest complete model of choice response time: Linear ballistic accumulation




S
D
Brown






A
Heathcote




10.1016/j.cogpsych.2007.12.002








Cognitive Psychology




57


3
















Cognitive and neural bases of multi-attribute, multi-alternative, value-based decisions




J
R
Busemeyer






S
Gluth






J
Rieskamp






B
M
Turner




10.1016/j.tics.2018.12.003








Trends Cogn Sci




23


3
















Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend




10.1037/0033-295x.100.3.432








Psychological review




100


3
















Decision-making with multiple alternatives




A
K
Churchland






R
Kiani






M
N
Shadlen




10.1038/nn.2123








Nature Neuroscience




11
















Decisions in changing conditions: The urgency-gating model




P
Cisek






G
A
Puskas






S
El-Murr




10.1523/JNEUROSCI.1844-09.2009








Psychological Review




29


37
















The gated cascade diffusion model: An integrated theory of decision making, motor preparation, and motor execution




E
Dendauw






N
J
Evans






G
D
Logan






E
Haffen






D
Bennabi






T
Gajdos






M
Servant




10.1037/rev0000464








Psychological Review
















Stochastic models of decisions about motion direction: Behavior and physiology




J
Ditterich




10.1016/j.neunet.2006.05.042








Neural Networks




19
















The cost of accumulating evidence in perceptual decision making




J
Drugowitsch






R
Moreno-Bote






A
K
Churchland






M
N
Shadlen






A
Pouget




10.1523/JNEUROSCI.4010-11.2012








The Journal of Neruoscience




32


11
















The quality of response time data inference: A blinded, collaborative assessment of the validity of cognitive models




G
Dutilh






J
Annis






S
D
Brown






P
Cassey






N
J
Evans






R
P
Grasman




10.3758/s13423-017-1417-2








Psychonomic bulletin & review




26


4
















Effects of noise letters upon the identification of a target letter in a nonsearch task




B
A
Eriksen






C
W
Eriksen




10.3758/BF03203267








Perception & Psychophysics




16
















Refining the law of practice




N
J
Evans






S
D
Brown






D
J K
Mewhort






A
Heathcote




10.1037/rev0000105








Psychological review




125


4
















When humans behave like monkeys: Feedback delays and extensive practice increase the efficiency of speeded decisions




N
J
Evans






G
E
Hawkins




















10.1016/j.cognition.2018.11.014








Cognition




184














The role of passing time in decision-making




N
J
Evans






G
E
Hawkins






S
D
Brown




10.1037/xlm0000725








Journal of Experimental Psychology: Learning, Memory, and Cognition




46


2
















Response-time data provide critical constraints on dynamic models of multi-alternative, multi-attribute choice




N
J
Evans






W
R
Holmes






J
S
Trueblood




10.3758/s13423-018-1557-z








Psychon Bull Rev




26


3
















A parameter recovery assessment of time-variant models of decision-making




N
J
Evans






J
S
Trueblood






W
R
Holmes




10.3758/s13428-019-01218-0








Behavior Research




52
















A reinforcement learning diffusion decision model for value-based decisions




L
Fontanesi






S
Gluth






M
Spektor






J
Rieskamp




10.3758/s13423-018-1554-2








Psychon Bull Rev




26
















Neural mechanisms, temporal dynamics, and individual differences in interference control




B
U
Forstmann






W
P
Van Den Wildenberg






K
R
Ridderinkhof




10.1162/jocn.2008.20122








Journal of Cognitive Neuroscience
















Universally sloppy parameter sensitivities in systems biology models




R
N
Gutenkunst






J
J
Waterfall






F
P
Casey






K
S
Brown






C
R
Myers






J
P
Sethna




10.1371/journal.pcbi.0030189








PLOS Computational Biology




3


10


189














Elapsed decision time affects the weighting of prior probability in a perceptual decision task




T
D
Hanks






M
E
Mazurek






R
Kiani






E
Hopp






M
N
Shadlen




10.1523/JNEUROSCI.5613-10.2011








The Journal of Neuroscience




31


17
















Revisiting the evidence for collapsing boundaries and urgency signals in perceptual decision-making




G
E
Hawkins






B
U
Forstmann






E
J
Wagenmakers






R
Ratcliff






S
D
Brown




10.1523/JNEUROSCI.2410-14.2015








The Journal of Neuroscience




35


6
















Quantile maximum likelihood estimation of response time distributions




A
Heathcote






S
Brown






D
J K
Mewhort




10.3758/BF03196299








Psychonomic Bulletin & Review




9


3
















A practical guide to the probability density approximation (pda) with improved implementation and error characterization




W
R
Holmes




10.1016/j.jmp.2015.08.006








Journal of Mathematical Psychology




68


69
















Bayesian analysis of the piecewise diffusion decision model




W
R
Holmes






J
S
Trueblood




10.3758/s13428-017-0901-y








Behavior Research Methods




50


2
















Internal and external influences on the rate of sensory evidence accumulation in the human brain




S
P
Kelly






R
G
Connell








Journal of Neuroscience, equations






Springer












Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel




10.1038/nn.2635








Nature Neuroscience




13


10
















Impact of context information on metaphor elaboration a diffusion model study




V
Lerche






U
Christmann






A
Voss




10.1027/1618-3169/a000422








Experimental Psychology




65


6
















Model complexity in diffusion modeling: Benefits of making the model more parsimonious




V
Lerche






A
Voss




10.3389/fpsyg.2016.01324








Frontiers in Psychology




7


1324














Response times: Their role in inferring elementary mental organization




R
D
Luce








Oxford University Press


New York












Time-varying decision boundaries: Insights from optimality analysis




G
Malhotra






D
S
Leslie






C
J H
Ludwig






R
Bogacz




10.3758/s13423-017-1340-6








Psychonomic Bulletin & Review




25


3
















Pybeam: A bayesian approach to parameter inference for a wide class of binary evidence accumulation models




M
Murrow






W
Holmes




10.3758/s13428-023-02162-w








Behavior Research




56
















Short-term memory scanning viewed as exemplar-based categorization




R
M
Nosofsky






D
R
Little






D
Donkin






M
Fific




10.1037/a0022494








Psychological review




118


2
















An exemplar-based random walk model of speeded classification




R
M
Nosofsky






T
J
Palmeri




10.1037/0033-295x.104.2.266








Psychological review




104


2
















Using response time distributions and race models to characterize primacy and recency effects in free recall initiation




A
F
Osth






S
Farrell




10.1037/rev0000149








Psychological review




126


4


















J
J
Palestro






E
Weichart






P
B
Sederberg






B
M
Turner




Some task demands induce collapsing bounds: Evidence from a behavioral analysis


















10.3758/s13423-018-1479-9








Psychonomic Bulletin and Review




25














Human scalp potentials reflect a mixture of decision-related signals during perceptual choices




M
G
Philiastides






H
R
Heekeren






P
Sajda




10.1523/jneurosci.3012-14.2014








Journal of Neuroscience




34


50
















A theory of memory retrieval




R
Ratcliff




10.1037/0033-295X.85.2.59








Psychological review




85


2
















The diffusion decision model: Theory and data for two-choice decision tasks




R
Ratcliff






G
Mckoon




10.1162/neco.2008.12-06-420








Neural Computation




20


4
















Modeling response times for two-choice decisions. psychological science




R
Ratcliff






J
N
Rouder




10.1111/1467-9280.00067








Psychological Science




9


5
















The effects of aging on reaction time in a signal detection task




R
Ratcliff






A
Thapar






G
Mckoon




10.1037/0882-7974.16.2.323








Psychology and Aging




16


2
















Estimating parameters of the diffusion model: Approaches to dealing with contaminant reaction times and parameter variability




R
Ratcliff






F
Tuerlinckx




















10.3758/BF03196302








Psychon Bull Rev




9


3














Connectionist and diffusion models of reaction time




R
Ratcliff






T
V
Zandt






G
Mckoon




10.1037/0033-295x.106.2.261








Psychological Review




106


2
















Probabilistic programming in python using pymc3




J
Salvatier






T
V
Wiecki






C
Fonnesbeck




10.7717/peerj-cs.55








PeerJ Computer Science




2


55














Using covert response activation to test latent assumptions of formal decisionmaking models in humans




M
Servant






C
White






A
Montagnini






B
Burle




10.1523/jneurosci.0078-15.2015








Journal of Neuroscience




35


28
















Linking theoretical decision-making mechanisms in the simon task with electrophysiological data: A model-based neuroscience study in humans




M
Servant






C
White






A
Montagnini






B
Burle




10.1162/jocn_a_00989








Journal of Cognitive Neuroscience




28


10
















A flexible framework for simulating and fitting generalized drift-diffusion models. eLife, 9




M
Shinn






N
H
Lam






J
D
Murray




10.7554/eLife.56938


















Processing auditory information: Interference from an irrelevant cue




J
R
Simon






J
Small






A
M




10.1037/h0028034








Journal of Applied Psychology




53


5
















Psychophysically principled models of visual simple reaction time




P
L
Smith




10.1037/0033-295X.102.3.567








Psychological Review




102


3
















Modeling evidence accumulation decision processes using integral equations: Urgency-gating and collapsing boundaries




P
L
Smith






R
Ratcliff




10.1037/rev0000301








Psychological Review




129


2
















Studies of interference in serial verbal reactions




J
R
Stroop




10.1037/h0054651








Journal of Experimental Psychology




18
















The elusive tradeoff: Speed vs accuracy in visual discrimination tasks




R
G
Swensson




10.3758/BF03212837








Perception & Psychophysics




12


1
















Decision making by urgency gating: theory and experimental support




D
Thura






J
Beauregard-Racine






C.-W
Fradet






P
Cisek




10.1152/jn.01071.2011








Journal of neurophysiology




108


11
















Urgency, leakage, and the relative nature of information processing in decision-making




J
S
Trueblood






A
Heathcote






N
J
Evans






W
R
Holmes




















10.1037/rev0000255








Psychological Review




128


1














A bayesian framework for simultaneously modeling neural and behavioral data




M
Steyvers




10.1016/j.neuroimage.2013.01.048








Neuroimage




72
















Why more is better: Simultaneous modeling of eeg, fmri, and behavioral data




B
M
Turner






C
A
Rodriguez






T
M
Norcia






S
M
Mcclure






M
Steyvers




















10.1016/j.neuroimage.2015.12.030








Neuroimage




128














A generalized, likelihood-free method for posterior estimation




B
M
Turner






P
B
Sederberg




10.3758/s13423-013-0530-0








Psychonomic Bulletin & Review




21


2
















Informing cognitive abstractions through neuroimaging: The neural drift diffusion model. psychological review




B
M
Turner






L
Van Maanen






B
U
Forstmann




10.1016/j.tics.2018.12.003








Psychological Review




122


2
















Automatic and controlled stimulus processing in conflict tasks: Superimposed diffusion processes and delta functions




R
Ulrich






H
Schröter






H
Leuthold






T
Birngruber




10.1016/j.cogpsych.2015.02.005








Cognitive Psychology




78
















The time course of perceptual choice: The leaky, competing accumulator model




M
Usher






J
L
Mcclelland




10.1037/0033-295x.108.3.550








Psychological Review




108


3
















How to use the diffusion model: Parameter recovery of three methods: Ez, fast-dm, and dmat




D
Van Ravenzwaaij






K
Oberauer




10.1016/j.jmp.2009.09.004








Journal of Mathematical Psychology




53


6
















Dissociable effects of dopamine on the initial capture and the reactive inhibition of impulsive actions in parkinson's disease




N
C
Van Wouwe






K
E
Kanoff






D
O
Claassen






C
A
Spears






J
Neimat






W
P
Van Den Wildenberg






S
A
Wylie




10.1162/jocn_a_00930








Journal of Cognitive Neuroscience




28


5
















Factoring out nondecision time in choice reaction time data: Theory and implications




S
Verdonck






F
Tuerlinckx




10.1037/rev0000019








Psychological Review




123


2
















Comparing fixed and collapsing boundary versions of the diffusion model




C
Voskuilen






R
Ratcliff






P
L
Smith




10.1016/j.jmp.2016.04.008








Journal of Mathematical Psychology




73
















Fast-dm: A free program for efficient diffusion model analysis




A
Voss






J
Voss




10.3758/BF03192967








Behavior Research Methods




39
















A diffusion model account of criterion shifts in the lexical decision task




E
J
Wagenmakers






R
Ratcliff






P
Gomez






G
Mckoon




10.1016/j.jml.2007.04.006








Journal of Memory and Language




58


1
















An ez-diffusion model for response time and accuracy




E.-J
Wagenmakers






H
L
Van Der Maas






R
P
Grasman




10.3758/BF03194023








Psychonomic Bulletin & Review




14


1
















The decisive role of non-decision time for interpreting the parameters of decision making models




G
Weindel






T
Gajdos






B
Burle






F.-X
Alario




10.31234/osf.io/gewb3


















Decomposing decision components in the stop-signal task: a model-based approach to individual differences in inhibitory control




C
N
White






E
Congdon






J
A
Mumford






K
H
Karlsgodt






F
W
Sabb






N
B
Freimer






.
.
Poldrack






R
A




10.1162/jocn_a_00567








Journal of Cognitive Neuroscience




26


8
















Anxiety enhances threat processing without competition among multiple inputs: A diffusion model analysis




C
N
White






R
Ratcliff






M
W
Vasey






G
Mckoon




10.1037/a0019474








Emotion




10


5
















Testing the validity of conflict drift-diffusion models for use in estimating cognitive processes: A parameter-recovery study




C
N
White






M
Servant






G
Logan




10.3758/s13423-017-1271-2








Psychonomic Bulletin & Review




25
















Age-related differences in decision-making: Evidence accumulation is more gradual in older age




E
M
Wieschen






A
Makani






S
T
Radev






A
Voss






J
Spaniol




10.1080/0361073X.2023.2241333








Experimental Aging Research



















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]