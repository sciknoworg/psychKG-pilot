You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



"Which meal would you like, chicken or pasta? Chicken please. . . . hmmm not sure. No sorry, I prefer pasta". Confidence, the subjective estimate of decision quality, is an essential component of decision making. It is necessary for learning from mistakes in the absence of immediate feedback and guiding future actions. Despite its importance, it remains unclear where confidence judgments originate from, especially for decisions that rely on individual subjective values and preferences. Here, we devised a behavioural paradigm and a computational framework that allowed us to formally tease apart the sources of confidence in value-based decisions. In line with canonical decision theories, we found that trial-to-trial fluctuations in the precision of value encoding impact economic choice consistency. Surprisingly, however, and contrary to canonical theories of confidence, this uncertainty has no influence on confidence reports. Instead, we find that confidence reflects the degree of balance and cognitive effort with which the choice alternatives have been compared. Specifically, we show that confidence emerges from endogenous attentional effort towards choice alternatives and down-stream noise in the comparison process. These findings caution a direct translation of canonical frameworks of confidence based on perceptual decision behavior into the valuebased choice domain. In addition our computational framework provides an explanation for confidence miss-attributions in economic behaviour and reveals the mechanistic interplay of endogenous attentional states and subjective value for guiding decisions and metacognitive awareness.
Correspondence: rafael.polania@hest.ethz.ch; jeroen.brus@hest.ethz.ch
The ability to evaluate the quality of our own decisions in the absence of immediate feedback is a fundamental aspect of cognition, which can be used to revise decisions and guide future behaviour. This kind of subjective evaluation of choice is known as confidence, which is particularly relevant in the domain of economic decisions, where subjective evaluations of choice can have far-reaching implications for the welfare of individuals and social groups 
(1)
(2)
(3)
. For instance, after finally deciding for a dish in a restaurant, we might feel that it was actually not the dish we wanted to eat, potentially leading us to revise our meal choice 
(4)
. Likewise, we may introspect decisions about what house we opted to buy, or what financial investment we have made. Despite its importance, little is known about the mechanisms underlying confidence originating from subjective value-based decisions.
Arguably, most of our knowledge regarding confidence mechanisms originates from the domain of perceptual decision making 
(1,
(5)
(6)
(7)
(8)
(9)
(10)
. A potential reason is that, in purely perceptual decision tasks, experimenters have full control of the objective stream of evidence presented to the decisionmaker, thus allowing to examine how each objective ingredi-ent of the input stimuli affects choice and the resulting confidence evaluation.
Normative approaches formulate that confidence reflects an optimal estimate that the decision was correct 
(11,
12)
 and is a direct transformation of evidence strength 
(13)
(14)
(15)
. This rational is particularly relevant to one of the central arguments that have sparked research in the last years: whether confidence represents an accurate index of decision uncertainty 
(11,
16,
17)
. Interestingly, earlier studies found that people indeed rely on the strength of evidence, but do not directly consider the uncertainty on that evidence when they make confidence reports 
(18)
. Also, the importance of studying different sources of error in the decision process has been stressed 
(19)
, however this aspect has not been formally studied in the domain of value-based choices.
A potential reason for this gap is that in the domain of valuebased choices neither the experimenter nor the decisionmaker have complete access to the subjective values of the alternatives comprising a decision, where values are potentially sampled from multiple attributes stored in memory 
(20)
. This is critical, as interpretation of confidence from decisions that rely on subjective-value estimations run the risk of being misattributed to aspects of the choice process that are actually choice-irrelevant. Therefore, processes that lead to confidence reports in value-based choice may differ from those supporting simple perceptual decisions. However, recent developments in the study of subjective valuation that more formally take into consideration some of these limiting aspects might be promising approaches to elucidate the sources of confidence in value-based choices 
(21,
22)
.
Another key difference from classical perceptual decision paradigms is that value-based choice tasks usually entail two or more alternatives for choice situated at different spatial locations of the visual field. That is, decision makers foveateoften repeatedly via changes in eye-fixation-to one of the choice options at a time, thereby gathering evidence from each alternative 
(23)
. Often subjects spend unequal amounts of time on the two options. This aspect is essential to consider, as seminal studies in the attention literature clearly indicate substantial influences of reward in biasing attention with direct consequences on choice processes 
(24)
(25)
(26)
. Thus, an unresolved question is whether observers have the capability to introspect about their endogenous attentional states of the decision processes, and whether these internal signals are used to inform post-decision confidence reports.
We argue that these issues have been difficult to tackle given the lack of mechanistic and formal models of decision be-haviour capable of dissecting the different components of choice processes that rely entirely on subjective value evaluations 
(21)
. Here, we address these issues via a novel combination of a behavioural task with eye-tracking and computational modeling, which allowed us to dissect what aspects of the choice process are linked to post-decision confidence reports. Across two independent datasets, we find that human participants incorporate knowledge of trial-to-trial fluctuations in attentional effort in their confidence reports, thus revealing that contrary to standard specifications 
(23)
 attentional effort is highly dynamic across trials and deeply influences both choices and confidence. Further investigating the role of different forms of noise in the decision process, we find that trial-to-trial fluctuations in encoding noise do not influence confidence, while down-stream comparison noise does.


Results
Value variability, choices, and confidence. We implemented a behavioral paradigm that allows teasing apart distinct sources of variability in decisions based on subjective values of the choice alternatives 
(21)
. In the first part of the experiment, participants (n=33) were presented with single food items and asked to indicate on a continuous rating scale their desirability to consume the presented item at the end of the experiment, rating phase 1 
(Fig. 1a)
. Participants then rated the same items a second time (rating phase 2, methods). Crucially, participants were not informed before rating phase 1 that a second rating phase would take place. This was important as it prevented participants from actively memorizing the location of the rating in the slider in the first phase, thus providing us with a clean measure of the variability in the value estimates. This procedure allows us to study whether trial-to-trial fluctuations in subjective value estimations are reflected on value coding/decoding operations rather than just random noise, and how this variability affects the quality of the decisions 
(21)
. Crucially, this also allows studying whether this source of variation is directly related to post-decision confidence reports. To investigate this, the same participants underwent a series of incentive-compatible choices in which they selected from pairs of the previously rated food items the one item they preferred to eat 
(Fig. 1a)
. While performing the incentive-compatible choices, the eyes of the participant were being tracked (methods). Information on gaze location has a critical role in the modelling of choice and confidence as well as in inferring the asserted attentional effort. All model latent variables reported throughout are derived from Bayesian models including random effects at the population level. For each latent variable, we report its posterior mean and standard deviation, and the "p-values" reported are not frequentist p-values but instead directly quantify the probability of the reported effect differing from zero (see methods).
As commonly adopted in studies of value-based choices (21, 23, 27), here we define a consistent choice as a trial in which the subject chose the item they had assigned a higher Top row: example display of the rating task. Participants rated their desirability to eat the displayed food item at the end of the experiment. Participants gave their rating by adjusting the position of a green arrow underneath the scale. Bottom row: example display of the choice task. Participants were asked to indicate which of the two food items they preferred to consume after the experiment. After their choice, participants were asked how confident they were about their decision. b) Left: standardized estimates of a multiple logistic regression on choice consistency (green) show that higher value difference (VD) leads to more consistent choices (β = 0.28 ± 0.04, P < 0.001). Higher variability in the rating of the two alternatives leads to less consistent choices (β = −0.15 ± 0.05, P = 0.002). The total value (TV) of the two items had no reliable influence on choice consistency (β = 8.7 × 10 −3 ± 0.05, P = 0.43). Right: standardized estimates of a multiple linear regression on confidence reports show that higher VD lead to more confidence (β = 0.05 ± 0.01, P < 0.001). Crucially, higher variability in the rating of the two alternatives does not have a reliable effect on confidence (β = 0.01 ± 0.02, P = 0.2). Higher TV increases confidence (β = 0.28 ± 0.06, P < 0.001). Error bars indicate the mean standard deviation of the posterior estimates in the hierarchical mixed-effects models. c) Comparing the effect sizes of the variability in the rating on choice consistency and confidence (effect size choice consistency -effect size confidence) we find that 99% of the density of the posterior estimates is below zero. Black vertical lines indicate the 95% highest density interval. d) Effects of trial-to-trial variability on choice consistency and confidence shown in panel b are also reflected in the overall rating variability at the participant level. The slope of a generalized linear regression between the log mean variability of subjects' ratings and choice consistency is significant (β = −0.15 ± 0.04, P < 0.001), however, the slope of a linear regression between the log mean variability of subjects' ratings and confidence is not significant (β = −0.09 ± 0.06, P = 0.18). e) Confidence as a function of evidence (absolute value difference) (left) shows the qualitative signatures of confidence reports guided by its statistical definition. Confidence as a function reaction time (center) shows signatures reported in previous work. Confidence as a function of TV confirms the quantitative results presented in panel b (right).
average rating across the two previous ratings. Using a multifactor hierarchical logistic regression, we found that choice consistency was influenced by the value difference between the two items' prior ratings: the higher the value difference (VD), the more consistent the choices (β = 0.28 ± 0.04, P < 0.001; 
Fig. 1b
), a result that is in line with previous work 
(4,
21,
23,
(28)
(29)
(30)
(31)
. Importantly, choice consistency also depended on the variability in the value ratings: the higher the rating variability for the items on a given trial, the less consistent the decision (β = −0.15 ± 0.05, P = 0.002; 
Fig. 1b)
, a result that replicates our previous work 
(21)
. After controlling for VD and rating variability, we found that the total value (TV) of the alternatives in each trial had no influence on choice consistency (β = 8.7×10 −3 ±0.05, P = 0.43; 
Fig.  1b
), a finding that is generally consistent with previous work 
(21,
31)
. We tested whether the null model (Choice ∼ VD + Var; which in this case excludes TV) is more credible than the full model (Choice ∼ VD + Var + TV) via the estimation of the Bayes Factor (BF 01 ). In this model comparison, we found BF 01 = 54, which indicates "very strong" evidence (32) for the absence of TV effects on choices.
A key aspect of this study is to test whether trial-to-trial fluctuations in the estimation of reward information have an impact on value-based decisions. Specifically, canonical theories of confidence predict that these trial-to-trial fluctuations impact the confidence reports because this variation directly affects evidence for choice. Using a multi-factor regression we found, as expected, that VD has an impact on confidence reports (β = 0.05 ± 0.01, P < 0.001; 
Fig. 1b
). However and surprisingly, trial-to-trial fluctuations in the estimation of reward values had no impact on confidence reports (β = 0.01 ± 0.02, P = 0.2; 
Fig. 1b
). Again, we tested whether the null model (Choice ∼ VD + TV; which in this case excludes Var) is more credible than the full model (Confidence ∼ VD + Var + TV). We found BF 01 = 450, which indicates "very strong" evidence for the absence of rating variability effects on confidence. Furthermore, we found a significant difference in the effect sizes of the regressor capturing trial-to-trial fluctuations of subjective valuation between the choice and confidence models (∆β EffectSize = −1.11 ± 0.48, P = 0.01; 
Fig. 1c
), indicating specificity of the effect on choice consistency but not on confidence. Extending this trial-to-trial effect of rating variability, we observed that each participant's average level of variability in the rating task was negatively correlated with the slope of the logistic regression of individual choices on the items' mean value difference (β = −0.15 ± 0.04, r = −0.56; P < 0.001; 
Fig. 1d
), and this effect was once again not present for the same analyses performed on confidence reports (β = −0.09 ± 0.06, r = −0.24; P = 0.18; 
Fig. 1d
). Moreover, contrary to the findings in the choice consistency logistic regression, our data reveal that total value has a large positive impact on confidence reports (β = 0.28 ± 0.06, P < 0.001; 
Fig. 1b
). Once again, we found a significant difference in the effect sizes of the regressor capturing trial-to-trial fluctuations of subjective valuation between the choice consistency and confidence models (∆β EffectSize = −0.82 ± 0.35, P = 0.009), but this time con-firming the specificity of the TV effect on confidence but not on choice consistency.
We investigated whether our data would still qualitatively capture the canonical signatures of confidence 
(16,
17)
 despite these surprising results ( 
Fig. 1b-d
). Indeed we found the often reported interaction between evidence (absolute value difference) and response accuracy where confidence responses ramp up and down for consistent and inconsistent decisions respectively (consistent: β = 0.056 ± 0.016, P < 0.001, inconsistent: β = −0.056 ± 0.027, P = 0.017, interaction evidence*consistency β = 1.11 ± 0.2, P < 0.001; 
Fig. 1e, left)
. Moreover, we also found that confidence was higher for faster reaction times (RTs) (β = −0.37 ± 0.013, P < 0.001; 
Fig. 1e, center)
. In line with the quantitative results in 
Fig. 1b
, qualitative inspection of the data shows that total value had a positive influence on confidence reports 
(Fig. 1e, right)
, which is not a direct prediction of the canonical model of confidence given its relative lack of weight on choice consistency, but it has previously been observed in value-based decision studies 
(4,
27)
. Thus, while most of the canonical signatures of confidence are qualitatively reflected in the data, our initial set of quantitative analyses suggest that confidence is influenced by factors other than uncertainty in the input values for decision making.
Generative models of confidence. In order to gain a mechanistic understanding underlying these descriptive results, we implemented a modeling approach allowing us to tease apart the different components of the decision process and how these are related to confidence reports. It has been shown that subjective value reports can be directly used as input evidence in dynamic accumulation models, which can successfully explain both choices and reaction times (RTs) 
(23,
28,
33,
34)
. Moreover, related work in the perceptual domain suggests that information of both RTs and evidence strength provide relevant information about decision confidence 
(5,
10)
. Additionally, given that during valuebased choices decision makers foveate--often repeatedly via changes in eye-fixation-to one of the choice options at a time, the degree of attentional effort during the decision process (formally defined below) has a significant impact on decision-making processes 
(23,
31,
35)
.
In order to account for these factors, here we make use of a recent evidence accumulation model that takes into account attentional effort and does an excellent job at explaining value-based decisions while jointly considering reaction times (RTs) and fixation patterns on a trial by trial basis: the Gaze-weighted Linear Accumulator Model (GLAM) 
(35)
. In this model, the effects of attention are captured by parameter θ, which can be interpreted as a cognitive process controlling the degree of effort the agent exerts to keep the evidence for the non-fixated choice option in working memory (henceforth, attentional effort). If θ = 0, the agent completely ignores the evidence for the non-fixated choice item. But if θ = 1 the agent exerts maximum effort and the two choice alternatives are equally weighted. The resulting gaze-weighted decision signals are then fed into a linear stochastic race (see methods for details). In typical applications the attentional effort θ is assumed to be agent-specific and a constant parameter in a given experiment 
(23,
35)
. Instead, here we considered the possibility that attentional effort can fluctuate from trial-to-trial and studied the potential impact of such fluctuations in confidence reports. To this end, we considered two families of generative models of confidence: (i) a heuristic model, and (ii) a normative model. The heuristic confidence model is based on previous proposals that confidence reports are based on the location of the loser accumulator in any given trial 
(27,
33)
. The closer the particle of the loser alternative is to the decision bound, the lower the confidence of the observer. In this case, on any given trial confidence is simply defined as:
confidence = B − e i (t),
(1)
Where B is the bound of the accumulator and e i (t) is the location of the loser accumulator at decision time t ( 
Fig. 2a
; see methods for a more detailed explanation of the model). Interestingly, this heuristic implicitly considers the effects RT, given that longer decisions imply a higher probability that the loser accumulator is closer to the bound ( 
Fig. 2a,b
). While readouts of confidence in this model are simple, this model does not directly consider the statistics of the environment and the decision process, hence labeled here as a heuristic model. The normative confidence model is based on the statistical definition of confidence 
(5,
11,
16)
. In the case of our model specification, it is assumed that the decision maker estimates the probability that the decision is correct by using the information of the decision time and the location of the losing accumulator, alongside the parameters of the decision process and the contextual statistics of the task (see methods).
Given that the experimenter has no access to the exact evidence of the losing accumulator in each trial, the best estimation the experimenter can assume is the expected evidence. In this case one must gather information about the statistics of the decision process, and marginalize out the variables of no interest (see 
Fig. 2c
; methods). In this case, confidence is defined as:
p(correct|C, t, Ω) = Ep (correct| e, C, t, Ω)p( e|C, t, Ω) de,
(2)
where Ω are the set of parameters of the GLAM (including attentional effort θ), e are the evidence levels of the correct and incorrect decision alternatives at the decision time t (thus e implicitly contains information of the bound B), and C is the observed type of choice from the experimenter's perspective (correct or incorrect). The contextual association between the probability of being correct and the dynamics of the choice process is represented byp(correct | e, C, t, Ω) (see equation 12 in methods).
A novel contribution of our work is that based on our model specification, it is possible to generate predictions about how attentional effort θ during the decision process influences confidence reports. The two models (heuristic and normative) generate qualitatively similar predictions ( 
Fig. 2e
 and Extended Data 
Fig. 1-3
), including the interesting result that the higher the total value (TV) of the input alternatives, the higher confidence is, crucially after controlling for other relevant factors ( 
Fig. 2e
). This prediction is in line with our data ( 
Fig. 1b,e
) and recent work 
(4,
33)
. This result emerges in the GLAM model based on the fact that under the assumption that attentional effort is not always maximal, higher input values amplify the relative difference of the choice alternatives, furthermore higher input values result in faster reaction times and therefore higher confidence. Interestingly, we find that only the normative model (and not the heuristic model) predicts that higher attentional effort θ leads to higher confidence reports ( 
Fig. 2d,e
). This prediction (alongside other slight qualitative differences between the two models, 
Fig. 2e
 and Extended Data 
Fig. 1-3
) allows us to formally test whether confidence reports in our experiments are more favoured by the heuristic model 
(27,
33)
 or are better explained by the statistical definition of confidence 
(5,
16)
.
Trial-to-trial fluctuations in attentional effort influence confidence. Based on these model predictions, we hypothesized that if participants use (or approximate) the statistical definition of confidence, then they should not only consider information about the strength of evidence and RT, but also attentional effort on a trial-to-trial basis. That is, we studied the possibility that human participants can introspect about how balanced (rational)-with respect to both items-they were during the comparison process, where high attentional effort (i.e. θ ≈ 1) should be related to high confidence. Crucially, we also considered in both heuristic and normative model specifications how fluctuations in the evidence gain k (also known as drift rate, which is input value independent; see methods) may affect confidence as it has been described in previous studies 
(27)
.
In order to evaluate the predictive power of the abovementioned families of generative models and take potential trial-to-trial fluctuations in the relevant decision model parameters into account (both θ and k), we adopt the "joint modelling" approach (36) 
(Fig. 3a)
. This approach allows us to enforce reciprocal statistical relationships between the confidence reports and the parameters of the sequential sampling model by modeling these random variables simultaneously (methods). Crucially, this approach also can automatically evaluate the statistical dependency between decision model parameters and confidence through correlation parameters (methods). Additionally, one can obtain approximate trial-to-trial readouts of the decision model parameters 
(36)
.
Here it is important to highlight that this method is completely agnostic as to which mechanism generates the confidence reports (this method allows evaluating potential cofluctuations between confidence and latent variables of the decision model). Therefore, this approach allows us to use information about the trial-to-trial readouts in the decision model and plug these values into the heuristic and normative Generative modelling of confidence: heuristic and normative. a) Illustration of how confidence reports are generated by the decision maker according to the heuristic process: confidence is simply computed as the difference between the decision bound and the evidence of the losing accumulator at the time of decision. b) Confidence can be computed via the estimation of the expected evidence of the losing accumulator. c) How the observer generates confidence reports according to the normative model: confidence is generated by computing the probability that the decision is correct given the decision time and the process model parameters. d) Confidence predictions generated by the normative model as a function of RTs, evidence of the loser accumulator and attentional effort. e) Linear regression analysis of confidence comparing the heuristic versus the normative model. Only the normative model predicts that confidence should be higher for higher values of attentional effort.
definitions of confidence (equations 1 and 2, respectively), thus allowing to obtain predictions of confidence and formally compare the predictive power of the two models ( 
Fig.  3a
).
First, we investigated which of the two models (heuristic or normative) can better predict future confidence reports assuming that attentional effort θ and evidence gain k have fixed values (i.e., no trial-to-trial fluctuations in the values of these parameters as it is usually assumed in the literature 
(23,
35)
). While both models were monotonically related to the confidence reports (β heuristic = 0.45 ± 0.04, P < 0.001; β norm = 0.53±0.06, P < 0.001), we found overwhelming evidence that the normative model provided more reliable predictions of confidence via model comparison (BF 1000 → ∞; also confirmed via leave-one-out (LOO) cross-validation metrics: ∆LOO = 29; 
Fig. 3b
).
We then investigated whether models incorporating trialto-trial-fluctuations according to the "joint modeling" approach provided more accurate predictions of confidence. We found significant trial-to-trial co-fluctuations between confidence and attentional effort θ (ρ = 0.54 ± 0.08, P < 0.001; 
Fig. 3b
) and also between confidence and evidence gain k (ρ = 0.87 ± 0.10, P < 0.001; 
Fig. 3b
). Subsequently, we used inferred trial-to-trial estimates of θ and k to generate confidence predictions 
(Fig. 3a, methods)
. Once again, we found that both models generate confidence predictions that are monotonically and significantly related to the empirical reports (β heuristic = 0.13 ± 0.04, P < 0.001; β norm = 0.61±0.05, P < 0.001). But crucially, we found overwhelming evidence that the normative model provided more reliable predictions of confidence via model comparison (BF 1000 → ∞; also confirmed via LOO cross-validation metrics: ∆LOO = 1260; 
Fig. 3b
). Moreover, across the normative models, we found that the confidence model incorporating trial-to-trial fluctuations in attentional effort θ and evidence gain k provide more reliable estimates of confidence reports than the models that assume fixed parameters across trials (BF 1000 → ∞ favoring the normative model with trial-to-trial variability in θ and k across all model comparisons, 
Fig. 3b
). Going beyond these quantitative analyses, importantly, we found that the qualitative predictions of the normative model closely match the empirical results ( 
Fig.  3d,e
; for completeness, we provide model predictions of the remaining models in Extended Data 
Fig. 1
).
To rule out that the results obtained are due to the specifics of our design or cultural differences, we reanalyzed a valuebased decision-making dataset from previous work (Folke et al., 
(4)
). Their experimental design is similar to our valuebased task, except that participants performed only one round of ratings, and they were asked to indicate their willingness to pay for a given item; while in our task participants were asked to indicate how much they wanted to consume the item at the end of the experiment. Analyzing the data of this independent dataset, we fully replicate all the key results of our data. Using the models with fixed θ and k parameters, we found that both models are monotonically related to the confidence reports (β heuristic = 0.51 ± 0.06, P < 0.001; β norm = 0.82 ± 0.15, P < 0.001), and found overwhelming evidence that the normative model provided more reliable predictions of confidence via model comparison (BF 1000 → ∞; also confirmed LOO cross-validation metrics: ∆LOO = 333; 
Fig. 3c
). Using the models allowing trial-totrial fluctuations in θ and k, we found significant trial-to-trial co-fluctuations between confidence and attentional effort θ (ρ = 0.47 ± 0.08, P < 0.001; 
Fig. 3c
) and also between confidence and gain parameter k (ρ = 0.70 ± 0.11, P < 0.001, see 
Fig. 3b
). Subsequently, we used inferred trial-to-trial estimates of θ and k to generate confidence predictions. We found overwhelming evidence that the normative model provided more reliable predictions of confidence via model comparison (BF 1000 → ∞; also confirmed via LOO cross-validation metrics: ∆LOO = 1548; 
Fig. 3c
). Moreover, across the normative models, we found that the confidence model incorporating trial-to-trial fluctuations in attentional effort θ and evidence gain k provide more reliable estimates of confidence reports than the models that assume fixed parameters across trials (BF 1000 → ∞ favoring the normative model with trial-to-trial variability in θ and k across all model comparisons, 
Fig. 3c
). Once again, we found that the qualitative predictions of the normative model closely match the empirical results ( 
Fig. 3f,g
; for completeness, we provide model predictions of the remaining models in Extended Data 
Fig. 2
).
Taken together, these results strongly suggest that attentional effort is not a fixed model parameter, but fluctuates from trialto-trial (alongside the evidence gain) and human participants incorporate this knowledge during their confidence reports as predicted by the normative definition of confidence. that the rating task is not repeated. Furthermore subjects were asked how much they were willing to pay for a certain food item using a standard incentive-compatible Becker-DeGroot-Marschak method. f-h) Same as a-d, but for the data generated by Folke et al.
Using confidence to infer potential latent variable fluctuations in static models. The results presented above show how it is possible to capture trial-to-trial fluctuations in relevant latent variables of a given sequential sampling model (the GLAM in our case) based on the "joint modeling" approach, where both latent variables and confidence reports are treated as random variables (and not observed point estimates). However, this approach relies on the estimation of covariance matrices that are computationally demanding (in particular for models with hierarchical Bayesian structures). Moreover, in some cases, access to reaction time data and specification of dynamical models is not always possible in some datasets and studies of psychology and economics (nevertheless, we emphasize that whenever possible, RT and decision data should jointly be used as they provide complementary information underlying decision processes (37)). Therefore, it might be of interest to investigate whether confidence reports-used in this case as observed (independent) variables-serve to infer potential fluctuations in latent variables in static decision-making models. We emphasize that in this case, it is not possible to establish generative models of confidence, but the goal is to study how observed confidence allows us to make inferences about the decision-making pro-cess.
We start by implementing a simple random utility model (RUM), which is a model that is widely used in the economics literature, that was extended to incorporate attentional factors (38) (methods). Crucially, this extension allows for a straightforward interpretation of parameter estimates with only a fraction of the computational costs of commonplace attentional sequential sampling models 
(23,
35)
 and the "joint modeling" approach. Therefore, this allows to flexibly compare a range of model alternatives concerning factors such as attentional effort and other sources of noise in more complex models as we elaborate further below.
First, we studied whether attentional effort influences choices in the RUM, as demonstrated in previous work using sequential sampling models 
(23)
. We find that participants discount the non-attended item (θ = 0.68 ± 0.04; 
Fig. 4c
), thus reproducing previous reports and validating our model specification. Then, we investigated whether post-decision confidence reports predict trial-to-trial fluctuations of attentional effort θ and evidence gain k. We find that trial-to-trial confidence reports are related to the degree of attentional effort (β θ = 0.80 ± 0.06, P < 0.001; 
Fig. 4d
), and notably, atten-tional effort θ ranges over its full range from low to high confidence 
(Fig. 4c)
. In the same model, the trial-to-trial confidence is positively related to changes in evidence gain (β k = 11.3 ± 3.8, P = 0.002; 
Fig. 4d
). The significant impact of confidence reports on these latent variables was confirmed by effect sizes significantly larger than zero (effect size β θ = 13.3±2.0, P < 0.001, effect size β k = 2.95±0.28, P < 0.001; 
Fig. 4d
). Additionally, cross-validation metrics revealed that the model that incorporates trial-to-trial fluctuations of θ and k as a function of confidence explains the data more parsimoniously compared to the standard RUM models (Extended 
Data Fig. 4
). This set of results mirror the ones obtained using the "joint modeling" approach, thus validating the usefulness of using confidence reports in order reverseengineer potential trial-to-trial fluctuations in latent variables of static decision-making models. For completeness, we applied the same inference approach, but this time using an attentional drift diffusion model variant based on the RUM in order to further validate our results. We found nearly identical qualitative and quantitative results to those obtained using the static models (Extended Data 
Fig. 5
).
Once again, in order to rule out that the results obtained are due to the specifics of our design or cultural differences, we reanalyzed the value-based decision-making dataset from previous work (Folke et al., 
(4)
). This independent dataset fully replicates our findings that confidence reports are related to fluctuations in attentional effort (β θ = 0.80 ± 0.18, P < 0.001, effect size β θ = 2.04 ± 0.47, P < 0.001; 
Fig.  4h
) and the evidence gain (β k = 12.1 ± 1.7, P < 0.001, effect size β k = 2.59 ± 0.36, P < 0.001; 
Fig. 4f-h)
. Furthermore, cross-validation metrics revealed that the model that incorporates trial-to-trial fluctuations of θ and k as a function of confidence explains the data more parsimoniously compared to the standard RUM models (Extended Data 
Fig. 4
). Thus, these converging results ensure that they are not a consequence of the specifics of our design or potential cultural differences.
Confidence reports are not related to trial-to-trial fluctuations in reward encoding. The models presented above depart from the strong assumption that the experimenter has complete knowledge of the input stimulus value v for each choice alternative, where v is taken from the rating task and directly fed into decision models 
(4,
23,
(27)
(28)
(29)
(30)
. This strategy is warranted in studies of perceptual decision-making where the experimenter has full knowledge of the input values. However, this assumption is not ideal in studies of subjective value-based decisions, given that in this case the experimenter has only limited access to the "true" input values v used to guide decisions. We account for this caveat by departing from the assumption that the observer needs to derive an estimatev of the items's value v to make the choice 
(21)
. Note that this assumption acknowledges the common believe of the brain acting as an inference machine (39), which is not strictly the case in standard specifications of value-based decision models. Thus, we model valuation as a probabilistic inference process incorporating both encoding and decoding operations (methods). The advantage of using this approach is that it allows to take into consideration: first, the statistics of the environment (i.e., the prior distribution) of subjective values for each individual; second, noisy encoding due to the limited capacity of systems to process information 
(21,
22)
; third, allows a parsimonious dissociation of noise at the encoding stage from downstream noise in the comparison process; and fourth, allows straight forward incorporation of information about fixation patterns (i.e., attentional effort). The computational extensions we introduce permit studying how post-decision confidence reports are related to each of these factors independently within one unified framework 
(Fig. 5a)
. Here, it is important to clarify that this model cannot be fitted to experiments that do not include information about rating variability (methods). Therefore, this model cannot be fitted to the data from Folke et. al., and in this part of the results we restrict our analyses to our experimental data.
First, we investigated whether the efficient coding model also reveals attentional discounting independent of confidence. In this model, we found that participants also discount the nonattended item (θ = 0.85 ± 0.03; 
Fig. 5f
), however to a lesser degree relative to the RUM (this result is discussed in further detail below). Then, we used the efficient coding model to test the potential relationship between post-decision confidence reports and trial-to-trial fluctuations in encoding noise (σ enc , which is input value specific), down-stream noise in the post-decoding comparison process (σ comp , which input value independent), and attentional discount (θ) (see 
Fig. 5a
).
In line with the "model-free" analyses results 
(Fig. 1b)
, we found that confidence reports appear to be unrelated to trialto-trial fluctuations in the encoding precision of the choice inputs (β σ enc = 0.015 ± 0.068, P = 0.41; 
Fig. 5b,d
). However, we found that confidence reports are strongly related to trial-to-trial fluctuations in down-stream comparison noise (β σ comp = 1.21 ± 0.22, P < 0.001; 
Fig. 5e
). The dissociation in the relationship between confidence reports and these two distinct noise sources was confirmed by a significant difference in their effect sizes (∆β σ EffectSize = 3.18 ± 0.71, P < 0.001; 
Fig. 5g
). These results are in line with the notion that integration noise of the input values for each choice alternative is not related to confidence reports during human value-based decisions as in our initial analyses 
(Fig. 1b)
, and now confirmed via a normative inference model 
(Fig. 5)
.
Additionally, we found that in this model confidence reports are also strongly related to the degree of attentional effort (β θ = 0.24 ± 0.06, P < 0.001; 
Fig. 5b)
. Interestingly, confidence appears to induce a smaller (but still highly significant) influence on θ in the efficient coding model relative to the RUM. This is evident by the fact that β θ was steeper in the RUM than in the efficient coding model (∆β θ = 0.55 ± 0.13, P < 0.001; 
Fig. 5i
) and additionally, the intercept parameter θ base (i.e. the value of θ for the lowest level of confidence, see methods) has a higher value in the efficient coding model than in the RUM (∆β θ base = −0.56 ± 0.11, P < 0.001; 
Fig.  5h
). This result reveals that incorporating input specific uncertainty in the decision model reduces the influence of attentional effort θ. It follows that participants are more "rational" than observed with models where this input specific uncertainty is not considered. Therefore, our formal and more statistically complete inference model highlights the importance of incorporating input-specific uncertainty in process models of preference-based behavior-a fundamental aspect classically considered in perceptual inference processes 
(40,
41)
.


Discussion
We implemented a behavioral task and a computational modeling approach that allowed us to dissect and understand how distinct components of the value-based choice process and associated sources of noise relate to choice behavior and post-decision confidence reports. Following the statistical computation definition that confidence should reflect choice consistency, one would expect that all factors in the decision process that affect decision variability and certainty should have a corresponding impact on confidence reports 
(11)
. However and to our surprise, we find that encoding precision of reward inputs has impact on choice (as it is expected from canonical inference models), but no impact on confidence reports. This result was initially reflected in our model-free analyses, revealing that rating variability negatively impacts choice consistency but not confidence. However, this analysis did not allow us to directly determine whether trial-totrial fluctuations in encoding precision were related to postdecision confidence reports. Therefore, we implemented an inference model allowing us to, not only, formally test the role of value encoding precision of the input options, but also to separate encoding noise from down-stream noise in the comparison process 
(21)
. This model confirmed that trial-totrial fluctuations in the encoding precision of reward values are not related to post-decision confidence reports. However, we found that sources of noise independent of input values substantially impact on confidence reports. These results reveal an important aspect of how confidence emerges in economic decisions, which is not congruent with the normative view that confidence reflects an optimal Bayesian estimate that the decision is correct 
(11,
12)
 nor with the idea that confidence is a direct transformation of evidence strength 
(13)
(14)
(15)
. Nevertheless, we acknowledge that there might be other processes that our model does not directly capture, but may also influence variability of confidence reports, such as how confidence can dynamically chance during choice (for instance due to dynamic adjustments of decision bounds (42)), and also after a decision is made 
(10,
43)
.
Regarding our established dissociation between encoding and comparison noise, at first sight this result seems at odds with recently reported results in the perceptual decision making domain. It was found that humans are blind to downstream integration noise, while using encoding noise to form believes about confidence 
(44)
. Here, we argue that the apparent difference between the influence of encoding noise on confidence in the perceptual and value-based decision domain has its basis in the characteristics of the task and the definition of encoding noise. Castanon et al. 
(44)
 use a categorization task where they present multiple tilted gratings in a circular array and vary either the contrast level of the gratings (resulting in different levels of encoding noise) or the variability of the gratings' orientations (resulting in different levels of integration noise, which they define as late noise). In their task subjects are asked to categorize the average orientation as tilted clockwise or counter-clockwise. First, we argue that what the authors of this work define as integration noise, could be very much related to what we define as encoding noise in our reward task. It has been suggested and is commonly accepted that reward value is formed via the integration of different discrete components (e.g., memories and emotions) associated to the physical features of the choice alternatives 
(20)
. Therefore, it is well possible that trial-totrial fluctuations in reward value estimations and its degree of variation is related to the definitions of integration noise in the above-mentioned categorization tasks. This would be in principle congruent with a previous study in the perceptual decision making domain, demonstrating that observers underestimate the variance of orientation noise, which leads to distorted confidence reports 
(8)
. Second, in our task, observers integrate information of two distinct choice alternatives thus resulting in two distinct value estimates that need to be compared via down-stream circuits. However, typically in categorization tasks observers integrate multiple cues and generate a single value estimate to be categorized. Therefore, we argue that perceptual decision tasks of the kind discussed above would resemble the characteristics of our task only in the event where feature integration of two distinct feature estimates takes place simultaneously (e.g., the comparison of two distinct arrays of tilted gratings) and then compared according to an abstract decision rule (e.g., which of the mean estimates is closer to cardinal). It will be interesting to investigate in future work whether a perceptual task designed in this way would also reveal that down-stream comparison noise heavily influences confidence reports.
A further contribution of our work is the finding that the degree of attentional effort in the comparison process is not just a static subject-specific characteristic as it is usually assumed in the literature 
(23,
31,
35)
, but it is a rather highly dynamic cognitive function that fluctuates considerably from trial-totrial. Interestingly, we found that subjects can introspect about their attentional effort which is subsequently reflected in their confidence reports. In other words, participants can detect whether they exerted enough effort to compare the two alternatives in a balanced way (resulting in high confidence judgments), or whether in any given trial they were "lazy" (that is, lacked effort) and did not pay enough attention to the options available. Bringing back the example of the client in a restaurant, the decision to revise the meal choice might be related to the fact that the client did not pay equal attention to all the decision alternatives, thus generating a low degree of confidence in her decision.
We speculate that trial-to-trial variations in attentional effort are related -at least to some extent -to fluctuations of working memory utilization during the comparison process. Recall that when an observer fixates one option, she needs to uphold the memory of the non-fixated option, which requires higher effort, but also results in a more balanced comparison and eventually more rational choice. Thus, we argue that there must exist a tight relationship between our definition of attentional effort with working memory and confidence as has been suggested in previous work 
(45,
46)
.
Our findings extend the intricate relationship between accumulation of evidence for decisions and confidence reports 
(42,
47)
. However, our results additionally indicate that not only is confidence used as an online control process, setting bounds on evidence accumulation, nor is it just a reflection of the quality of the evidence. Confidence also reflects trial-totrial fluctuations in the amount of effort exerted during the accumulation process. Our results also indicate that metacognitive processes appear to be blind to the irreducible uncertainty that emerges during the integration of value information, suggesting that people acknowledge their capacity limitations to process information 
(22,
48)
 and rather use late stage processes of the decision formation to guide their metacognitive processes. Indeed, this argument is generally in line with a range of studies suggesting that confidence depends on late stage processing 
(1,
6,
43,
(49)
(50)
(51)
(52)
(53)
.
Taken together, our study shows compelling evidence that we can introspect about how much attention we pay to the choice options available during our decisions, thus, revealing a new mechanistic interplay of endogenous attentional effort and rewards for guiding decisions and metacognitive awareness of choice certainty. We argue that our findings might not be limited to the domain of value-based decisions, but might have important implications for refining models of metacognitive distortions in psychiatric disorders 
(54)
, where the interaction between attention, cognitive effort and goal-directed processes play a key role in the characterization of diverse psychopathologies (55).


Methods
Participants. The study tested healthy young volunteers (n=35, age 19-37 years). However, due to bad eye-tracking recording quality two subjects have been excluded from analysis. Sample size was determined based on previous studies using similar stimuli and tasks 
(21,
28,
29)
. Participants were instructed about all aspects of the experiment and gave written informed consent. None of the participants suffered from any neurological or psychological disorder or took medication that interfered with participation in our study. Participants received monetary compensation for their participation in the experiment, in addition to receiving one food item after the choice task (see below). The experiments conformed to the Declaration of Helsinki and the experimental protocol was approved by the Ethics Committee of the Canton of Zurich.
In addition to the data collected in our lab, we also analyze the choice data from Folke et. al. 
(4)
. We used the data from experiment 1 in their study in an attempt to replicate the novel contributions of our work. The dataset consists of n=28 healthy young volunteers.
Behavioral task. Our experiment consisted of three main phases: (1) rating phase 1, (2) rating phase 2, and (3) the choice task. In rating phase 1, we asked the participants to provide subjective preference ratings for a set of 64 food items using an on-screen slider scale 
(Figure 1a)
. All of the food items were in stock in our lab and participants were notified about this. Importantly, participants saw all food products before the ratings so that they could effectively use the full range of the rating scale. Moreover, participants knew that all products were randomly drawn from the two biggest supermarket chains in Switzerland. Based on previous studies in our lab 
(21,
28,
29)
, we selected food items that varied all the way from items that most participants would find unappealing (e.g., cucumber) to items that most participants would find highly appetitive (e.g., ice cream). This was important as our model should capture the full range of subjective values that humans typically assign to food items on a daily basis.
During the ratings, participants indicated "how much they want to eat the presented food item at the end of the experiment". Participants were informed that the rightmost endpoint would indicate items that they would most love to eat, whereas the leftmost endpoint would indicate items that they would most hate to eat. The initial location of the slider was randomized for each item to reduce anchoring effects.
Rating phase 2 was identical to rating phase 1 and took place immediately after phase 1. The order of the items' presentation was randomized. Crucially, participants were not informed before the rating phase 1 that a second rating phase and a decision-making task would take place. This was important as it prevented participants from actively memorizing the location of the rating in the slider in the first phase, thus providing us with a clean measure of the variability in the value estimates.
Immediately after the two rating phases, an algorithm selected a balanced set of decision trials divided into four value difference levels on the rating scale (rating difference 5%, 10%, 15% and 20% of the length of the rating scale), as defined by the average rating across phases 1 and 2 provided by each participant. Decision-making trials started with a central presentation of a fixation cross for 1-2 seconds. Immediately after this, two food items were displayed simultaneously, one in the upper and one in the lower part of the screen 
(Fig. 1a)
. The food items were presented until response and participants had up to four seconds to make a choice. Participants were instructed to choose which of the two items (upper or lower) they preferred to consume at the end of the experiment. To make these choices, participants pressed one of two buttons on a standard keyboard with their right-index finger (upper item) or their right thumb (lower item). We defined a consistent choice as a trial in which the subject chose the item with a higher mean rating from the prior rating phase. Each experimental session comprised a maximum of 240 trials (this depended on the rating distribution of each participant) divided into 6 runs of 40 trials each. The trials were fully balanced across rating-difference levels and location of consistent response option (Up or Down).
Participants eye movements were recorded throughout the choice task at 1,000 Hz with an EyeLink 1000 Plus eyetracker (SR Research). To make sure that participants deliberated between the two alternatives, we excluded trials where participants had not fixated on every option available at least once. Based on poor quality of the eyetracking data during the whole session, two participants were excluded from the analyses, thus resulting with a final sample of n=33 subjects.
After each choice, participants indicated their confidence in their decision on a continuous rating scale. We informed participants that the leftmost side of the confidence rating scale means "Not at all" confident and the rightmost side means "Totally" confident. Neither choices nor confidence ratings were time-constrained.
The dataset that we reanalyze here from Folke et. al. (4) is similar to our value-based task, exept for the following main aspects. First, in their rating task participant were instructed to indicate their willingness to pay for a given item; in our task we asked to indicate how much they wanted to consume the item. Second, in their experiment they collected one round of ratings; we collected two. Here it is important to mention that the lack of more than one rating does not allow us to test all effects that are specific to item-specific variability in value coding in the efficient coding model (see below). However, all other analyses related to the influences of attention can be studied in both tasks. Crucially, these differences between the two tasks allow us to rule out that the results obtained in our experiment are due to specific aspects of the design or cultural differences between Swiss and British food decisions.
Generative models of confidence. In this section, we describe (i) the sequential sampling model used to jointly account for RTs and choices, (ii) the generative models of con-fidence based on the sequential sampling model, and (iii) the "joint modeling" approach used to estimate trial-to-trial fluctuations in the relevant latent variables of the decision process which are then used as inputs to the generative models.
Sequential sampling model. In order to implement the generative models of confidence, we make used the Gaze-weighted Linear Accumulator Model (GLAM), which allows to incorporate RTs, choices and gaze information in the decision process 
(35)
. In brief, the GLAM belongs to the class of race models and assumes noisy accumulation in favor of each alternative i, j, where choices are determined once the winner accumulator reaches a decision boundary B. We define the relative accumulated evidence in favor of alternative i as e i (t) = e i (t − 1)
+ kR i + ε,
(3)
with e i (0) = 0 and ε ∼ N (0, σ 2 ), where σ is the standard deviation of an unbiased normally distributed noise, k is the drift rate and R i is the average amount of relative evidence for alternative i at each time point t.
We define the absolute evidence signal S i for alternative i
S i = g i v i + (1 − g i )θv i ,
(4)
where v i is the subjective value readout based on the average ratings of each alternative i, g i is the proportion of time that the agent looks at item i on each trial, and θ ≤ 1 is the attentional effort parameter, which determines the strength of down-weighting when the agent does not fixate item i. If θ = 1, then the agent exerts high effort to keep item i in memory when she is not looking at it. On the other hand, if θ = 0, then the agent ignores the evidence of the non-fixated item at any given moment during the choice process. This suggests that for values of θ closer to 1 the agent is being fully rational in her choices, which additionally could be interpreted as exerting effort to keep the unattended items in working memory. On the other hand for values of θ closer to zero, the agent is being "lazy" and tends to ignore the unattended alternative in the comparison process.
The GLAM assumes an adaptive representation of the relative evidence signals via
s(x) = 1 1 + exp(−τ x) ,
(5)
where τ is a scaling parameter and x ≡ S i − S j , and finally
R i in equation 3 is defined as R i ≡ s(x).
The first passage time density of a single accumulator e i with decision boundary B is given by
f i (t) = λ 2πt 3 1 2 exp −λ(t − µ) 2 2µ 2 t ,
(6)
with
µ ≡ B kR i and λ ≡ B 2 σ 2 .
(7)
Therefore, the probability that accumulator e i crosses B at time t before accumulator e j is given by
p i (t) = f i (t)(1 − F j (t)),
(8)
where F () is the cumulative distribution function of f (), which is given by
F (t) = Φ λ t t µ − 1 + exp 2λ µ Φ − λ t t µ + 1 ,
(9)
where Φ() is the standard normal cumulative density function.
Heuristic confidence model. The heuristic confidence reports are based on the location of the loser accumulator in any given trial. The closer the particle of the loser alternative is to the decision bound, the lower the confidence of the observer 
(27,
33)
. In this case, on any given trial confidence is defined as (Equation 1 in main text):
confidence = B − e i (t),
where B is the bound of the accumulator and e i (t) is the location of the loser accumulator at decision time t (or reaction time (RT)).
On any given trial the experimenter has information about the RT, but has no access to the location of the loser accumulator, therefore we must marginalize over all possible locations of the loser accumulator. Based on the process model assumptions of the GLAM, it can be shown that the expected confidence for a particular reaction time is given by:
E[confidence|e i , t] = B − (kR i )t + φ(β) Φ(β) σ (t) , (10) with β ≡ B − (kR i )t σ √ t ,
(11)
where φ() is the density function of the normal distribution (see 
Fig. 2b
).
Normative confidence model. The normative confidence model is based on the statistical definition of confidence. In this case, it is assumed that the decision maker estimates the probability that the decision is correct by using the information of the decision time, alongside the parameters of the decision process and the contextual statistics of the task. More formally, one can calculate the log-posterior odds of a correct response for all possible combinations of RTs and decision variables utilized by the observer in a given context or environment:
log p(a 1 | e, t) p(a 2 | e, t) = log i p( e, t|a 1 , Ω i )p(Ω i ) i p( e, t|a 2 , Ω i )p(Ω i ) ,
(12)
where Ω are the set of parameters of the decision model, e are the evidence levels of the correct and incorrect decision alternatives at the decision time t, and a 1 and a 2 are the correct and incorrect decision alternatives, respectively (see also 
Fig. 2c
).
Once again, given that the experimenter has no access to the exact evidence of the losing accumulator in each trial, the best estimation the experimenter can assume is the expected evidence. In this case one must gather information about the statistics of the decision process, and marginalize out the location of the loser. In this case, confidence is defined as (Equation 2 in main text):
p(correct | C, t, Ω) = Ep (correct | e, C, t, Ω)p( e | C, t, Ω) de,
where C is the observed type of choice from the experimenter's perspective (correct or incorrect), andp(correct | e, C, t, Ω) represents the contextual association between the probability of being correct and the dynamics of the choice process.
Joint modelling approach. In order to derive confidence predictions based on the generative models defined above, we implemented the "joint modelling" approach 
(36)
, which allows us to enforce reciprocal statistical relationships between the confidence reports and the parameters of the sequential sampling models by modeling these random variables simultaneously. Specifically, we adopt a "covariance approach" which allows to describe the joint distribution of the decision model parameters Ω and the confidence reports c through a statistical constraint, and crucially, where confidence is not treated as a fixed point estimate, but as a random variable. That is, we impose an overarching distribution governed by parameters Ψ which are used to describe the patterns of the joint distribution (Ω, c). This is achieved via a linking function M with parameters Ψ:
(Ω, c) ∼ M (Ψ).
(13)
Here, we assume that the linking function M is given by the multivariate normal distribution, and the goal in this statistical model is to find the hyperparameters of the mean vector µ and the variance-covariance matrix Σ. For instance, if one would like to investigate potential trial-to-trial co-fluctuations between attentional effort θ, evidence gain k, and confidence c, the goal is to find the set of hyperparameters
µ =   µ c µ θ µ k   (14) Σ =   σ 2 c ρ cθ σ c σ θ ρ ck σ c σ k ρ cθ σ c σ θ σ 2 θ ρ kθ σ k σ θ ρ ck σ c σ k ρ kθ σ θ σ k σ 2 k  
(15)
Conveniently, this method allows to automatically evaluate the statistical dependency between decision model parameters and confidence through the correlation parameter ρ.
Confidence predictions and model comparison. We obtained trial-to-trial predictions in parameters θ and k by sampling from the distribution
(c, θ, k) ∼ M (µ, Σ).
(16)
Predictions of θ and k were then plugged to the confidence generative models described above-alongside all other GLAM parameters fitted using the joint approach-in order to derive confidence predictions on a trial-by-trial level. In order to account for differences in the use of the confidence rating scale, the predicted values were re-scaled via a simple linear regression. The predictions from these models were used to generate the qualitative predictions presented in 
Fig.  3e
,g and Extended Data 
Fig. 1-3
. Model comparison was carried out via computation of the Bayes Factor estimated based on the bridge sampling approach using the brms package in R 
(56)
. For completeness, the leave-one-out (LOO) information criterion was also computed.
Reverse inference of latent variables based on confidence. We investigated whether confidence reports-used in this case as observed (independent) variables-serve to backengineer potential fluctuations in latent variables of static decision-making models (i.e., models that do not explicitly consider RT information). We emphasize that in this case, it is not possible to establish generative models of confidence, but the goal is to study how observed confidence allows us to make inferences about the decision-making process.


Random utility model (RUM).
In the standard random utility model (RUM), the agent faces two options i and j, where each option has a subjective value v i and v j , respectively. In standard neuroeconomic experiments, v is assumed to be the outcome of their willingness to pay for a given option (4), or the desirability to consume a given item 
(21,
23)
. In standard RUMs, it is usually assumed that a given option i is corrupted by some general noise η i , with the usual assumption η i ∼ N (0, σ i ). If σ is assumed to be constant for all universe of goods in a given context, then the probability of choosing option i over j is given by
P (v i > v j ) = Φ v i − v j σ √ 2 .
(17)
If one would like to take into account the fact that when making decisions, people tend to look back and forth between choice alternatives, then one must take into consideration these potential shifts in attention between the choice alternatives. Recently, Smith et. al. developed a variant of the RUM that allows to take into account the proportion of time that participants spend looking at a pair of choice alternatives 
(38)
. Let A i be the fraction of time spent looking at option i (with A j = 1 − A i ). Then it can be shown that the probability of choosing option i over j while considering the effects of attention is given by
P (v i > v j ) = Φ A i v i − A j v j + θ(A j v i − A i v j ) σ √ 2 ,
(18)
where θ ≤ 1 is defined here as the attentional effort parameter.
Given that in our study we use a hierarchical Bayesian data analyses framework, this allows the convenient possibility of studying the effects of an observed variable (e.g., confidence) on a latent variable (e.g., θ). For simplicity we investigate such influences via linear relationships. Thus, in order to study the link between confidence reports and attentional effort, we assume
θ n = θ base + β θ s * c n ,
(19)
where β θ s is the effect of confidence c n on attention in a given trial n. The subscript s denotes that the effect is participant specific which is modeled as a random effects factor under the assumption that it is drawn from a population distribution β θ s ∼ N (β θ , σ θ ), where β θ and σ θ determine the mean and the s.d. of the population distribution, respectively. In this case, positive values of β θ would indicate that higher levels of attentional effort θ are reflected in higher levels of confidence.
Likewise, we can study the relationship between confidence and reward variability as defined by the RUM (σ in Eqs. 17 and 18, which directly influences the consistency of the choices). Defining k ≡ 1 σ √ 2 , we study the influence of trialto-trial fluctuations of the evidence gain k on confidence as follows
k n = k base + β k s * c n .
(20)
As before, the possible influence of confidence β k s * c n is drawn from a population distribution N (β k , σ k ). Efficient random utility model. Different to the simple RUM, here we assume that the input reward values v in the inference process are not the observed ratings, but rather the most likely input values of a resource-constrained generative model that leads to the generation of noisy value estimatesv This is an important consideration that is different from classical approaches in perceptual decision making, since experimenters have no direct access to the "true" value v of the presented object to an observer. Here we assume that this "true" value v has been shaped by each observer's personal history of experiences with this type of object and is therefore entirely subjective. Based on studies supporting the notion of contextual adaptation of valuation circuits given capacity limitations, we assume optimal use of the underlying neuronal scale to represent reward values given the expected/learned natural distribution of values in the given environment, i.e. the prior p(v). Under assumptions of mutual information maximization at the encoding stage and minimization of the Bayesian mean squared error at the decoding stage, one can obtain approximate expressions for the expected value and variance that explain the generation of noisy estimationsv conditional on a particular input stimulus with value
v 0 E[v|v 0 ] ≈ v 0 + φ • σ 2 enc (21) Var[v|v 0 ] ≈ (φ ) 2 • σ 2 enc ,
(22)
where σ enc is the noise of the limited system that encodes reward values (which we assume to be constant across the dynamic neural range, i.e, one free parameter), and φ is the quantile function of the prior p(v; ω), where ω are the parameters of the prior (for details about exact derivation of these expressions see 
(21)
). In the rating task, the experimenter does not directly observe the decoded valuesv but the rating valuesv on the physical bounded scale. The joint probability density (v, v 0 ) on the rating scale is thus given by 
(21)
 
p(v; v 0 , ω, σ enc , σ comp ) = N (g −1 (v); E[v|v 0 ], Var[v|v 0 ] + σ 2 ext ) • p(v; ω) • (g −1 (v)) ,
(23)
where g(•) is the logistic function which provides a one-toone mapping of the estimatev from the subjective to the physical scale on any given trial. In addition to internal noise σ enc in the coding of value, we also account for late noise in the decision stage (i.e., post-decoding noise), which may capture any unspecific forms of downstream noise occurring during the response process that are unrelated to the valuation process per se, which can include for instance late comparison noise. This external noise is represented as σ comp in the variance term of the normal distribution (Eq. 23) which captures the random fluctuations. Thus a key feature of this inference model specification is that it allows to separate noise in the encoding of values (which is by definition value specific) and value-unspecific noise that might be related to downstream processes.
In order to fit the efficient coding model to the rating data, we found the stimulus values v 1,...,M , parameters of the prior ω, encoding noise σ enc and external noise σ comp that maximized the likelihood functionp(v; v 0 , ω, σ enc , σ comp ) (Eq. 23) of the observed set of ratings for each participant under the constraint that v 1,...,M is distributed following p(v; ω). Posterior inference of the parameters for this model can be conveniently performed via the Gibbs sampler.
Subsequently, we used the stimulus values v 1,...,M and prior parameters ω fitted to the rating in order to predict choices in the two-alternative choice task. Please note that this strategy alleviates any concern for allowing an arbitrary choice of priors and likelihood functions in the choice models, given that the prior distribution is fully determined by out of sample data (i.e., the rating task) and the likelihood is fully constrained by the prior and our efficient coding specification. Based on this model, over many trials the probability that an agent chooses an alternative with stimulus value v i over a second alternative with stimulus value v j is given by:
P (v i >v j |v i , v j ) = Φ   E[v i |v i ] − E[v j |v j ] Var[v i |v i ] + Var[v j |v j ] + σ 2 ext   ,
(24)
where Φ(•) is the CDF of the standard normal distribution and the expressions for E[] and Var[] are given in Eqs 21 and 22 (see above). Thus, the input values of the choice model are fully constrained by the efficient coding model based on the fits to the rating data and therefore the choice model has only two free parameters, namely the resource noise of the encoder σ enc and the external noise σ comp .
This choice model can be naturally extended to incorporate the effect of the attentional discounting parameter θ
P (v i >v j |v i , v j ) = Φ   A i E[v i |v i ] − A j E[v j |v j ] + θ(A j E[v i |v i ] − A i E[v j |v j ]) Var[v i |v i ] + Var[v j |v j ] + σ 2 ext  
(25)
Behavioral analyses and statistics. Rating variability in the data from our study was computed as the variance for each item across the rating phases 1 and 2. To investigate the influence of value-difference (VD), rating variability and reward on the consistency of choices in each trial, we performed a hierarchical logistic mixed-effects regression of choices (defining consistent=1, inconsistent=0) on the above-mentioned regressors of interest, namely: VD, summed-variability (Var, defined as the sum of the two variances of the two food items presented in each trial), and the total value (TV, defined as the sum of mean rating values of the two food items presented in each trial). All regressors of interest were included in the same model. Similarly, the influence of the same regressors on confidence were based on a hierarchical linear mixed-effects regression approach. Bayes Factors reported for these regressions were estimated based on the bridge sampling approach using the brms package in R (56).
All mixed-effects regressions in this study had varying subject-specific constants and slopes for the linear models, the joint modeling approach, and the RUMs parameter estimates, where the random effects parameter estimates are denoted in this work as β, unless otherwise specified. Posterior inference of the parameters in the hierarchical models was performed via the Gibbs sampler using the Markov Chain Monte Carlo (MCMC) technique implemented in JAGS, assuming flat priors for both the mean and the noise of the estimates. For each model a total of 100,000 samples were drawn from an initial burn-in step and subsequently a total of new 100,000 samples were drawn with three chains (each chain was derived based on a different random number generator engine, and each with a different seed). We applied a thinning of 100 to this final sample, thus resulting in a final set of 1,000 samples for each parameter. We conducted Gelman-Rubin tests for each parameter to confirm convergence of the chains. All latent variables in our Bayesian models hadR < 1.05, which suggests that all three chains converged to a target posterior distribution. We checked via visual inspection that the posterior population level distributions of the final MCMC chains converged to our assumed parametrizations. For all random effects β reported here, the reported value corresponds to the median of the posterior distribution, the ± values refer to 1 s.d. of the posterior distributions and the "p-values" reported for these regressions are not frequentist p-values but instead directly quantify the probability of the reported effect differing from zero. They were computed using the posterior population distributions estimated for each parameter and represent the portion of the density functions that lies above/below 0 (depending on the direction of the effect).
Fig. 1 .
1
Experiment and regression analysis of choice consistency and confidence. a)


Fig. 2 .
2
Fig. 2. Generative modelling of confidence: heuristic and normative. a) Illustration of how confidence reports are generated by the decision maker according to the heuristic process: confidence is simply computed as the difference between the decision bound and the evidence of the losing accumulator at the time of decision. b) Confidence can be computed via the estimation of the expected evidence of the losing accumulator. c) How the observer generates confidence reports according to the normative model: confidence is generated by computing the probability that the decision is correct given the decision time and the process model parameters. d) Confidence predictions generated by the normative model as a function of RTs, evidence of the loser accumulator and attentional effort. e) Linear regression analysis of confidence comparing the heuristic versus the normative model. Only the normative model predicts that confidence should be higher for higher values of attentional effort.


Fig. 3 .
3
Joint modelling, the covariance approach. a) Graphical diagram for the joint model with the covariance approach. White circular nodes represent latent variables, grey rectangular nodes represent observable variables. b) On the left: confidence is positively related to trial-to-trial fluctuations of attentional effort and the evidence gain, shown for three example subjects (for all subjects see Extended Data 6 and 7). In the middle: the estimated density of correlation parameters for confidence and attentional effort and for confidence and the evidence gain. In both cases ρmcmc > 0 with p < 0.001. On the right: Loo model comparison of the fixed heuristic (FH), variable heuristic (VH), fixed normative (FN) and variable normative (VN) model versions. The Bayes Factor (BF) is calculated between the variable normative model and all other models, for all comparisons we find and infinite BF in favor of the variable normative model. c) The same as b), but for the Folke data. d) The empirically found confidence levels as a function of (from left to right) value difference, reaction time, total value, attentional effort and the evidence gain, split for consistent and inconsistent choice. e) The same as in d, but for the predictions of the variable normative model. f, g) The same as in d and e, but for the data of Folke et al.


Fig. 4 .
4
The RUM decision model. a) Sketch of the decision process modeled by the simple RUM, color coded to match the graphs. Observers infer the value of the food items by looking back and forth between choice alternatives. The subsequent comparison process is noisy. We investigate how confidence ratings influence trial-to-trial fluctuations of attentional factors and the evidence gain. b) Left column: the empirical probabilities of choosing the upper item; up: as a function of value difference; down: as a function of the difference in dwell time. Right column: the same as left but for the predicted probabilities of choosing the upper item by the simple RUM. The trials are median split in high/low confidence and color coded in respectively black/yellow. Value difference and dwell time difference are split into eight groups of equal size. Error bars indicate the s.e.m. c) Comparison of parameter estimates of two alternative RUMs: a RUM with agent-specific estimates of k and θ and a RUM that allows for trial-to-trial fluctuations of k and θ. Up: the median of the posterior estimate of k of the agent-specific RUM is indicated as the horizontal orange line, the shaded grey area indicates the 95% confidence interval. The diagonal orange lines represent 100 random samples of the posterior distribution of how k changes with confidence in the RUM allowing for trial-to-trial fluctuations. Bottom: the same as up, but for θ. Remarkably, θ changes over its full range as a function of confidence. d) Left: standardized posterior estimates of the beta values of the relation between confidence and k and θ. Error bars indicate the mean posterior estimate of the standard deviation. Both β k and β θ are significantly bigger than zero with P<0.001. Right: effect sizes of the results shown on the left. Error bars indicate the standard deviation of the posterior estimates of the mean of the effect size. Both the effect sizes of β k and β θ are significantly bigger than zero with P<0.001. e) Folke et al. peformed similar experiments, with the key difference


Fig. 5 .
5
The efficient coding model. a) The decision process with three distinct process stages, color coded to match the graphs. The prior p(v) matches the distribution of subjective values v of supermarket products. When facing a choice between two of these items, subjects will look repeatedly at them, often spending unequal amounts of time on the two options. The subjective value of the items is internally encoded, the corresponding likelihood function p(v|v) is constrained by the prior p(v) via efficient coding. Lastly, noise that occurs after the decoding is taken into account, this is unspecific downstream noise unrelated to the valuation process and not constrained by efficient coding. This can include for example late comparison noise. b) Left: Standardized posterior estimates of the beta values of the relation between confidence and variance in the encoding process (β σenc ), the variance in the comparison process (β σcomp ) and attentional factors (β θ ). Error bars indicate the mean posterior estimate of the standard deviation. (β σenc ) is not significantly different from 0, both (β σcomp ) and (β θ ) are significantly bigger than zero with P<0.001. Right: Effect sizes of the results shown on the left. Error bars indicate the standard deviation of the posterior estimates of the mean of the effect size. The effect size of (β σenc ) is not significantly different from 0. Both the effect sizes of (β σcomp ) and (β θ ) are significantly bigger than zero with P<0.001. c) Left column: the empirical probabilities of choosing the upper item; up: as a function of value difference; down: as a function of the difference in dwell time. Right column: the same as left but for the predicted probabilities of choosing the upper item by the efficient coding model. The trials are median split in high/low confidence and color coded in respectively black/yellow. Value difference and dwell time difference are split into eight groups of equal size. Error bars indicate the s.e.m. d) Comparison of parameter estimates of two alternative efficient coding models: a model with agent-specific estimates of σenc and a model that allows for trial-to-trial fluctuations of σenc. The median of the posterior estimate of σenc of the agent-specific model is indicated as the horizontal green line, the shaded grey area indicates the 95% confidence interval. The diagonal green lines represent 100 random samples of the posterior distribution of how σenc changes with confidence in the model allowing for trial-to-trial fluctuations. e, f) Same as e) but for σcomp and θ. g) Comparison of the effect sizes of the posterior estimates of σenc and σcomp h) Comparison of the posterior estimates of the intercept of θ in the efficient coding model and the RUM. i) Comparison of the posterior estimates of the slope of θ in the efficient coding model and the RUM.


| bioRχiv Brus et al. | Confidence in value-based choice


| bioRχiv Brus et al. | Confidence in value-based choice


| bioRχiv Brus et al. | Confidence in value-based choice


Brus et al. | Confidence in value-based choice bioRχiv | 17 Extended data 2 Confidence predictions. Same as Extended data 3, but for the Folke data. 18 | bioRχiv Brus et al. | Confidence in value-based choice


Brus et al. | Confidence in value-based choice bioRχiv | 19


| bioRχiv Brus et al. | Confidence in value-based choice


Brus et al. | Confidence in value-based choice bioRχiv | 21 Extended data 7 Relation between confidence and θ i and k i . Same as Extended data 6, but for the Folke data. 22 | bioRχiv Brus et al. | Confidence in value-based choice








ACKNOWLEDGEMENTS
We thank Hsin-Hung Li for helpful comments and suggestions on the manuscript. This work was supported by a European Research Council (ERC) starting grant (ENTRAINER) to R.P. This project has received funding from the European Research Council (ERC) under the European Union's Horizon 2020 research and innovation programme (grant agreement No. 758604).






Extended data 6
Positive relation between confidence and θ i and k i . With the joint modelling approach we inferred values of θ i and k i for all trials. For most subjects there exists a strong positive relation between θ i , k i and confidence. a) For each individual subject the confidence on each trial is plotted versus the estimated θ i . b) Same as a) but for the relation of confidence and the estimated k i . Based on the Brus data.
 










Bahador Bahrami, and Christopher Summerfield. Confidence matching in group decision-making




Dan
Bang






Laurence
Aitchison






Rani
Moran






Banafsheh
Santiago Herce Castanon






Ali
Rafiee






Mahmoodi






Y
F
Jennifer






Peter
E
Lau






Latham




10.1038/s41562-017-0117






Nature Human Behaviour




1


6














Computational and neurobiological foundations of leadership decisions




Rafael
Micah G Edelson






Polania






C
Christian






Ernst
Ruff






Todd A
Fehr






Hare




10.1126/science.aat0036






Science




6401


36














Overconfidence and excess entry: An experimental approach




Colin
Camerer






Dan
Lovallo




10.1257/aer.89.1.306






American Economic Review




89


1
















Explicit representation of confidence informs future value-based decisions




Tomas
Folke






Catrine
Jacobsen






Stephen
M
Fleming






Benedetto De
Martino




10.1038/s41562-016-0002






Nature Human Behaviour




1


2














Choice Certainty Is Informed by Both Evidence and Decision Time




Roozbeh
Kiani






Leah
Corthell






Michael
N
Shadlen




10.1016/j.neuron.2014.12.015






Neuron




84


6
















Multivoxel neurofeedback selectively modulates confidence without changing perceptual performance




Aurelio
Cortese






Kaoru
Amano






Ai
Koizumi






Mitsuo
Kawato






Hakwan
Lau




10.1038/ncomms13669






Nature Communications




7


1


13669














The idiosyncratic nature of confidence




Joaquin
Navajas






Chandni
Hindocha






Hebah
Foda






Mehdi
Keramati






Peter
E
Latham






Bahador
Bahrami




10.1038/s41562-017-0215-1






Nature Human Behaviour




1


11
















Variance misperception explains illusions of confidence in simple perceptual decisions




Ariel
Zylberberg






Pieter
R
Roelfsema






Mariano
Sigman




10.1016/j.concog.2014.05.012






Consciousness and Cognition




27


1
















Perceptual confidence neglects decision-incongruent evidence in the brain




A
K
Megan






Thomas
Peters






Yoshiaki
D
Thesen






Brian
Ko






Chad
Maniscalco






Matt
Carlson






Werner
Davidson






Ruben
Doyle






Orrin
Kuzniecky






Eric
Devinsky






Hakwan
Halgren






Lau




10.1038/s41562-017-0139






Nature Human Behaviour




1


7














Two-stage dynamic signal detection: a theory of choice, decision time, and confidence




J
Timothy






Jerome
R
Pleskac






Busemeyer








Psychological review




117


3


864














Confidence and certainty: Distinct probabilistic quantities for different goals




Alexandre
Pouget






Jan
Drugowitsch






Adam
Kepecs




15461726


















Florent
Meyniel






Mariano
Sigman






Zachary
F
Mainen




10974199


Confidence as Bayesian Probability: From Neural Origins to Behavior
















Neural correlates, computation and behavioural impact of decision confidence




Adam
Kepecs






Naoshige
Uchida






A
Hatim






Zachary
F
Zariwala






Mainen




10.1038/nature07200






Nature




455


7210
















Representation of confidence associated with a decision by neurons in the parietal cortex




Roozbeh
Kiani






Michael
N
Shadlen




10.1126/science.1169405






Science




324


5928
















The Relationship between Perceptual Decision Variables and Confidence in the Human Brain




Martin
N
Hebart






Yoren
Schriever






Tobias
H
Donner






John
Dylan
Haynes




10.1093/cercor/bhu181






Cerebral Cortex




26


1
















Signatures of a Statistical Computation in the Human Sense of Confidence




Joshua I
Sanders






Balázs
Hangya






Adam
Kepecs




10.1016/j.neuron.2016.03.025






Neuron




90


3
















Limitations of proposed signatures of Bayesian confidence




T
William






Wei
Ji
Adler






Ma




1530888X
















The weighing of evidence and the determinants of confidence




Dale
Griffin






Amos
Tversky








Cognitive psychology




24


3
















Simultaneous over-and underconfidence: The role of error in judgment processes




Ido
Erev






David
V
Thomas S Wallsten






Budescu








Psychological review




101


3


519














Decision Making and Sequential Sampling from Memory




N
Michael






Daphna
Shadlen






Shohamy




10.1016/j.neuron.2016.04.036






Neuron




90


5
















Efficient coding of subjective value




Rafael
Polanía






Michael
Woodford






Christian
C
Ruff




1097-6256. doi: 10.1038/ s41593-018-0292-0






Nature Neuroscience




22


1
















Efficient sampling and noisy decisions. eLife, 9




A
Joseph






Michael
Heng






Rafael
Woodford






Polania




10.7554/eLife.54962
















Visual fixations and the computation and comparison of value in simple choice




Krajbich






A
Armel






Rangel




10.1038/ nn.2635






Nat Neurosci




13


10










doi








Reward modulates attention independently of action value in posterior parietal cortex




Christopher
J
Peck






David
C
Jangraw






Mototaka
Suzuki






Richard
Efem






Jacqueline
Gottlieb




10.1523/JNEUROSCI.1929-09.2009






Journal of Neuroscience




29


36
















Value-driven attentional capture




Brian
A
Anderson






Patryk
A
Laurent






Steven
Yantis




10.1073/pnas.1104047108






Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






108














Automatic versus Choice-Dependent Value Representations in the Human Brain




Marcus
Grueschow






Rafael
Polania






Todd
A
Hare






Christian
C
Ruff




10.1016/j.neuron.2014.12.054






Neuron




85


4
















Confidence in value-based choice




Benedetto De Martino






M
Stephen






Neil
Fleming






Raymond J
Garrett






Dolan




10.1038/nn.3279






Nature neuroscience




16


1
















Neural oscillations and synchronization differentially support evidence accumulation in perceptual and valuebased decision-making




Rafael
Polanía






Ian
Krajbich






Marcus
Grueschow






Christian
C
Ruff




08966273. doi: 10.1016/ j.neuron.2014.03.014






Neuron




82


3
















The precision of value-based choices depends causally on fronto-parietal phase coupling




Rafael
Polanía






Marius
Moisa






Alexander
Opitz






Marcus
Grueschow






Christian
C
Ruff




10.1038/ncomms9090






Nature Communications




6


8090














Effective Connectivity between Hippocampus and Ventromedial Prefrontal Cortex Controls Preferential Choices from Memory




Sebastian
Gluth






Tobias
Sommer






Jörg
Rieskamp






Christian
Büchel




10.1016/j.neuron.2015.04.023






Neuron




86


4
















Value-based attention but not divisive normalization influences decisions with multiple alternatives




Sebastian
Gluth






Nadja
Kern






Maria
Kortmann






Cécile
L
Vitali




10.1038/s41562-020-0822-0






Nature Human Behaviour
















neuroscience to establish evidence of absence




Christian
Keysers






Valeria
Gazzola






Eric-Jan
Wagenmakers




1546-1726. doi: 10.1038/ s41593-020-0660-4






Nature Neuroscience




23


2020












Visual attention modulates the integration of goal-relevant evidence and not value. eLife, 9




Pradyumna
Sepulveda






Marius
Usher






Ned
Davies






Amy
A
Benson






Pietro
Ortoleva






Benedetto De
Martino




10.7554/elife.60705
















Dissociable mechanisms govern when and how strongly reward attributes affect decisions




U
Silvia






Anjali
Raja
Maier






Rafael
Beharelle






Christian
C
Polanía






Todd
A
Ruff






Hare




10.1038/s41562-020-0893-y






Nature Human Behaviour




4


9
















Gaze bias differences capture individual choice behaviour




W
Armin






Felix
Thomas






Ian
Molter






Krajbich






R
Hauke






Peter
N C
Heekeren






Mohr




10.1038/s41562-019-0584-8






Nature Human Behaviour




3


6
















A tutorial on joint models of neural and behavioral measures of cognition




James
J
Palestro






Giwon
Bahg






B
Per






Sederberg






Lin
Zhong






Mark
Lu






Brandon
M
Steyvers






Turner




10.1016/j.jmp.2018.03.003






Journal of Mathematical Psychology




84
















Improving out-of-sample predictions using response times and a model of the decision process




John
A
Clithero




10.1016/J.JEBO.2018.02.007






Journal of Economic Behavior Organization




148
















Estimating the dynamic role of attention via random utility




Stephanie
M
Smith






Ian
Krajbich






Ryan
Webb




10.1007/s40881-019-00062-4






Journal of the Economic Science Association




5


1
















Learning and inference in the brain




Karl
Friston




10.1016/j.neunet.2003.06.005






Neural Networks




16


9
















Humans incorporate attention-dependent uncertainty into perceptual decisions and confidence




Rachel
N
Denison






William
T
Adler






Marisa
Carrasco






Wei
Ji
Ma




10.1073/pnas.1717720115






Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






115














Noise characteristics and prior expectations in human visual speed perception




A
Alan






Stocker






P
Eero






Simoncelli




10.1038/nn1669






Nature neuroscience




9


4
















Confidence controls perceptual evidence accumulation




Tarryn
Balsdon






Valentin
Wyart






Pascal
Mamassian




10.1038/s41467-020-15561-w






Nature Communications




11


1
















You'd Better Think Twice: Post-Decision Perceptual Confidence




Raphael
Hilgenstock






Thomas
Weiss






Otto
W
Witte




10.1016/j.neuroimage.2014.05.049






NeuroImage




99
















Human noise blindness drives suboptimal cognitive inference




Rani
Santiago Herce Castañón






Jacqueline
Moran






Tobias
Ding






Dan
Egner






Christopher
Bang






Summerfield




20411723. doi: 10.1038/ s41467-019-09330-7






Nature Communications




10


1
















Fechner's law in metacognition: A quantitative model of visual working memory confidence




Ronald
Van Den






Aspen
H
Berg






Wei
Ji
Yoo






Ma




10.1037/rev0000060






Psychological Review




124


2
















Working memory capacity, confidence and scientific thinking




Fatheya
Al-Ahmadi






Fatima
Oraif




10.1080/02635140902853673






Research in Science Technological Education




27


2
















A common mechanism underlies changes of mind about decisions and confidence. eLife, 5(FEBRUARY2016)




Ronald
Van Den






Kavitha
Berg






Ariel
Anandalingam






Roozbeh
Zylberberg






Michael
N
Kiani






Daniel
M
Shadlen






Wolpert




10.7554/eLife.12192
















Do humans make good decisions?




Christopher
Summerfield






Konstantinos
Tsetsos




10.1016/j.tics.2014.11.005






Trends in Cognitive Sciences




19


1
















Action-Specific Disruption of Perceptual Confidence




M
Stephen






Brian
Fleming






Yoshiaki
Maniscalco






Namema
Ko






Tony
Amendi






Hakwan
Ro






Lau




10.1177/0956797614557697






Psychological Science




26


1
















Causal evidence for frontal cortex organization for perceptual decision making




Dobromir
Rahnev






Derek
Evan
Nee






Justin
Riddle






Alina
Sue
Larson






Mark D'
Esposito




10.1073/pnas.1522551113






Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






113














Theta-burst transcranial magnetic stimulation to the prefrontal cortex impairs metacognitive visual awareness




Elisabeth
Rounis






Brian
Maniscalco






John
C
Rothwell






Richard
E
Passingham






Hakwan
Lau




10.1080/17588921003632529






Cognitive Neuroscience




1


3
















Orbitofrontal cortex is required for optimal waiting based on decision confidence




Armin
Lak






Gil
M
Costa






Erin
Romberg






Alexei
A
Koulakov






Zachary
F
Mainen






Adam
Kepecs
















10.1016/j.neuron.2014.08.039






Neuron




84


1
















Paradoxical interaction between ocular activity, perception, and decision confidence at the threshold of vision




Aaron
Schurger






Min
Soo
Kim






Jonathan
D
Cohen




10.1371/journal.pone.0125278






PLoS ONE




10


5
















Psychiatric Symptom Dimensions Are Associated With Dissociable Shifts in Metacognition but Not Task Performance




Marion
Rouault






Tricia
Seow






Claire
M
Gillan






Stephen
M
Fleming




10.1016/j.biopsych.2017.12.017






Biological Psychiatry




84


6
















Neuroscience of apathy and anhedonia: a transdiagnostic approach




Masud
Husain






Jonathan
P
Roiser




10.1038/s41583-018-0029-9






Nature Reviews Neuroscience




1














Advanced Bayesian Multilevel Modeling with the R Package brms




Paul-Christian
Bürkner




10.32614/RJ-2018-017






The R Journal




10


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]