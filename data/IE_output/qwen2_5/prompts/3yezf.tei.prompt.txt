You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
From deciding how long to wait for a bus to deciding how long to stay on a diet, decisions about how long to persist for delayed rewards are pervasive. These decisions can be difficult when the timing of delayed rewards is uncertain. In such cases, people have to use their previous experiences to make predictions about how long delays will last, and then act accordingly. Research has shown that predictions and decisions about temporally uncertain events can be well calibrated to the true environmental statistics 
(Griffiths & Tenenbaum, 2011;
Griffiths & Tenenbaum, 2006;
McGuire & Kable, 2012
, 2013
. Little is known, however, about the learning mechanisms through which such calibration is accomplished. One possibility is that people use their experience to build a representation of the distribution of reward delays in an environment. Once they know what the reward timing distribution is, they could then infer and apply the optimal strategy. Another possibility is that even with knowledge of the reward timing distribution, people still need to learn the optimal waiting policy from direct experience. Here, in a series of experiments, we examined the extent to which providing individuals with information about reward timing statistics influenced their decisions about how long to persist for delayed rewards.
The majority of previous research on persistence for delayed rewards has assumed that, once a delayed reward is chosen, waiting until it arrives is the rational choice. For example, in the famous "marshmallow test" paradigm 
(Mischel et al., 1972;
Mischel & Ebbesen, 1970)
, the length of time that a child waits for an experimenter to return with two treats before giving up and eating just one treat is taken as an index of their self-control. How long someone should wait for a delayed reward when there is uncertainty about reward timing depends, however, on their expectations about the distribution of possible reward times 
(McGuire & Kable, 2013)
. In some scenarios, like waiting for a movie to end 
(Griffiths & Tenenbaum, 2006)
, people know that the distribution of wait times is approximately Gaussian, and the expected time remaining decreases as time elapses. In these cases, it makes sense to keep waiting. In other cases, like waiting for a bus to arrive late at night, wait time distributions are "heavy-tailed," such that the expected time remaining actually increases as time elapses, as you become more convinced that the bus will not arrive for a very long time 
(Rachlin, 2000)
. A heavy-tailed timing distribution can create a limited-persistence environment in which waiting beyond a certain point is counterproductive.
Previous findings indicate that people can adapt their persistence decisions to the temporal statistics of their environment. 
McGuire & Kable (2012
, 2015
 examined willingness to wait using a laboratory task in which participants waited for small rewards (~10¢) on each trial.
Participants did not know how long the delay would be on any given trial, and they had the option to quit waiting at any time during the delay, in order to move on to a new trial. When the actual distribution of reward delays was manipulated so that it was heavy-tailed, people learned to quit waiting sooner for those rewards (an effect that has subsequently been replicated: 
Fung et al., 2017;
Lang et al., 2021;
Lempert et al., 2018;
Massar & Chee, 2015)
. These findings suggest that people's waiting decisions respond to experience with the relevant reward timing distribution. The findings raise the question, however, of how people learn to make decisions that are well-calibrated to reward timing distributions.
The current studies tackled this question of learning, with a specific emphasis on persistence behavior in limited-persistence environments. Limited-persistence environments present an interesting case for a few reasons. First, many real-world situations that seem to challenge self-control have the feature that estimated remaining delays increase as time elapses 
(McGuire & Kable, 2013)
. For example, if someone has been on a diet for a while and has not 5 seen any change in their weight, they might reasonably infer that the diet will take too much time to work and is therefore no longer worth continuing. Second, unlike other reward timing environments (e.g., Gaussian or uniform) in which waiting through each delay is optimal, the advantageous solution in limited-persistence environments is more complex to express, because the individual has to learn when exactly to quit. Indeed, in previous studies that involved participants adjusting waiting times based on experience, many individuals showed a lasting tendency to wait too long for rewards in heavy-tailed environments 
(Lempert et al., 2018;
McGuire & Kable, 2012
, 2015
. Finally, limited-persistence environments are interesting because they have similarities to patch-foraging scenarios, in which animals must decide when to stop exploiting a current, depleting resource (e.g., a patch or tree) and explore other resources 
(Constantino & Daw, 2015;
Hutchinson et al., 2008;
McNamara, 1982)
. In both cases, in order to maximize reward rate, there is a point at which it is beneficial to stop waiting (or harvesting from the current resource) and move on. It could be that some of the same learning processes that support adaptive patch-leaving decisions also support learning how long to wait in heavy-tailed persistence scenarios.
A common finding in both foraging and heavy-tailed persistence settings is that people over-persist; they stay in patches or wait for rewards for longer than is optimal, given that they are trying to maximize reward over time. This tendency toward over-persistence does decrease as people gain more experience with a limited-persistence environment, suggesting that it might be driven at least partially by information-gathering. In other words, people might persist too long in an effort to learn the structure of the reward timing distribution, since quitting prevents them from observing when a delayed reward would have arrived. If an information-gathering motive is the main driver of over-persistence, then over-persistence might be reduced by providing alternative sources of information about the statistics of the environment.
We conducted a series of studies to test three possible strategies for equipping decision makers with a generalizable mental model of the probability distribution that governed reward arrival times. In Study 1, we provided counterfactual feedback to participants when they quit, by signaling the exact future time at which the reward would have occurred. Counterfactual feedback could eliminate the need for over-persisting in the service of information-gathering, while still requiring participants to accumulate statistical information through a trial-by-trial sequence of observations. In the next two studies, we provided individuals with information about the reward timing distribution before they started the decision-making task -either through a passive experiential learning block (Study 2a and Study 2b) or through explicit description (Study 3a and Study 3b). We expected that, if adaptive decisions were supported by a general-purpose cognitive model of the probabilistic environment, providing information would hasten the development of context-appropriate decision strategies and would result in a lower willingness to wait in limited-persistence environments in the informed groups.
Foreshadowing the results, we found little evidence that providing information about reward timing statistics substantially accelerated learning. The overall pattern of results did not strongly support the idea that adaptive calibration of persistence relies on inferring an optimal strategy from a general-purpose probabilistic model of the environment. Instead, learning how long to persist for delayed rewards before quitting may depend on direct experience with actions and outcomes in the decision-making context.


Methods Overview 7


Ethics Statement
The following studies were carried out in accordance with the Declaration of Helsinki.
The protocols for Studies 1, 2a, and 3a were approved by the University of Pennsylvania Institutional Review Board. The protocols for Studies 2b and 3b were approved by the Boston University Institutional Review Board. All participants provided informed consent. All data, task code, and analysis code are publicly available via GitHub at this link: https://github.com/cdlab/wtw-statistical-learning.


Willingness-to-wait task


Task overview
In each of the studies described in this paper, participants performed a willingness-towait task that has been used previously to study persistence 
(McGuire & Kable, 2012)
. This task was programmed using the Psychophysics Toolbox in MATLAB 
(Brainard, 1997;
Kleiner et al., 2007)
. Studies 1, 2a, and 3a were conducted in person, at the University of Pennsylvania.
Participants were tested individually or in non-interacting groups of up to three. Participants performed the task on laptop computers and made their responses using the keyboard. Studies 2b and 3b (follow-up, partial replication studies, described in detail below) were programmed in jsPsych (de Leeuw, 2015), hosted on Pavlovia, and administered through Amazon Mechanical Turk using CloudResearch (formerly TurkPrime; see 
Litman et al., 2017)
. We used the CloudResearch Approved List to ensure high data quality, targeted MTurk workers within the United States, and did not include any MTurk worker qualifications (e.g., approval rating, previous HITs completed). Participants in the online studies were also required to use computers with keyboards to view the task and make their responses. A demographics questionnaire was administered via Qualtrics.
At the beginning of the task, participants were encouraged to earn as much money as possible in a fixed amount of time (15 min for all studies, except for Study 2b, which had a 10 min decision block), since they would keep any money that they earned in the task as additional compensation for the study. On each trial of the task, participants saw a circular green token labeled "0¢" appear on the screen. After a variable delay, the token turned blue and was worth 10¢ (in the in-person studies) or 3¢ (in the online studies). Participants could sell the token at any time by pressing the spacebar. After pressing the spacebar, they were shown feedback (the word "SOLD" appeared over the token) for 500 ms. Then, after a 500 ms blank ITI, a new trial began (see 
Fig. 1
 for sample trial). The token's value was added to the participant's total earnings, which accumulated throughout the block. The earnings were displayed on the screen throughout the experiment, along with the time remaining in the block. A white progress bar marked the amount of time the current token had been on the screen, and the full length of the bar corresponded to 32 s. The bar grew continually from the left and reset when a new token appeared. The progress bar was included to discourage a strategy of counting time 
(McGuire & Kable, 2015)
 and to facilitate explicit visual cuing of delay intervals in certain experimental conditions (see below). Participants were informed that they could sell the token before it matured if they felt it was taking too long and they wanted to move on to a new token, but they would not earn any money from selling 0¢ tokens. 9
Fig. 1. Sample trial in task. On each trial, participants saw a circular green token worth 0¢. After a variable delay, it "matured" and was worth 10¢ (in the in-person studies) or 3¢ (in the online studies). Participants could either wait for the token to mature to sell it, or sell the token before it matured to advance to the next trial. Once they pressed the spacebar to sell the token, the word "SOLD" appeared over the token for 500 ms. Then, after a blank 500 ms inter-trial interval, a new 0¢ token appeared on the screen. Accumulated earnings and time remaining were shown on the bottom of the screen throughout the block. The progress bar (total length = 32 s) marked the amount of time the current token had been on the screen, and reset at the start of each trial.


Reward timing distributions
Participants were randomly assigned to either a high-persistence (HP) or limitedpersistence (LP) task condition in Studies 2a and 3a. All participants in Studies 1, 2b, and 3b were in the LP condition. The HP and LP conditions differed in the timing statistics of token maturation, and were designed so that either high or limited persistence was advantageous. In the high-persistence condition, delays were drawn from a discrete set of ten equally probable durations spaced uniformly from 2-20 s in 2 s steps ( 
Fig. 2a)
. Here, the reward-maximizing strategy was always to wait for the token to mature. In the limited-persistence condition, delays were drawn from a discrete set of ten equally probable durations spaced on a logarithmic scale as follows, in seconds: 
{0.26, 0.66, 1.26, 2.15, 3.49, 5.50, 8.52, 13.04, 19.82, 30}
. The values were selected so that each successive interval between potential reward times was 1.5 times the previous interval. In the LP environment, the optimal waiting policy was to quit if the token had not arrived within ~2.15 seconds (that is, if none of the four shortest delays had been drawn).
After 2.15 seconds had elapsed, the expected reward rate decreased. In both conditions, sampling of the ten possible waiting times was done pseudo-randomly, so that each delay was equally likely to be followed by every other delay (for example, a short delay was equally likely to be followed by either a short delay or a long delay).


Normative analysis
The optimal waiting policy was determined as follows. The "giving-up time" is defined as the time at which a decision maker will give up waiting on each trial if the reward has not yet arrived. The expected return for giving up at time t is calculated as follows. Let pt be the proportion of rewards delivered earlier than t. Let τt be the mean duration of these rewarded trials. One trial's expected return, in cents per second, is:
! = 10( ! ) τ ! ! + t (1 − ! ) + 1
The numerator is the trial's expected gain in cents, and the denominator is the trial's expected cost in seconds, given a 10¢ reward and 1-s ITI (includes 500 ms feedback and 500 ms blank ITI). The value of t that maximizes Rt is the optimal giving-up time. The optimal giving-up time in the HP condition was 20 s, while the optimal giving-up time in the LP condition was just past the 2.15 s mark, so we rounded to 2.16 s 
(Fig. 2b)
. Changing the reward magnitude from 10¢ to 3¢ (for the online studies) did not change the optimal giving-up time.


Statistical analyses overview
All analyses were conducted in R (R Core Team, 2022). To operationalize participants' willingness to wait, we constructed a Kaplan-Meier survival curve for each participant using all trials in the decision-making block. The Kaplan-Meier is a nonparametric estimator of the survival function 
(Kaplan & Meier, 1958)
. For each time t, it plots the participant's probability of waiting at least until t if the reward is not delivered earlier. The area under the survival curve (AUC) represents the average number of seconds an individual was willing to wait within the analyzed interval. The AUC was our primary dependent measure in all studies, and we examined the extent to which our experimental manipulations affected it. We also report, for each LP group in each study, using one-sample t-tests, whether the AUCs differed from the optimal waiting policy (i.e., 2.16 s). For the HP environments, since the AUC could only be less than or equal to the optimal waiting time, we report bootstrapped 95% CIs for the difference from the optimal waiting policy of 20 s, in lieu of test statistics.
We also assessed the change in persistence over time, by approximating a local estimate of willingness-to-wait (WTW), corresponding to every 1 s interval throughout the block. WTWs were calculated as follows. For quit trials, the WTW was equal to the trial duration. For rewarded trials, it equaled the previous trial's WTW, or the rewarded trial duration, whichever was greater. Mean WTWs are plotted as a function of time for each condition in each experiment for visualization purposes. In addition, we estimated the linear trend in willingness-to-wait ("WTW trend") for each participant, by regressing the number of elapsed seconds against the WTW at any given second. This secondary measure served as a proxy for the learning rate, with a more negative WTW trend corresponding to a faster learning curve in the LP conditions, and a more positive WTW trend corresponding to faster learning in HP conditions (since WTW should decrease over time in LP environments, and should increase over time in HP environments).
Note that there is a point beyond which WTW should no longer decrease in LP environments; waiting less than 2.16 seconds in those conditions is also suboptimal. However, few participants in any of our studies routinely waited less than 2.16 seconds (10 of 160 participants in Study 2b, 4 of 160 participants in Study 3b, and no participants in Studies 1, 2a, or 3a). Therefore, more negative WTW trends in the LP environment can generally be interpreted as corresponding to faster learning.
Sample sizes for the in-person studies were not based on a power analysis but were selected informally to match previous work that identified effects of reward-timing statistics on waiting behavior (e.g., 
McGuire & Kable, 2012)
. To determine the sample sizes for the partial online replications, Studies 2b and 3b, we conducted a simulation-based power analysis based on the largest effect observed in the in-person studies (the difference in AUC between the "LP standard" and "LP instructed" conditions in Study 3a; see below). Across 10,000 iterations, we resampled the participants with replacement using a range of sample sizes per group 
(i.e., 16, 32, 48, 64, 80)
, conducted an independent samples t-test, and recorded the proportions of p-values below 0.05. With a sample size of 80 participants per group, >99% of the results were significant, suggesting that we would have >99% power to find the effect on which our simulation was based. Planned sample sizes of n = 80 per group were pre-registered, together with exclusion criteria and analysis plans, both for Study 2b (https://osf.io/zyn7r) and Study 3b (https://osf.io/k76ha). time waited in each trial for the high-persistence (HP) and limited-persistence (LP) conditions. In the limited-persistence conditions, the probability of the token maturing if it has not already matured increases according to a heavy-tailed distribution, thus dictating an optimal giving-up time of 2.16 seconds (i.e., the participant should quit if none of the first 4 possible delays are realized). In the high-persistence conditions, the probability of the token maturing if it has not already matured increases linearly, thus dictating persistence through all possible waiting times (up to 20 s). Note that since there are only 10 possible token maturation times sampled uniformly in each condition, plots are presented as if the only possible giving-up times were directly after each token maturation time. In practice, participants could give up at any time during the trial.


Study 1: Fictive feedback about unrealized outcomes


Study 1 Procedure and Hypotheses
The purpose of the first study was to see if providing fictive feedback about when a token would have matured would reduce over-persistence in the limited-persistence (LP) environment.
In the standard version of the task, a participant can only observe the reward timing if they choose to wait for the token to mature. If they quit, they do not find out when the token would have matured, and therefore, they gather less information about the reward timing distribution on quit trials. Therefore, it is possible that, in the standard version, over-persistence is strategic; participants may be waiting too long on purpose in order to obtain observations of the possible reward times. Providing feedback about when a token would have matured on each trial (regardless of whether the participant waited for the token to mature) could obviate the need for strategic information-gathering and thereby reduce willingness to wait in LP environments.
Forty participants (mean age = 21.48; SD = 3.84; 16 M; 24 F) completed this study. Half (n = 20) completed 15 min of the standard willingness-to-wait task with the LP distribution ("LP standard" group). The other half completed the same task, with one critical change: each time the participant sold a token, a marking appeared temporarily on the progress bar, indicating the token's scheduled maturation time ("LP fictive information" group; 
Fig. 3a
). This counterfactual feedback was shown for 500 ms at the same time as the "SOLD" message. The feedback was shown whether the participant waited for the token to mature or quit before it matured, but it only provided new information on quit trials.
We had two hypotheses: Hypothesis 1.1. Counterfactual feedback will decrease willingness to wait, since prolonged persistence no longer serves as an information-seeking strategy. To test this hypothesis, we performed an independent samples t-test to compare AUC values between the two conditions.
While we report two-tailed p-values from this test, we also calculated a Bayes factor (BF10; van Doorn et al., 2021) in order to quantify the strength of evidence for the null hypothesis (i.e., that LP standard AUC = LP fictive information AUC) relative to the alternative hypothesis (i.e., that LP fictive information AUC < LP standard AUC).


Hypothesis 1.2. If participants learn the optimal policy faster with counterfactual feedback
(since each trial is informative), then the linear trend in local willingness-to-wait (WTW trend) will be steeper (more negative) for the LP fictive information condition compared to the LP standard condition. We tested this hypothesis by comparing WTW trend values between conditions using an independent samples t-test. We report the two-tailed p-value and BF10.


Study 1 results
Contrary to the first hypothesis, fictive information did not reduce persistence in limitedpersistence environments (t38 = 1.31; p = 0.198; Cohen's d = 0.42; BF10 = 0.15, indicative of moderate evidence for the null hypothesis; 
Fig. 3b
). In fact, AUC values were numerically greater when fictive information was given (mean AUC for LP standard = 9.02 s; 95% bootstrapped confidence intervals (henceforth, 95% CI): 
[6.86, 11.25
 There was also no evidence that participants decreased their quitting time more rapidly in the LP fictive information condition: the linear trends in local willingness-to-wait estimates were comparable between conditions (mean WTW trend for LP standard = -0.005; 95% CI: [-0.009, -0.002]; mean WTW trend for LP fictive information = -0.009; 95% CI: [-0.01, -0.005]; t38 = -1.32; p = 0.196; Cohen's d = 0.42; BF10 = 1.07, indicative of anecdotal evidence for the alternative hypothesis; 
Fig. 3c
).


Study 1 Discussion
In Study 1, we examined whether providing feedback about when a token would have matured, even when the participant quit earlier, would decrease willingness to wait. We found that this manipulation had no effect on behavior overall. Although the sample size was small, the result was not even in the expected direction, and the Bayes factor suggests that there was moderate evidence for the null hypothesis. These results suggest, first, that over-persistence is unlikely to be caused by participants adopting a strategy of waiting for the token to mature merely to obtain observations of the delay durations. The results also suggest that providing additional descriptive information about reward timing through feedback was not effective at accelerating learning.
However, this manipulation was minimal, and new information was provided to participants only on quit trials. Participants still had to learn about the reward timing distribution while they made decisions. It is possible that exposing participants to the reward timing distribution prior to their having to make any decisions would facilitate learning. In the next study, we examined whether providing feedback about reward timing statistics before participants had the opportunity to make active decisions would promote behavior that was closer to optimal.


Fig. 3. Study design and results. (A)
In the fictive information condition, a mark appeared on the progress bar at the same time that the "SOLD" feedback appeared, indicating to participants when the token would have matured on that trial had they waited for it to mature before selling it. The mark appeared even if they chose to wait for the reward on that trial, but it was most informative on quit trials. (B) Average Kaplan-Meier survival curves for the limited-persistence (LP) fictive information group (n = 20) and LP standard group (n = 20), showing, for each time point into the trial, the probability that the participant was still waiting for the token to mature at that time, conditional on the reward not yet having been delivered. The area under each subject's survival curve (AUC) was taken as a summary measure of their willingness to wait. There were no differences in AUC between conditions (t38 = 1.31; p = 0.198). (C) Mean estimated willingness-to-wait as a function of task progress. There were no differences in the linear trends in local willingness-to-wait between conditions (t38 = -1.32; p = 0.196). Error bars indicate SEM.


Studies 2a and 2b: Latent learning of environmental structure


Study 2a Procedure and Hypotheses
In this study, each participant performed two 15 min blocks of the willingness-to-wait task, but crucially, the participant was not allowed to quit waiting in the first of these blocks. The first block was a "passive" block in which participants were asked simply to press the spacebar as quickly as possible after the token matured on each trial (the reward expired if it was not collected within 1 s). The purpose of the passive block was to expose participants to the timing statistics of either the same distribution that they would later see ("congruent": HP followed by HP or LP followed by LP) or a different one ("incongruent": HP followed by LP or LP followed by HP; 
Fig. 4a
). Therefore, in this 2 x 2 design, eighty-two participants (mean age = 21.16; SD = Following the decision-making block of the willingness-to-wait task, participants were asked to explicitly report what giving-up time they thought was ideal. They were shown the same progress bar that they had seen throughout the task (with the length corresponding to 32 s) and were instructed as follows: "Please mark what you think is the ideal maximum waiting time.
That is, when should you give up on a token that has not yet matured?" The mark that participants made was then converted to a time in seconds, rounded to the nearest hundredth of a second.
We had the following hypotheses: Hypothesis 2a.1. If learning occurred in the passive blocks, we will see that an implicit measure of learning -response times (RTs) -reveals the participants' expectations about reward timing. In the HP passive blocks, RTs to sell a token after it matured were expected to decrease as the waiting times increased, since the probability of the token maturing if it has not already matured increases with waiting time. Faster RTs as a function of uniformly distributed pre-target intervals have been identified as a hallmark of temporal preparation in variable foreperiod paradigms 
(Nickerson, 1965
) and a similar pattern has been observed previously in the WTW task in an HP environment 
(McGuire & Kable, 2015)
. Predictions are less clear for RTs in the LP environment, but it is possible that RTs will increase as a function of waiting time.
Since short delay intervals occur more frequently in the LP condition than in the HP condition, they may be more strongly expected, yielding faster RTs for short delay intervals. In contrast, at longer intervals, rewards in the LP condition are sparser; this may result in slower RTs at longer intervals in that condition. To make the two conditions more comparable, we restricted our analyses to trials on which waiting times were less than or equal to 20 s. We also restricted analyses to trials in the second half of the passive block, to ensure sufficient exposure for learning. We conducted two mixed-effects linear regressions, one for the group of participants who experienced the HP passive block (i.e., the HP congruent and LP incongruent groups, n = 42), and one for the group of participants who experienced the LP passive block (LP congruent and HP incongruent groups, n = 40). The dependent variable was the RT on each trial after subtracting the median RT for each participant. The independent variable was the wait time that preceded the reward on each trial. We allowed slopes (for the wait time) and intercepts to vary by subject. Hypothesis 2a.2. Willingness to wait will be more in line with the optimal waiting policy in people who had seen the congruent timing distribution in the passive block compared to those who were exposed to the incongruent distribution. In other words, AUC should be lower in the LP congruent condition compared to the LP incongruent condition, and AUC should be higher in the HP congruent condition compared to the HP incongruent condition.
Hypothesis 2a.3. Consistent with previous research, people in the HP groups will wait longer for rewards on average compared to the LP groups. We conducted an ANOVA with distribution type (LP / HP) and the nature of the initial passive block (congruent / incongruent) as factors, and followed it with post-hoc independent samples t-tests, reporting two-tailed p-values and Bayes factors for the comparisons of interest.
Hypothesis 2a.4. WTW trend will be more negative in the LP congruent group compared to the LP incongruent group, and more positive in the HP congruent group compared to the HP incongruent group. To test this hypothesis, we conducted the same ANOVA and post-hoc t-tests as described above, this time with the WTW trend as the dependent variable.
Hypothesis 2a.5. Self-reported "ideal maximum waiting time" following the task will also be more in line with the optimal waiting policy in those who had experienced the congruent timing distributions compared to those who had trained on the incongruent distribution. We conducted another ANOVA with distribution type (LP / HP) and the nature of the initial passive block (congruent / incongruent) as factors, with the self-reported ideal maximum waiting time as the dependent variable. This ANOVA was also followed with post-hoc independent samples ttests.


Study 2a Results
We first examined response time data in the second half of the passive block for evidence of learning. Consistent with our hypotheses, response times decreased as a function of token maturation time in the HP condition (collapsed across HP congruent and LP incongruent groups, n = 42: b = -0.002; t = -3.04; 95% CI: [-0.003, -0.0007]; p = 0.004; 
Fig. 4b
). In contrast, response times increased with token maturation time in the LP condition (collapsed across HP incongruent and LP congruent groups, n = 40: b = 0.002; t = 4.43; 95% CI: [0.001, 0.003]; p < 0.001). This provides evidence that participants implicitly learned to update their expectations on the basis of the statistics of each timing distribution.
When examining the decision blocks, however, previous experience with the congruent timing distribution had no detectable impact on willingness to wait. While there was a significant main effect of distribution type on AUC, as expected (F(1,78) = 41.65; p < 0.001; ηp² = 0.35) with people in the HP condition waiting longer than those in the LP condition, there was no distribution type x congruency interaction (F(1,78) = 0.16; p = 0.695; ηp² = 0.002; 
Fig. 4c
). There was also no main effect of congruency (F(1,78) = 0.16; p = 0.688; ηp² = 0.002). Post-hoc t-tests for relevant comparisons confirmed that there was no difference in AUC between participants who completed the LP decision block after being exposed to the passive LP block (n = 20; mean AUC = 10.13 s; 95% CI: [8.23, 12.02]) and those who were exposed to the passive HP block (n = 22; mean AUC = 10.14 s; 95% CI: [7.99, 12.31]; t40 = 0.01; p = 0.991; Cohen's d = 0.003; BF10 = 0.31, moderate evidence for the null hypothesis). Similarly, participants who completed the decision block with the HP distribution were willing to wait about the same amount of time on There was also no effect of training block congruency on WTW linear trends. Although there was an (expected) main effect of distribution type (LP vs. HP) on WTW linear trends (F(1,78) = 4.95; p = 0.029; ηp² = 0.06), with people waiting increasingly longer in HP conditions and increasingly less time in the LP conditions, there was no main effect of congruency (F(1,78) = 0.23; p = 0.632; ηp² = 0.003) or distribution type x congruency interaction (F(1,78) = 1.26; p = 0.265; ηp² = 0.02; 
Fig. 4d
). Participants in the LP congruent condition (mean WTW trend = -0.002; 95% CI: [-0.004, 0.001]) did not show significantly faster learning than those in the LP incongruent condition (mean WTW trend = -0.001; 95% CI: [-0.003, 0.001]) t40 = 0.44; p = 0.667; Cohen's d = 0.13; BF10 = 0.43, anecdotal evidence for the null hypothesis). In addition, the HP congruent group (mean WTW trend = 0.002; 95% CI: [-0.0004, 0.005]) did not learn faster than the HP incongruent group (mean WTW trend = 0.0003; 95% CI: [-0.002, 0.002]; t38 = 1.16; p = 0.256; Cohen's d = 0.37; BF10 = 0.88, anecdotal evidence for the null hypothesis).
Thus, experience with the reward timing distributions -without the option of quitting -was insufficient to bias later behavior.
We found the same pattern of results when examining the self-reported ideal maximum waiting time as the dependent variable. There was a significant main effect of distribution type on this explicit report (F(1,78) = 12.22; p = 0.001; ηp² = 0.14), with people in the HP conditions reporting longer ideal maximum waiting times than those in the LP conditions, but there was no main effect of congruency (F(1,78) = 1.10; p = 0.298; ηp² = 0.01) or distribution type x congruency interaction (F(1,78) = 0.42; p = 0.517; ηp² = 0.005). On average, participants who completed the decision block with the LP distribution reported comparable ideal maximum waiting times whether they had initially done the passive LP block (n = 20; mean self-reported ideal waiting time = 10.74 s; 95% CI: 
[8.16, 13.32
  and HP incongruent (n = 20) groups showing, for each time point into the trial, the probability that the participant was still waiting for the token to mature at that time. Although there were significant differences in behavior between HP and LP conditions, there was no effect of the congruency of the passive block (LP congruent vs. LP incongruent: t40 = 0.44; p = 0.667; HP congruent vs. HP incongruent: t38 = 0.70; p = 0.488). (D) Mean running willingness-to-wait as a function of task progress. There was no effect of the congruency of the passive block on the WTW linear trend (LP congruent vs. LP incongruent: t40 = 0.44; p = 0.660; HP congruent vs. HP incongruent: t38 = 1.16; p = 0.256). Error bars indicate SEM.


Study 2b Procedure and Hypotheses
The results from Study 2a indicated that passive learning of timing distributions in an initial 15-min block did not accelerate the optimal calibration of persistence. Hypothesis 2a.1 was supported, suggesting that participants did show evidence of learning the reward timing statistics during the passive block. We also found evidence for Hypothesis 2a.3, since participants waited longer for rewards in the HP environments compared to the LP environments.
Hypotheses 2a.2, 2a.4, and 2a.5 were not supported, however; exposure to a passive block with the same reward timing statistics did not influence willingness to wait, learning rate, or selfreported optimal waiting times in the decision block.
However, one limitation of Study 2a is that participants may have assumed that the timing distribution would change from the first block to the second. It is possible that they "reset" their expectations for the decision block, and did not use the information that they learned in the passive learning block. We did not explicitly instruct participants that the decision block would have the same reward timing statistics as the passive block, since this would not have been true in the incongruent conditions. We did not want to provide false information to half the participants, because then learning might be slower in the incongruent conditions not because the timing distributions did not match, but because those participants would have to override the verbal instructions that they received.
To address this limitation, we conducted a partial replication (Study 2b) with one critical change. In Study 2b, we did not deceive participants, but we did add the following statement to the instructions directly preceding the decision block: "Your task in the second block will be similar to your task in the first block, and tokens will behave in a similar way to the first block."
Since we did not explain the extent to which (or the ways in which) the tokens would "behave in a similar way," we expected that participants would interpret this statement to mean that the reward timing distribution they learned in the first block was at least relevant to the reward timing distribution in the second block. The decision block was limited to 10 min (to reduce fatigue in participants, since we could not monitor them) and focused only on the limitedpersistence condition, since this was the main condition of interest. Note that the passive block was of the same duration in Study 2b as in Study 2a, so the learning experience is comparable.
One hundred sixty participants (mean age = 40.93; SD = 11.91; 89 M; 71 F) were randomly assigned to experience either LP or HP reward distributions in the passive block, followed by the LP distribution in the decision block (resulting in "LP congruent" and "LP incongruent" conditions). Twenty additional subjects were recruited but failed the pre-registered inclusion criteria (see: https://osf.io/zyn7r) such as not completing the entire task (15 min in passive exposure block and 10 min in decision block) or letting more than 20% of tokens expire (assessed per block). We also excluded participants who responded prematurely (by making a "sell" response before the token matured) on more than 20% of trials in the passive block.
Data for Study 2b were collected through Amazon Mechanical Turk using CloudResearch (formerly TurkPrime; 
Litman et al., 2017)
 between January 5th and February 5th 2023. Study 3b was expected to take 35 minutes and participants were paid $6 base pay and an additional performance-based bonus (3¢ per matured token that was sold). This study was pre-registered and we had the following hypotheses (see: https://osf.io/zyn7r): Hypothesis 2b.1. If learning occurred in the passive blocks, we will see that an implicit measure of learning -response times (RTs) -reveals the participants' expectations about reward timing. See Hypothesis 2a.1. above for more details. Hypothesis 2b.2. Willingness to wait will be more in line with the optimal waiting policy in people who had seen the congruent timing distribution in the passive block compared to those who were exposed to the incongruent distribution. This hypothesis would be confirmed if we find lower AUC values in the LP congruent condition than in the LP incongruent condition.


Study 2b Results
We examined the response time data in the second half of the passive block for evidence of learning. As expected, response times decreased as a function of scheduled maturation time in the LP incongruent condition (HP timing statistics in passive block: n = 80: b = -0.00; t = -11.77; 95% CI: [-0.004, -0.003]; p < 0.001; 
Fig. 5b
). Contrary to our expectation, response times for participants in the LP congruent condition also decreased as a function of token maturation (LP timing statistics in passive block, n = 80: b = -0.0006; t = -2.05; 95% CI: [-0.001, -0.00003]; p = 0.044). This suggests that participants updated their expectations on the basis of experience in the HP environment, but learning was less evident in the LP environment in this online study.
An independent samples t-test revealed that there was no difference in willingness-to-wait between the LP congruent and the LP incongruent group (t158 = -0.93; p = 0.354; Cohen's d = -0.15; BF10 = 0.09, strong evidence for the null hypothesis; 
Fig. 5c
). Participants who completed the LP decision block after being exposed to the passive LP block (mean AUC for LP congruent = 11.06 s; 95% CI: [9.84, 12.26]) did not wait less than those who were exposed to the passive HP block (mean AUC for LP incongruent = 10.20 s; 95% CI: 
[8.87, 11.54]
). Independent of passive exposure, participants in both groups persisted for longer than optimal (LP congruent: t79 = 14.21; p < 0.001; Cohen's d = 1.59; LP incongruent: t79 = 11.85; p < 0.001; Cohen's d = 1.32).
In an exploratory analysis, we also investigated whether there was an effect of passive exposure on the linear trend in willingness-to-wait. Participants in the LP congruent group (mean WTW trend = -0.0008; 95% CI: [-0.003, 0.001]) did not show significantly faster learning than those in the LP incongruent group (mean WTW trend = -0.001; 95% CI: [-0.004, 0.001]; t158 = -0.31; p = 0.755; Cohen's d = 0.05; BF10 = 0.14, moderate evidence for the null hypothesis, see 
Fig. 5d
). Thus, experiencing congruent timing statistics was not sufficient to accelerate learning in the decision block. 10-minute decision block with a limited persistence (LP) reward timing distribution, preceded by a "passive" block in which they saw tokens mature according to either the LP distribution (congruent) or an HP distribution (incongruent). In the passive block, participants were not permitted to quit before the token matured and merely pressed the spacebar to sell each token after it matured. (B) Average (per-subject median-subtracted) response time for each bin of waiting times in the second half of the passive block. When the reward timings in the passive block followed an HP distribution, people were faster to respond as wait times got longer; this was also the case in the LP condition. (C) Average Kaplan-Meier survival curves for the LP congruent (n = 80) and LP incongruent (n = 80) groups showing, for each time point in the trial, the probability that the participant was still waiting for the token to mature at that time. There was no effect of the congruency of the passive block (LP congruent vs. LP incongruent: t158 = -0.93; p = 0.354). (D) Mean running willingness-to-wait as a function of task progress. There was no effect of the congruency of the passive block on the WTW linear trend (t158 = -0.31; p = 0.755). Error bars indicate SEM.


Study 2a and 2b Discussion
In Study 2a, we found that providing participants with an initial 15-minute block in which they could learn reward timing distributions from feedback (without making any decisions) did not help them to express the optimal waiting policy. This null result was unlikely to be due to participants failing to attend to the first block. Participants responded to matured tokens within a fast, 1 s deadline, and response times suggested they were learning the distribution of token maturation times. Nevertheless, the passive block had no effect on behavior in either the HP or LP environments.
Study 2b found that results were similar for the LP environment when the task was performed online, in a bigger sample, and with an additional instruction that suggested to participants that they should apply what they learned in the passive block to their decisions in the active block. It is noteworthy that the response time data for the participants who were passively exposed to LP timing statistics differed between Study 2a and Study 2b. In Study 2a, RTs increased as token maturation times increased, whereas in Study 2b, the opposite was true. It is unlikely that this discrepancy is due to participants not paying sufficient attention in Study 2b, since the same response deadline was in effect and the RT data followed the expected pattern for the HP group (for which we had a stronger prediction). In general, it is harder to draw conclusions from RT data that are collected online, but it is a limitation that we did not fully replicate Study 2a's RT results in Study 2b.
Together, the results of Studies 1, 2a, and 2b suggest that providing feedback to participants about reward arrival times was not sufficient to speed up learning in environments that called for quitting earlier. Integrating trial-by-trial reward timing information, in the absence of active decisions about waiting versus quitting, did not appear to help participants infer the optimal waiting policy. In the next two studies -Studies 3a and 3b -we removed the need for participants to integrate information about reward timing across individual experiences; we simply instructed them about the possible reward times and their probabilities. To minimize demands on memory, full information about the reward timing distribution was made perceptually available to participants throughout the task.


Studies 3a and 3b: Descriptive information about probabilistic timing


Study 3a Procedure and Hypotheses
Sixty-four participants (mean age = 21.5; SD = 3.17; 22 M; 42 F) were randomly assigned into one of four groups: LP instructed, LP standard, HP instructed, and HP standard (n = 16 each). The LP standard and HP standard groups performed 15 min blocks of the LP and HP versions of the willingness-to-wait task respectively, as described above. In the "instructed" groups, throughout the task, marks on the progress bar indicated the equiprobable times at which the token could mature 
(Fig. 6a)
. The "instructed" groups were also given the following additional instructions before the task began, following the introduction of the progress bar: "The bar is crosshatched to mark the possible reward times. For each token, one of the marked times is selected at random, with equal probability, as the time when the token will mature." None of the participants were informed about the optimal strategy, but the participants in the instructed groups had full information about the reward timing distributions. The task was followed by the same explicit report task described in Study 2, in which participants marked their perceived ideal maximum waiting time on a progress bar. Our hypotheses were as follows:
Hypothesis 3a.1. Providing information about the reward timing distribution will promote more optimal decision-making. We expected that AUC values would be higher in the HP instructed group compared to the HP standard group, and AUC values would be lower in the LP instructed group compared to the LP standard group. Hypothesis 3a.2. We will see a main effect of distribution type, with people waiting longer in the HP groups compared to the LP groups. We conducted an ANOVA with distribution type (LP / HP) and task type (instructed / standard) as factors, and followed it with post-hoc independent samples t-tests, reporting two-tailed p-values and Bayes factors.
We also expected that this information would influence (a) WTW trends (Hypothesis 3a.3), and (b) explicit reports of the ideal maximum waiting time (Hypothesis 3a.4). We performed the same ANOVA described above with the WTW trends and explicit reports as dependent variables.


Study 3a Results
A 2 x 2 ANOVA with task type (instructed / standard) and distribution (HP / LP) revealed a main effect of distribution (F(1,60) = 29.06; p < 0.001; ηp² = 0.33), no main effect of task type (F(1,60) = 2.75; p = 0.102; ηp² = 0.04), and no task type x distribution interaction (F(1,60) = 2.54; p = 0.116; ηp² = 0.04; 
Fig. 6b-d)
. Follow-up t-tests indicated, however, that there was a marginal difference between the LP groups, with participants showing lower willingness to wait in the instructed group (n = 16; mean AUC = 8.17 s; 95% CI: [6.55, 9.80]) compared to the standard group (n = 16; mean AUC = 11.24 s; 95% CI: [9.03, 13.42]; t30 = 2.13; p = 0.042;
Cohen's d = 0.75; BF10 = 3.45, moderate evidence for the alternative hypothesis). There was no difference in willingness to wait between the two HP groups (HP standard mean AUC = 14.82 s; 95% CI: 
[13.10, 16.53]
; n = 16; HP instructed mean AUC = 14.75 s; 95% CI: 
[13.21, 16.29]
; n = 16; t30 = -0.05; p = 0.959; Cohen's d = -0.02; BF10 = 0.32, moderate evidence for the null hypothesis). These results suggest that while instruction about reward timing did not facilitate learning in high-persistence environments, it may have helped when the best policy was to wait less time. Although the differences in AUC between instructed and standard conditions were small, the punctuated, stair-step pattern in the survival curves in the instructed conditions 
(Fig.    6b
) suggest that participants did understand the descriptive information given; they considered as candidate giving-up times only the times directly following the possible token maturation times indicated on the progress bar. Whether participants were given descriptive information or not, those in the LP environments over-persisted on average (LP instructed compared to optimal: t15 = 7.04; p < 0.001; Cohen's d = 1.76; LP standard: t15 = 7.81; p < 0.001; Cohen's d = 1.95), and those in the HP conditions did not wait long enough before quitting on average (HP instructed: mean difference from 20 s = -5.25 s; 95% CI: 
[-6.79, -3
.71]; HP standard: mean difference from 20 s = -5.18 s; 95% CI: 
[-6.90, -3.47]
).
Next, we tested whether the rate of learning differed between groups by examining the effects of instruction and distribution type on the linear trend in willingness-to-wait. While there was a main effect of distribution type on WTW trend (F(1,60) = 28.98; p < 0.001; ηp² = 0.33), with the rate of persistence over time being more positive for the HP groups (as expected), there was no main effect of task type (F(1,60) = 0.04; p = 0. 843; ηp² < 0.001) or task type x distribution interaction (F(1,60) = 0.23; p = 0.632; ηp² = 0.004). The linear trends in local willingness-to-wait did not differ between the LP instructed (mean WTW trend = -0.008; 95% CI: [-0.01, -0.005]) and LP standard groups (mean WTW trend = -0.008; 95% CI: [-0.01, -0.006]; t30 = 0.18; p = 0.854; Cohen's d = 0.07; BF10 = 0.38, anecdotal evidence for the null hypothesis). The HP groups also did not differ from each other in this measure (HP instructed WTW trend = -0.0004; 95% CI: [-0.003, 0.002]; HP standard WTW trend = -0.001; 95% CI: [-0.004, 0.001]; t30 = 0.53; p = 0.603; Cohen's d = 0.19; BF10 = 0.50, anecdotal evidence for the null hypothesis). The lack of difference in the change in persistence over time between the instructed and standard groups suggests that, while participants did wait less time before quitting on average in the LP instructed conditions, this did not appear to be driven by faster learning. Rather, the difference in willingness to wait was apparent early on in the task block 
(Fig. 6d)
.
The LP instructed group was also not significantly more likely to explicitly report that waiting less time was better relative to the LP standard group. There was a main effect of distribution type on the explicit reports of ideal waiting policy (F(1,60) = 15.52; p < 0.001; ηp² = 0.21), but there was no distribution type x task type interaction (F(1,60) = 0.03; p = 0.875; ηp² < 0.001; the main effect of task type was also null, albeit trending toward significance: F(1,60) = 3.48; p = 0.067; ηp² = 0.05. The LP instructed group (mean self-reported ideal waiting time = 9.24 s; 95% CI: [7.00 11.50]) did not report significantly lower ideal waiting policies than the LP standard group (mean = 11.39 s; 95% CI: [8.91, 13.91]; t30 = 1.21; p = 0.236; Cohen's d = 0.43; BF10 = 0.996, anecdotal evidence for the null hypothesis) and the HP instructed group (mean = 14.01 s; 95% CI: 
[11.66, 16
.34]) did not report higher ideal waiting policies than the HP standard group (mean = 16.56 s; 95% CI: 
[14.13, 19
.01]; t30 = 1.43; p = 0.164; Cohen's d = 0.50; BF10 = 0.16, moderate evidence for the null hypothesis). and HP instructed (n = 16) groups showing, for each time point into the trial, the probability that the participant was still waiting for the token to mature at that time. There was a significant main effect of distribution type (HP / LP), with participants in the LP groups waiting less time before quitting compared to participants in the HP groups. There was a marginally significant difference in willingness to wait between the LP groups, with participants showing less willingness to wait in the instructed group compared to the standard group (t30 = 2.13; p = 0.042). There was no difference in willingness to wait between the two HP groups (t30 = 0.05; p = 0.959). Mean running willingness-to-wait as a function of task progress for HP groups (C) and LP groups (D).
There was no difference in the linear trend for local willingness-to-wait between the HP groups (t30 = -0.77; p = 0.445) or LP groups (t30 = 0.52; p = 0.605). Error bars indicate SEM.


Study 3b Procedure and Hypotheses
In Study 3a, we found that providing full information about the reward timing distribution did decrease willingness to wait slightly in the LP condition, but had no effect on waiting times in the HP condition. This result was not conclusive, however, given that the sample size was small (n = 16 in each group), and the initial ANOVA did not reveal a significant interaction effect. Therefore, we decided to run a partial replication study online (Study 3b) with a larger sample size, examining only the two LP conditions (LP instructed and LP standard). Here again we chose to focus only on the LP condition since (1) it was the primary environment of interest, and (2) it was the only one in which instruction had a marginal effect.
One hundred sixty participants (mean age = 39.28; SD = 11.00; 92 M; 68 F) were randomly assigned to one of the two conditions. Twelve additional subjects were recruited but failed the pre-registered inclusion criteria (https://osf.io/k76ha) such as not completing the entire task or responding too slowly on tokens that had matured and delivered rewards. More specifically, participants were excluded if their median response time exceeded 1.25 s. We additionally excluded participants who accumulated more than 180 s of off-task time during the 15 min-block (more than 20%). Off-task time was defined as time in excess of 1 s between the delivery of a reward and the participant's "sell" response to collect the reward (on any given trial).
Data for Study 3b were collected through Amazon Mechanical Turk using CloudResearch, between December 8th 2022 and January 5th 2023. Study 3b was expected to take 20 minutes and participants were paid $3 base pay and an additional performance-based bonus (3¢ per matured token that was sold). This study was pre-registered and we had the following hypotheses (see: https://osf.io/k76ha):
Hypothesis 3b.1. Providing information about the reward timing distribution will promote more optimal decision-making. Our hypothesis would be confirmed if AUC values would be lower in the LP instructed group compared to the LP standard group. Hypothesis 3b.2. We expected that providing information about the reward distribution would influence WTW trends. Our hypothesis would be confirmed if we find evidence for a more negative trend in the instructed than the standard LP condition.
Both hypotheses were investigated using independent samples t-tests, reporting two-tailed pvalues and Bayes factors.


Study 3b Results
An independent samples t-test revealed that there was no difference in willingness-to-wait between the LP standard and the LP instructed group (LP standard: n = 80; mean AUC = 10.50 s; 95% CI: 
[9.38, 11.63
], LP instructed: n = 80; mean AUC = 9.74 s; 95% CI: 
[8.46, 11.01]
, t158 = -0.87; p = 0.388; Cohen's d = 0.14; BF10 = 0.38, anecdotal evidence for the null hypothesis). This result suggests that explicit instruction about reward timing did not facilitate learning in limitedpersistence environments and thus did not replicate the inconclusive effect found in Study 3a.
Similar to Study 3a, we found a punctuated, stair-step pattern in the survival curves in the instructed condition ( 
Fig. 7b
), suggesting that participants did understand the provided descriptive information. However, this understanding did not lead to more optimal behavior as participants in both groups over-persisted on average (LP standard compared to optimal: t79 = 14.45; p < .001; Cohen's d = 1.62; LP instructed compared to optimal: t79 = 11.49; p < .001;
Cohen's d = 1.28).
We also tested whether there was an effect of instruction on the linear trend in willingnessto-wait. Participants in the LP instructed group (mean WTW trend = -0.004; 95% CI: 
[-0.005, -0
.002]) did not show significantly faster learning than those in the LP standard group (mean WTW trend = -0.003; 95% CI: [-0.005, -0.002]; t158 = 0.26; p = 0.799; Cohen's d = 0.040; BF10 = 0.210, moderate evidence for the null hypothesis). This suggests that the change in persistence over time also remained unaffected by explicit instructions 
(Fig. 7c)
. instructed (n = 80) groups showing, for each time point into the trial, the probability that the participant was still waiting for the token to mature at that time. There was no difference in willingness to wait between the two groups (t158 = -0.87; p = 0.388). Mean running willingnessto-wait as a function of task progress for LP groups (C). There was no difference in the linear trend for local willingness-to-wait between the groups (t158 = 0.26; p = 0.799). Error bars indicate SEM.


Studies 3a and 3b Discussion
Study 3b was a pre-registered, partial replication of Study 3a, comparing only the LP instructed and LP standard conditions. In this larger study, the small effect of instruction that was evident in Study 3a did not replicate, and the Bayes factor suggests that there was anecdotal evidence for the null hypothesis that instructing participants explicitly about the reward timing distribution does not impact their persistence. Instructions about reward timing also did not accelerate the learning process. It is unlikely that participants misunderstood the reward timing information that was given to them; in both Study 3a and Study 3b, there was a stair-step pattern in the average survival curves of the instructed conditions. This pattern suggests that participants knew that the best potential quitting times were the times directly following each of the progress bar markings. Nevertheless, this knowledge did not help them to infer that the optimal quitting time in the LP conditions was at ~2.16 seconds (directly after the fourth bar marking).


Discussion
Previous research has shown that people calibrate their willingness to wait for delayed rewards based on their experiences with delayed reward timing. For example, they wait less time when reward timing distributions are heavy-tailed, and more time when reward timing distributions are uniform. That pattern was replicated in the studies described here. Learning when to quit waiting for delayed rewards is a gradual, experience-dependent process, however.
Here we took an experimental approach to gain some insight into how this learning unfolds. We provided participants with general information about reward timing in three different waysthrough counterfactual feedback (Study 1), a passive exposure block (Studies 2a and 2b), and explicit instruction (Studies 3a and 3b) -to see whether that information would be generalized to inform behavioral decisions. If so, then providing general information might accelerate learning or even eliminate the need for incremental, experience-dependent learning altogether. The overall pattern of results suggests that general information about the reward timing distributions did not lead participants to infer and express the optimal strategy. Rather, direct experience with actions and outcomes appeared to be necessary for learning when to quit.
In Study 1, which examined behavior in limited-persistence environments only, providing counterfactual feedback about when rewards would have arrived -which reduces the need to persist for the sake of information-seeking -was not effective in reducing willingness to wait, whether examining a summary measure (AUC) or a measure of learning (WTW trend). In Study 2a, there was no effect of passive exposure to the congruent reward timing environment prior to the decision block, either on AUC or WTW trends. This null result cannot be explained by participants not paying attention to the reward timing in the passive block, since response time data suggested that participants were forming expectations in line with our predictions. A similar null result was found in Study 2b, in which we suggested to participants (without deceiving them) that the reward timing distribution would be similar between the passive block and the decision block. Finally, in Study 3a, in which participants in the "instructed" groups were shown exactly when to expect delayed rewards to arrive, participants in the LP condition did shift their behavior slightly toward the optimal policy, but those in the HP group did not. However, in a larger, pre-registered, replication study (Study 3b) the inconclusive LP condition result did not replicate. Therefore, we conclude that none of our informational manipulations had a robust effect on the expression of an optimal waiting policy during voluntary persistence.
These null behavioral findings were reflected in self-reports as well: after participants completed the task in Studies 2a and 3a, they were asked what they thought was the optimal maximal time someone should be willing to wait for the delayed reward. The resulting selfreports were too long relative to optimal in the limited-persistence conditions, and too short relative to optimal in the high-persistence conditions. These estimates were also unaffected by whether participants had been informed about the reward timing distributions before performing the task.
Our findings imply that excessive persistence toward delayed rewards in limitedpersistence environments cannot be explained solely as a strategy for gathering information about the reward timing distribution. Having access to other sources of timing information had very little influence on behavior, suggesting that expressing the optimal waiting strategy may require direct experience with the consequences of quitting and waiting. This result has implications for interventions directed at optimizing persistence behaviors. Whether the goal is to promote persistence or curtail it, the best strategy may be to let individuals directly experience the consequences of waiting and quitting. For example, if you want to promote persistence in your children (e.g., having them wait before they can play video games), the present results suggest it would be more effective to introduce a routine in which waiting is consistently rewarded than it would be to tell them how long they have to wait 
(Leonard et al., 2021)
. If, on the other hand, you want to promote quitting, such as in individuals with obsessive-compulsive disorder who persist in time-consuming rituals despite the opportunity costs, it could be more effective to have patients experience the consequences of quitting those rituals. In line with this idea that direct experience is key, one of the most effective therapies for obsessive-compulsive disorder involves exposing individuals to the consequences of quitting their rituals 
(Reid et al., 2021)
.
Even with significant direct experience with waiting for delayed rewards, however, we found that individuals did not converge on the optimal waiting policy, either in their behavior or self-reports. Why might this be? To infer a reward-maximizing strategy based on a reward timing distribution, individuals must know what the relevant variables are. One relevant variable that people might discount is opportunity cost. Waiting only a limited amount of time for a delayed reward in a limited-persistence environment is optimal because the time spent waiting for a late-maturing reward is time that could be better spent collecting rewards that arrive faster. There is a well-known tendency for people to neglect opportunity costs when making decisions, most likely because such costs are not explicitly presented in the problem frame 
(Frederick et al., 2009;
Spiller, 2019)
. Moreover, the relevance and salience of opportunity costs varies widely from one real-world situation to the next 
(Fawcett et al., 2012)
, so people may not always account for them in a manner that is contextually appropriate. In contrast to opportunity cost, an irrelevant variable that people might overweigh (leading to over-persistence) is sunk cost. People may value rewards that they waited for longer just because they have already invested time waiting for them 
(Arkes & Blumer, 1985;
Kazinka et al., 2021;
Magalhães & Geoffrey White, 2016;
Sweis et al., 2018)
. Sunk costs cannot fully explain over-persistence in the present experiments, however, since people did learn to quit earlier in LP environments as the task progressed, and it is unlikely that perceived sunk costs would lessen over time. Future research that emphasizes either sunk costs or opportunity costs in this type of paradigm will shed some light on the extent to which these factors influence persistence decisions. Other factors that have been identified as potentially underpinning over-persistence in foraging scenarios, such as risk aversion 
(Constantino & Daw, 2015)
, behavioral variability 
(Cash-Padgett & Hayden, 2020)
, and a distorted perception of background reward rates due to negative affect 
(Lenow et al., 2017)
, may also play a role in persistence decisions.
Of the experimental manipulations described here, the one that had an impact on behavior was the explicit instruction manipulation in Studies 3a and 3b. However, contrary to our expectations, the effect was not an overall reduction in waiting times in the LP condition and an increase in waiting times in the HP condition. Instead, we found that in the instructed conditions, people's quitting times tended to cluster in the time periods that directly followed each of the possible waiting times 
(Fig. 6b
). This punctuated pattern suggests that participants believed that the reward timing demarcations were valid, and they applied a strategy of quitting at only specific intervals, and not in between them. Therefore, despite knowing and using information about the possible reward times, participants were unable to make the inference that they should wait very little time in the LP environments and wait for the full length of time in the HP environments.
Studies 3a and 3b -in which verbal and graphical instruction was provided about reward timing -add to the literature on the relationship between instruction-based learning and direct experience-based learning. Valid verbal instructions about task structure (e.g., reward probabilities) have been found to accelerate experiential learning 
(Atlas et al., 2016;
Li et al., 2011)
. Instructions can also impair feedback-based learning, however, since they induce a "confirmation bias" that biases the processing of outcomes 
(Delgado et al., 2005;
Doll et al., 2009
Doll et al., , 2011
, such that people discount outcomes that are incompatible with their prior beliefs.
Our design more closely resembles those studies that provided valid information about task structure, but we did not observe an acceleration in learning. This discrepancy further supports our overall conclusion that information about reward timing statistics does not facilitate optimal persistence behavior. In other contexts, people adjust their behavior once they know the task parameters, even if they are not explicitly instructed what that behavior should be; in the case of calibrating persistence, knowledge about task parameters appeared unable to substitute for direct experience.
A few limitations of our research are worthy of mention. First, the sample sizes in Studies 1, 2a, and 3a were small, thus increasing the risk of Type II error. The Bayes factors we report, however, suggest anecdotal-to-moderate evidence for the null hypotheses. In Study 1, the difference between conditions was not only not significant, but actually opposite of what we expected. Therefore, we think it is unlikely that we would have seen a reduction in willingness to wait with counterfactual feedback had the sample been larger. For Studies 2a and 3a, however, the data were less conclusive, so we conducted pre-registered partial replication studies in larger samples (Studies 2b and 3b). Study 2b confirmed that the effect of the passive exposure block was null or very small. It is a limitation that we could not explicitly instruct participants that the reward timing distribution of the decision-making block would have the same properties as the distribution in the passive exposure block (since we wanted to avoid deception). However, in Study 2b, we did emphasize connections between the two blocks, and it had no impact on the results. It remains to be seen whether passive exposure would be effective at accelerating learning if participants were explicitly instructed that the timing distribution would definitely remain stable throughout the experiment. In Study 3b, we failed to replicate the marginal finding that providing descriptive information about LP environment statistics reduced willingness to wait. Given that Study 3b was the larger study, and given that we found no effects of instruction on behavior in the HP environment in Study 3a, we are inclined to conclude that having information about reward timing has a null, or very small, influence on learning the optimal waiting policy.
In sum, the current studies have shown that, when deciding how long to persist for delayed rewards of uncertain timing, a general mental representation of the reward timing distribution was not sufficient to promote optimal quitting behavior. Although people adapted their waiting times in response to the reward timing distribution -waiting less time in limitedpersistence environments than in high-persistence environments -they still over-persisted in limited-persistence environments, behavior that could not be explained by information gathering about reward timing statistics.
Fig. 2 .
2
Cumulative probability distribution (A) and expected rate of return (B) as a function of


]; mean AUC for LP fictive information = 11.66 s; 95% CI: [8.50, 14.81]). Participants in both groups over-persisted relative to the optimal waiting policy (i.e., relative to quitting after 2.16 s if the reward had not arrived: LP standard: t19 = 5.97; p < 0.001; Cohen's d = 1.33; LP fictive information: t19 = 5.77; p < 0.001; Cohen's d = 1.29).


3.44; 36 M; 46 F) were randomly assigned to one of four groups: LP Congruent (n = 20), LP Incongruent (n = 22), HP Congruent (n = 20), and HP Incongruent (n = 20), manipulating the distribution type in the second, decision-making block (LP / HP) and the nature of the preceding passive block (congruent / incongruent).


average whether they had initially done the passive HP block (n = 20; mean AUC = 15.67 s; 95% CI: [14.32, 17.02]) or the passive LP block (n = 20; mean AUC = 16.41 s; 95% CI:[15.06,    17.76]; t38 = -0.74; p = 0.461; Cohen's d = -0.24; BF10 = 0.20, moderate evidence for the null hypothesis). Moreover, participants in both LP groups persisted for longer than optimal (LP congruent: t19 = 8.02; p < 0.001; Cohen's d = 1.79; LP incongruent: t21 = 7.07; p < 0.001;Cohen's d = 1.51), and participants in both HP groups did not persist long enough relative to optimal (HP congruent: mean difference from 20 s = -4.33 s; 95% CI:[-5.68, -2.98]; HP incongruent: mean difference from 20 s = -3.59 s; 95% CI:[-4.94, -2.24]).


]) or the passive HP block(n = 22; mean = 11.34 s; 95% CI:    [8.35, 14.36]; t40 = 0.29; p = 0.772; Cohen's d = 0.09; BF10 = 0.38, anecdotal evidence for the null hypothesis). Similarly, the HP congruent (n = 20) and HP incongruent (n = 20) groups showed no difference in explicit self-reports of ideal maximum waiting times (HP congruent mean = 14.91 s; 95% CI:[12.18, 17.69]; HP incongruent mean = 17.41 s; 95% CI:[14.64,    20.22]; t38 = -1.22; p = 0.227; Cohen's d = -0.39; BF10 = 0.16, moderate evidence for the null hypothesis). Therefore, the explicit self-report data corroborated the behavioral data.


Fig. 4 .
4
Study 2a design and results. (A) In this 2 x 2 between-subjects design, participants did a decision block with a high persistence (HP) reward timing distribution or a limited persistence (LP) reward timing distribution, either after having seen tokens mature according to the same distribution in a previous "passive" block (congruent) or a different one (incongruent). In the passive block, participants were not permitted to quit before the token matured and just pressed the spacebar to sell the token after it matured. (B) Average (per-subject median-subtracted) response time for each bin of waiting times in the second half of the passive block. When the reward timings in the passive block followed an HP distribution, people were faster to respond as wait times got longer; the opposite was true in the LP condition. (C) Average Kaplan-Meier survival curves for the LP congruent (n = 20), LP incongruent (n = 22), HP congruent (n = 20)


Fig. 5 .
5
Study 2b design and results. (A) In this partial replication of Study 2a, participants did a


Fig. 6 .
6
Study 3a design and results. (A) In this 2 x 2 between-subjects design, participants either did a standard version of a high-persistence task (HP standard) or limited persistence task (LP standard), or a version in which markings on the progress bar indicated the equiprobable times at which the token could mature (HP instructed and LP instructed groups). (B) AverageKaplan-    Meier survival curves for the LP standard (n = 16), LP instructed (n = 16), HP standard (n = 16)


Fig. 7 .
7
Study 3b design and results. (A) In this partial replication of Study 3a, participants either did a standard version of the limited persistence task (LP standard), or a version in which markings on the progress bar indicated the equiprobable times at which the token could mature (LP instructed). (B) Average Kaplan-Meier survival curves for the LP standard (n = 80) and LP








Acknowledgements
This work was supported by the National Institutes of Health (grant numbers F32-DA030870, R21-MH124095, and R01-DA029149). 












The psychology of sunk cost




H
R
Arkes






C
Blumer




10.1016/0749-5978(85)90049-4








Organizational Behavior and Human Decision Processes




35


1
















Instructed knowledge shapes feedback-driven aversive learning in striatum and orbitofrontal cortex, but not the amygdala




L
Y
Atlas






B
B
Doll






J
Li






N
D
Daw






E
A
Phelps




10.7554/eLife.15192


















The Psychophysics Toolbox




D
H
Brainard




10.1163/156856897X00357








Spatial Vision




10


4
















Behavioural variability contributes to over-staying in patchy foraging




T
Cash-Padgett






B
Hayden




10.1098/rsbl.2019.0915








Biology Letters




3


16














Learning the opportunity cost of time in a patchforaging task




S
M
Constantino






N
D
Daw








Cognitive, Affective & Behavioral Neuroscience




15


4


















10.3758/s13415-015-0350-y














jsPsych: a JavaScript library for creating behavioral experiments in a Web browser




J
R
De Leeuw




10.3758/S13428-014-0458-Y








Behavior Research Methods




47


1
















Perceptions of moral character modulate the neural systems of reward during the trust game




M
R
Delgado






R
H
Frank






E
A
Phelps




10.1038/NN1575








Nature Neuroscience




8


11
















Dopaminergic genes predict individual differences in susceptibility to confirmation bias




B
B
Doll






K
E
Hutchison






M
J
Frank




10.1523/JNEUROSCI.6486-10.2011








Journal of Neuroscience




16
















Instructional control of reinforcement learning: A behavioral and neurocomputational investigation




B
B
Doll






W
J
Jacobs






A
G
Sanfey






M
J
Frank




10.1016/j.brainres.2009.07.007








Brain Research




1299
















When is it adaptive to be patient? A general framework for evaluating delayed rewards




T
W
Fawcett






J
M
Mcnamara






A
I
Houston




10.1016/j.beproc.2011.08.015








Behavioural Processes




89


2
















Opportunity Cost Neglect




S
Frederick






N
Novemsky






J
Wang






R
Dhar






S
Nowlis




10.1086/599764








Journal of Consumer Research




36


4
















High monetary reward rates and caloric rewards decrease temporal persistence




B
J
Fung






S
Bode






C
Murawski




10.1098/rspb.2016.2759








Proceedings. Biological Sciences




284














Predicting the future as Bayesian inference: People combine prior knowledge with observations when estimating duration and extent




T
L
Griffiths






J
B
Tenenbaum




10.1037/a0024899








Journal of Experimental Psychology: General




140


4
















Optimal Predictions in Everyday Cognition




T
Griffiths






J
Tenenbaum




10.1111/J.1467-9280.2006.01780.X








Psychological Science




17


9
















Patch leaving in humans: can a generalist adapt its rules to dispersal of items across patches?




J
M C
Hutchinson






A
Wilke






P
M
Todd




10.1016/j.anbehav.2007.09.006








Animal Behaviour




75


4
















Nonparametric Estimation from Incomplete Observations




E
L
Kaplan






P
Meier








Journal of the American Statistical Association




53


282


















10.1080/01621459.1958.10501452














Sensitivity to Sunk Costs Depends on Attention to the Delay




R
Kazinka






A
W
Macdonald






A
D
Redish




10.3389/FPSYG.2021.604843








Frontiers in Psychology




12


















M
Kleiner






D
H
Brainard






D
G
Pelli






A
Ingling






R
Murray






C
Broussard


















What's New in Psychtoolbox-3. Perception




36


1












Learned temporal statistics guide information seeking and shape memory




E
A
Lang






C
Van Geen






E
Tedeschi






C
B
Marvin






D
Shohamy




10.1037/XGE0001122








Journal of Experimental Psychology: General
















The effects of acute stress on the calibration of persistence




K
M
Lempert






J
T
Mcguire






D
B
Hazeltine






E
A
Phelps






J
W
Kable




10.1016/j.ynstr.2017.11.001








Neurobiology of Stress




8














Chronic and acute stress promote overexploitation in serial decision-making




J
K
Lenow






S
M
Constantino






N
D
Daw






E
A
Phelps










Journal of Neuroscience




37


23
















Leveraging cognitive science to foster children's persistence




J
A
Leonard






A
L
Duckworth






L
E
Schulz






A
P
Mackey








Trends in Cognitive Sciences




25


8


















10.1016/J.TICS.2021.05.005














How instructed knowledge modulates the neural systems of reward learning




J
Li






M
R
Delgado






E
A
Phelps




10.1073/pnas.1014938108








Proceedings of the National Academy of Sciences of the United States of America


the National Academy of Sciences of the United States of America






108














TurkPrime.com: A versatile crowdsourcing data acquisition platform for the behavioral sciences




L
Litman






J
Robinson






T
Abberbock




10.3758/S13428-016-0727-Z








Behavior Research Methods




49


2
















The sunk cost effect across species: A review of persistence in a course of action due to prior investment




P
Magalhães






K
White




10.1002/jeab.202








Journal of the Experimental Analysis of Behavior




105


3
















Preserved calibration of persistence based on delaytiming distribution during sleep deprivation




S
A A
Massar






M
W L
Chee




10.1111/jsr.12325








Journal of Sleep Research




24


6
















Decision makers calibrate behavioral persistence on the basis of time-interval experience




J
T
Mcguire






J
W
Kable








Cognition




124


2


















10.1016/j.cognition.2012.03.008














Rational temporal predictions can underlie apparent failures to delay gratification




J
T
Mcguire






J
W
Kable








Psychological Review




120


2


















10.1037/a0031910














Medial prefrontal cortical activity reflects dynamic reevaluation during voluntary persistence




J
T
Mcguire






J
W
Kable








Nature Neuroscience




18


5


















10.1038/NN.3994














Optimal patch use in a stochastic environment




J
Mcnamara




10.1016/0040-5809(82)90018-1








Theoretical Population Biology
















Attention in delay of gratification




W
Mischel






E
B
Ebbesen




10.1037/h0029815








Journal of Personality and Social Psychology




16


2
















Cognitive and attentional mechanisms in delay of gratification




W
Mischel






E
B
Ebbesen






A
R
Zeiss








Journal of Personality and Social Psychology




21


2
















Response time to the second of two successive signals as a function of absolute and relative duration of intersignal interval




R
S
Nickerson




10.2466/pms.1965.21.1.3








Perceptual and Motor Skills




21


1
















R: A language and environment for statistical computing. R Foundation for Statistical Computing




R Core Team










Vienna, Austria












The Science of Self-Control




H
Rachlin








Harvard University Press












Cognitive behavioural therapy with exposure and response prevention in the treatment of obsessive-compulsive disorder: A systematic review and meta-analysis of randomised controlled trials




J
E
Reid






K
R
Laws






L
Drummond






M
Vismara






B
Grancini






D
Mpavaenda






N
A
Fineberg




10.1016/j.comppsych.2021.152223








Comprehensive Psychiatry




106


152223














Opportunity cost neglect and consideration in the domain of time




S
A
Spiller




10.1016/j.copsyc.2018.10.001








Current Opinion in Psychology




26
















Sensitivity to "sunk costs" in mice, rats, and humans




B
M
Sweis






S
V
Abram






B
J
Schmidt






K
D
Seeland






A
W
Macdonald






M
J
Thomas






A
D
Redish




10.1126/science.aar8644








Science




361


6398


















J
Van Doorn






D
Van Den Bergh






U
Böhm






F
Dablander






K
Derks






T
Draws






A
Etz






N
J
Evans






Q
F
Gronau






J
M
Haaf






M
Hinne






Š
Kucharský






A
Ly






M
Marsman






D
Matzke






A
R K N
Gupta






A
Sarafoglou






A
Stefan






J
G
Voelkel






E
J
Wagenmakers




The JASP guidelines for conducting and reporting a Bayesian analysis


















10.3758/S13423-020-01798-5/FIGURES/7








Psychonomic Bulletin and Review




28


3















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]