You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



Introduction
The past twenty years have seen a great deal of interest in understanding how our brains implement economic choices 
(Glimcher and Fehr, 2013;
Rushworth et al., 2011;
Rangel et al., 2008;
Padoa-Schioppa, 2011;
Loewenstein et al., 2008;
Camerer et al., 2005)
. Much research in this field of neuroeconomics rests on the assumption that choices between options rely on an explicit valuation process 
(Kable and Glimcher, 2009;
Montague and Berns, 2002;
Padoa-Schioppa, 2011;
O'Doherty, 2014;
Levy and Glimcher, 2012)
. That is, that the brain first assigns value to each option and then compares those values to determine choice. The concept of valuation -which stems from economic theory -is so ingrained that it may seem inevitable. How else would one literally compare apples to oranges? Indeed, the idea that value exists on a single cardinal scale, also called a "common currency," has been extended to encompass not only goods, but also effort costs and time delays; everything an agent needs to bundle into evaluation of a mode of action that is aimed at procuring a specific outcome.
In parallel, the computational framework of reinforcement learning, which has been a cornerstone of neuroeconomics, also makes a scalar value signal central to its implementation 
(Sutton & Barto, 2018;
Niv, 2009)
. Specifically, in reinforcement learning, the value of an option-a state or an action-is the expected sum of future rewards contingent upon that choice. As a sum of future rewards that may be of different types (and include costs as negative rewards), reinforcement-learning value is naturally calculated in some unitless common currency.
However, not all reinforcement learning algorithms rely on or even calculate values 
(Sutton & Barto, 2018)
, and reinforcement-learning values, as sums of future rewards, are not synonymous with economic values of specific goods. Likewise, many empirically-supported process models of choice get by with no valuation 
(Vlaev et al., 2011;
Miller et al., 2019;
Gigerenzer and Gaissmaier, 2011)
. The fact that the brain can compute values to compare apples and oranges does not mean that it routinely does so, or that valuation is the primary process underlying choice. In this opinion paper, we argue that in many choice scenarios the brain may not be computing values at all, despite appearing to do so. We will demonstrate that the rationale for a value signal is weak, as are both behavioral and neural evidence supporting value computation. Finally, we propose an alternative -direct learning of action policies -and suggest there is scant direct evidence for value learning that cannot be explained by this and other alternative theories. Our hypothesis is important as it suggests a different interpretation of previous data and requires that studies attempting to resolve mechanisms of value computation in the brain first establish that in the specific situation studied, valuation is indeed occurring. In particular, much work has associated the orbitofrontal cortex in representing the expected economic value of different goods or options 
(Bartra et al., 2013;
Levy & Glimcher, 2012
) -a role that must be critically reconsidered if we agree that the brain may not necessarily be representing such values in many of the experiments so far used to test this hypothesis.


Why argue against value?
Intuitively, our thesis is that while we may know that we prefer an orange to an apple (for one thing, oranges don't brown when exposed to oxygen), we may make this judgment without consulting an internal scalar (cardinal) or even a universal ordinal value signal. Consequently, we may be hard-pressed to express the precise value that we put on an orange. This is not merely an issue of conscious access to our internal value of oranges (and we note here that, in neuroeconomics, value-based choices are generally thought to be part of explicit, aware, goaldirected or model-based decision making that relies on frontal cortex areas, in particular, the orbitofrontal cortex), but may be due to the fact that deciding on preferences can rely on many alternative mechanisms that don't require or rely on calculation of such a value.
Valuation is hard 
(Payne et al., 1992)
. It is also often unnecessary: when choosing between, say, an orange and a car, it is immediately clear that one is better than the other without calculating the precise value of either. If you are extremely thirsty, you might choose the orange, whereas if you need to go somewhere a car is the only relevant option. Arguably, many real-life choices are between options that are sufficiently different in the needs that they fulfill as to be more similar to this extreme example than they are to the choice between apples and oranges 
(Juechems & Summerfield, 2019)
. Valuation may only be necessary when choosing between two very similarly valued items. However, if the items are sufficiently similar in how they satisfy our needs, the brain may decide to choose randomly, according to some value-free heuristic, or according to past choices -and move on 
(Chater, 2018)
. Alternatively, the brain can try to calculate the exact values of the options to the necessary precision that arbitrates between them. Indeed, choosing between similar options often takes longer than choosing between very different options, even when making rather trivial choices that do not warrant the time and effort invested 
(Pirrone et al., 2018;
Teodorescu et al., 2016)
. An example is the inordinate amount of time some of us may spend deciding what brand of tuna fish to buy, despite the fact that our time (as per our salary) is worth much more than the money we will save by correctly evaluating which brand provides the best "value for money". This scenario also illustrates how inept we are at comparing the value of different kinds -here, time and money -which should have been straightforward if the modus operandi of the brain was to evaluate everything in terms of some common currency (see below).
So perhaps the brain can, when needed, calculate values. However, we argue that this is not the main means by which the brain makes decisions, and perhaps not the natural mode of decision making.


What is value?
Before moving on, we would like to delineate precisely how we are defining value for the sake of our argument. The term "value" has multiple uses (the problems this multiplicity raises are carefully laid out by O'Doherty, 2014). We consider "value" a hypothesized scalar parameter that reflects the worth of a specific item or outcome 1 . Because it is scalar, it is necessarily abstract. It can refer to any good, and makes use of a common currency code that is comparable across goods of different types (e.g., food, water, recreation time). Value, by this definition, is cardinal, not ordinal, meaning it can be defined for an option per se, rather than solely relative to other options. That is, it reifies the idea of "utils" -quantifiable units of value, often used in a jocular manner in Economics classes.
The idea of a common currency is key as it implies that all relative calculations have already happened -the "value" is in some denomination that objectively defines it as compared to other such values. One might argue that this is too narrow a definition, but we believe this is what neuroeconomists have in mind when talking about representation of common currency values in the brain. For example, we know of no neuroeconomic model that imagines a neural implementation of an ordinal value scale. This having been said, even an ordinal scale should not change based on the comparison set, and should satisfy transitivity -which many of the neural signals attributed to value do not, as we detail below.
Our definition of value, for the purpose of this paper, is different from other types of value that are discussed in reinforcement learning. Specifically, here we are discussing value as the reward worth of a single item/event, not the expected sum of all future rewards (R in reinforcement learning models, not V). One might argue that in order to compute such an expected sum V, the subjective worth of all individual rewards must be translated to a common currency that can be added. In this sense, reinforcement learning models do presuppose a common currency reward value. However, they don't necessarily commit to economic properties of such values, such as transitivity and consistency (see also Juechems & Summerfield, 2019), and we discuss below a class of reinforcement learning algorithms that can make do with evaluations that are only relative to the current options, and not applicable in other situations.
One important feature of our definition of value is that in our view, although value is inferred from choice, it is not strictly identical to choice, nor necessarily implied by choice. For instance, if we observe a consistent preference for A over B, A is assumed to have a higher value than B. But choice of A over B isn't sufficient to infer the existence of a self-consistent value function: a decision-maker may adhere to a heuristic policy that results in stable preference for 
[A>B]
, 
[B>C]
, and 
[C>A] (Lichtenstein and Slovic, 2006)
. Moreover, choice can be consistently altered without manipulating the reward value of an item 
(Schonberg & Katz, 2020)
, which suggests that value, as inferred from choice, is not untarnished by processes that are not economic in nature. Thus, value can be inferred from behavior given certain assumptions, but preferences do not always lead to a value function.


The common currency hypothesis
The notion that economic decision-makers make use of internal value functions to compare options is often dated to Daniel Bernoulli's proposal in 1738 of a logarithmic utility curve to explain preferences in the St. Petersburg Paradox 
(Martin, 2011)
. Here, a decisionmaker is offered a chance to play a game in which they win $2 (n-1) with n being the first time, in a series of coin tosses, that a coin falls on "heads". The paradox is that although the expected monetary value of this game (that is, the sum of expected wins multiplied by their probability ∑ 2 ("#$) • 0.
5 " = ∑ 0.5 & "'$ & "'$ )
is infinity, people are not willing to pay even $10 to play this game 
(Hayden and Platt, 2009)
. The explanation that Bernoulli proposed proved foundational within microeconomic theory. He argued that decision-makers don't base calculations on the nominal, objective cash value of the potential gain, but rather on its subjective value. If the subjective value grows more slowly than the objective value (the idea of "diminishing marginal utility"), an optimizing decision-maker will appear risk-averse, for instance, when evaluating the St. Petersburg gamble.
Utility, or subjective value, has been central to many if not most microeconomic models. These include the axiomatic approaches of Pareto, Von Neumann and Morgenstern, and Samuelson. It is also central to behavioral theories such as prospect theory and decision field theory 
(Kahneman and Tversky, 1979;
Busemeyer and Townsend, 1993)
. Ironically, however, explaining choices in the St. Petersburg paradox using such a subjective value function requires utility for money that diminishes so rapidly that it does not generalize to choices in other contexts. Instead, heuristic accounts -accounts that don't rely on ideas about value maximization -provide better quantitative matches for St. Petersburg choices 
(Hayden and Platt, 2009)
.
Despite its central importance in economics, economists are typically agnostic about whether the concept of value is just a convenient description, or whether it is instantiated in the brain. As Friedman argued, decision-makers behave as if we compute and compare values, but we cannot conclude that we actually do so 
(Friedman, 1953)
. In that work, he famously compared economic agents to a trained billiards player who makes excellent shots as if having a sophisticated grasp of Euclidean geometry, although in fact such a theoretical understanding is not necessary for good billiards skill.
Economists typically stop at the point of saying that economic models are 'as if' models, with some arguing that the question of the underlying reality of economic variables is outside the domain of economics 
(Gul and Pesendorfer, 2008;
Harrison, 2008)
. In contrast, neuroeconomics has generally taken as a default assumption that these 'as if' theories are reified in the brain 
(Kable and Glimcher, 2009;
Montague and Berns, 2002;
Padoa-Schioppa, 2011;
ODoherty, 2014;
Levy and Glimcher, 2012;
Rich and Wallis, 2011)
.
Modern tools such as neuroimaging and single unit physiology provide the opportunity to assess the implementation of decision making directly. Indeed, neuroscientists have had little trouble identifying correlates of value in several brain areas 
(Levy and Glimcher, 2012;
Wallis, 2007;
Plassmann et al., 2007;
Knutson et al., 2001
), leading to the suggestion that the orbitofrontal cortex (OFC) is a nexus for representing the economic value of goods in the brain (see, for example, 
Rushworth et al., 2011;
Wallis, 2007)
, alongside other brain areas that are important for computing and representing value such as the ventromedial prefrontal cortex 
(Bartra et al., 2013)
 and ventral striatum 
(Haber and Knutson, 2010)
. However, it is not clear that the signals identified in these studies actually represent value as proposed -on a common currency scale, for comparing options and making choices. Moreover, so called "value signals" only correlate with value, so may be signaling other quantities, such as attention, action plans, vigor, or preference, which also correlate with value (O'Doherty, 2014; 
Wallis and Rich, 2011;
Maunsell, 2004)
. Hence it is important to carefully consider alternative interpretations for these findings, as we do further below, after discussing some practical constraints and philosophical conundrums.


Alternatives to valuation in decision making
While common currency value provides a convenient and general mechanism for making choices, there are many possible alternatives 
(Vlaev et al., 2011;
Gigerenzer and Gaissmaier, 2011;
Lichtenstein and Slovic, 2006;
Kahneman et al., 1982)
, some of which are quite general and robust. Consider for example the "priority heuristic" 
(Branstätter et al., 2006)
. This de minimis heuristic approach proposes that decision-makers first identify a dimension along which options vary and then compare options along that dimension. If that results in a choice, they stop; otherwise, they move on to the next dimension. This heuristic can explain many phenomena, including Allais preferences 
(Allais, 1953)
, the reflection effect 
(Fishburn & Kochenberger, 1979)
, the certainty effect 
(Kahneman and Tversky, 1979)
, the fourfold pattern in risky choice 
(Tversky and Fox, 1995)
 that motivates prospect theory, and several intransitivities -all without ever requiring computing of value 
(Brandstätter et al., 2006)
. And the priority heuristic is one of a large number of heuristics that do a remarkable job at describing behavior 
(Gigerenzer and Gaissmaier, 2011)
. These heuristics are generally motivated by psychological observations, and thus are consistent with known data from the psychology -if not the neuroscience -of choice. In particular, they reflect the assumption that calculating value is difficult, that humans typically use shortcuts whenever possible, and that heuristics are a good shortcut 
(Payne et al., 1992;
Gigerenzer and Gaissmaier, 2011;
Lieder and Griffiths, 2020)
. Moreover, these heuristics are not limited to humans, but apply to other species, including monkeys 
(Santos and Rosati, 2015;
Marsh et al., 2002;
Heilbronner and Hayden, 2016;
Shafir et al., 2002)
.
Importantly for our argument, the success of heuristic approaches demonstrates that value calculations are not a priori essential for neuroeconomic theories of choice. In particular, heuristic theories can solve many problems for which value is proposed to be needed 
(Vlaev et al., 2011;
Stevens, 2016;
Piantadosi and Hayden, 2015;
Tversky, 1969;
Lichtenstein and Slovic, 2006;
Kahneman et al., 1982)
. Heuristics readily allow for comparison of multi-dimensional goods and bundles, and for choice across dissimilar goods. While heuristics are not perfect, and lead to many choice anomalies, choice is, empirically, full of anomalies. Moreover, several nonheuristic process models also eschew value computation steps, including decision by sampling, query theory, and fuzzy trace theory; these all account for a wide range of choice behavior as well 
(Stewart et al., 2006;
Stewart and Simpson, 2008;
Reyna, 2008;
Weber et al., 2008)
.


Practical issues in the neuroscience of value representation
Despite the above, it is often considered axiomatic that an internal, neural, value scale must exist in the brain. The job of neuroscientists is then to find this signal -to pinpoint brain activity that correlates with value. In this section, we challenge this viewpoint by considering some basic issues that come up in the neuroscience of value.
The first problem is that it is impossible to precisely measure value. We can measure preferences between options, and use the data to infer option values, but elicited preferences are noisy measurements that also reflect factors other than value. For example, depending on how preferences are elicited, they may also reflect the tendency to press the same button repeatedly rather than change actions, the tendency to switch between options due to a prior belief about depleting resources, or the amount of attention or looking time for each of the options 
(Shimojo et al., 2003;
Armel et al., 2008;
Sugrue et al., 2005;
Schonberg & Katz, 2020)
. Finally, value may shift from trial to trial, even depending on recent outcomes, meaning that methods that average across trials produce misleading value estimates 
(Sugrue et al., 2005)
. One could, in theory, incorporate these factors into the inferred value of an option. For example, there may be inherent value of choosing the same thing twice in a row. However, it becomes unclear what the definition of the "option" is that is being evaluated: if the value of an apple after eating (or choosing, or even just viewing) an orange is different from the value of an apple without that proximal experience, can we determine the value of goods at all? And if we can change the value (read: preference) for an option just by directing more attention to it 
(Schonberg et al., 2014;
Salomon et al., 2018)
, or inducing choice of it 
(Izuma et al., 2010;
Voigt et al., 2017;
Sharot et al., 2012)
, is preference really measuring the subjective economic worth of a good? The risk is circularity -if any choice behavior can be explained by supposing value that depends on local history, then the concept of value adds no additional explanatory power beyond that of recent events and choices.
Different ways to measure value raise a second challenge of inconsistent measures. Indeed, if we had a single neural value function we called on, values elicited by different measures would match. Unfortunately, they do not 
(Lichtenstein and Slovic, 2006)
. To explain this, in their seminal work, Sarah Lichtenstein and Paul Slovic proposed that preferences do not arise from any internal value function, but instead are constructed at the time of elicitation (see also 
Tversky and Shafir, 1992;
Payne et al., 1992;
Ariely et al., 2003)
. That is, in the view of these and like-minded scholars, value doesn't sit in the brain waiting to be used; rather, preference is a complex and active process that takes place at the time the decision is made. Critically, in this theory we compute choices in a largely ad-hoc manner based on the available options, without an intermediary common-currency valuation stage. As such, there is no guarantee of consistency or reliability; any consistency or reliability observed may be explained as a result of strong attractor states in the way the system determines the choice, and deviations from consistency are evidence for the specific nature of the algorithm and its idiosyncrasies.
This having been said, experimenters can roughly estimate value, even if not measure it precisely. For example, in a given experiment they can examine choices and determine with confidence that a monkey (behaves as if it) places more value on a gamble as compared to a safe option with a matched expected value. One could then use this fact to try to identify a neural correlate of value. However, for this neural endeavor to be valid, it is important to identify all confounding variables and regress them out. O'Doherty's (2014) review delineates the practical difficulty of doing so, using the overall rubric of "visceral, autonomic, and skeletomotor" activity. In practice, confounding variables include both stimulus and outcome identity, information about the state or structure of the world, the surpriseness, informativeness, and informational value of stimuli, details of the action associated with selecting of consuming the reward, including its likelihood and vigor, and the attention and arousal engendered by the stimulus (e.g. 
Botvinik-Nezer et al., 2020;
Roesch et al., 2006;
Wilson et al., 2014;
Blanchard et al., 2015;
O'Doherty, 2007;
Niv et al., 2007;
Roesch and Olson, 2004)
. Indeed, in studies that separately assess encoding of outcome identity versus outcome value, activity in brain areas that are often considered to be emblematic of economic value (in particular, the OFC) turns out to correlate with outcome identity instead (Klein-Flügge et al., 2013).
A final insurmountable problem is that it may be impossible, even in theory, to obtain a brain measure of value that is independent of behavior. Suppose for example, that we identify a particular class of neurons whose firing rates are perfectly correlated with value down to our ability to measure it through preference. Supporting this idea, we observe that any procedure that modifies value (as inferred from behavior) changes the firing rate of these neurons in a manner consistent with our predictions. We may tentatively hypothesize that these neurons are (or are among) the value neurons of the brain. However, as shown by Schonberg and colleagues, preference can be changed irrespective of changing the economic worth of goods 
(Schonberg & Katz, 2020)
. Therefore, to differentiate value neurons from preference neurons, we would need to show that these neurons do not strictly follow expressed preference when the value function diverges from it. This is, of course, not possible if the value function never measurably diverges from preference. And if we assume that values can diverge from preference, it is not clear how to define values to start with. We call this "the neuroeconomic relativity problem" because, like Einstein's relativity problem, it reflects the fact that there is no external reference frame to which one can calibrate value inferences.


Reconsidering the motivation for common currency
It may be worth asking, then, what does having a single common currency buy you? Why would the brain invest in such an organization? One advantage of a common currency scale is that it simplifies comparing options that differ along multiple dimensions. For example, when hunting for an apartment, the options may differ along dimensions of price, area, neighborhood, and amenities. The logic is that these dimensions must be first combined into a single scalar per apartment so that the scalars can be compared. However, this is not the only way to solve the problem, and importantly, may not be the way humans make their decisions. For example, the apartment shopper may choose a single dimension and pick the winner along that dimension, as discussed above, or may compare separately on each dimension and choose the apartment that wins on most counts 
(Tversky, 1972)
. Laboratory studies where humans can choose what attributes to view indeed suggest that people don't uncover all the attributes of one option (to calculate its value) and then continue to the next option, but rather prefer to view information for all options attribute by attribute 
(Fellows, 2006;
Hunt et al., 2014)
. Indeed, as mentioned, much empirical work indicates that human decision-makers broadly favor heuristic approaches that eschew a value stage in a large number of contexts 
(Gigerenzer and Gaissmeier, 2011;
Lieder and Griffiths, 2020;
Brandstätter et al., 2006;
Kahneman et al., 1982)
.
Notably, systems that make use of heuristics may generate internal variables that are conceptually distinct from value but that correlate with value, thus leading to an interpretational confound. Consider, for example, a relatively well-understood implementation of choice in a (non-brain) distributed system: the selection of hive sites in bees (Apis mellifera, 
Seeley, 2010;
Seeley and Burhman, 1999;
Seeley et al., 2006)
. Bee swarms select a hive site by sending out scouts to investigate potential sites. Each site differs along roughly 20 dimensions of varying but measurable importance (size, safety from predators, exposure to sunlight, wind, etc.). Each scout bee that encounters the hive site performs an extremely poor estimation of the value of the siteit typically will only sample three-to-four of the dimensions and even then, estimates them poorly. The bee then returns and if the estimated site quality is sufficiently good, indicates an assessment of its quality to the other bees in the swarm. The quality it signals will be correlated with the overall value of the hive site, but only weakly, and, critically, will only integrate a subset of relevant value components. The overall comparison between options is indirect -the options race to attract adherents; the majority of the decision is made by a positive feedback process. This example is particularly relevant because scholars of perceptual decision making may recognize this process as strongly related to ideas about how the brain decides between options by racing to bounds, and there is evidence that deliberative processes in the brain follow the same principles as choice processes in bee swarms 
(Franks et al., 2003;
Mitchell, 2009;
Passino et al. 2008;
Pirrone et al., 2018;
Pais et al., 2013;
Eisenreich et al, 2017)
.


Evaluating the neural evidence for the common currency hypothesis
Evidence for the common currency hypothesis comes from the observation that firing rates of single neurons or hemodynamic responses of voxels correlate with values of offers and outcomes 
(Padoa-Schioppa, 2011;
Rangel et al., 2008;
Levy and Glimcher, 2012;
Kennerley et al., 2009;
Kennerley et al., 2011)
. These responses depend on multiple elements of offers (e.g., the expected reward, as well as the associated response costs), and are modulated by factors that affect subjective value, such as context or level of satiety (see 
O'Neill and Schultz, 2010;
Rudebeck et al., 2017;
Conen and Padoa-Schioppa, 2019;
Azab and Hayden, 2018
 for only a few examples). Often, variations in these firing rates predict variations in choice 
(Conen and Padoa-Schioppa, 2015;
Strait et al., 2014;
Sugrue et al., 2004)
. Such patterns have been taken as evidence that the neural signal encodes value, in particular implicating the OFC (O'Reilly 2020; 
Bartra et al., 2013;
Levy & Glimcher, 2012)
.
However, such patterns of neural responding do not definitively demonstrate a commoncurrency value signal. For example, in the original finding of value-encoding neurons in the OFC 
(Tremblay & Schultz, 1999)
, neurons responded more strongly to a high-valued option than to a low-valued one. However, the principle of common currency only held within a given choice pair -responses for option B were low when this option was paired with a better option A, but were high when this same option was paired with a worse option C. Other studies found valuecorrelated responses to be more stable across contexts 
(Padoa-Schioppa and Assad, 2008)
, but most findings support an encoding that depends on the alternatives (e.g. 
Padoa-Schioppa, 2009;
Zimmermann et al., 2018;
Kobayashi et al., 2010)
. One might interpret this finding as reflecting simple range adaptation of neurons that have a finite firing rate; however, a more parsimonious explanation is that the firing pattern is consistent with a relative preference code rather than an abstract value code. This interpretation places the putative neural representation of value one stage later than we would expect from a common-currency code -immediately after comparison (because a relative valuation is itself a comparison) rather than as an input to comparison, raising the question of where the input came from. An interpretation of this code as something other than economic value would obviate this worry. Importantly, with a code that depends on alternatives, there is no real sense in which we can read out the "true subjective value" of an option. We can only know if an option's value is higher than another value -similar to the information provided by preferences and choice behavior.
Another corollary of such a relative code is that it is unclear to what extent we can read out a meaningful value signal when only one option is available. Indeed, presenting a subject with one option at a time should, theoretically, provide the best ability to read out option values from neural activity in areas associated with value, such as OFC, ventromedial prefrontal cortex, and dorsal and subgenual anterior cingulate cortices. Doing so reveals that while neural activity in these regions does correlate with the value of the first option, neural responses to the second (alternative) option correlate with the value difference, that is, they reflect the result of value comparison rather than valuation per se 
(Strait et al., 2014;
Azab and Hayden, 2018;
Hunt et al., 2018)
. Moreover, even responses to the first offer do not simply encode its value, but also contain information about the likelihood that option will be chosen (presumably relative to the expected value of the second offer, 
Azab and Hayden, 2017)
. These results suggest that even when evaluation is experimentally segregated from comparison, pure value encodings may not exist. In fact, the idea that prefrontal neurons are selective or responsive to a single experimenter-defined variable has been increasingly falling out of favor 
(Rigotti et al., 2013;
Fusi et al., 2016;
Raposo et al., 2014)
, with "mixed selectivity" appearing to be a core operating principle of prefrontal cortex, including in ostensible value regions 
(Kimmel et al., 2020;
Blanchard et al., 2018;
Hayden and Platt, 2010;
.
A third issue is that although the activity of some neurons in the OFC is correlated with value (but not necessarily linearly related to value), activity of other neurons in this same area is anticorrelated with value, with the majority of neurons showing no relationship at all with value. This raises the possibility that the neurons are encoding something other than value, for instance, a distributed representation of the identity of each of the three options, A, B and C above, or the identity of the stimulus representing the offer. With the small number of options evaluated in most experiments, such a distributed code of outcome or stimulus identity (but not value) can easily result in some neurons randomly firing most strongly for the higher-valued of the three options and least for the worse option, while in other neurons the relationship would be in the opposite direction. This would also explain why many neurons show a non-monotonic relationship between value and their firing.
Recently, using ensemble recordings in the OFC that allow analysis on the level of a single trial, Wallis and colleagues have attempted a more direct test of the hypothesis that OFC encodes value 
(Rich & Wallis, 2016)
. In their task, monkeys were offered two options (denoted by images corresponding to the options) and asked to choose between them. On some trials, only one option was offered. Classifiers were trained to classify options corresponding to each of 4 offer-value levels (0.05, 0.10, 0.18, and 0.30 ml juice, or, in separate blocks, 4 levels of secondorder reinforcer), aggregating over the two images corresponding to each value level. Using single-unit activity and local field-potential recordings in the OFC, the authors could classify the offered value above chance, suggesting that OFC neurons encoded information about value. However, here too, offer values may have been encoded as different (outcome stimulus) identities, not different (ordinal) values in a common currency. One stringent test of the valuecoding hypothesis would be to show that a combination of two offers of value level 0.05 ml resulted in similar activation pattern to a single offer of value level 0.10 ml. Ensemble recordings that give ample data in a single trial allow testing this hypotheses with novel combinations that have not been trained to predict the same identity of reward through multiple presentations, therefore testing the assumptions of the additivity of common currency directly. This critical test has not been conducted, to our knowledge.
As mentioned, many factors that are conceptually distinct from value can influence choice -and are therefore closely correlated with value 
(Maunsell, 2004)
. Reward value drives attention, promotes both short-and long-term learning, primes behavioral adjustments, updates internal models, activates circuitry that detect both positive and negative surprises, and elicits mental computations of cost-benefit tradeoffs as well as comparisons with what could have been chosen. All of these are different from scalar, common-currency value, but are known to drive neural activity in the regions usually associated with economic value. As such, they confound that interpretation. This problem is a long-standing and notorious one in neuroeconomics 
(O'Doherty, 2014;
Maunsell, 2004;
Roesch and Olson, 2003)
.
To overcome some of these potential confounds, a strong tradition in neuroeconomics research is to control for extraneous factors such as salience and response cost (although we note that many factors -e.g., covert attention -cannot be controlled for). As a practical issue, it is difficult to control for alternative interpretations without making the task so convoluted that it becomes unnatural for the animal, in the ethological sense 
(O'Doherty, 2014)
. As a result, it is not clear if findings of value computation (if we believe them to be so) in these tasks would naturally translate to how the brain computes choice in naturalistic situations. But the deeper issue remains that value as inferred in most experiments is definitionally a summary of aggregated choice behavior, and therefore, any variable that influences choice behavior will necessarily be correlated with value. It is for this reason that we suggest that a stronger demonstration of scalar value coding in the brain should show mathematical properties such as the additivity of value, or separation from preferences as these are changed without changing value, as suggested above. If the response of neurons to the novel sum of two stimuli each promising 0.1 ml of juice is similar to the response of those same neurons to a different stimulus associated with 0.2 ml of juice, and especially if this response did not change when preference for an option was induced by means such as the mere exposure effect 
(Schonberg & Katz, 2020)
, it would be harder to argue that this is due to a shared motor plan, or attentional capture. We note that research to date has shown that the activity of brain areas associated with value, in particular the orbitofrontal cortex, does change when preferences are modified through methods that should, in principle, not change economic value 
(Botvinik-Nezer et al., 2020
).


An alternative view: direct learning of policies
Although reinforcement-learning models have contributed to the assumption that the brain computes values, many reinforcement-learning algorithms do not learn or estimate values for different actions. Instead, they directly learn action policies. In fact, in the reinforcementlearning literature, the goal of an agent is to obtain as much reward as possible by executing optimal actions -calculating values is only one means to achieve that end.
In explaining reinforcement-learning methods, 
Dayan and Abbott's (2001)
 textbook begins with the "direct actor" -an actor that learns actions without computing their values. The Actor-Critic model, a prominent algorithm for reinforcement learning that has been linked to the brain 
(Barto, 1995;
Joel et al., 2002;
O'Doherty et al., 2004;
Takahashi et al., 2008;
Maia, 2010)
, does exactly that. In this algorithm, a Critic module learns values of states in terms of expected future rewards (here, the state includes all available actions, averaging over choices and explicitly not computing the value of each possible choice), and uses these to compute reward prediction errors. These prediction errors are used to learn an action policy in the Actor module: the probability of actions that are followed by positive prediction errors is increased, and the probability of actions that are followed by negative prediction errors is decreased. Under some reasonable conditions, this model learns correct reward-maximizing policies 
(Sutton & Barto, 2018)
. However, the quantities learned by the Actor -tendencies to perform one action over the other -cannot be read out as action values. In particular, due to the way the algorithm learns, ties are broken between equally good actions such that eventually agents learn deterministic policies. To be clear, if four actions were to lead to 1, 2, 3 and 3 drops of juice, respectively, the model may learn to always choose the third option, or to always choose the fourth (both optimal policies). At the end of learning, action weights in the Actor may be 0, 0, 1, 0 respectively, losing all information about value, or relative value. Even before convergence to a deterministic policy, weights may be 0, 0.1, 0.95, 0.2 respectively (or any other combination -weights here do not have to sum up to 1, and these are just illustrative numbers). Importantly, if the basal ganglia indeed implement an Actor-Critic learning algorithm in the brain, there is no sense in which we can glean action values from the Actor or the Critic.
The Actor-Critic model is only one of a class of reinforcement-learning algorithms that learn policies directly, that is, without calculating option values (e.g., 
Williams, 1992;
Sutton et al., 2000)
. In their general form, these algorithms maintain an action policy, use experience to evaluate a gradient direction for this policy (that is, what change in policy would increase the overall obtained reward), and change the policy in that direction. Another notable model, developed to explain behavioral patterns in choices, is the Experience-Weighted Attraction model of 
Camerer & Ho (1999)
, which interpolates between value calculation and direct policy learning.
Recent findings suggest that both behavior and learning signals measured in humans during decision making are more in line with a policy-learning algorithm than with value estimation. For instance, 
Li & Daw (2011)
 had participants choose between two options that gave reward with different probabilities. After each choice, both the outcome of the chosen option and the counterfactual outcome of the unchosen option were displayed. Behavior, as well as neural signals corresponding to prediction errors in the basal ganglia, suggested that subjects were updating both options in opposite directions, learning relative choice propensities (a policy) rather than tracking the expected value of each option. In another task in which humans chose between pairs of options and were able to view both the outcome of their choice and the counterfactual outcome of the forgone option, 
Palminteri et al. (2015)
 had subjects learn which of two probabilistically rewarding options is better, and which of two probabilistically punishing options was better. At test, subjects were asked to choose between pairs from both the rewarding and the punishing contexts. Surprisingly, when choosing between the less rewarding option and the less punishing option, subjects tended to choose the less punishing option. This is consistent with policy learning, as that option had been the favored option in the punishment context, whereas the less rewarding option had been the disfavored one in the reward context. However, the value of a sometimes-rewarding option is clearly higher than that of a sometimes-punishing option, hence value learning cannot explain this fundamentally suboptimal choice pattern.
Direct learning of policies is consistent with basic tenets of decision making, such as the fact that choices are stochastic even when no exploration is necessary or warranted (e.g., choosing between two gambles that are fully described; 
Khaw et al., 2017a)
. Because policies are relative quantities (preference for one option implies unfavorability of another, as the probabilities of all choices have to sum to one), they also explain common violations of the independence axiom such as the effects of third-option "decoys" on choice 
(Soltani et al., 2012)
, and temporal and spatial contextual influences on choice 
(Khaw et al., 2017b)
, although these phenomena can also be explained by valuation models that involve range normalization.


Conclusion
The field of neuroeconomics started with the putative identification of pure value signals (Platt and 
Glimcher, 1999)
. The meaning of these signals was disputed early on 
(Roesch et al., 2003;
Maunsell, 2004)
, but deep questions were set aside as researchers continued to identify brain areas with parts of the computational processes of choice, and in particular, identified the orbitofrontal cortex with the seat of economic value. However, while those debates have subsided, the problems they raised have not been resolved. Progress on these issues will require additional data, but we stress that not every experiment that involves choices also implies valuation, and one must be careful in interpreting data not only because of potential confounds, but also because we must be wary of treating a hypothesis -that the brain computes value -as an axiom. We also suggest the need for additional philosophical work to define value in a way that is -at least in principle -dissociable from other factors that promote choices 
(Juechems & Summerfield, 2019)
. In other words, we argue for a return to the productive debates of the early days of the field, twenty years ago (for neuroeconomics), and earlier (for its psychological underpinnings). Bolstered by an additional twenty years of new data, such debates would surely benefit the field of neuroeconomics moving forward. They would also potentially help reconcile conflicting views on what the orbitofrontal cortex might or might not be doing in decision making 
(Stalnaker et al., 2015)
.
 
We consider subjective worth as revealed by preference, following neuroeconomic theory, but note that the limiting focus on only the 'wanting' not the 'liking' side of value
(Berridge, 1996)
.








Acknowledgements
We thank the Gordon Research Conference on Neurobiology of Cognition 2018, organized by Jennifer Groh and David Leopold, for providing the context in which this collaboration was seeded. We thank Sarah Heilbronner, Rei Akaishi, Becket Ebitz and many commentators on Twitter for helpful discussions.






Funding statement
This research was supported by National Institute on Drug Abuse Grants R01 DA038615 (BYH) and R01 DA042065 (YN), and by grants from the John Templeton Foundation (to both YN and BYH). The opinions expressed in this publication are those of the authors and do not necessarily reflect the views of the John Templeton Foundation or the National Institute on Drug Abuse.


Competing interests
The authors have no competing interests to declare.
 










Le comportement de l'homme rationnel devant le risque: critique des postulats et axiomes de l'école Américaine




M
Allais








Econometrica: Journal of the Econometric Society


















Coherent arbitrariness": Stable demand curves without stable preferences




D
Ariely






G
Loewenstein






D
Prelec








The Quarterly journal of economics




118


1
















Biasing simple choices by manipulating relative visual attention




K
C
Armel






A
Beaumel






A
Rangel








Judgment and Decision making




3


5
















Correlates of decisional dynamics in the dorsal anterior cingulate cortex




H
Azab






B
Y
Hayden








PLoS biology




15


11


2003091














Correlates of economic decisions in the dorsal and subgenual anterior cingulate cortices




H
Azab






B
Y
Hayden








European Journal of Neuroscience




47


8
















Partial integration of the components of value in anterior cingulate cortex




H
Azab






B
Y
Hayden








Behavioral Neuroscience




134


4


296














Adaptive critics and the basal ganglia




A
G
Barto








Models of information processing in the basal ganglia


J. Houk, J.Davis, & D. Beiser


Cambridge, MA




MIT Press
















The valuation system: a coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value




O
Bartra






J
T
Mcguire






J
W
Kable








Neuroimage




76
















Food reward: brain substrates of wanting and liking




K
C
Berridge








Neuroscience & Biobehavioral Reviews




20


1
















Ramping ensemble activity in dorsal anterior cingulate neurons during persistent commitment to a decision




T
C
Blanchard






C
E
Strait






B
Y
Hayden








Journal of neurophysiology




114


4
















Robust mixture modeling reveals category-free selectivity in reward region neuronal ensembles




T
C
Blanchard






S
T
Piantadosi






B
Y
Hayden








Journal of neurophysiology




119


4
















Enhanced bottom-up and reduced topdown fMRI activity is related to long-lasting nonreinforced behavioral change




R
Botvinik-Nezer






T
Salomon






T
Schonberg








Cerebral Cortex




30


3
















The priority heuristic: making choices without trade-offs




E
Brandstätter






G
Gigerenzer






R
Hertwig








Psychological review




113


2


409














Decision field theory: a dynamic-cognitive approach to decision making in an uncertain environment




J
R
Busemeyer






J
T
Townsend








Psychological review




100


3


432














Neuroeconomics: How neuroscience can inform economics




C
Camerer






G
Loewenstein






D
Prelec








Journal of economic Literature




43


1
















Experience-weighted attraction learning in normal form games




C
Camerer






T
Ho








Econometrica




67


4
















The mind is flat: The remarkable shallowness of the improvising brain




N
Chater








Yale University Press












Eliminative materialism and propositional attitudes




P
M
Churchland








the Journal of Philosophy




78


2
















Eliminative materialism. Matter and Consciousness




P
Churchland




















Matter and consciousness




P
M
Churchland








MIT press












Partial adaptation to the value range in the macaque orbitofrontal cortex




K
E
Conen






C
Padoa-Schioppa








Journal of Neuroscience




39


18
















Neuronal variability in orbitofrontal cortex during economic decisions




K
E
Conen






C
Padoa-Schioppa








Journal of neurophysiology




114


3
















Theoretical neuroscience: computational and mathematical modeling of neural systems




P
Dayan






L
F
Abbott








Computational Neuroscience Series
















Control without controllers: toward a distributed neuroscience of executive control




B
R
Eisenreich






R
Akaishi






B
Y
Hayden








Journal of cognitive neuroscience




29


10
















Speed versus accuracy in collective decision making




N
R
Franks






A
Dornhaus






J
P
Fitzsimmons






M
Stevens








Proceedings of the Royal Society of London. Series B: Biological Sciences


the Royal Society of London. Series B: Biological Sciences






270














Neuroeconomics: Decision making and the brain




P
W
Glimcher




& Fehr, E.






Academic Press












Heuristic decision making. Annual review of psychology




G
Gigerenzer






W
Gaissmaier








62














The case for mindless economics. The foundations of positive and normative economics: A handbook




F
Gul






W
Pesendorfer








1














On the flexibility of basic risk attitudes in monkeys




S
Farashahi






H
Azab






B
Hayden






A
Soltani








Journal of Neuroscience




38


18
















Deciding how to decide: ventromedial frontal lobe damage affects information acquisition in multi-attribute decision making




L
K
Fellows








Brain




129


4
















Two-piece von Neumann-Morgenstern utility functions




P
C
Fishburn






G
A
Kochenberger








Decision Sciences




10


4
















The methodology of positive economics




M
Friedman








Essays in positive economics




3


3
















Why neurons mix: high dimensionality for higher cognition




S
Fusi






E
K
Miller






M
Rigotti








Current opinion in neurobiology




37
















The reward circuit: linking primate anatomy and human imaging




S
N
Haber






B
Knutson








Neuropsychopharmacology




35


1
















Neuroeconomics: A critical reconsideration




G
W
Harrison








Economics & Philosophy




24


3
















The mean, the median, and the St. Petersburg paradox




B
Y
Hayden






M
L
Platt








Judgment and Decision Making




4


4


256














Neurons in anterior cingulate cortex multiplex information about reward and action




B
Y
Hayden






M
L
Platt








Journal of Neuroscience




30


9
















A neuronal theory of sequential economic choice




B
Y
Hayden






R
Moreno-Bote








Brain and Neuroscience Advances




2


2398212818766675














The description-experience gap in risky choice in nonhuman primates




S
R
Heilbronner






B
Y
Hayden








Psychonomic bulletin & review




23


2
















Hierarchical competitions subserving multiattribute choice




L
T
Hunt






R
J
Dolan






T
E
Behrens








Nature neuroscience




17


11
















Triple dissociation of attention and decision computations across prefrontal cortex




L
T
Hunt






W
N
Malalasekera






A
O
De Berker






B
Miranda






S
F
Farmer






T
E
Behrens






S
W
Kennerley








Nature neuroscience




21


10
















Neural correlates of cognitive dissonance and choice-induced preference change




K
Izuma






M
Matsumoto






K
Murayama






K
Samejima






N
Sadato






K
Matsumoto








Proceedings of the National Academy of Sciences




107


51
















Actor-critic models of the basal ganglia: New anatomical and computational perspectives




D
Joel






Y
Niv






E
Ruppin








Neural networks




15


4-6
















Where does value come from?




K
Juechems






C
Summerfield








Trends in cognitive sciences




23


10
















The neurobiology of decision: consensus and controversy




J
W
Kable






P
W
Glimcher








Neuron




63


6
















Prospect theory: an analysis of decisions under risk




D
Kahneman






A
Tversky








Econometrica




47


















D
Kahneman






S
P
Slovic






P
Slovic




Judgment under uncertainty: Heuristics and biases


& Tversky, A.




Cambridge university press














Neurons in the frontal lobe encode the value of multiple decision variables




S
W
Kennerley






A
F
Dahmubed






A
H
Lara






J
D
Wallis








Journal of cognitive neuroscience




21


6
















Double dissociation of value computations in orbitofrontal and anterior cingulate neurons




S
W
Kennerley






T
E
Behrens






J
D
Wallis








Nature neuroscience




14


12


1581














Risk aversion as a perceptual bias (No. w23294)




M
W
Khaw






Z
Li






M
Woodford








National Bureau of Economic Research
















Normalized value coding explains dynamic adaptation in the human valuation process




M
W
Khaw






P
W
Glimcher






K
Louie








Proceedings of the National Academy of Sciences




114


48
















Value and choice as separable, stable representations in orbitofrontal cortex




D
L
Kimmel






G
F
Elsayed






J
P
Cunningham






W
T
Newsome








Nature Communications




11


3466














Segregated encoding of reward-identity and stimulus-reward associations in human orbitofrontal cortex




M
C
Klein-Flügge






H
C
Barron






K
H
Brodersen






R
J
Dolan






T
E J
Behrens








Journal of Neuroscience




33


7
















Anticipation of increasing monetary reward selectively recruits nucleus accumbens




B
Knutson






C
M
Adams






G
W
Fong






D
Hommer








Journal of Neuroscience




21


16
















Adaptation of reward sensitivity in orbitofrontal neurons




S
Kobayashi






O
P
De Carvalho






W
Schultz








Journal of Neuroscience




30


2
















The root of all value: a neural common currency for choice




D
J
Levy






P
W
Glimcher








Current opinion in neurobiology




22


6
















Signals in human striatum are appropriate for policy update rather than value prediction




J
Li






N
D
Daw








Journal of Neuroscience




14
















Resource-rational analysis: understanding human cognition as the optimal use of limited computational resources




F
Lieder






T
L
Griffiths








Behavioral and Brain Sciences




43














The construction of preference


Lichtenstein, S., & Slovic, P.






Cambridge University Press
















G
Loewenstein






S
Rick






J
D
Cohen








Neuroeconomics. Annu. Rev. Psychol




59
















Two-factor theory, the actor-critic model, and conditioned avoidance




T
V
Maia








Learning & behavior




38


1
















Do animals use heuristics?




B
Marsh








Journal of Bioeconomics




4


1
















The St. Petersburg paradox




R
Martin












Stanford Encyclopedia of Philosophy












Neuronal representations of cognitive state: reward or attention?




J
H
Maunsell








Trends in cognitive sciences




8


6
















Habits without values




K
J
Miller






A
Shenhav






E
A
Ludvig








Psychological review




126


2


292














Complexity: A guided tour




M
Mitchell








Oxford University Press












Neural economics and the biological substrates of valuation




P
R
Montague






G
S
Berns








Neuron




36


2
















Reinforcement learning in the brain




Y
Niv








Journal of Mathematical Psychology




53


3
















Tonic dopamine: opportunity costs and the control of response vigor




Y
Niv






N
D
Daw






D
Joel






P
Dayan








Psychopharmacology




191


3
















The problem with value




J
P
O'doherty








Neuroscience & Biobehavioral Reviews




43
















Lights, camembert, action! The role of human orbitofrontal cortex in encoding stimuli, rewards, and choices




J
P
O'doherty








Annals of the New York Academy of Sciences




1121


1
















Dissociable roles of ventral and dorsal striatum in instrumental conditioning




J
O'doherty






P
Dayan






J
Schultz






R
Deichmann






K
Friston






R
J
Dolan








science




304


5669
















Coding of reward risk by orbitofrontal neurons is mostly distinct from coding of reward value




M
O'neill






W
Schultz








Neuron




68


4
















Unraveling the Mysteries of Motivation




R
C
O'reilly








Trends in Cognitive Sciences
















Neurobiology of economic choice: a good-based model. Annual review of neuroscience




C
Padoa-Schioppa








34














The representation of economic value in the orbitofrontal cortex is invariant for changes of menu




C
Padoa-Schioppa






J
A
Assad








Nature neuroscience




11


1
















Range-adapting representation of economic value in the orbitofrontal cortex




C
Padoa-Schioppa








Journal of Neuroscience




29


44
















A mechanism for value-sensitive decision-making




D
Pais






P
M
Hogan






T
Schlegel






N
R
Franks






N
E
Leonard






J
A
Marshall








PLoS One




8


9


73216














Contextual modulation of value signals in reward and punishment learning




S
Palminteri






M
Khamassi






M
Joffily






G
Coricelli








Nature communications




6


1
















Swarm cognition in honey bees




K
M
Passino






T
D
Seeley






P
K
Visscher








Behavioral Ecology and Sociobiology




62


3
















Behavioral decision research: A constructive processing perspective. Annual review of psychology




J
W
Payne






J
R
Bettman






E
J
Johnson








43














Utility-free heuristic models of two-option choice can mimic predictions of utility-stage models under many conditions




S
T
Piantadosi






B
Y
Hayden








Frontiers in neuroscience




9


105














Evidence for the speed-value trade-off: Human and monkey decision making is magnitude sensitive




A
Pirrone






H
Azab






B
Y
Hayden






T
Stafford






J
A
Marshall








Decision




5


2


129














Orbitofrontal cortex encodes willingness to pay in everyday economic transactions




H
Plassmann






J
O'doherty






A
Rangel








Journal of neuroscience




27


37
















A framework for studying the neurobiology of value-based decision making




A
Rangel






C
Camerer






P
R
Montague








Nature reviews neuroscience




9


7
















A category-free neural population supports evolving demands during decision-making




D
Raposo






M
T
Kaufman






A
K
Churchland








Nature neuroscience




17


12


1784














A theory of medical decision making and health: fuzzy trace theory




V
F
Reyna








Medical decision making




28


6
















Decoding subjective decisions from orbitofrontal cortex




E
L
Rich






J
D
Wallis








Nature neuroscience




19


7
















The importance of mixed selectivity in complex cognitive tasks




M
Rigotti






O
Barak






M
R
Warden






X
J
Wang






N
D
Daw






E
K
Miller






S
Fusi








Nature




497


7451
















Neuronal activity related to reward value and motivation in primate frontal cortex




M
R
Roesch






C
R
Olson








Science




304


5668
















Encoding of time-discounted rewards in orbitofrontal cortex is independent of value representation




M
R
Roesch






A
R
Taylor






G
Schoenbaum








Neuron




51


4
















Impact of expected reward on neuronal activity in prefrontal cortex, frontal and supplementary eye fields and premotor cortex




M
R
Roesch






C
R
Olson








Journal of neurophysiology




90


3
















In defense of eliminative materialism. The review of metaphysics




R
Rorty




















Specialized representations of value in the orbital and ventrolateral prefrontal cortex: desirability versus availability of outcomes




P
H
Rudebeck






R
C
Saunders






D
A
Lundgren






E
A
Murray








Neuron




95


5
















Frontal cortex and reward-guided learning and decision-making




M
F
Rushworth






M
P
Noonan






E
D
Boorman






M
E
Walton






T
E
Behrens








Neuron




70


6
















Changing value through cued approach: an automatic mechanism of behavior change




T
Schonberg






A
Bakkour






A
M
Hover






J
A
Mumford






L
Nagar






J
Perez






R
A
Poldrack








Nature neuroscience




17


4
















A Neural Pathway for Nonreinforced Preference Change




T
Schonberg






L
N
Katz








Trends in Cognitive Sciences
















The cue-approach task as a general mechanism for long-term non-reinforced behavioral change




T
Salomon






R
Botvinik-Nezer






T
Gutentag






R
Gera






R
Iwanir






M
Tamir






T
Schonberg








Scientific reports




8


1
















The evolutionary roots of human decision making. Annual review of psychology




L
R
Santos






A
G
Rosati








66


321












Honeybee democracy




T
D
Seeley








Princeton University Press












Group decision making in swarms of honey bees




T
D
Seeley






S
C
Buhrman








Behavioral Ecology and Sociobiology




45


1
















Group Decision Making in Honey Bee Swarms: When 10,000 bees go house hunting, how do they cooperatively choose their new nesting site




T
D
Seeley






P
K
Visscher






K
M
Passino








American scientist




94


3
















Context-dependent violations of rational choice in honeybees (Apis mellifera) and gray jays (Perisoreus canadensis)




S
Shafir






T
A
Waite






B
H
Smith








Behavioral Ecology and Sociobiology




51


2
















Is choice-induced preference change long lasting? Psychological science




T
Sharot






S
M
Fleming






X
Yu






R
Koster






R
J
Dolan








23














Gaze bias both reflects and influences preference




S
Shimojo






C
Simion






E
Shimojo






C
Scheier








Nature neuroscience




6


12
















A range-normalization model of contextdependent choice: a new model and evidence




A
Soltani






B
De Martino






C
Camerer








PLoS Comput Biol




8


7


1002607














What the orbitofrontal cortex does not do




T
A
Stalnaker






N
K
Cooch






G
Schoenbaum








Nature neuroscience




18


5


620














Decision by sampling




N
Stewart






N
Chater






G
D
Brown








Cognitive psychology




53


1
















A decision-by-sampling account of decision under risk. The probabilistic mind: Prospects for Bayesian cognitive science




N
Stewart






K
Simpson




















Intertemporal similarity: Discounting as a last resort




J
R
Stevens








Journal of Behavioral Decision Making




29


1
















Choosing the greater of two goods: neural currencies for valuation and decision making




L
P
Sugrue






G
S
Corrado






W
T
Newsome








Nature Reviews Neuroscience




6


5
















Matching behavior and the representation of value in the parietal cortex




L
P
Sugrue






G
S
Corrado






W
T
Newsome








science




304


5678
















Policy gradient methods for reinforcement learning with function approximation




R
S
Sutton






D
A
Mcallester






S
P
Singh






Y
Mansour








Advances in neural information processing systems


















Reinforcement learning: An introduction




R
S
Sutton






A
G
Barto








MIT press












Silencing the critics: understanding the effects of cocaine sensitization on dorsolateral and ventral striatum in the context of an actor/critic model




Y
Takahashi






G
Schoenbaum






Y
Niv








Frontiers in neuroscience




2


14














Absolutely relative or relatively absolute: violations of value invariance in human decision making




A
R
Teodorescu






R
Moran






M
Usher








Psychonomic bulletin & review




23


1
















Relative reward preference in primate orbitofrontal cortex




L
Tremblay






W
Schultz








Nature




398


6729
















Weighing risk and uncertainty




A
Tversky






C
R
Fox








Psychological review




102


2


269














Elimination by aspects: A theory of choice




A
Tversky








Psychological review




79


4


281














Choice under conflict: The dynamics of deferred decision




A
Tversky






E
Shafir








Psychological science




3


6
















Intransitivity of preferences




A
Tversky








Psychological review




76


1


31














Does the brain calculate value?




I
Vlaev






N
Chater






N
Stewart






G
D
Brown








Trends in cognitive sciences




15


11
















Endogenous formation of preferences: Choices systematically change willingness-to-pay for goods




K
Voigt






C
Murawski






S
Bode








Journal of Experimental Psychology: Learning, Memory, and Cognition




43


12


1872
















Von
Neumann






J
Morgenstern






O




Theory of games and economic behavior




Princeton university press








commemorative edition








Challenges of interpreting frontal neurons during value-based decision-making




J
D
Wallis






E
L
Rich








Frontiers in neuroscience




5


124














Orbitofrontal cortex and its contribution to decision-making




J
D
Wallis








Annu. Rev. Neurosci




30
















Asymmetric discounting in intertemporal choice: A query-theory account




E
U
Weber






E
J
Johnson






K
F
Milch






H
Chang






J
C
Brodscholl






D
G
Goldstein








Psychological science




18


6
















Simple statistical gradient-following algorithms for connectionist reinforcement learning




R
J
Williams








Machine learning




8


3-4
















Orbitofrontal cortex as a cognitive map of task space




R
C
Wilson






Y
K
Takahashi






G
Schoenbaum






Y
Niv








Neuron




81


2
















Robust encoding of spatial information in orbitofrontal cortex and striatum




S
B M
Yoo






B
J
Sleezer






B
Y
Hayden








Journal of cognitive neuroscience




30


6
















Economic choice as an untangling of options into actions




S
B M
Yoo






B
Y
Hayden








Neuron




99


3
















Multiple timescales of normalized value coding underlie adaptive choice behavior




J
Zimmermann






P
W
Glimcher






K
Louie








Nature communications




9


1

















"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]