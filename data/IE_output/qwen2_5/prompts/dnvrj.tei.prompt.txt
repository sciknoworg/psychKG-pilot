You are an expert in psychology and computational knowledge representation. Your task is to extract key scientific information from psychology research articles to build a structured knowledge graph.

The knowledge graph aims to represent the relationships between psychological **topics or constructs** and their associated **measurement instruments or scales**. Specifically, for each article, extract information in the form of triples that capture:

1) The psychological topic or construct being studied
2) The measurement instrument or scale used to assess it
3) A brief justification (1–3 sentences) from the article text supporting this measurement link

Guidelines:
- Extract meaningful **phrases** (not full sentences or vague descriptions) for both `topic_or_construct` and `measured_by`, suitable for inclusion in a knowledge graph.
- Include a short justification for each extraction that clearly supports the connection.
- If the article does not discuss psychological constructs and how they are measured (e.g., no mention of constructs, instruments, or scales), return an empty list `[]`.

Input Paper:
"""



For decades, research into the mechanisms of how people adjust their information processing to achieve their goals (cognitive control) and how they weigh costs and benefits to make a choice (value-based decision-making) was conducted largely in parallel, distinctions between which were seemingly underscored by differences in their dominant experimental paradigms. In a typical decision-making experiment (e.g., a choice between two gambles, food items, or consumer goods; 
Collins & Shenhav, 2021;
Glimcher, 2002;
Hare, Schultz, Camerer, O'Doherty, & Rangel, 2011;
, a participant must weigh the relevant costs and benefits to determine for themselves what the best course of action is. In a typical cognitive control experiment (e.g., a Stroop, Eriksen flanker, or Simon task; 
Friedman & Robbins, 2021)
, the best course of action is indicated unambiguously (e.g., the participant is instructed to name the stimulus color, and that color is easy to identify), but choosing that response requires engaging control processes to overcome a bias towards automatically responding in a different way (e.g., based on another salient feature of the stimulus). While these two sets of tasks involve similar sets of computations 
(Rangel, 2009;
Ritz, Leng, & Shenhav, under review)
, they are used to address questions that are in large part non-overlapping ( 
Fig. 1
).
Decision-making research typically gives greater focus to the process of integrating information about the stimuli to select a response ( 
Fig. 1A)
, taking account of previous learning, long-run preferences (e.g., risk aversion), motivational state (e.g., current hunger level), and more 
(Campbell-Meiklejohn, Simonsen, Frith, & Daw, 2016;
Lempert & Phelps, 2016;
Louie, Grattan, & Glimcher, 2011)
. By contrast, cognitive control research typically gives greater focus to the factors that shape the response selection process 
(Fig. 1B)
, for instance how people enhance their processing of the target feature (e.g., color) and/or suppress their processing of the distractor (e.g., word) based on recent performance 
(Ritz et al., under review)
.
Interactions across these fields have increased in recent years, addressing questions at their intersection that could not have previously been addressed by either alone. A recent example of this is a body of work that has used models of value-based learning and decisionmaking to understand how people select the best level of cognitive control for a given situation 
(Lieder, Shenhav, Musslick, & Griffiths, 2018;
Shenhav et al., 2017)
. Here, we will highlight the significant advances that have been made through the opposite direction of interchange: ways in which insights drawn from research on cognitive control have illuminated the mechanisms by which people make value-based decisions. For example, the process by which people select COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE between a given set of options has been well-described by an array of decision-making models, but accounting for how the parameters of this process change over time (e.g., the threshold for making a decision; 
Ratcliff & McKoon, 2008)
 may require an additional level of description beyond the choice itself. What determines when and how these parameters are adjusted? What kind of information about the choice process and/or the options themselves needs to be monitored to inform these adjustments. In other words, how is decision-making controlled?
These are questions central to research into traditional cognitive control tasks like the Stroop .
We will argue that drawing parallels to traditional research in cognitive control has not only helped understand how value-based decision-making is modulated, but has also provided a different lens through which to (re-)interpret elements of the decision process itself. We will highlight three areas where such connections have proven particularly valuable. First, while goals already play an important role in common models of decision-making -particularly when determining how attributes are weighted in option valuation (e.g., a goal of being healthy will be associated with a stronger weight on options' health attributes relative to others) -cognitive control research provides insights into how these goals are regulated and flexibly adjusted; how goals defined at the task level additionally shape the selection process (and its correlates) (e.g. whether a person is identifying the best or the worst option in a set); and what types of processes occur automatically in response to a set of stimuli irrespective of one's goal. Second, as noted above, whereas decision-making research defines the decision process in rich detail, cognitive control research provides insights into how the parameters of this process are altered and under what conditions, including which neural circuits are most likely to be responsible based on analogous control adjustments in more traditional control tasks. Third, whereas decision-making research describes how representations of value are updated, integrated, and transformed to determine one's actions (e.g., from attribute value to option value to action value), cognitive control research provides insights into the higher-order information that is represented about this very choice process (e.g., choice difficulty or confidence) that might bear on adjustments to ongoing or future choices. Understanding these choice monitoring processes can in turn help identify cases in which such monitoring signals can be misattributed to signatures of decisionmaking per se. Collectively, these different lines of work highlight important synergies that have COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 5 emerged through the interdisciplinary interactions between decision-making and cognitive control research, and point to fruitful directions for future work.


Figure 1. Basic mechanisms of value-based decision-making and cognitive control. A) A typical
decision-making paradigm requires participants to choose between two options. Weighted attribute values determine the subjective value of each option, and the subjective values of these options feed into an evidence accumulation process that determines the final choice. (Note that models differ in how subjective values are translated into evidence accumulation, including whether this is done at the level of the attributes or options as a whole, as well as the extent of interactions between different streams of evidence accumulation.) The weight placed on different choice attributes (e.g., taste vs. health) is shaped by a person's evaluative goals (e.g., whether they are currently on a diet or were instructed by the experimenter to focus attention on the healthy attribute). B) In a typical cognitive control task, a participant's choice depends on their task goal (e.g., whether to read a displayed word or name its color). Information about different stimulus features (e.g., word, ink color) enters an evidence accumulation process that gives rise to the response. Critically, one of these feature processing pathways is more automatic than the other (reflected in thicker arrow for word-reading), increasing the potential for interference with processing the goal-relevant feature. Monitoring of this accumulation process, and its outcomes (not shown), helps determine when additional control is demanded to up-regulate the current goal.


Representations of value are shaped by a diversity of goals
A central question in research on value-based decision-making is how the brain computes and compares values. Addressing this question requires knowing what the relevant representations are that underlie these computations and how they are encoded in the brain.
Decision-making research has developed a good understanding of how the brain represents the variable that is at the center of these decisions: subjective value. Studies have demonstrated how the subjective value of one's options is determined by integrating over its attributes and their meaning for that individual in that particular context . They have further demonstrated that these integrative values are encoded by a consistent set of brain regions COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 
(Levy & Glimcher, 2012)
, with activity in those regions increasing with the subjective value a person assigns to a given option (though see 
Hayden & Niv, 2021)
. A critical feature of value representations is that they have a canonical, directional, and task-independent meaning. That is, even though subjective values are multidimensional and can vary dynamically with context and with the decision-maker's motivational state, these values are always assumed to fall on an ordinal scale whereby some options are more preferred to others at a given point. Where options fall relative to each other on this scale (and their relative activations in value-encoding regions of the brain) is therefore meaningful not only for the immediate task (e.g., choose Option A vs.
Option B) but also for other tasks you might engage in outside of the lab (e.g., likelihood of recommending Option A to a friend or buying products that share properties with that option).
Within research on cognitive control, by contrast, it is typically assumed that the relevant representations are fundamentally and flexibly defined by the current task and that these representations encompass not only information about the features themselves, but also how these currently relate to relevant target responses 
(Badre, Bhandari, Keglovits, & Kikumoto, 2021;
Collins & Frank, 2013;
Kikumoto & Mayr, 2017)
. Thus, information about stimuli and potential responses is considered with respect to one's current task goals (e.g., when responding to the ink color of "BLUE" written in red, "red" achieves my current task goal better than "blue" and vice versa for word reading). Ultimately, these goals themselves need to be considered in terms of their overall value for an individual 
(Shenhav, Botvinick, & Cohen, 2013;
Shenhav et al., 2017)
, which is something we will return to later, but in this section we will instead focus on what critical new insights cognitive control research can offer into the different ways goals can shape these representations that underlie value-based choice.


The influence of goals on how we weigh elements of value
The fundamental assumption that our goals shape the way we process stimuli links research into decision-making and cognitive control. In the case of value-based choice, one of the most straightforward ways this manifests is in how strongly an individual considers different attributes of their options. For instance, when facing a set of food options, someone who is currently on a diet, might place greater weight on the healthiness-related attributes of those options (i.e., those that determine which foods are the healthiest) than on their tastiness-related attributes 
(Hare, Camerer, & Rangel, 2009)
. The same goals can be induced exogenously (e.g., COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 7 through the experimenter's instruction to focus on one attribute versus another; 
(Maier, Raja Beharelle, Polania, Ruff, & Hare, 2020;
Tusche & Hutcherson, 2018)
, demonstrating that valuation can adjust flexibly and dynamically with an individual's current goals. Indeed, people are even able to adjust this valuation process based on the goals that they infer another person would have in this situation, for instance when choosing on behalf of someone who cares more about health than taste (or vice versa) 
(Harris, Clithero, & Hutcherson, 2018)
. In each of these cases, a common finding is that regions of the valuation network track the weighted value of a given option, that is, how preferable that option is when accounting for how much weight will be placed on each of the choice attributes 
(Hare et al., 2009;
Hutcherson, Plassmann, Gross, & Rangel, 2012;
Douglas G. Lee & Hare, 2021)
. Notably, the brain regions most commonly implicated in directing more attention towards choice attributes that are weighted most stronglyand thereby modulating value-related activity in regions such as vmPFC -are the same ones that have also traditionally been implicated in directing attention towards goal-relevant attributes in standard cognitive control paradigms like the Stroop (e.g., dlPFC 
(Hutcherson et al., 2012)
).
These parallels have led to the view that cognitive control acts on value representations analogously to how it acts on perceptual information: When our goal is to attend to faces rather than houses 
(Nelissen, Stokes, Nobre, & Rushworth, 2013)
 or the direction of motion for a set of dots rather than their color 
(Danielmeier, Eichele, Forstmann, Tittgemeyer, & Ullsperger, 2011)
, the dlPFC maintains that goal and acts on stimulus processing regions to prioritize some stimulus attributes over others when determining how to respond 
(MacDonald, Cohen, Stenger, & Carter, 2000)
. When our goal is to maximize the value of some choice attributes over others (e.g., health over taste), the dlPFC similarly facilitates the prioritization of one attribute value over another 
(Hutcherson et al., 2012)
. Under this view, it is natural to think of control as directing the flow of reward information within the value network, such that neural signals within vmPFC come to signal how rewarding an option is based on one's current goals. However, as we discuss next, it turns out that this is only one way goals alter the representation of value.


The influence of goals on how we represent value
As discussed earlier, activity in specific regions of the valuation network (e.g., vmPFC and ventral striatum) has been shown to track reward value in a directionally consistent manner 
(Blair et al., 2006;
V. M. Brown, Wilson, Hallquist, Szanto, & Dombrovski, 2020
; De Martino, COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 
Fleming, Garrett, & Dolan, 2013;
Grabenhorst & Rolls, 2011;
Grueschow, Polania, Hare, & Ruff, 2015;
Hutcherson et al., 2012;
Jocham, Klein, & Ullsperger, 2011;
Lebreton, Abitbol, Daunizeau, & Pessiglione, 2015;
Lim, O'Doherty, & Rangel, 2011;
Moneta, Garvert, Heekeren, & Schuck, 2021;
Plassmann, O'Doherty, & Rangel, 2010;
Shapiro & Grafton, 2020;
Vaidya & Badre, 2020;
Vassena, Krebs, Silvetti, Fias, & Verguts, 2014;
Westbrook, Lamichhane, & Braver, 2019)
, with greater activity coding for higher levels of expected reward (meta-analyses in 
(Bartra, McGuire, & Kable, 2013;
Levy & Glimcher, 2012)
). This accumulation of findings suggests that, as goals shape value-based choices, ventral striatum and vmPFC should be expected to track the ultimate read-out of how those goals shaped the reward a person expects, with lower activity reflecting lower expected reward and greater activity reflecting greater expected reward. Water may be experienced as more rewarding when one is thirsty than when they are not, and a healthy food may be experienced as more rewarding when one is on a diet than when they are not, but activity in these regions should nevertheless always provide a directionally consistent read-out of those expected rewards 
(Levy & Glimcher, 2012)
.
The problem with this account arises when you consider the typical task set under which choice values are studied. In the vast majority of research on value-based choice, the participant's goal (implicitly and/or explicitly) is the same: choose the option you most prefer. As a result, signals of reward value can carry two kinds of information. First, as described above, they reflect a directional read-out of how much the person likes those options. Second, these reward signals reflect the extent to which a given option supports their current task goal. From this perspective, a signal that an option is highly rewarding can indicate that this option is more aligned with (i.e., more congruent with) the overarching goal of finding the best option, compared to a less rewarding option.
If choice value signals can carry either of these types of information, the striking implication is that correlates of choice value that have predominantly been interpreted as reflecting (directionally-consistent) reward value may have in fact reflected goal congruency instead. We recently tested this question by examining which of these two accounts better explains value-related neural activity as well as a common behavioral signature of choice value, the effect of overall value on choice speed. Past work has shown that people are faster to choose among a set of options (1) the greater the difference between the best option and the remaining options (higher value difference) and (2) the more valuable the options are on average (higher COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 9 overall value) 
(Hunt et al., 2012;
Pirrone, Azab, Hayden, Stafford, & Marshall, 2017;
Smith & Krajbich, 2019;
Teodorescu, Moran, & Usher, 2016)
. The former effect follows naturally from the fact that larger value differences make it easier to discriminate between the options (as is the case for more discriminable options in a perceptual decision-making task), the explanation for the latter, overall value, effect has been less straightforward. Drawing on the animal learning literature, one plausible explanation is that choice sets with high overall value are taken as signals of higher reward rates in the current environment, encouraging them to respond faster (e.g., more vigorously) in order to move on to the next choice sooner 
Niv, Daw, Joel, & Dayan, 2007;
Niv, Joel, & Dayan, 2006)
. However, it is also possible that high value options yield faster choices not because of their reward value but because of the fact that such options are more congruent with the typical goal of choosing the best option. Indeed, past work on recognition memory showed that when participants are asked to choose which of a set of items they had seen more frequently, they are faster to respond when sets were overall higher in frequency (holding constant the relative frequency of the options, the analog to value difference) 
(Guerin & Miller, 2011;
Hintzman & Gold, 1983)
. When they were asked to instead choose which item they had seen less frequently, this overall frequency effect reversed -now, participants were faster for sets with the lowest frequency items rather than the highest frequency items (as had been the case for the opposite instruction), suggesting that response speed was determined by how goal congruent those options were, rather than how high or low their frequency was. Thus, by reversing the task set, these authors were able to distinguish directionally-specific versus goal congruency accounts of item frequency on behavior.
To test the extent to which choice value effects were reward versus goal-specific, we borrowed a similar approach 
(Frömer, Dean Wolf, & Shenhav, 2019)
. On some blocks of trials, we had participants choose the item they most prefer out of a set of four options (as is standard), whereas on other blocks we had them instead choose the item they least prefer. Behaviorally, we found that higher-valued sets were associated with faster responding in the "choose best" task context (replicating numerous past studies 
(Hunt et al., 2012;
Pirrone et al., 2017;
Smith & Krajbich, 2019;
Teodorescu et al., 2016)
) but they were associated with slower responding in the "choose worst" context. When choosing the worst item, participants were instead faster the less good the choice set was as a whole, consistent with a goal congruency account ( 
Fig. 2 A, B
). We COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 10 were able to capture this finding using a modified leaky competing accumulator model 
(Bogacz, Usher, Zhang, & McClelland, 2007;
Usher & McClelland, 2001)
, according to which the current choice goal defined how the subjective value of a given item entered the evidence accumulation process -when the goal was to choose the worst item in a set, the least preferred items in a set provided the strongest evidence towards that goal (cf. Sepulveda et al., 2020 for a similar approach using GLAM and a generalization to perceptual choice). Using fMRI, we tested the complementary set of predictions for neural activity, in particular whether value-related BOLD activity in the valuation network would maintain directional consistency across these two choice contexts (suggesting that such activity always reflects how rewarding those options are, independent of the goal) or whether this value code would reverse when choosing the least preferred option (suggesting that such activity reflects goal congruency rather than reward value per se). We found that the latter coding scheme was the only one that accounted both for correlates of relative value and overall value in the valuation network ( 
Fig. 2 C)
. Recent work has extended these findings to show that even arbitrary goals such as lighting a fire versus tying a boat can flexibly warp putative value representations of options to reflect their usefulness for that goal 
(Castegnetti, Zurita, & De Martino, 2021)
, and that multiple potentially conflicting goals can be simultaneously represented in mOFC 
(Moneta et al., 2021)
. consistently observed that people are faster to choose when faced with high-value options compared to low-value options (holding choice difficulty constant). One account of these findings is that they reflect speeding effects related to expected reward per se. This reward-based account predicts that COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 11 participants respond faster when choosing among higher-valued options, regardless of whether their task is to choose the best or the worst option (left). A goal-congruency account predicts that this typical overall value effect should reverse when the participant's task is to choose the worst option (right). Across two studies, Frömer, Dean Wolf and  found behavior consistent with a goal-congruency account (bottom). C) BOLD activity within the value network tracked the relative and overall value of one's options in a goal-specific (directionally-flexible) rather than rewardspecific (directionally-consistent) manner. In addition to goal-values, this study found activity related with the overall reward value of options, potentially reflecting additional processes related to automatic appraisal (cf. 
Fig. 3
).
While our recent study provided strong evidence that neural signals of choice value can reflect goal congruency rather than reward value, that study also found evidence of directionallyconsistent overall value signals (i.e., always reflected how good the set was), over and above those associated with goal congruency (and in the absence of any corresponding directionallyconsistent relative value signals). This result suggests that there may be multiple forms of valuation occurring in parallel, a possibility we explore next.


Distinguishing value signals that are goal-related from those that are not
So far, we have focused on choice value as the medium through which people make their decisions. The default interpretation of neural activity in a given region associated with the values of one's options while making a decision, tends to be that this activity (e.g., correlates of relative value, overall value, and chosen/unchosen values) reflects an element of the decision process (e.g., valuation and/or comparison between options). Choice value signals are therefore treated analogously to goal-directed signals in studies of cognitive control, ones that might determine, for instance, whether to give a leftward or a rightward response based on the current stimulus and task set. However, a core assumption of cognitive control research is that engaging with a stimulus will often trigger more automatic (e.g., habitual) signals that are overlaid with (and sometimes compete against) the goal-directed ones.
In the context of value-based learning and decision-making, there is a form of automatic processing that is engaged by Pavlovian associations, that is, associations between stimuli/cues and expected outcomes that can trigger approach or avoidance behavior 
(Dickinson & Balleine, 1994)
. For instance, the smell of popcorn or cigarette smoke can trigger physiological responses and approach behavior for people who have positive associations with either 
(Wood & Neal, 2007;
Wood & Runger, 2016)
. Importantly, these Pavlovian processes are distinguishable from those that give rise to goal-directed decision-making, and a large body of work has demonstrated that these have distinct behavioral signatures 
(Dayan, Niv, Seymour, & Daw, 2006)
 and are underpinned by separable neural circuits (van der Meer, 
Kurth-Nelson, & Redish, 2012)
. Thus, despite correlates of option values being typically interpreted in goal-directed terms (i.e., as inputs to a value-based comparison), it is possible that these value signals are heterogenous in nature, reflecting both goal-directed and more automatic forms of value processing.
Recent work supports this heterogenous account of value signals observed during decision-making. For instance, Shenhav and Buckner (2014) had participants make value-based choices between pairs of goods, and later provide an overall appraisal of how good they had felt about each pair of options. Consistent with past work 
(Arana et al., 2003;
C. Padoa-Schioppa, 2013;
Strait, Blanchard, & Hayden, 2014)
, they found that activity in the value network (in particular, vmPFC) was greatest when participants were choosing between two options of similarly high value, compared to when they were choosing between options that differed in value or were similarly low in value. This finding aligns well with the interpretation that vmPFC is involved in choice comparison, and therefore tracks both the value of one's options and the demand for comparison between them 
(Hunt et al., 2012;
Camillo Padoa-Schioppa & Conen, 2017;
Pelletier & Fellows, 2019)
. This study found that activity in the value network during these choices (again, including vmPFC) also tracked how good subjects felt to see those options (appraisals that were assessed retrospectively, after subjects left the scanner). These appraisalrelated signals, denoting the overall value of one's options, were also broadly consistent with putative decision-making functions proposed for these value regions. For instance, some classes of evidence accumulation models -including the Leaky Competing Accumulator 
(Bogacz et al., 2007;
Usher & McClelland, 2001)
, which was used to account for behavioral variability in Frömer et al.' study of goal congruency -naturally generate overall value-like effects over the course of their dynamic processing of choice options 
(Hunt & Hayden, 2017;
Hunt et al., 2012)
.
Thus, both types of signals that this study observed in the value network could be accounted for within a goal-directed framework. What was surprising was that -across two experiments -these signals were consistently found in different parts of the value network.
Signatures of difficult high-value choices were found in a more ventral region of vmPFC, within medial OFC, whereas signatures of overall appraisal were found in a more dorsal regions, within pregenual ACC 
(Fig. 3B
). This dissociation within vmPFC was mirrored by an equivalent dorsalventral dissociation within regions of the posterior midline (retrosplenial cortex vs. PCC, COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 13 respectively). The canonical valuation network 
(Bartra et al., 2013)
 tends to encompass both sets of regions, despite evidence that this dorsal-ventral divide is also seen within patterns of structural and functional connectivity across these regions 
(Choi, Yeo, & Buckner, 2012;
Toro-Serey, Tobyne, & McGuire, 2020;
Yeo et al., 2011)
. The authors interpreted this finding to suggest that (a) these two forms of choice value signals may reflect distinct processes rather than two elements of a common goal-directed valuation process and that (b) the appraisal-related signals observed in the more dorsal regions (e.g., pgACC) may in fact reflect a relatively automatic (e.g., Pavlovian) response that occurs independently of choice 
(Grabenhorst & Rolls, 2011;
Lebreton, Jorge, Michel, Thirion, & Pessiglione, 2009)
.  
2014
found that dissociable networks track the appraisal of one's options (dorsal) versus choosing among them (ventral) (bottom left). Shenhav and Karmarkar (2019) followed up on this finding and showed that across an appraisal and a choice task, the dorsal network, always tracked how much people liked their options overall (top right), whereas the ventral network was significantly more active when participants choose among options rather than appraising them (bottom right). C) Frömer, Nassar, Ehinger & Shenhav (in submission) showed that appraisalrelated factors correlated with activity locked to stimulus onset, whereas choice-related factors correlated with activity locked to the response. These findings are consistent with appraisal of one's options occurring more rapidly and in parallel with goal-directed processes that lead up to one's response.
We recently performed two follow-up experiments to more directly test this hypothesized dissociation between more automatic appraisal occurring in parallel with goal-directed valuation.
In one study, we had participants evaluate sets of options and either choose between those COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 14 options (as in the earlier experiment) or appraise their overall value 
(Shenhav & Karmarkar, 2019)
. We found that BOLD activity in the more ventral cortical regions of the value network (including mOFC) was greater when participants were choosing compared to when they were appraising, consistent with a role in goal-directed decision-making. Conversely, we found that activity in the more dorsal regions (including pgACC) tracked how much participants liked the set overall, and did so irrespective of the task goal on that trial (i.e., whether it was an appraisal trial or a choice trial), consistent with a more automatic appraisal process 
(Fig. 3C
). Using EEG, in a more recent study we showed that appraisal-related and choice-related signals have distinct spatiotemporal profiles ( 
Fig. 3D
  ). Whereas choice-related variables (e.g., value difference, choice confidence) were most closely associated with response-locked EEG activity at fronto-central and centro-parietal electrodes (consistent with previous research on value-based evidence accumulation 
(Pisauro, Fouragnan, Retzler, & Philiastides, 2017;
Polania, Krajbich, Grueschow, & Ruff, 2014;
Polania, Moisa, Opitz, Grueschow, & Ruff, 2015)
), appraisal-related variables (e.g., overall value, set liking) were instead most closely associated with stimulus-locked EEG activity at parietal electrodes (consistent with past research on affective reactions to emotional stimuli (Abdel Rahman, 2011)).
Collectively, this work suggests that value-based choices trigger both goal-directed and automatic forms of evaluation, and that these different types of value signals occur within overlapping but dissociable circuits and time windows. Thus, it is possible for one form of value signal to be confused for another.


Exerting control over our current choice
Value-based choice has been successfully described using evidence accumulation models 
Hunt et al., 2012;
Krajbich, Armel, & Rangel, 2010;
Pisauro et al., 2017;
Polania et al., 2015
) and such models have been able to account for patterns of neural activity observed during value-based choice. This broad class of evidence accumulation modelsborrowed from research on judgments of memory and perception -describes how categorization problems are solved over time 
(Bogacz et al., 2007;
Fontanesi, Gluth, Spektor, & Rieskamp, 2019;
Ratcliff & McKoon, 2008;
Usher & McClelland, 2001
). According to these models, noisy evidence (decision-relevant information that varies across observations) is sampled from memory 
(Bakkour, Zylberberg, Shadlen, & Shohamy, 2018;
Shadlen & Shohamy, 2016;
Vaidya & Badre, 2020)
 and accumulated over time, and this process is terminated when a prespecified level of evidence (decision boundary) is reached. Classic (and widely used) versions of such models assume that the input to the accumulation process as well as the decision-bound are constant throughout a decision 
(Pisauro et al., 2017;
Polania et al., 2014;
Vassena, Deraeve, & Alexander, 2020)
, and that deciding for either option requires the same amount of evidence.
More recent work has shown that this is neither normative (i.e. the best way to solve the problem) nor always observed in value-based choice. In what follows, we will discuss ways in which control might be recruited to dynamically adjust the inputs to evidence accumulation, the threshold for deciding (decision-bound), and/or to inhibit biases towards particular options.


Controlling the flow of information
According to evidence accumulation models, decision-makers accumulate evidence for each option and that evidence competes to determine one's response. However, this approach quickly comes up against the limitations of our cognitive resources to collect and hold the necessary information in mind, particularly for large choice sets. One way that our control system can help resolve this is to focus attention on a subset of options at a time, and vary which options we attend to over the course of a decision. Researchers have shown that people do systematically adjust which options they attend to and, more importantly, that these attentional adjustments influence how those options are evaluated. For instance, when choosing among rewarding options, all else being equal, the longer an option is attended, the more likely it is to be selected 
(Armel, Beaumel, & Rangel, 2008;
Krajbich et al., 2010)
.
There are multiple proposals for how attention influences choice. One prominent account proposes that attention has the effect of increasing the influence of the attended option on evidence accumulation (by magnifying its value) and diminishes the influence of the unattended options 
(Fig. 4A
). This so-called attentional drift diffusion model (aDDM) explains why, for instance, greater attention to a rewarding option makes it more likely to be chosen and greater attention to an aversive option makes it less likely to be chosen 
(Armel et al., 2008)
. The aDDM has more generally been successful at accounting for the influence of overt attention (typically measured by the direction of eye gaze) on choice behavior 
(Smith & Krajbich, 2019;
Thomas, Molter, Krajbich, Heekeren, & Mohr, 2019)
 and associated neural activity 
(Lim et al., 2011
). An alternative account of attention's influence on choice is that attention serves to reduce COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 16 uncertainty in one's options rather than simply magnifying their value per se (Z. 
Li & Ma, 2020)
.
Here, attention helps construct the values of options using efficient coding 
(Polanía, Woodford, & Ruff, 2019)
. Under this account, items that are attended more have a stronger influence on choice merely because the decision-maker had more opportunity to sample their value.
Our understanding of how attention directs the flow of information has been improved by emerging work on how people decide where to deploy their attention. One account proposes that people direct their gaze towards options they believe to have a high value 
(Gluth, Kern, Kortmann, & Vitali, 2020)
, and shows that incorporating this account of gaze allocation into the aDDM can improve its ability to account for both eye movements and choice behavior. It can explain a gaze bias towards the option that is ultimately chosen, a bias that emerges as the choice progresses 
(Westbrook et al., 2020)
 and which may account for past observations of a direct influence of gaze on choice likelihood (J. F. 
Cavanagh, Wiecki, Kochar, & Frank, 2014;
Mormann & Russo, 2021)
. This model was inspired by research that suggests that rewards can "capture" attention in an automatic or bottom-up fashion 
(Anderson, 2019;
Anderson, Laurent, & Yantis, 2012;
Vaidya & Fellows, 2015)
, but a more recent set of studies shows that the allocation of gaze to the most promising options may be goal-driven rather than reward-driven. By varying the participant's choice goal between choosing the best option and the worst options, as in Frömer et al (2019), Sepulveda and colleagues (2020) showed that eye-movements are drawn towards the most goal-congruent option (see also 
Kovach, Sutterer, Rushia, Teriakidis, & Jenison, 2014)
 and that this goal-driven allocation of attention drove choice behavior in both value-based and perceptual decisions.
These findings resonate with an emerging new perspective that frames decision-making primarily as a process of active information search 
(Hunt, 2021)
. This view not only bridges decision-making with active information-sampling 
(Boldt, Blundell, & De Martino, 2019;
Cohen, McClure, & Yu, 2007;
Gottlieb, 2018;
Gottlieb, Cohanpour, Li, Singletary, & Zabeh, 2020;
Gottlieb & Oudeyer, 2018;
Hunt et al., 2018;
Hunt, Rutledge, Malalasekera, Kennerley, & Dolan, 2016;
Kaanders, Nili, O'Reilly, & Hunt, 2020;
Kobayashi & Hsu, 2019;
Kobayashi et al., 2021)
, extended behaviors 
(Callaway, van Opheusden, et al., 2021;
Holroyd & Yeung, 2012)
, and learning 
(Behrens, Woolrich, Walton, & Rushworth, 2007;
Frömer et al., 2020;
Nassar et al., 2012;
O'Reilly, 2013)
, it also highlights a fundamental control problem in decision-making.
Accordingly, a group of recently proposed process models puts information search at the core of the decision process 
(Callaway, Rangel, & Griffiths, 2021;
Jang, Sharma, & Drugowitsch, 2021;
Song, Wang, Zhang, & Li, 2019)
. These authors address the question of how information should be sampled through gaze based on what the decision-maker knows, and doesn't know, at a given point in time. Here, gaze is used as a means to reduce uncertainty in a goal-directed way. In effect, this expands the decision-makers response space, such that in addition to choosing any of the choice options, the decision-maker can now also decide to keep sampling the current option or shift their gaze to any of the alternative options 
(Fig. 4A)
. The decision-maker makes these decisions continuously 
(Yoo, Hayden, & Pearson, 2021)
 rather than making one discrete choice at the end. This perspective change could have implications for our interpretations of behavioral and neural correlates of choice value. Active sampling requires representations of uncertainty for each option's value individually and relative to the values of the others (I might be more certain that option A is better than option B than in the specific value of option A). It also requires decisions about whether to exploit the current option or shift gaze and sample the other one.
dACC activity has been linked to both levels of uncertainty and decisions to explore one's environment (Bobadilla-Suarez, Guest, & Love, 2020; J. F. 
Cavanagh, Figueroa, Cohen, & Frank, 2012;
Cohen et al., 2007;
Monosov, 2017
Monosov, , 2020
White et al., 2019)
, as well as to conflicts in the decision of what to attend to 
(Shenhav, Straccia, Musslick, Cohen, & Botvinick, 2018)
.
These all thus offer salient alternative interpretations of choice-related activity to evidence accumulation. As we will review next, monitoring mechanisms likewise impact how much information we gather before we decide. 


Controlling our threshold for deciding
Control can not only adjust the flow of information for a decision but also play a role in determining how much information is sufficient in order to make a choice. Within the evidence accumulation framework, a default solution to this problem is to specify a predetermined amount of evidence that needs to be accumulated in support of one option over another, which is referred to as the decision bound or decision threshold 
(Ratcliff & McKoon, 2008;
Schulz, Fleming, & Dayan, 2021)
. The bound assures a desired level of accuracy, on average, while limiting deliberation time in a principled and evidence-dependent way. For a given bound, the stronger the evidence the faster decisions will be made, and the weaker the evidence the more time the decision-maker will allow the decision to take. The height of one's threshold thus determines their speed-accuracy tradeoff, with higher thresholds producing slower and more accurate choices and lower thresholds producing faster and less accurate choices. Theoretically, the same decision threshold can be maintained across all tasks and across all choices within a given task, but there are a variety of factors that may lead someone to want to adjust their decision threshold.
First, people may have reasons to specifically prioritize speed over accuracy or vice versa 
(Wickelgren, 1977)
, leading them to lower or raise their threshold accordingly. The motive for this can be extrinsic -for instance if the individual is explicitly instructed to focus more on one goal than the other 
(van Veen, Krug, & Carter, 2008)
 -but these priorities can also arise from intrinsic motives. For example, research has shown that people tend to set higher thresholds than is generally optimal (e.g., vacillating over options that are equally rewarding; 
(Oud et al., 2016;
Shenhav & Buckner, 2014)
), which may be accounted for by a general bias towards being accurate and/or aversion to making an error 
(Bogacz, Brown, Moehlis, Holmes, & Cohen, 2006;
Bogacz, Hu, Holmes, & Cohen, 2010;
Simen et al., 2009)
.
A second factor that can warrant threshold adjustments is the presence of a deadline.
Having a single threshold means waiting until a specific quantity of evidence is accumulated, which is not always guaranteed to happen within a desired time window. One solution to this is to set a lower threshold (as in the example above) but, in addition to still not offering a guaranteed time window (e.g., if the evidence is very weak), it also sacrifices the accuracy across all choices. An alternate way of addressing this is to vary the threshold over the course of a decision, such that it is initially high enough to achieve a reasonable speed-accuracy tradeoff but then gradually lowers ("collapses") over time, reaching a minimum close to one's time deadline (e.g., 2 seconds) 
(Frazier & Yu, 2007;
Karsilar, Simen, Papadakis, & Balci, 2014;
Miletic & van Maanen, 2019)
. This guarantees that some response is made by that point, but allows that choice to be noisier or more random the closer the participant is to the deadline.
People can also adjust their threshold based on information they acquire about the choice options. For instance, when they experience high levels of conflict between their options (i.e., when those options are similarly valued), they increase their threshold for responding on that trial (J. F. 
Cavanagh et al., 2011;
Fontanesi, Palminteri, & Lebreton, 2019;
Frank, 2006;
Frank et
 COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 20 al., 2015; 
Frank, Samanta, Moustafa, & Sherman, 2007)
, buying the decision-maker time to identify the best option 
(Fig. 4B)
. These conflict-related decision threshold adjustments have been shown to be mediated by the same circuits that are involved in guiding analogous conflictrelated control adjustments in typical cognitive control tasks, namely through interactions between dACC, which detects the need for control 
(Botvinick, Nystrom, Fissell, Carter, & Cohen, 1999;
Pochon, Riis, Sanfey, Nystrom, & Cohen, 2008)
, and subthalamic nucleus (STN), which acts as a global break 
(Frank, 2006;
Frank et al., 2015;
Frank et al., 2007)
.
Conflict provides an indication that the decision-maker may benefit from additional evidence, but how do they balance that against the costs of delaying their choice? After all, taken to the extreme, this approach of increasing thresholds in response to conflict leads one down the dirty path to Buridan's ass, the allegorical donkey who famously starved to death between two equally-sized hay stacks 
(Lipowski, 1970
(Lipowski, , 1971
 . Clearly, if one's options are the same (or indiscriminately similar), no amount of time will help choosing correctly among them. It has recently been shown that a collapsing bound can also provide the optimal solution to this problem 
(Tajima, Drugowitsch, Patel, & Pouget, 2019;
Tajima, Drugowitsch, & Pouget, 2016)
, balancing the value of additional information against the opportunity costs associated with the additional time required to make a response. Consistent with predictions of this account, both these costs and benefits have been shown to influence decisions of how much additional information to collect 
(Gluth, Rieskamp, & Buchel, 2012)
.


Controlling which option we choose
The point of decision-making is to identify which option best suits our goal. Since we typically start from a position of not knowing which option is best, it is generally in our best interest as decision-makers to start a decision by giving each option equal footing in the race towards a decision threshold. There are however, many cases in which some information is available before our choice or where we have a natural inclination toward one option over the other. We may for instance have a favorite dish at our local restaurant that we choose most of the time or tend to follow the chef's daily recommendation -whatever that is. In the framework of evidence accumulation, such biases are captured through asymmetries in the bound heights or starting point biases 
(Mulder, Wagenmakers, Ratcliff, Boekel, & Forstmann, 2012)
. That makes it easier to pick the bias option and requires that we accumulate more evidence for the alternative.
Some of these biases are goal-directed and adaptive. For instance, if one knows that there are regularities in one's choice environment that render one choice more likely than the other (e.g. that the chef's recommendations are typically the best choice), biasing one's starting point speeds up decision-making at no considerable cost. Leveraging structure this way may even help make better decisions on average when choices are difficult, as when momentary evidence is weak 
(Braun, Urai, & Donner, 2018)
. In such cases, the bias will facilitate the optimal decision most of the time. There are, however, also cases in which these biases are more habitual and potentially maladaptive. Several such biases are well documented, including loss aversion, immediacy, and default bias. In these cases, the biases lead to poorer decisions and choosing against them requires investing additional time and effort. For instance, for economically equivalent outcomes, people tend to choose the certain option over gambles, when it is framed as a gain, while choosing gambles over those same options when they are framed as a loss (De 
Martino, Kumaran, Seymour, & Dolan, 2006;
Tversky & Kahneman, 1981)
. People also tend to prefer immediate over delayed rewards, but these preferences can be altered by changing people's reference point in a similar way as the gain/loss framing 
(Lempert & Phelps, 2016;
Weber et al., 2007)
. When the options are framed as a reward in the future that can be accelerated by forgoing part of the reward, people prefer the later reward instead of the immediate reward (G. F. 
Loewenstein, 1988
). These findings demonstrate that the reference point for choices influences how they are made. Even for simple perceptual judgments, people exhibit a status quo bias that makes choices against the default require outsized evidence in their favor 
(Fleming, Thomas, & Dolan, 2010)
. Thus, when in doubt, people stick with the default 
(Bruckner, Nassar, Li, & Eppinger, 2020)
. Such a bias towards the status quo also leads people to overharvest in foraging tasks and require outsized evidence in favor of leaving a depleting patch 
(Kolling, Behrens, Mars, & Rushworth, 2012;
Shenhav, Straccia, Botvinick, & Cohen, 2016;
Shenhav, Straccia, Cohen, & Botvinick, 2014)
.
Choosing against these biases is associated with greater dACC activity, consistent with its involvement in default override in cognitive control tasks 
(Botvinick, Braver, Barch, Carter, & Cohen, 2001
). For instance, dACC activity increases when overcoming one's bias to respond according to the status quo 
(Fleming et al., 2010)
 or to respond based on Pavlovian drives (J. F.


COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 22
Cavanagh, Eisenberg, Guitart-Masip, Huys, ), suggesting that these and other forms of override that occur during value-based choice engage similar control mechanisms as those responsible for overriding automatic responses in standard response conflict paradigms (e.g., Stroop or flanker tasks) within research on cognitive control. Venkatraman and colleagues 
(Venkatraman, Payne, Bettman, Luce, & Huettel, 2009;
Venkatraman, Rosati, Taren, & Huettel, 2009
) provided direct evidence for this, showing that nearby regions of dACC signal (a) Strooplike conflict between responses, (b) value-based conflict between similarly valued decision options , and (c) the need to override one's default strategy for selecting between those valuebased options.
Choice biases can therefore significantly impact how correlates of choice value are interpreted. For instance, when the decision-maker is biased towards harvesting their current patch of rewards rather than switching to a different patch, as is typically the case in foraginglike environments 
(Kane et al., 2019)
, enticing them to switch can result in greater levels of choice conflict and, with it, the need to potentially exert control to override that stay bias. Thus, neural correlates of the value of a non-default response (e.g., the value of foraging) can capture signatures of decision conflict and default override such as those observed by Venkatraman and colleagues 
(Kolling et al., 2012;
Shenhav et al., 2016;
. The converse is true of correlates of the value of the default response (e.g., the value of staying 
(Shenhav et al., 2016)
), which can capture activity related to the ease of choice, the relevance of which we discuss in the next section.


Exerting control beyond our current choice
We have so far discussed choices the way they are typically studied: in isolation.
However, we don't make choices in a vacuum, and our current choices depend on previous choices we have made 
(Erev & Roth, 2014;
Keung, Hagen, & Wilson, 2019;
Talluri et al., 2020;
Urai, Braun, & Donner, 2017;
Urai, de Gee, Tsetsos, & Donner, 2019)
. One natural way in which choices influence each other is through learning about the options, where the evaluations of the outcome of one choice refines the expected value (incorporating range and probability) assigned to that option in future choices 
(Fontanesi, Gluth, et al., 2019;
Fontanesi, Palminteri, et al., 2019;
Miletic et al., 2021
). Here we focus on a different, complementary way, central to cognitive control research, where evaluations of the process of ongoing and past choices inform the process of future choices 
(Botvinick et al., 1999;
Bugg, Jacoby, & Chanani, 2011;
Verguts, Vassena, & Silvetti, 2015)
. In cognitive control research, these choice evaluations and their influence on subsequent adaptation are studied under the umbrella of performance monitoring 
(Carter et al., 1998;
Ullsperger, Fischer, Nigbur, & Endrass, 2014)
. Unlike option-based learning, performance monitoring influences not only which options are chosen, but also how subsequent choices are made. It also informs higher order decisions about strategy and task selection 
(Fig.    5A
).


Monitoring to adjust future decisions
We have reviewed earlier that people rely on performance monitoring (e.g. conflict) to detect the need to adjust decision parameters online. While only signals preceding the initial decision can be used to trigger such adaptation of the ongoing response, monitoring continues beyond this initial decision and dynamically updates estimates of the goodness of the decision as novel information becomes available 
(Fig. 5B
)(Calder-Travis, 
Charles, Bogacz, & Yeung, 2020;
Charles & Yeung, 2019;
Desender, Donner, & Verguts, 2021;
Shapiro & Grafton, 2020;
Steinhauser & Yeung, 2010
, 2012
Ullsperger et al., 2014;
Yeung, Botvinick, & Cohen, 2004;
Yeung & Cohen, 2006;
Yeung & Nieuwenhuis, 2009;
Yeung & Summerfield, 2012)
.
Collectively, these signals can be leveraged to adjust the parameters of subsequent choices.
People for instance slow down following incorrect choices 
(Fischer, Nigbur, Klein, Danielmeier, & Ullsperger, 2018)
 and bias information-processing in favor of goal-relevant information following the experience of conflict 
(Bejjani, Tan, & Egner, 2020;
Botvinick et al., 1999;
Fröber, Stürmer, Frömer, & Dreisbach, 2017)
. Surprisingly little empirical work has been done to explore to what extent such dynamics impact value-based decisions. Within the domain of perceptual decision-making, research suggests that people use performance monitoring to inform future decisions parameters. People for instance have a sense of confidence in their decisions 
(Fig. 5B)
, often conceptualized as the subjective probability that a choice was correct 
(Pouget, Drugowitsch, & Kepecs, 2016)
.
Continued evaluations of choices can elicit changes in confidence and, at the extreme, changes of mind 
(Resulaj, Kiani, Wolpert, & Shadlen, 2009;
van den Berg et al., 2016;
Yeung & Summerfield, 2012)
, and such continued evaluations are reflected in shared neural correlates of confidence and error monitoring 
(Boldt & Yeung, 2015;
Murphy, Robertson, Harty, & O'Connell,
 COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 24 2015; 
Vaccaro & Fleming, 2018)
. It has been proposed that one's momentary sense of confidence both reflects and guides the amount of evidence accumulated for decision-making 
(Yeung & Summerfield, 2012)
. In line with this idea, when given the option to seek additional information following initial choices, people are more likely to do so when their confidence is low, but not low enough to invoke a change of mind, that is when they are most uncertain whether their choice was correct or an error 
(Desender, Boldt, & Yeung, 2018;
Desender, Murphy, Boldt, Verguts, & Yeung, 2019;
Schulz et al., 2021)
. In the absence of such an option, people respond to choices made with low confidence by increasing their choice caution (decision bound) on subsequent choices, similar to post-error slowing 
(Desender, Boldt, Verguts, & Donner, 2019)
.
Experiences of confidence can inform parameters not only for decisions immediately following the current one, but also exert an influence at longer time scales by informing expectations of how likely one is to choose correctly when making similar decisions. It has been proposed that evidence accumulation is effortful and that decision-makers economize the time spent on it 
(Drugowitsch, Moreno-Bote, Churchland, Shadlen, & Pouget, 2012)
. People invest more cognitive effort when they expect those efforts to be rewarding and for those efforts to matter for achieving those rewards (i.e., when they expect their efforts to be efficacious) 
(Frömer, Lin, Dean Wolf, Inzlicht, & Shenhav, 2021;
Schevernels, Krebs, Santens, Woldorff, & Boehler, 2014;
Shenhav et al., 2013;
Shenhav, Prater Fahey, & Grahek, 2021)
. Because expectations about confidence predict accuracy and thus the delivery of rewards, such confidence signals can be considered value signals in themselves 
(Lebreton et al., 2015)
 and thereby inform the extent to which engaging in effort is worth it. People should therefore be more motivated to engage in and accumulate evidence for types of choices associated with high confidence. Indeed, that is what 
Boldt, Schiffer, Waszak, and Yeung (2019)
 found. Participants were cued with the type of the upcoming choice and learned to associate each cue with a level of confidence. They invested more effort, in that they prepared more (indicated by larger preparatory EEG activity between cue and target) and adopted a higher threshold when they had higher confidence in the upcoming choice type (indicated by larger peak amplitude in decision-related EEG activity, and confirmed with computational modeling). This finding contrasts with the typical bound increase following low confidence or errors, and probably reflects different origins of low confidence that call for different adjustments. On one hand, low confidence can indicate that insufficient evidence was accumulated prior to making a choice, which prompts a higher threshold to avoid repeated COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 25 premature responding. On the other hand, it can also indicate that the evidence available for a decision is weak, in which case there is marginal return for longer evidence accumulation, prompting a lower decision bound 
(Fig 5 D)
. In the former situation, accumulating evidence longer is worthwhile, while in the latter it is not. and then decreases again as the conflict is resolved and the right option is correctly identified. The confidence in the initial decision was low, and the error in approaching this boundary was detected. C) Confidence increases monotonically with the probability that one's choice was correct/good. In contrast, uncertainty is low when an error was detected, as well as when the response is unambiguously correct. Confidence can also serve as a proxy for feedback -low confidence serves as a negative reinforcement signal, whereas high confidence serves as a positive reinforcement signal. D) Uncertainty can be reduced by sampling longer, but is also influenced by the strength of the evidence. Sampling is more efficacious when evidence strength is high compared to when it is low, leading to higher certainty and confidence gains. One's past experiences of confidence can inform how much evidence accumulation is worthwhile.
The worth and worthwhileness of prolonged evidence accumulation should not just depend on properties of the ongoing (or in this case upcoming) choice, but also how valuable alternative choices are that could be made during that time. This is another way in which past choices can influence the parameters of future choices; by shaping expectations about the value COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 26 of future choices. A plethora of work has shown that humans and animals alike increase response vigor with increasing reward rates 
(Niv, Daw, et al., 2006;
Niv et al., 2007;
Niv, Joel, et al., 2006)
. This behavior was explained as an attempt to reduce the opportunity cost of sloth, which increases as the amount of reward increases that is forgone through inaction. 
Otto and Daw (2019)
 recently demonstrated that this principle extends to incentivized perceptual decisionmaking. They varied the magnitude of rewards people would receive for accurate perceptual decisions and showed that people adopt a lower decision threshold as the reward rate goes up, allowing them to complete more trials. Decision-makers thus balance the trade-off between maximizing reward on the current trial versus obtaining rewards on other choices. To achieve that, they need to make higher order decisions about when to decide 
(Boureau, Sokol-Hessner, & Daw, 2015;
Dayan, 2012;
Gluth et al., 2012)
. When the current choice requires a great deal of effort or takes a long time, whereas other potential choices promise greater rewards, it is normative to cut one's losses and move on to the next choice. Yet, the effort and time requirements typically only become apparent while making the choice. A principled solution to achieve this balance is therefore to employ a collapsing bound (see above) and calibrate its shape to the expected reward and ease of alternative choices 
(Tajima et al., 2016)
. To do that, people would need to monitor and update the value of their choice context as well as the effort and confidence associated with their decisions. This offers yet another potential interpretation of neural correlates of either value difference or overall value. Instead of being integral to the ongoing choice process itself, they might reflect the tracking and updating of variables relevant to control 
Kane et al., 2021;
Y. S. Li, Nassar, Kable, & Gold, 2019)
.
Just as rewards can serve as training signals to guide future choices, so can confidence and conflict 
(Yeung & Summerfield, 2012)
. For instance, people use confidence as a proxy for feedback when actual feedback is not available or delayed, as is often the case in real world decisions 
(Carlebach & Yeung, 2020a;
Guggenmos, Wilbertz, Hebart, & Sterzer, 2016;
Ptasczynski, Steinecker, Sterzer, & Guggenmos, 2021)
. High confidence -or ease -then can serve as a positive reinforcer 
(Winkielman, Schwarz, Fazendeiro, & Reber, 2003)
. Conversely, conflict-related signals -including errors and subjective effort -have been proposed to reinforce avoidance 
(Botvinick, 2007)
. Indeed, people are more likely to subsequently reverse choices made with low confidence 
(Folke, Jacobsen, Fleming, & De Martino, 2016;
Shenhav & Buckner,
 COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 27 2014) and conflict signals have been found to diminish reward-based approach learning and enhance punishment-based avoidance learning (J. F. 
Cavanagh, Masters, Bath, & Frank, 2014
).
These findings demonstrate that monitoring influences valuation and comparison of subsequent choices. We will next discuss how similar decision-making factors, related to reinforcement and opportunity costs, shape higher-order decisions.


Monitoring over multiple levels of a response hierarchy
So far we have focused on the ways in which monitoring informs how we select responses. These decisions -among response options (e.g., which item to select) -are not the only ones that people make and monitor, but a hierarchy of decisions are made and evaluated in parallel (cf. 
Fig. 5A
). It is clear from a large body of literature that people use a range of different strategies to make choices, and that strategy selection is influenced by features of the choice problem, the choice context, and individual characteristics of the decision-maker 
(Beach & Mitchell, 1978)
. For instance, people adjust attentional priorities under time pressure, resulting in different choice patterns than in the absence of time constraints 
(Teoh, Yao, Cunningham, & Hutcherson, 2020)
. They also adjust how thoroughly they attend to each of their options based on the size of the set and which options they encounter while searching it 
(Thomas, Molter, & Krajbich, 2021)
. In this section, we review the mechanisms that inform such higher order adjustments.
In many instances people have learned the strategies they use based on previous experience. A variety of strategies people use when making decisions, such as risk-minimizing strategies 
(Erev & Barron, 2005)
, are rooted in biases in previously experienced outcomes which shape choice strategies over time 
(Erev & Roth, 2014)
. Participants may for instance be more likely to engage a risk-minimizing strategy when they have happened to experience disproportionately more negative outcomes. Such learning need not be driven by the chosen outcome only, but also the counterfactual one that was forgone. Counterfactual feedback elicits behavioral adjustments just like factual choice outcomes and through similar mechanisms 
(Fischer & Ullsperger, 2013)
. For instance, when provided with counterfactual choice outcomes that elicit regret, people adjust their decision strategy in a way to minimize future regret at the expense of maximal reward 
(Coricelli et al., 2005)
. Like errors or negative feedback, COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 28 counterfactual outcomes that elicited regret were associated with increased activity in dACC, and so were decisions to minimize regret at the expense of reward.
It is conceivable that we experience similar negative emotions to regret when our efforts are not justified by their outcomes, including lower confidence than we expected. Such negative evaluations of the choice process are thought to teach us to avoid strategies whose costs exceed their benefits 
(Botvinick, 2007)
. In line with this framework, the engagement of control appears to be registered as a subjective cost (mental effort; 
(Westbrook & Braver, 2015)
, that drives choices to avoid such costs   
(Desender, Buc Calderon, Van Opstal, & Van den Bussche, 2017;
Dunn, Lutes, & Risko, 2016;
Kool, McGuire, Rosen, & Botvinick, 2010)
, unless offset by sufficient expected reward 
(Westbrook et al., 2019)
. People thus select choice strategies that balance the value of the outcome itself against the (cognitive) cost of obtaining it (D. G. 
Lee & Daunizeau, 2021;
Shenhav et al., 2013)
. One well-known consequence of this is that people may choose to satisfice rather than put in the effort to maximize rewards 
(Wabba & House, 1974)
 , as they for instance increasingly do as their option set grows 
(Thomas et al., 2021)
. To find the strategy that optimizes the balance between outcome and effort, people could monitor not only the outcome itself, but whether it was worth the cost of the strategy that brought it about 
Lieder et al., 2018;
Shenhav et al., 2017)
. Thus, a variety of signals derived from performance monitoring, including evaluations of outcomes and conflict, could inform the cost-benefit evaluation of choice strategies, influence how choices under consideration are made, and be leveraged to adjust choice strategy selection across multiple choices. These signals all likely correlate with and are thus easily misattributed to choice value. These same signals may also influence which choices are sought out and whether choices are made at all.
Another way in which monitoring guides higher order decisions is by informing the value we assign to tasks. We have mentioned earlier that engaging in one choice typically comes at the expense of engaging in something else. We thus need to choose at all times what to engage with and, by extension, what not to engage with. To make this choice, we need to learn, monitor and update the costs and benefits associated not only with options or strategies, but with entire tasks.
There is growing evidence that people determine the value of engaging in a given task by learning abstract features of their environment (e.g. reward rate -how good is my current environment?) 
(Wittmann et al., 2016)
 or of their own capacities (global performance on a task -COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 29 how good am I at this?) 
(Rouault, Dayan, & Fleming, 2019)
. It is becoming increasingly clear that people use such information to adjust behavior in flexible ways when given the opportunity to do so. One example is a recent study that modified the standard foraging paradigm, where people need to decide when to abandon a depleting patch for an unknown new one 
Shenhav et al., 2016;
 so that people could revisit previous patches and decide where to forage next. 
Hall-McMaster, Dayan, and Schuck (2021)
 showed that people learn and represent reward rates of different patches and use this information to choose patches that maximize reward. Importantly, they also leverage information about the rewards at other patches to adaptively adjust decisions about when to leave the current patch. Thus, ubiquitous neural representations of overall value in value-based choice may not be related to the ongoing choice at all , but instead may reflect an automatic evaluation of a choice context that under typical real-world circumstances could be used to determine whether to engage with that context again in the future (cf. 
Shenhav & Karmarkar, 2019)
.
People do not require explicit rewards to estimate the values of tasks. They can estimate how worthwhile engaging in a task is by integrating experiences of local confidence into taskdependent expectations of success 
(Boldt, Schiffer, et al., 2019;
Rouault et al., 2019)
. It has been proposed that -similar to reward -confidence may serve as a common currency to compare and prioritize between tasks (de Gardelle, Le 
Corre, & Mamassian, 2016;
de Gardelle & Mamassian, 2014)
. In line with this proposal, people prioritize higher confidence tasks over lower confidence tasks when sequencing tasks, all else being equal 
(Aguilar-Lleyda, Lemarchand, & de Gardelle, 2020)
. Given that confidence is typically higher for easier tasks, these findings could reflect another instance of effort avoidance 
(Desender et al., 2017;
Dunn et al., 2016;
Kool et al., 2010;
. In a series of experiments, Carlebach and Yeung (2020b) tested explicitly whether confidence -like effort -acts as a cost-benefit factor when choosing between tasks. They asked participants to choose between tasks that were identical with regards to demands and performance, but elicited different levels of confidence through varying post decision evidence. Participants avoided tasks in which they had made an error but, more importantly, preferred tasks in which they were more confident in their correct responses. This preference for high confidence tasks prevailed even when feedback was provided, ruling out a simple reward-learning account in favor of a more nuanced cost-benefit estimation.
Collectively, the work reviewed above shows that monitoring informs cost-benefit decisions across multiple levels, from the selection of options to the selection of decision parameters to the selection of choice strategies to the selection of tasks to engage with. This highlights the remarkable efficiency of the deciding mind that recycles information to optimize decisions across multiple time-scales and levels of abstraction. At the same time, it underscores the tremendous credit assignment problem we face when interpreting the functional significance of these signals.


Monitoring ongoing cognitive processes
Up to now, we have focused on the implications of cognitive control for decision-making, including for one's current decision, subsequent decisions, and other types of decisions. But the set of controlled cognitive processes that decision-making draws on -including attention, working memory, and episodic memory -are also required for other tasks that an individual needs to perform, often in parallel or in sequence with the need to make a decision. The information generated while evaluating one's choices, and the processes that are engaged, thus help determine what resources are available to or required of choice. Information generated while evaluating one's choices can therefore impact a person independently of its influence on a given decision. While research in this area is still relatively limited, in this section we extrapolate from work highlighted above to identify important areas of intersection that would benefit from further research.
Earlier, we discussed the important role that choice conflict can play as a signal that additional information may be needed for the current decision (i.e., adjusting decision threshold).
But conflict can also serve as a signal that additional cognitive resources are needed for the current task and thus that potentially fewer resources are available to other tasks being performed in parallel 
(Botvinick, 2007;
Lehle, Cohen, Sangals, Sommer, & Sturmer, 2011)
. For instance, it is possible that when engaged in a difficult decision (e.g., which item on the menu to select or which school to attend) we may have more difficulty engaging in other control-demanding tasks (cf. 
Navon & Miller, 1987)
. Choice conflict serves as a direct proxy for how long a decision will take  and thus how many cognitive resources this will draw on in terms of overall attention to one's options, maintaining relevant information in working memory, and/or directing search through episodic memory 
(Botvinick et al., 2001;
Chong & Akrami, 2021;
 COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 31 
Grinband et al., 2011)
. Being aware of the potential drain on cognitive capacity caused by a given decision may further influence what other tasks the person chooses to achieve in parallel (e.g., how many items to try to remember from your shopping list, or what kind of conversation to engage in with your dinner partner). Such signals can also help determine whether additional cognitive resources need to be directed to any of those tasks.
Decisions can also induce surprise. One's options can be unexpectedly good or unexpectedly bad, and the choice between them can be unexpectedly easy or unexpectedly hard 
(Lin, Saunders, Hutcherson, & Inzlicht, 2018;
Vassena et al., 2020;
Williams, Ferguson, Hassall, Wright, & Krigolson, 2021)
. Whether it is in reaction to oddball stimuli, unexpected noises, or unpredicted events, research has shown that the experience of surprise triggers changes in physiology and cognition, including changes in overall attention (to detect changes in the environment), arousal, pupil diameter, affective appraisals, and levels of caution 
(McNaughton & Gray, 2000;
Notebaert et al., 2009;
Sokolov, 1963;
Wessel, 2018a
Wessel, , 2018b
Wessel et al., 2016)
. As in the examples above, such reactions to surprise or novelty while making a decision can occur independent of the decision process itself. That does not mean that they have no bearing on cognitive control. Those same surprise signals can serve as a proxy for additional demands for cognitive control being redirected towards other tasks 
(Razmi & Nassar, 2021)
, and/or the downstream impact of such attentional reorienting on one's ability to maintain focus on the current decision-making task 
(Shenhav, Musslick, Botvinick, & Cohen, 2020
).
Finally, choices can trigger affective reactions. First, conflict can itself induce negative affective states and concomitant bodily reactions 
(Braem et al., 2017;
Dreisbach & Fischer, 2015
) and thus can serve as an indirect proxy for the demand for additional regulatory resources 
(Shackman et al., 2011;
Wager et al., 2016)
. Second, as reviewed earlier, the choice options themselves also, and in parallel, trigger affective reactions related to how good or bad those options are 
(Shenhav & Buckner, 2014;
Shenhav, Dean Wolf, & Karmarkar, 2018)
. Thus, considering options for delicious foods or potential vacation spots often entails generating anticipatory affective reactions to those enjoyable outcomes (B. 
Knutson & Greer, 2008;
Brian Knutson, Rick, Wimmer, Prelec, & Loewenstein, 2007;
G. Loewenstein, 1987)
, and the same is true for aversive decisions like which of several risky medical procedures to undertake 
(Botti, Orfali, & Iyengar, 2009)
. These affective reactions can contribute in a goal-directed way, as part of the process of accumulating evidence for different courses of action 
(Sharot & Sunstein, 2020)
. But, as the example of medical decision-making makes vivid, the affective states that are induced when considering potential future outcomes can independently influence cognitive processing 
(Shenhav & Buckner, 2014;
Shenhav & Karmarkar, 2019)
. Such changes in affective or mood state can influence where and how we direct our attention (e.g., to mood-congruent information) and how effectively we engage controlled resources 
(Dreisbach, 2006;
Grahek, Musslick, & Shenhav, 2020;
Mather & Carstensen, 2005;
Moser, Moran, Schroder, Donnellan, & Yeung, 2013
Proudfit, Inzlicht, & Mennin, 2013;
van Steenbergen, Band, & Hommel, 2010)
. To remain focused on the decision-making task at hand, additional cognitive resources may be required to regulate the influence of these changes in affective state, and concomitant alterations in bodily state, on ongoing cognition.


Decisions and control over future research directions
We have reviewed work that incorporates ideas from cognitive control to provide novel insights into value-based decision-making. We highlighted the importance of decision makers' goals for understanding the relationship between preferences and behavior, and that neural activity can separately reflect the value of one's options with respect to one's current goal and the choice-independent affective appraisal of those same options. We have outlined how control helps guide information flow, response caution, and helps overcome choice biases. And, finally, we have reviewed work that investigates how the same monitoring functions that help evaluate our current choice also shape our behavior beyond the current choice, and even beyond decisionmaking entirely. A set of common themes emerges from the sum of this work, which in turn point to remaining gaps in the literature and potential research directions aimed at addressing those gaps. First, the representation and processing of value-related information is incredibly flexible, suggesting that people can make choices in many different ways. Second, decision-making occurs across multiple levels of hierarchy and over multiple time scales, and each of these represents a target for control. Third, in parallel to decision-making, monitoring supports these different control adaptations. Together, these directions support an overarching aim of understanding what determines how an individual makes their choices, and of computationally and neurally dissociating mechanisms underpinning the decision-making process from those that underpin how decision-making influences and is influenced by cognitive control.
To achieve this, future work would benefit from studying a greater variety of choice contexts that considers the cognitive resources and cognitive flexibility that decision-makers have at their disposal. It remains unclear how the brain decides whether to compute and compare value (and/or how precisely) versus using a simplifying approach to generating a choice 
(Hayden & Niv, 2021)
, nor what the underlying computations and neural value correlates of simplified choice strategies are 
(Binz, Gershman, Schulz, & Endres, 2020;
Dayan, 2012)
. Decision-makers could, for instance, rely on memory to retrieve previous solutions rather than recomputing value and comparison each time 
(Dasgupta & Gershman, 2021)
, or they could have heuristics such as always choosing certain options if they are part of the set (e.g. if the vending machine has Snickers, I get Snickers and ignore the other options).
Many of the choice paradigms reviewed above use small sets of options, both across and within choices, which allows for such strategies, so that it is possible that participants in these studies might not engage in the type of choice we assume they are. In particular, many of the neuroscience findings are based on two-alternative forced choices among a small set of options.
If familiarity with a small set of options allows the choice to be reduced to a perceptual one or a simple recognition task, we might have identified correlates of choice value that really reflect signatures of perceptual decision-making 
(Pisauro et al., 2017)
, object/state recognition 
(Grill-Spector & Kanwisher, 2005)
, or direct retrieval of a learned policy 
(Hayden & Niv, 2021)
.
Indeed, it has recently been shown that decision-makers change how they interact with their options as they become more and more familiar with them, as evidenced by changes in their gaze patterns (S. E. 
Cavanagh, Malalasekera, Miranda, Hunt, & Kennerley, 2019)
. Finer-grained estimates of choice dynamics such as gaze or mouse tracking therefore hold promises for further elucidating interactions between strategic/heuristic processes and more comprehensive evaluations 
(Callaway, Rangel, et al., 2021;
Hunt et al., 2016;
Jang et al., 2021;
Stillman, Krajbich, & Ferguson, 2020)
. Computational models that explicitly address these interactions may then also scale better to larger choice sets, where strategies that reduce information processing costs play a much more prominent role 
(Thomas et al., 2021)
, and could provide insights into the mechanisms by which decision-making is adapted to changing contextual demands 
(Teoh et al., 2020)
.
Investigating alternative ways in which people choose -and the cognitive computational and neural mechanisms they employ to do so (perhaps routinely) -requires utilizing paradigms COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 34 that afford these strategies. Currently, choices are often studied "all else being equal", omitting many features of more naturalistic choices such as contextual and temporal dependencies, competing alternative tasks, control over choices, etc. by design 
(Gabay & Apps, 2020;
Mormann & Russo, 2021;
Yoo et al., 2021)
. As demonstrated with the learnable version of the foraging paradigm we reviewed earlier 
(Hall-McMaster et al., 2021)
, providing people with contextual structure and additional control over their choices provides a new window into how they make them 
(Constantino & Daw, 2015;
Kolling et al., 2012;
Shenhav et al., 2016;
Yoon, Geary, Ahmed, & Shadmehr, 2018)
. Taking this route may also shed new light on the computations underlying neural correlates of choice value. Overall, these studies uncover additional computations supporting decision-making that are ripe for study.
How are decisions shaped by adaptations across multiple levels and time-scales? We have outlined earlier that decisions between options are shaped by decisions about components of the ongoing choice (e.g. what to attend to in order to maximize information gain), and decisions about resource allocation beyond the current choice (e.g. how worthwhile are other choices or tasks). A common theme across all of these levels is that decision-makers minimize effort. It is likely that when making real-world decisions, people reduce effort by remembering solutions that might be useful in the future 
(Dasgupta & Gershman, 2021)
, not only for choices among options, but also for higher order decisions about how to decide 
(Griffiths et al., 2019)
 and what information to pay attention to 
(Callaway, Rangel, et al., 2021;
Jang et al., 2021)
. These solutions across different levels of hierarchy (e.g., choice parameters, strategies), could then serve as defaults and be iteratively refined to support goal-directed behaviors (J. W. 
Brown & Alexander, 2017;
Holroyd & Verguts, 2021;
Holroyd & Yeung, 2012;
Lieder et al., 2018)
. In addition to better understanding the strategies people use to simplify decision-making, future work should also seek to better explain how people learn when and how to use these different strategies. For instance, it could be that people initially implement default strategies and parameters, and then systematically override them when the values or other features of those choice options diverge from expectations (e.g., when these deviations suggest that the default strategy is no longer optimal; 
Daw, Niv, & Dayan, 2005;
Miller, Shenhav, & Ludvig, 2019)
.
Another, somewhat rocky but important path for future research is towards a better understanding of the role that monitoring plays in decision-making. We have reviewed earlier how experiences of conflict and confidence guide decision-making across levels of hierarchy and COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE 35 different time-scales. Dissociating monitoring from choice-related processes is a major challenge precisely because monitored signals are often aliased with signals of choice value and its derivatives 
(Desender, Ridderinkhof, & Murphy, 2021)
. For instance, confidence in value-based choices integrates multiple cues related to choice difficulty 
(De Martino et al., 2013)
, changes of mind 
(Folke et al., 2016)
, goal congruency of options 
(Sepulveda et al., 2020)
, and value certainty 
(Boldt, Blundell, et al., 2019;
D. Lee & Coricelli, 2020;
D. G. Lee & Daunizeau, 2021)
.
Like estimates of value 
(Callaway, Rangel, et al., 2021;
Gluth et al., 2020;
Jang et al., 2021;
Z. Li & Ma, 2020)
, local expressions of confidence likely evolve dynamically over time 
(Desender, Donner, et al., 2021;
van den Berg et al., 2016)
, and are perhaps even integral to regulating the ongoing choice process 
(Balsdon, Wyart, & Mamassian, 2020;
Schulz et al., 2021;
Yeung & Summerfield, 2012)
. One way of disambiguating whether a neural correlate of choice value reflects functions integral or external to choice is to test whether such activity has a necessary or causal role in driving choice behavior. Doing so, recent studies have provided evidence that correlates of value-based evidence accumulation within regions such as the dACC are more consistent with a role in monitoring than choice 
(Kane et al., 2021;
Y. S. Li et al., 2019)
.
Overall, the work we have reviewed demonstrates the incredible progress that has been made through interactions between research on decision-making and cognitive control. As research at and across these intersections continues to proliferate, we are hopeful that these respective fields (and associated fields within the cognitive, affective, and social neurosciences) will continue to identify theoretical and experimental gaps in one another, and through persistent collaborations that these gaps will be filled just as rapidly. These efforts will benefit from innovations in both modeling and experimentation, in particular ones that seek to account for ever more complex aspects of the deciding mind.
Figure 2 .
2
The influence of task goals on behavioral and neural correlates of value-based decision-making. A) While evaluative goals determine how subjective values are computed, task goals determine the mapping between those values and potential responses. B) Past work has


Figure 3 .
3
Dual roles of value in appraisal and goal-directed processing. A) Subjective values play roles in determining choice (blue dashed square) as well as in separate appraisal processes (green dashed square) that can inform functions outside the decision-making process (e.g., affective experiences and approach or avoidance tendencies). B) Reward processing consistently triggers activity in a network comprising vmPFC, striatum and posterior cingulate cortex (top left). Shenhav and Buckner


Figure 4 .
4
Controlling our ongoing decisions. A) Control affects the flow of information. Left: In the attention drift diffusion model, attention affects the weighting of options' impact on the drift rate.Attended options have a stronger impact than unattended options, which makes options that are attended more likely to be chosen. Right: Newer work accounts not only for attention effects, but also explains how attention is deployed to reduce choice uncertainty in a goal-directed manner.Decision-makers decide continuously whether to keep sampling information about the currently attended option, shift their gaze to the other option, or make a choice based on the available information. The values of options are estimated over time based on Bayesian value estimation, so that the momentary value representation approaches the true values of options over time while uncertainty in those value estimates decreases. Attention impacts the precision of the momentary evidence based on which Bayesian value estimation operates. This figure is reproduced from Jang, Sharma and Drugowitsch (2021). B) Control affects the threshold for deciding. When a conflict is detected, (yellow arrow) the threshold can be increased to buy the decision-maker time to make the right choice. C) Control supports overcoming choice biases. Choice biases shift the starting point for evidence accumulation (e.g., towards repeating the previous response, or a choice default). This facilitates responding consistently with one's bias, but requires control to choose against one's bias.


Figure 5 .
5
Monitoring to guide behavior across multiple levels. A) Monitoring not only informs control over the ongoing choice, but also higher-order strategy and task selection. B) Performance monitoring provides a continuous readout of the evaluation of one's choice process. As the decisionvariable for one's decision evolves, estimates of confidence and uncertainty are updated. Here, we illustrate a change of mind, where the initial decision is identified as erroneous and reversed. Note how uncertainty increases as evidence for the right option catches up with evidence for the left option,








Acknowledgments
We thank Matt Nassar, Fred Callaway, Annika Boldt and Senne Braem for their helpful feedback on an earlier version of this manuscript. This work was funded by a Center of Biomedical Research Excellence grant P20GM103645 from the National Institute of General Medical Sciences and grant R01MH124849 from the National Institute of Mental Health (A.S.).












Facing good and evil: Early brain signatures of affective biographical knowledge in face recognition




Abdel
Rahman






R




10.1037/a0024717






Emotion




11


6
















Confidence as a Priority Signal




D
Aguilar-Lleyda






M
Lemarchand






V
De Gardelle




10.1177/0956797620925039






Psychol Sci




31


9
















Neurobiology of value-driven attention




B
A
Anderson




10.1016/j.copsyc.2018.11.004






Curr Opin Psychol




29
















Generalization of value-based attentional priority




B
A
Anderson






P
A
Laurent






S
Yantis




10.1080/13506285.2012.679711






Vis cogn




20


6




















F
S
Arana






J
A
Parkinson






E
Hinton






A
J
Holland






A
M
Owen






A
C
Roberts


















Dissociable contributions of the human amygdala and orbitofrontal cortex to incentive motivation and goal selection


10.1523/jneurosci.23-29-09632.2003






J Neurosci




23


29














Biasing simple choices by manipulating relative visual attention




K
C
Armel






A
Beaumel






A
Rangel








Judgment and Decision Making




3


5


000259234800004














The dimensionality of neural representations for control




D
Badre






A
Bhandari






H
Keglovits






A
Kikumoto




10.1016/j.cobeha.2020.07.002






Curr Opin Behav Sci




38
















Value-based decisions involve sequential sampling from memory




A
Bakkour






A
Zylberberg






M
N
Shadlen






D
Shohamy




10.1101/269290
















Confidence controls perceptual evidence accumulation




T
Balsdon






V
Wyart






P
Mamassian




10.1038/s41467-020-15561-w






Nature Communications




11


1


1753














The valuation system: A coordinate-based meta-analysis of BOLD fMRI experiments examining neural correlates of subjective value




O
Bartra






J
T
Mcguire






J
W
Kable




10.1016/j.neuroimage.2013.02.063








NeuroImage




76
















A Contingency Model for the Selection of Decision Strategies




L
R
Beach






T
R
Mitchell




10.2307/257535






The Academy of Management Review




3


3




















Cognitive Control As A Lens






Value-Based








CHOICE




38












Learning the value of information in an uncertain world




T
E
Behrens






M
W
Woolrich






M
E
Walton






M
F
Rushworth




10.1038/nn1954






Nat Neurosci




10


9
















Performance feedback promotes proactive but not reactive adaptation of conflict-control




C
Bejjani






S
Tan






T
Egner




10.1037/xhp0000720






Journal of Experimental Psychology: Human Perception and Performance




46


4


















M
Binz






S
J
Gershman






E
Schulz






D
Endres




Heuristics From Bounded Meta-Learned Inference




















K
Blair






A
A
Marsh






J
Morton






M
Vythilingam






M
Jones






K
Mondillo














Choosing the lesser of two evils, the better of two goods: specifying the roles of ventromedial prefrontal cortex and dorsal anterior cingulate in object choice




J
R
Blair




10.1523/JNEUROSCI.1640-06.2006






J Neurosci




26


44
















Subjective value and decision entropy are jointly encoded by aligned gradients across the human brain




S
Bobadilla-Suarez






O
Guest






B
C
Love




10.1038/s42003-020-01315-3






Communications Biology




3


1


597














The physics of optimal decision making: a formal analysis of models of performance in two-alternative forcedchoice tasks




R
Bogacz






E
Brown






J
Moehlis






P
Holmes






J
D
Cohen




10.1037/0033-295X.113.4.700






Psychol Rev




113


4
















Do humans produce the speedaccuracy trade-off that maximizes reward rate?




R
Bogacz






P
T
Hu






P
J
Holmes






J
D
Cohen




10.1080/17470210903091643






Q J Exp Psychol




63


5
















Extending a biologically inspired model of choice: multi-alternatives, nonlinearity and value-based multidimensional choice




R
Bogacz






M
Usher






J
Y
Zhang






J
L
Mcclelland










Philosophical Transactions of the Royal Society B: Biological Sciences




362


1655














Confidence modulates exploration and exploitation in value-based learning




A
Boldt






C
Blundell






B
Martino




10.1093/nc/niz004






Neurosci Conscious


2019


4


















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




39












Confidence Predictions Affect Performance Confidence and Neural Preparation in Perceptual Decision Making




A
Boldt






A.-M
Schiffer






F
Waszak






N
Yeung




10.1038/s41598-019-40681-9






Scientific Reports




9


1


4031














Shared neural markers of decision confidence and error detection




A
Boldt






N
Yeung




10.1523/JNEUROSCI.0797-14.2015






J Neurosci




35


8
















Tragic Choices: Autonomy and Emotional Responses to Medical Decisions




S
Botti






K
Orfali






S
S
Iyengar




10.1086/598969






Journal of Consumer Research




36


3
















Conflict monitoring and decision making: Reconciling two perspectives on anterior cingulate function




M
M
Botvinick




10.3758/cabn.7.4.356






Cognitive, Affective, & Behavioral Neuroscience




7


4
















Conflict monitoring and cognitive control




M
M
Botvinick






T
S
Braver






D
M
Barch






C
S
Carter






J
D
Cohen




10.1037/0033-295X.108.3.624






Psychological Review




108


3
















The computational and neural basis of cognitive control: charted territory and new frontiers




M
M
Botvinick






J
D
Cohen




10.1111/cogs.12126






Cogn Sci




38


6
















Conflict monitoring versus selection-for-action in anterior cingulate cortex




M
M
Botvinick






L
E
Nystrom






K
Fissell






C
S
Carter






J
D
Cohen




10.1038/46035






Nature




402


6758
















Deciding How To Decide: Self-Control and Meta-Decision Making




Y
L
Boureau






P
Sokol-Hessner






N
D
Daw




10.1016/j.tics.2015.08.013








Trends in Cognitive Sciences




19


11
















The Role of Anterior Cingulate Cortex in the Affective Evaluation of Conflict




S
Braem






J
A
King






F
M
Korb






R
M
Krebs






W
Notebaert






T
Egner




10.1162/jocn_a_01023






J Cogn Neurosci




29


1
















Adaptive History Biases Result from Confidence-Weighted Accumulation of past Choices




A
Braun






A
E
Urai






T
H
Donner




10.1523/JNEUROSCI.2189-17.2017






J Neurosci




38


10






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




40












Foraging Value, Risk Avoidance, and Multiple Control Signals: How the ACC Controls Value-based Decision-making




J
W
Brown






W
H
Alexander




10.1162/jocn_a_01140






J Cogn Neurosci






















V
M
Brown






J
Wilson






M
N
Hallquist






K
Szanto






A
Y
Dombrovski


















Ventromedial prefrontal value signals and functional connectivity during decision-making in suicidal behavior and impulsivity


10.1038/s41386-020-0632-0






Neuropsychopharmacology




45


6














Differences in adaptive learning across the lifespan are driven by satisficing




R
Bruckner






M
R
Nassar






S.-C
Li






B
Eppinger








PsyArXiv
















Why it is too early to lose control in accounts of item-specific proportion congruency effects




J
M
Bugg






L
L
Jacoby






S
Chanani








Journal of Experimental Psychology: Human Perception and Performance




37


3


844














Bayesian confidence for drift diffusion observers in dynamic stimuli tasks. bioRxiv




J
M
Calder-Travis






L
Charles






R
Bogacz






N
Yeung




10.31234/osf.io/j8sxz








965384












Fixation patterns in simple choice reflect optimal information sampling




F
Callaway






A
Rangel






T
L
Griffiths




10.1371/journal.pcbi.1008863






PLoS Comput Biol




17


3


1008863














Human planning as optimal information seeking




F
Callaway






B
Van Opheusden






S
Gul






P
Das






P
Krueger






F
Lieder






T
Griffiths




10.31234/osf.io/byaqd


















Independent Neural Computation of Value from Other People's Confidence




D
Campbell-Meiklejohn






A
Simonsen






C
D
Frith






N
D
Daw




10.1523/JNEUROSCI.4490-15.2016






J Neurosci
















Flexible use of confidence to guide advice requests




N
Carlebach






N
Yeung




10.31234/osf.io/ctyqp


















Subjective confidence acts as an internal cost-benefit factor when choosing between tasks




N
Carlebach






N
Yeung




10.1037/xhp0000747






Journal of Experimental Psychology: Human Perception and Performance




46


7




















Cognitive Control As A Lens






On




VALUE-BASED CHOICE 41
















C
S
Carter






T
S
Braver






D
M
Barch






M
M
Botvinick






D
Noll






J
D
Cohen


















Anterior Cingulate Cortex, Error Detection, and the Online Monitoring of Performance














10.1126/science.280.5364.747






Science




280


5364














How usefulness shapes neural representations during goal-directed behavior




G
Castegnetti






M
Zurita






B
Martino




10.1126/sciadv.abd5363






Science Advances




7


15


5363














Frontal Theta Overrides Pavlovian Learning Biases




J
F
Cavanagh






I
Eisenberg






M
Guitart-Masip






Q
Huys






M
J
Frank




10.1523/jneurosci.5754-12.2013






The Journal of Neuroscience




33


19
















Frontal theta reflects uncertainty and unexpectedness during exploration and exploitation




J
F
Cavanagh






C
M
Figueroa






M
X
Cohen






M
J
Frank




10.1093/cercor/bhr332






Cereb Cortex




22


11
















Conflict acts as an implicit cost in reinforcement learning




J
F
Cavanagh






S
E
Masters






K
Bath






M
J
Frank




10.1038/ncomms6394






Nature Communications




5


1


5394














Subthalamic nucleus stimulation reverses mediofrontal influence over decision threshold




J
F
Cavanagh






T
V
Wiecki






M
X
Cohen






C
M
Figueroa






J
Samanta






S
J
Sherman






M
J
Frank




10.1038/nn.2925






Nat Neurosci




14


11
















Eye tracking and pupillometry are indicators of dissociable latent decision processes




J
F
Cavanagh






T
V
Wiecki






A
Kochar






M
J
Frank




10.1037/a0035813






J Exp Psychol Gen




143


4




















S
E
Cavanagh






W
M N
Malalasekera






B
Miranda






L
T
Hunt






S
W
Kennerley


















Visual fixation patterns during economic choice reflect covert valuation processes that emerge with learning


10.1073/pnas.1906662116






Proc Natl Acad Sci




116


45














Dynamic sources of evidence supporting confidence judgments and error detection




L
Charles






N
Yeung




10.1037/xhp0000583






J Exp Psychol Hum Percept Perform




45


1
















The organization of the human striatum estimated by intrinsic functional connectivity




E
Y
Choi






B
T
Yeo






R
L
Buckner




10.1152/jn.00270.2012






J Neurophysiol




108


8






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




42












Closing the gate to distractors during decision-making




E
Chong






A
Akrami




10.1038/s41593-021-00833-5






Nat Neurosci




24


6
















Informatic parcellation of the network involved in the computation of subjective value




J
A
Clithero






A
Rangel




10.1093/scan/nst106






Soc Cogn Affect Neurosci




9


9
















Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration




J
D
Cohen






S
M
Mcclure






A
J
Yu




10.1098/rstb.2007.2098






Philos Trans R Soc Lond B Biol Sci




362
















Cognitive control over learning: creating, clustering, and generalizing task-set structure




A
G E
Collins






M
J
Frank




10.1037/a0030852






Psychological Review




120


1
















Advances in modeling learning and decision-making in neuroscience




A
G E
Collins






A
Shenhav




10.1038/s41386-021-01126-y






Neuropsychopharmacology
















Learning the opportunity cost of time in a patchforaging task




S
M
Constantino






N
D
Daw




10.3758/s13415-015-0350-y






Cogn Affect Behav Neurosci




15


4
















Regret and its avoidance: a neuroimaging study of choice behavior




G
Coricelli






H
D
Critchley






M
Joffily






J
P
O'doherty






A
Sirigu






R
J
Dolan




10.1038/nn1514






Nat Neurosci




8


9




















C
Danielmeier






T
Eichele






B
U
Forstmann






M
Tittgemeyer






M
Ullsperger


















Posterior medial frontal cortex activity predicts post-error adaptations in task-related visual and motor areas


10.1523/JNEUROSCI.4299-10.2011






J Neurosci




5














Memory as a Computational Resource




I
Dasgupta






S
J
Gershman




10.1016/j.tics.2020.12.008






Trends Cogn Sci




25


3
















Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control




N
D
Daw






Y
Niv






P
Dayan




10.1038/nn1560






Nat Neurosci




8


12
















How to set the switches on this thing




P
Dayan




10.1016/j.conb.2012.05.011






Curr Opin Neurobiol




22


6






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




43












The misbehavior of value and the discipline of the will




P
Dayan






Y
Niv






B
Seymour






N
D
Daw




10.1016/j.neunet.2006.03.002






Neural Netw




19


8
















Confidence as a Common Currency between Vision and Audition




V
De Gardelle






F
Le Corre






P
Mamassian




10.1371/journal.pone.0147901






Plos One




11


1


147901














Does confidence use a common currency across two visual tasks?




V
De Gardelle






P
Mamassian




10.1177/0956797614528956






Psychol Sci




25


6
















Confidence in value-based choice




De
Martino






B
Fleming






S
M
Garrett






N
Dolan






R
J




10.1038/nn.3279






Nat Neurosci




16


1
















Frames, biases, and rational decision-making in the human brain




De
Martino






B
Kumaran






D
Seymour






B
Dolan






R
J




10.1126/science.1128356






Science




5787
















Confidence predicts speed-accuracy tradeoff for subsequent decisions in humans. eLife, 8, e43499




K
Desender






A
Boldt






T
Verguts






T
H
Donner




10.7554/eLife.43499
















Subjective Confidence Predicts Information Seeking in Decision Making




K
Desender






A
Boldt






N
Yeung




10.1177/0956797617744771






Psychol Sci




0


0


956797617744771














Avoiding the conflict: Metacognitive awareness drives the selection of low-demand contexts




K
Desender






C
Buc Calderon






F
Van Opstal






E
Van Den Bussche




10.1037/xhp0000391






J Exp Psychol Hum Percept Perform




43


7
















Dynamic expressions of confidence within an evidence accumulation framework




K
Desender






T
H
Donner






T
Verguts




10.1016/j.cognition.2020.104522






Cognition




207


104522














A post-decisional neural marker of confidence predicts information-seeking in decision-making




K
Desender






P
Murphy






A
Boldt






T
Verguts






N
Yeung




10.1523/JNEUROSCI.2620-18.2019






J Neurosci


















Understanding neural signals of post-decisional performance monitoring: An integrative review. eLife




K
Desender






K
R
Ridderinkhof






P
R
Murphy




10.7554/eLife.67556






10


67556












Motivational control of goal-directed action




A
Dickinson






B
Balleine




10.3758/BF03199951






Animal Learning & Behavior




22


1






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




44












How positive affect modulates cognitive control: the costs and benefits of reduced maintenance capability




G
Dreisbach




10.1016/j.bandc.2005.08.003






Brain Cogn




60


1
















Conflicts as Aversive Signals for Control Adaptation




G
Dreisbach






R
Fischer




10.1177/0963721415569569






Current Directions in Psychological Science




24


4
















The cost of accumulating evidence in perceptual decision making




J
Drugowitsch






R
Moreno-Bote






A
K
Churchland






M
N
Shadlen






A
Pouget




10.1523/JNEUROSCI.4010-11.2012






J Neurosci




32


11
















Metacognitive evaluation in the avoidance of demand




T
L
Dunn






D
J
Lutes






E
F
Risko




10.1037/xhp0000236






J Exp Psychol Hum Percept Perform




42


9
















On adaptation, maximization, and reinforcement learning among cognitive strategies




I
Erev






G
Barron




10.1037/0033-295x.112.4.912






Psychological Review




112


4
















Maximization, learning, and economic behavior




I
Erev






A
E
Roth




10.1073/pnas.1402846111






Proc Natl Acad Sci U S A




111


3










Suppl. Supplement 3








Cortical beta power reflects decision dynamics and uncovers multiple facets of post-error adaptation




A
G
Fischer






R
Nigbur






T
A
Klein






C
Danielmeier






M
Ullsperger




















10.1038/s41467-018-07456-8






Nat Commun




9


1


5038












Real and fictive outcomes are processed differently but converge on a common adaptive mechanism




A
G
Fischer






M
Ullsperger




10.1016/j.neuron.2013.07.006






Neuron




79


6
















Overcoming status quo bias in the human brain




S
M
Fleming






C
L
Thomas






R
J
Dolan




10.1073/pnas.0910380107






Proc Natl Acad Sci U S A




107


13
















Explicit representation of confidence informs future value-based decisions




T
Folke






C
Jacobsen






S
M
Fleming






B
Martino




10.1038/s41562-016-0002






Nature Human Behaviour




1


1


2














A reinforcement learning diffusion decision model for value-based decisions




L
Fontanesi






S
Gluth






M
S
Spektor






J
Rieskamp




10.3758/s13423-018-1554-2






Psychon Bull Rev




26


4






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




45












Decomposing the effects of context valence and feedback information on speed and accuracy during reinforcement learning: a metaanalytical approach using diffusion decision modeling




L
Fontanesi






S
Palminteri






M
Lebreton




10.3758/s13415-019-00723-1






Cogn Affect Behav Neurosci




19


3
















Hold your horses: a dynamic computational role for the subthalamic nucleus in decision making




M
J
Frank




10.1016/j.neunet.2006.03.006






Neural Netw




19


8
















fMRI and EEG predictors of dynamic decision parameters during human reinforcement learning




M
J
Frank






C
Gagne






E
Nyhus






S
Masters






T
V
Wiecki






J
F
Cavanagh






D
Badre




10.1523/JNEUROSCI.2036-14.2015






J Neurosci




35


2
















Hold your horses: impulsivity, deep brain stimulation, and medication in parkinsonism




M
J
Frank






J
Samanta






A
A
Moustafa






S
J
Sherman




10.1126/science.1146157






Science




318


5854
















Sequential hypothesis testing under stochastic deadlines




P
I
Frazier






A
J
Yu












Paper presented at the NIPS








The role of prefrontal cortex in cognitive control and executive function




N
P
Friedman






T
W
Robbins




10.1038/s41386-021-01132-0






Neuropsychopharmacology
















The role of affective evaluation in conflict adaptation: An LRP study




K
Fröber






B
Stürmer






R
Frömer






G
Dreisbach




10.1016/j.bandc.2017.05.003








Brain Cogn




116
















Goal congruency dominates reward value in accounting for behavioral and neural correlates of value-based decision-making




R
Frömer






C
K
Dean Wolf






A
Shenhav




10.1038/s41467-019-12931-x






Nature Communications




10


1


4926














Expectations of reward and efficacy guide cognitive control allocation




R
Frömer






H
Lin






C
K
Dean Wolf






M
Inzlicht






A
Shenhav




10.1038/s41467-021-21315-z






Nature Communications




12


1


1030














I knew that! Response-based Outcome Predictions and Confidence Regulate Feedback Processing and Learning. bioRxiv




R
Frömer






M
R
Nassar






R
Bruckner






B
Stürmer






W
Sommer






N
Yeung




10.1101/442822






442822


















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




46












Spatiotemporally distinct neural mechanisms underlie our reactions to and comparison between value-based options. bioRxiv




R
Frömer






A
Shenhav




10.1101/609198






609198












Foraging Optimally in Social Neuroscience: Computations and Methodological considerations




A
S
Gabay






M
A J
Apps




10.1093/scan/nsaa037






Soc Cogn Affect Neurosci
















Decisions, Decisions, Decisions




P
W
Glimcher




10.1016/S0896-6273(02)00962-5






Neuron




36


2
















Value-based attention but not divisive normalization influences decisions with multiple alternatives




S
Gluth






N
Kern






M
Kortmann






C
L
Vitali




10.1038/s41562-020-0822-0






Nat Hum Behav
















Deciding when to decide: time-variant sequential sampling models explain the emergence of value-based decisions in the human brain




S
Gluth






J
Rieskamp






C
Buchel




10.1523/JNEUROSCI.0727-12.2012






J Neurosci




32


31
















Understanding active sampling strategies: Empirical approaches and implications for attention and decision research




J
Gottlieb




10.1016/j.cortex.2017.08.019






Cortex




102
















Curiosity, information demand and attentional priority. Current Opinion in Behavioral Sciences




J
Gottlieb






M
Cohanpour






Y
Li






N
Singletary






E
Zabeh




10.1016/j.cobeha.2020.07.016






35














Towards a neuroscience of active sampling and curiosity




J
Gottlieb






P
Y
Oudeyer




10.1038/s41583-018-0078-0






Nat Rev Neurosci




19


12
















Value, pleasure and choice in the ventral prefrontal cortex




F
Grabenhorst






E
T
Rolls




10.1016/j.tics.2010.12.004






Trends in Cognitive Sciences




15


2
















A computational perspective on the roles of affect in cognitive control




I
Grahek






S
Musslick






A
Shenhav




10.1016/j.ijpsycho.2020.02.001






Int J Psychophysiol
















Doing more with less: meta-reasoning and meta-learning in humans and machines




T
L
Griffiths






F
Callaway






M
B
Chang






E
Grant






P
M
Krueger






F
Lieder




10.1016/j.cobeha.2019.01.005






Current Opinion in Behavioral Sciences




29
















Visual Recognition




K
Grill-Spector






N
Kanwisher




10.1111/j.0956-7976.2005.00796.x






Psychol Sci




16


2




















J
Grinband






J
Savitskaya






T
D
Wager






T
Teichert






V
P
Ferrera






J
Hirsch






















Rt: Response To
Conflict






&
Brown






Yeung




10.1016/j.neuroimage.2011.04.027






NeuroImage




57


2














Automatic versus Choice-Dependent Value Representations in the Human Brain




M
Grueschow






R
Polania






Todd
A
Hare






Ruff






C
Christian




10.1016/j.neuron.2014.12.054






Neuron




85


4
















Parietal cortex tracks the amount of information retrieved even when it is not the basis of a memory decision




S
A
Guerin






M
B
Miller




10.1016/j.neuroimage.2010.11.066






NeuroImage




55


2
















Mesolimbic confidence signals guide perceptual learning in the absence of external feedback. eLife, 5, e13388




M
Guggenmos






G
Wilbertz






M
N
Hebart






P
Sterzer




10.7554/eLife.13388
















Control over patch encounters changes foraging behaviour. bioRxiv




S
Hall-Mcmaster






P
Dayan






N
W
Schuck




10.1101/2021.01.19.426950
















Self-Control in Decision-Making Involves Modulation of the vmPFC Valuation System




T
A
Hare






C
F
Camerer






A
Rangel




10.1126/science.1168450






Science




324


5927
















Transformation of stimulus value signals into motor commands during simple choice




T
A
Hare






W
Schultz






C
F
Camerer






J
P
O'doherty






A
Rangel




10.1073/pnas.1109322108






Proc Natl Acad Sci




108


44
















Accounting for Taste: A Multi-Attribute Neurocomputational Model Explains the Neural Dynamics of Choices for Self and Others




A
Harris






J
A
Clithero






C
A
Hutcherson




10.1523/JNEUROSCI.3327-17.2018






J Neurosci




38


37
















The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)




B
Y
Hayden






Y
Niv




10.1037/bne0000448






Behav Neurosci




135


2
















A Congruity Effect in the Discrimination of Presentation Frequencies -Some Data and a Model




D
L
Hintzman






E
Gold




10.3758/bf03329939






Bulletin of the Psychonomic Society




21


1
















The Best Laid Plans: Computational Principles of Anterior Cingulate Cortex




C
B
Holroyd






T
Verguts




10.1016/j.tics.2021.01.008






Trends Cogn Sci






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




48












Motivation of extended behaviors by anterior cingulate cortex




C
B
Holroyd






N
Yeung




10.1016/j.tics.2011.12.008






Trends Cogn Sci




16


2
















Frontal circuit specialisations for decision making




L
T
Hunt




10.1111/ejn.15236






Eur J Neurosci
















A distributed, hierarchical and recurrent framework for reward-based choice




L
T
Hunt






B
Y
Hayden




10.1038/nrn.2017.7






Nat Rev Neurosci




18


3
















Mechanisms underlying cortical activity during value-guided choice




L
T
Hunt






N
Kolling






A
Soltani






M
W
Woolrich






M
F
Rushworth






T
E
Behrens




10.1038/nn.3017






Nat Neurosci




15


3
















Triple dissociation of attention and decision computations across prefrontal cortex




L
T
Hunt






W
M N
Malalasekera






A
O
De Berker






B
Miranda






S
F
Farmer






T
E J
Behrens






S
W
Kennerley




10.1038/s41593-018-0239-5






Nat Neurosci




21


10
















Approach-Induced Biases in Human Information Sampling




L
T
Hunt






R
B
Rutledge






W
M
Malalasekera






S
W
Kennerley






R
J
Dolan




10.1371/journal.pbio.2000638






PLoS Biol




14


11














Cognitive regulation during decision making shifts behavioral control between ventromedial and dorsolateral prefrontal value systems




C
A
Hutcherson






H
Plassmann






J
J
Gross






A
Rangel




10.1523/JNEUROSCI.6387-11.2012






J Neurosci




32


39
















Optimal policy for attention-modulated decisions explains human fixation behavior. eLife




A
I
Jang






R
Sharma






J
Drugowitsch




10.7554/eLife.63436






10


63436












Dopamine-mediated reinforcement learning signals in the striatum and ventromedial prefrontal cortex underlie value-based choices




G
Jocham






T
A
Klein






M
Ullsperger




10.1523/JNEUROSCI.3904-10.2011






J Neurosci




5
















Medial frontal cortex activity predicts information sampling in economic choice




P
Kaanders






H
Nili






J
X
O'reilly






L
T
Hunt




10.1101/2020.11.24.395814
















Rats exhibit similar biases in foraging and intertemporal choice tasks. eLife, 8, e48429




G
A
Kane






A
M
Bornstein






A
Shenhav






R
C
Wilson






N
D
Daw






J
D
Cohen




10.7554/eLife.48429






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




49
















G
A
Kane






M
H
James






A
Shenhav






N
D
Daw






J
D
Cohen






G
Aston-Jones


















Rat Anterior Cingulate Cortex Continuously Signals Decision Variables in a Patch Foraging Task. bioRxiv


10.1101/2021.06.07.447464






447464












Speed accuracy trade-off under response deadlines




H
Karsilar






P
Simen






S
Papadakis






F
Balci




10.3389/fnins.2014.00248






Front Neurosci




8


248


248














Regulation of evidence accumulation by pupillinked arousal processes




W
Keung






T
A
Hagen






R
C
Wilson




10.1038/s41562-019-0551-4






Nat Hum Behav




3


6
















The Nature of Task Set Representations in Working Memory




A
Kikumoto






U
Mayr




10.1162/jocn_a_01173






J Cogn Neurosci




29


11
















Anticipatory affect: neural correlates and consequences for choice




B
Knutson






S
M
Greer




10.1098/rstb.2008.0155






Philos Trans R Soc Lond B Biol Sci




363


1511
















Neural Predictors of Purchases




B
Knutson






S
Rick






G
E
Wimmer






D
Prelec






G
Loewenstein




10.1016/j.neuron.2006.11.010






Neuron




53


1
















Common neural code for reward and information value




K
Kobayashi






M
Hsu




10.1073/pnas.1820145116






Proc Natl Acad Sci




116


26
















Dynamic Representation of the Subjective Value of Information




K
Kobayashi






S
Lee






A
L S
Filipowicz






K
D
Mcgaughey






J
W
Kable






M
R
Nassar




10.1523/JNEUROSCI.0423-21.2021






J Neurosci




39
















Neural Mechanisms of Foraging




N
Kolling






T
E J
Behrens






R
B
Mars






M
F S
Rushworth




10.1126/science.1216930






Science




336


6077
















Decision making and the avoidance of cognitive demand




W
Kool






J
T
Mcguire






Z
B
Rosen






M
M
Botvinick




10.1037/a0020198






J Exp Psychol Gen




139


4
















Two systems drive attention to rewards




C
K
Kovach






M
J
Sutterer






S
N
Rushia






A
Teriakidis






R
L
Jenison




10.3389/fpsyg.2014.00046






Front Psychol




5


46


46














Visual fixations and the computation and comparison of value in simple choice




I
Krajbich






C
Armel






A
Rangel




10.1038/nn.2635






Nat Neurosci




13


10






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




50












Automatic integration of confidence in the brain valuation signal




M
Lebreton






R
Abitbol






J
Daunizeau






M
Pessiglione




10.1038/nn.4064






Nat Neurosci




18


8
















An automatic valuation system in the human brain: evidence from functional neuroimaging




M
Lebreton






S
Jorge






V
Michel






B
Thirion






M
Pessiglione




10.1016/j.neuron.2009.09.040






Neuron




64


3
















An Empirical Test of the Role of Value Certainty in Decision Making




D
Lee






G
Coricelli




10.3389/fpsyg.2020.574473






Frontiers in Psychology




11














Trading mental effort for confidence in the metacognitive control of value-based decision-making. eLife




D
G
Lee






J
Daunizeau




10.7554/eLife.63282






10


63282












Evidence Accumulates for Individual Attributes during Value-Based Decisions. bioRxiv, 2021




D
G
Lee






T
A
Hare




10.1101/2021.08.05.455296






455296












Differential dynamics of spatial and non-spatial stimulus-response compatibility effects: a dual task LRP study




C
Lehle






A
Cohen






J
Sangals






W
Sommer






B
Sturmer




















10.1016/j.actpsy.2010.09.013






Acta Psychol (Amst)




136


1














The Malleability of Intertemporal Choice




K
M
Lempert






E
A
Phelps




10.1016/j.tics.2015.09.005






Trends Cogn Sci




20


1
















The root of all value: a neural common currency for choice




D
J
Levy






P
W
Glimcher




10.1016/j.conb.2012.06.001






Curr Opin Neurobiol




22


6
















Individual Neurons in the Cingulate Cortex Encode Action Monitoring, Not Selection, during Adaptive Decision-Making




Y
S
Li






M
R
Nassar






J
W
Kable






J
I
Gold




10.1523/JNEUROSCI.0159-19.2019






J Neurosci




39


34
















An uncertainty-based model of the effects of fixation on choice




Z
Li






W
Ma




10.31234/osf.io/ajmwx


















Strategy selection as rational metareasoning




F
Lieder






T
L
Griffiths








Psychological Review




124


6


762














Rational metareasoning and the plasticity of cognitive control




F
Lieder






A
Shenhav






S
Musslick






T
L
Griffiths




10.1371/journal.pcbi.1006043






PLoS Comput Biol




14


4


1006043




















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




51












The Decision Value Computations in the vmPFC and Striatum Use a Relative Value Code That is Guided by Visual Attention




S.-L
Lim






J
P
O'doherty






A
Rangel




10.1523/jneurosci.1246-11.2011






The Journal of Neuroscience




31


37
















Midfrontal theta and pupil dilation parametrically track subjective conflict (but also surprise) during intertemporal choice




H
Lin






B
Saunders






C
A
Hutcherson






M
Inzlicht




10.1016/j.neuroimage.2017.10.055






NeuroImage




172
















The conflict of Buridan's ass or some dilemmas of affluence: the theory of attractive stimulus overload




Z
J
Lipowski








American Journal of Psychiatry




127


3
















Surfeit of attractive information inputs: a hallmark of our environment




Z
J
Lipowski








Behavioral Science




16


5
















Anticipation and the Valuation of Delayed Consumption




G
Loewenstein




10.2307/2232929






Economic Journal




387
















FRAMES OF MIND IN INTERTEMPORAL CHOICE




G
F
Loewenstein




10.1287/mnsc.34.2.200






Management Science




34


2
















Reward value-based gain control: divisive normalization in parietal cortex




K
Louie






L
E
Grattan






P
W
Glimcher




10.1523/JNEUROSCI.1237-11.2011






J Neurosci




29
















Dissociating the Role of the Dorsolateral Prefrontal and Anterior Cingulate Cortex in Cognitive Control




A
W
Macdonald






J
D
Cohen






V
A
Stenger






C
S
Carter




10.1126/science.288.5472.1835






Science




288


5472
















Dissociable mechanisms govern when and how strongly reward attributes affect decisions




S
U
Maier






A
Raja Beharelle






R
Polania






C
C
Ruff






T
A
Hare




10.1038/s41562-020-0893-y






Nat Hum Behav
















Aging and motivated cognition: the positivity effect in attention and memory




M
Mather






L
L
Carstensen




10.1016/j.tics.2005.08.005






Trends Cogn Sci




9


10
















Prefrontal cortex, cognitive control, and the registration of decision costs




J
T
Mcguire






M
M
Botvinick




10.1073/pnas.0910662107






Proc Natl Acad Sci U S A




107


17
















Anxiolytic action on the behavioural inhibition system implies multiple types of arousal contribute to anxiety




N
Mcnaughton






J
A
Gray




10.1016/s0165-0327(00)00344-xCOGNITIVECONTROLASALENSONVALUE-BASEDCHOICE52






J Affect Disord




61


3
















A new model of decision processing in instrumental learning tasks. eLife




S
Miletic






R
J
Boag






A
C
Trutti






N
Stevenson






B
U
Forstmann






A
Heathcote




10.7554/eLife.63055






10


63055












Caution in decision-making under time pressure is mediated by timing ability




S
Miletic






L
Van Maanen




10.1016/j.cogpsych.2019.01.002






Cogn Psychol




110
















Habits without values




K
J
Miller






A
Shenhav






E
A
Ludvig




10.1037/rev0000120






Psychol Rev




126


2
















Parallel representation of context and multiple context-dependent values in ventro-medial prefrontal cortex. bioRxiv




N
Moneta






M
M
Garvert






H
R
Heekeren






N
W
Schuck




10.1101/2021.03.17.435844






435844












Anterior cingulate is a source of valence-specific information about value and uncertainty




I
E
Monosov




10.1038/s41467-017-00072-y






Nature Communications




8


1


134














How Outcome Uncertainty Mediates Attention, Learning, and Decision-Making




I
E
Monosov




10.1016/j.tins.2020.06.009






Trends in Neurosciences
















Does Attention Increase the Value of Choice Alternatives?




M
Mormann






J
E
Russo




10.1016/j.tics.2021.01.004






Trends Cogn Sci
















On the relationship between anxiety and error monitoring: a meta-analysis and conceptual framework




J
S
Moser






T
P
Moran






H
S
Schroder






M
B
Donnellan






N
Yeung




10.3389/fnhum.2013.00466






Front Hum Neurosci




7


466


466














The case for compensatory processes in the relationship between anxiety and error monitoring: a reply to Proudfit




J
S
Moser






T
P
Moran






H
S
Schroder






M
B
Donnellan






N
Yeung




10.3389/fnhum.2014.00064






Inzlicht, and Mennin. Front Hum Neurosci




8


64














Bias in the brain: a diffusion model analysis of prior probability and potential payoff




M
J
Mulder






E
J
Wagenmakers






R
Ratcliff






W
Boekel






B
U
Forstmann




10.1523/JNEUROSCI.4156-11.2012






J Neurosci




32


7
















Neural evidence accumulation persists after choice to inform metacognitive judgments. eLife, 4




P
R
Murphy






I
H
Robertson






S
Harty






R
G
Connell




10.7554/eLife.11946






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




53












Rational regulation of learning dynamics by pupil-linked arousal systems




M
R
Nassar






K
M
Rumsey






R
C
Wilson






K
Parikh






B
Heasly






J
I
Gold




10.1038/nn.3130






Nat Neurosci




15


7
















Role of outcome conflict in dual-task interference




D
Navon






J
Miller




10.1037//0096-1523.13.3.435






J Exp Psychol Hum Percept Perform




13


3
















Frontal and parietal cortical interactions with distributed visual representations during selective attention and action selection




N
Nelissen






M
Stokes






A
C
Nobre






M
F
Rushworth




10.1523/JNEUROSCI.2625-13.2013






J Neurosci




33


42
















How fast to work: Response vigor, motivation and tonic dopamine




Y
Niv






N
Daw






P
Dayan








Advances in neural information processing systems


Y. Weiss, B. Scholkopf, & J. Platt




MIT Press




18














Tonic dopamine: opportunity costs and the control of response vigor




Y
Niv






N
D
Daw






D
Joel






P
Dayan




10.1007/s00213-006-0502-4






Psychopharmacology (Berl)




191


3
















A normative perspective on motivation




Y
Niv






D
Joel






P
Dayan




10.1016/j.tics.2006.06.010






Trends Cogn Sci




10


8
















Post-error slowing: an orienting account




W
Notebaert






F
Houtman






F
V
Opstal






W
Gevers






W
Fias






T
Verguts




10.1016/j.cognition.2009.02.002






Cognition




111


2
















Making predictions in a changing world-inference, uncertainty, and learning




J
X
O'reilly




10.3389/fnins.2013.00105






Front Neurosci




7


105














The opportunity cost of time modulates cognitive effort




A
R
Otto






N
D
Daw




10.1016/j.neuropsychologia.2018.05.006








Neuropsychologia




123
















Irrational time allocation in decision-making




B
Oud






I
Krajbich






K
Miller






J
H
Cheong






M
Botvinick






E
Fehr




10.1098/rspb.2015.1439






Proc Biol Sci




283


20151439














Neuronal origins of choice variability in economic decisions




C
Padoa-Schioppa




10.1016/j.neuron.2013.09.013






Neuron




80


5
















Orbitofrontal Cortex: A Neural Circuit for Economic Decisions




C
Padoa-Schioppa






K
E
Conen




10.1016/j.neuron.2017.09.031






Neuron




96


4






















COGNITIVE CONTROL AS A LENS ON VALUE-BASED CHOICE




54












A Critical Role for Human Ventromedial Frontal Lobe in Value Comparison of Complex Objects Based on Attribute Configuration




G
Pelletier






L
K
Fellows




10.1523/JNEUROSCI.2969-18.2019






J Neurosci




39


21
















Evidence for the Speed-Value Trade-Off: Human and Monkey Decision Making Is Magnitude Sensitive. Decision




A
Pirrone






H
Azab






B
Y
Hayden






T
Stafford






J
A R
Marshall




10.1037/dec0000075
















Neural correlates of evidence accumulation during value-based decisions revealed via simultaneous EEG-fMRI




M
A
Pisauro






E
Fouragnan






C
Retzler






M
G
Philiastides




10.1038/ncomms15808






Nat Commun




8


15808














Appetitive and aversive goal values are encoded in the medial orbitofrontal cortex at the time of decis"""

Output: Provide your response as a JSON list in the following format:

[
  {
    "topic_or_construct": "...",
    "measured_by": "...",
    "justification": "..."
  },
  ...
]