[
  {
    "topic_or_construct": "Cognitive Bias",
    "measured_by": "Range normalization and reference point centering",
    "justification": "These methods are used to illustrate how subjective value of an outcome is rescaled based on the contextual bounds (minimum and maximum rewards) or the average value of the context, providing evidence for how cognitive biases are measured in reinforcement learning tasks."
  },
  {
    "topic_or_construct": "Epistemic Bias in Outcome Encoding",
    "measured_by": "Two-Phase Learning/Transfer Design",
    "justification": "This design involves a learning phase where participants associate options with specific outcomes within stable contexts, followed by a transfer phase with novel pairings. It demonstrates how participants encode outcomes in a context-dependent manner, leading to suboptimal choices, thus measuring the epistemic bias."
  },
  {
    "topic_or_construct": "Positivity Bias in Option Value Updating",
    "measured_by": "Asymmetric Learning Rates for Positive and Negative Prediction Errors",
    "justification": "Different learning rates for positive versus negative prediction errors are used to model and measure the positivity bias, showing how individuals learn faster from positive than negative outcomes when the outcomes follow freely chosen actions."
  },
  {
    "topic_or_construct": "Reinforcement Learning",
    "measured_by": "Bandit Tasks",
    "justification": "Bandit tasks, particularly those adapted into textual formats for LLMs and behavioral tasks for humans, are used to examine the reinforcement learning capacities and to measure specific biases such as relative value learning biases and positivity bias."
  }
]