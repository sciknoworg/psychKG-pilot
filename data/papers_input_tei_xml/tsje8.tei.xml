<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">BOOSTING WISDOM OF THE CROWD</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Eeshan</forename><surname>Hasan</surname></persName>
							<email>eehasan@iu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychological and Brain Sciences</orgName>
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cognitive Science Program</orgName>
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Erik</forename><forename type="middle">P</forename><surname>Duhaime</surname></persName>
							<affiliation key="aff2">
								<orgName type="laboratory">Centaur Labs</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jennifer</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychological and Brain Sciences</orgName>
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="department">Cognitive Science Program</orgName>
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychological and Brain Sciences</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<addrLine>1101, E. 10th St. Bloomington</addrLine>
									<postCode>47405-7007</postCode>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff4">
								<orgName type="department">Department of Psychological and Brain Sciences</orgName>
								<orgName type="institution">Indiana University</orgName>
								<address>
									<addrLine>1101, E. 10th St. Bloomington</addrLine>
									<postCode>47405-7007</postCode>
									<region>IN</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">BOOSTING WISDOM OF THE CROWD</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Medical Image Decision Making</term>
					<term>Wisdom of the Crowd</term>
					<term>Crowdsourcing</term>
					<term>Accuracy</term>
					<term>Performance</term>
					<term>Annotation</term>
					<term>Bayesian</term>
					<term>Prevalence</term>
					<term>Expertise</term>
					<term>Medical artificial intelligence BOOSTING WISDOM OF THE CROWD</term>
				</keywords>
			</textClass>
			<abstract>
				<p>A crucial bottleneck in medical artificial intelligence (AI) is high quality labeled medical datasets. In this paper, we test a large variety of wisdom of the crowd algorithms to label medical images that were initially classified by individuals recruited through an app-based platform. Individuals classified skin lesions from the International Skin Lesion Challenge 2018 into 7 different categories. There was a large dispersion in the geographical location, experience, training, and performance of the recruited individuals. We tested several wisdom of the crowd algorithms of varying complexity from a simple unweighted average to more complex Bayesian models that account for individual patterns of errors. Using a switchboard analysis, we observe that the best-performing algorithms rely on selecting top performers, weighting decisions by training accuracy, and take into account the task environment. These algorithms far exceed expert performance. We conclude by discussing the implications of these approaches for the development of medical AI. Significance Statement The revolution of medical artificial intelligence (AI) largely depends on its training with accurate, labeled data. However, the scarcity of such specialized data limits AI&apos;s potential to revolutionize patient care. Our research addresses this roadblock by exploring how &quot;wisdom of the crowd&quot; can enhance the labeling of medical images, using skin lesions as a case study. Using an app based platform to recruit a diverse pool of contributors globally, we tested multiple algorithms to determine which best harnessed the collective intelligence. Our top-performing algorithms, which factored in individual accuracy and the specific context of tasks, not only utilized this collective wisdom but surpassed the accuracy of medical experts. Our findings bridge the gap between a critical real-world challenge and basic research, opening the door for scalable, accurate, and cost-effective dataset generation, potentially expediting advancements in medical AI applications.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The future of medical artificial intelligence (AI) relies on the existence of large, high quality labelled biomedical image datasets for machine learning training <ref type="bibr" target="#b14">(Codella et al., 2019;</ref><ref type="bibr" target="#b53">Ørting et al., 2020;</ref><ref type="bibr" target="#b69">Tschandl et al., 2018)</ref>. Currently, the lack of such datasets is considered one of the largest bottlenecks in the development and training of medical AI systems <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b41">Kentley et al., 2023;</ref><ref type="bibr" target="#b53">Ørting et al., 2020)</ref>. Traditionally, these datasets have been meticulously curated based on the consensus of expert medical professionals <ref type="bibr" target="#b69">(Tschandl et al., 2018;</ref><ref type="bibr" target="#b73">van der Wal et al., 2021)</ref>. In contrast, the labeling of datasets involving everyday objects, such as ImageNet, scales easily through the use of online crowdsourcing <ref type="bibr" target="#b19">(Deng et al., 2009)</ref>.</p><p>Thus, some researchers and entrepreneurs have suggested that labeling medical images through crowdsourcing might provide one solution to the medical AI data bottleneck <ref type="bibr" target="#b1">(Alialy et al., 2018;</ref><ref type="bibr" target="#b22">Duhaime et al., 2023;</ref><ref type="bibr" target="#b41">Kentley et al., 2023;</ref><ref type="bibr" target="#b53">Ørting et al., 2020)</ref>.</p><p>Applying crowdsourcing to complex medical image decision-making tasks presents distinct challenges <ref type="bibr" target="#b70">(Tucker et al., 2019)</ref>. Not only are the images and tasks often unfamiliar to individuals outside the medical specialization, but they often need to be classified into one of many different classes with subtle differences. Even experts with extensive training are often wrong <ref type="bibr" target="#b6">(Barnett et al., 2019;</ref><ref type="bibr" target="#b40">Kämmer et al., 2017;</ref><ref type="bibr" target="#b67">Tschandl et al., 2019)</ref>. In this high-stakes domain, training medical AI systems with low-quality datasets could have serious health impacts.</p><p>Effectively harnessing collective intelligence using the wisdom of the crowd approaches has emerged as a powerful approach to solving many complicated classification problems including misinformation <ref type="bibr" target="#b2">(Allen et al., 2021)</ref> and deep fake detection <ref type="bibr" target="#b30">(Groh et al., 2022)</ref> as well as medical image decision making <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b45">Kurvers et al., 2016)</ref>. In medical domains, the aggregated decisions of multiple individuals can, not only match but, at times, surpass the performance of seasoned medical experts <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b45">Kurvers et al., 2016;</ref><ref type="bibr" target="#b49">Litvinova et al., 2022)</ref>. In this paper, we explore the possibility of harnessing collective wisdom from a wide variety of individuals to obtain classification decisions on complex medical images of skin lesions.</p><p>Translating the wisdom of the crowds from a controlled lab environment to a real-world application requires the testing and development of scalable systems that can acquire a large number of decisions in a short time at low costs <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b41">Kentley et al., 2023;</ref><ref type="bibr" target="#b53">Ørting et al., 2020)</ref>. A company -Centaur Labs -developed an app-based platform where individuals with a varying range of experience and expertise sign up to provide medical decisions <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b57">Press, 2021)</ref>. This is provided as a service to medical institutions that are interested in harnessing the wisdom of the crowd to label large medical datasets. In this paper, we use data collected by Centaur Labs in <ref type="bibr" target="#b22">Duhaime et al. (2023)</ref>, to comprehensively test the effectiveness of different approaches at arriving at the group decision.</p><p>Participants made decisions on images from the International Skin Lesion Collaboration (2018) <ref type="bibr" target="#b14">(Codella et al., 2019;</ref><ref type="bibr" target="#b69">Tschandl et al., 2018)</ref>. The images were collected from several different institutions so that they contained a wide variety of skin types and lesions <ref type="bibr" target="#b69">(Tschandl et al., 2018)</ref>. Participants categorized skin lesion images into one of seven different classes.</p><p>Participants received feedback on their decisions and learned the task after they signed up on the app. This task was difficult since even board-certified dermatologists made mistakes and had an accuracy of 74.7% <ref type="bibr" target="#b67">(Tschandl et al., 2019)</ref>. Further, the true label of the lesion was often determined through extensive testing such as histopathology and microscopy <ref type="bibr" target="#b69">(Tschandl et al., 2018)</ref>. Hence, all the necessary information about the true label of the lesion was sometimes not knowable through the image alone.</p><p>Since individuals could freely sign up on the mobile app, they had a range of different backgrounds. Many of them were medical students or pre-med students whereas others had no medical experience. As a result, there was a large variation in the accuracy, prior information, and dermatology knowledge across individuals. When confronted with a wide range of individuals, what is the best way of combining their individual decisions to produce a high-quality labeled dataset? On the one hand, the wisdom of the crowd crucially hinges on collecting enough decisions so that the biases of an individual decision-maker are canceled out during the aggregation process. The diversity of the crowd is an important component in the success of the wisdom of the crowd <ref type="bibr" target="#b8">(Broomell &amp; Davis-Stober, 2023;</ref><ref type="bibr" target="#b18">Davis-Stober et al., 2014;</ref><ref type="bibr" target="#b63">Surowiecki, 2005</ref>). Using the most common decision as the group decision -the majority-plurality rule -has been shown to be very robust and easy to implement <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b36">Hastie &amp; Kameda, 2005)</ref>. Weighting individual decisions (e.g., by their accuracy on training images) might have limited effectiveness since unweighted aggregation can perform as well as more complicated algorithms <ref type="bibr" target="#b3">(Armstrong, 2001;</ref><ref type="bibr" target="#b12">Clemen, 1989;</ref><ref type="bibr" target="#b17">R. N. Collins et al., 2023)</ref>. On the other hand, when there is a large dispersion in individual performance, it is possible to exploit the dispersion to improve the crowd performance <ref type="bibr" target="#b9">(Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b22">Duhaime et al., 2023;</ref><ref type="bibr" target="#b51">Mannes et al., 2014</ref>).</p><p>On the app, the training dataset was used to assess the performance of participants and give them daily rewards. This gave us the opportunity to objectively measure the performance of individuals. How does one effectively use this information to design wisdom of the crowd algorithms? In one approach, one could select the best decision-makers and discard the individuals with low accuracy. In another approach, one could weigh the decisions by performance. Or one could select the top performers and weigh their decisions appropriately.</p><p>The first approach based on selecting a smaller smarter sub-crowd has shown to improve accuracy in some domains <ref type="bibr" target="#b0">(Afflerbach et al., 2021;</ref><ref type="bibr" target="#b4">Atanasov &amp; Himmelstein, 2023;</ref><ref type="bibr" target="#b9">Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b23">Galesic et al., 2018;</ref><ref type="bibr" target="#b26">D. Goldstein et al., 2014;</ref><ref type="bibr" target="#b51">Mannes et al., 2014)</ref>. While different measures can be used to select a smarter sub-crowd <ref type="bibr" target="#b4">(Atanasov &amp; Himmelstein, 2023)</ref>, we can select individuals based on task performance on the training images. However, it is not clear how many people one must retain during the aggregation process. <ref type="bibr" target="#b64">Tetlock and Gardner (2016)</ref> and <ref type="bibr" target="#b37">Himmelstein et al. (2023)</ref> argue for the existence of superforecasters, who if identified can consistently beat the crowd. In D. <ref type="bibr" target="#b26">Goldstein et al., 2014</ref>, the authors find a decreasing relationship with the number of experts, where the performance decreases as more individuals are included.</p><p>However, including the decisions of more than one expert turned out to be useful. On the other hand, relying on one expert makes the algorithm susceptible to biases and noise of the expert.</p><p>Despite their extensive training, even experts are susceptible to noise in their decision process (R. <ref type="bibr" target="#b27">Goldstein et al., 2008;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b39">Kahneman et al., 2021;</ref><ref type="bibr" target="#b42">Koriat, 2012;</ref><ref type="bibr" target="#b47">Kurvers et al., 2023;</ref><ref type="bibr" target="#b49">Litvinova et al., 2022)</ref> and might even make inconsistent decisions on the same image <ref type="bibr" target="#b34">(Hasan et al., , 2023</ref><ref type="bibr" target="#b49">Litvinova et al., 2022)</ref>. Hence, there seems to be a need to not just rely on one expert but take multiple readings to reduce the noise in the final decision. This indicates that decisions might be improved by aggregating the decisions of multiple people.</p><p>The second approach is to apply weight to every individual's decision based on their performance <ref type="bibr" target="#b3">(Armstrong, 2001;</ref><ref type="bibr" target="#b5">Atanasov et al., 2017;</ref><ref type="bibr" target="#b9">Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b17">R. N. Collins et al., 2023;</ref><ref type="bibr" target="#b22">Duhaime et al., 2023;</ref>.</p><p>Initial results in <ref type="bibr" target="#b22">Duhaime et al. (2023)</ref> showed that directly weighting by the training accuracy can improve test accuracy. However, there are different ways in which performance is measured and weighted (R. N. <ref type="bibr" target="#b17">Collins et al., 2023)</ref>. For example, suppose we are interested in using accuracy as a means of measuring performance. It is unclear how this accuracy score is converted into a weight. For a binary classification problem with two classes of equal prevalence, a person responding randomly will have an accuracy of 0.5. Should one then assign the weight to be 0 for that individual? Should one transform it by some function -say the log before aggregation?</p><p>One might perform weighting in such a way as to account for individual biases and idiosyncrasies of individual decision-makers <ref type="bibr" target="#b38">(Juni &amp; Eckstein, 2017;</ref><ref type="bibr" target="#b61">Steyvers et al., 2014)</ref>. For instance, an individual might have a tendency to be cautious when declaring a skin lesion as cancerous. On the other hand, another individual might err on the other side, and call a lesion cancerous even when there is a small but non-zero chance of it being cancerous <ref type="bibr" target="#b76">(Wickens, 2001)</ref>.</p><p>Some wisdom of the crowd algorithms based on signal detection theory re-calibrate the judgments of different individuals before aggregating to account for these biases <ref type="bibr" target="#b38">(Juni &amp; Eckstein, 2017;</ref><ref type="bibr" target="#b61">Steyvers et al., 2014)</ref>. In this paper, we will address the question of whether one should correct for differences in response tendencies and accuracy in multiclass classification tasks.</p><p>We adopt a comprehensive approach and develop models of different sophistication. First, we establish a baseline using simple voting (i.e., majority voting), where the decision of the crowd is determined by the majority decision on every image. We compare this to algorithms based on selection alone while varying the number of individuals that are selected. We test simple models based on directly weighting by training accuracy. We develop a Bayesian framework that is based on estimating the probability of the different classes. Using this framework we specify different models that can account for individual differences in accuracy. We also develop algorithms that are based on the pattern of errors that are made in the task. We then tailor these for individuals by explicitly taking into account the different response tendencies. We also take into account the different prevalence rates of different lesion types. Finally, we conduct a comprehensive switchboard analysis, varying all of the different factors that make the algorithms <ref type="bibr" target="#b71">(Turner et al., 2018;</ref><ref type="bibr" target="#b81">Zhao et al., 2022)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>We used an app-based platform to recruit participants. The task involved the classification of images of skin lesions from the International Skin Imaging Collaboration (ISIC) 2018</p><p>Challenge <ref type="bibr" target="#b14">(Codella et al., 2019;</ref><ref type="bibr" target="#b69">Tschandl et al., 2018)</ref>. The goal was to obtain decisions on the 1511 test images to investigate the effectiveness of the wisdom of the crowds and to study different aggregation algorithms in a medical setting. We use the same data as <ref type="bibr" target="#b22">Duhaime et al. (2023)</ref> for our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>Participants were recruited from an iOS app-based platform called DiagnosUs.</p><p>Participants were told that they could improve their skills and contribute to medical artificial intelligence. They were rewarded based on their daily performance. The daily prizes were $40, $25, $20, $15, $10, $5, $4, $3, $2 and $1 respectively. The winners were determined based on their performance on the training set. To win a prize they would have needed to contribute at least service agreement where they consented to their data being used for commercial and academic purposes. Subsequent data analysis of the collected data was approved by the Institutional Review Board at Indiana University Bloomington (#20135).</p><p>Of the 458 people that signed up on the app, 315 participants gave at least one response in the task. In terms of gender, 167 (53.0%) of the participants identified as female, 127 (41.0%) as male, 8 (2.5%) as other, and 13 (4.1%) gave no response. There was a large variation in the geographical location, experience, and occupation of the participants. Individuals from all over the world belonging to 47 countries participated. Most of them (124, 39.4%) were from the Americas. Eighty-seven (27.6%) were from Africa, 50 (15.9%) were from Asia, and 39 (12.4%) were from Europe. Most (64.7%) of the participants said that they had no dermatology experience while others had differing amounts of dermatology experience (16.1% &lt;1 year; 7.4% 1-3 years;</p><p>2.4% 3-5 years; 1.2% 5-10 years; 1.8% 10+ years, 6.1% no response). A large number of participants were medical students (56.5%) or pre-medical students (8.8%). Some individuals were residents or fellows (4.3%), attending physicians (4.0%), nurse practitioners (2.1%), and 10.3% said that they had no medical experience. Some respondents (6.1%) gave no response to this question.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>The images were from the International Skin Imaging Collaboration (ISIC) 2018</p><p>Challenge <ref type="bibr" target="#b14">(Codella et al., 2019;</ref><ref type="bibr" target="#b69">Tschandl et al., 2018)</ref>. The full details of the dataset and challenge can be found on the website (https://challenge.isic-archive.com/landing/2018/47/) and in <ref type="bibr" target="#b69">Tschandl et al., 2018</ref>. We go over the main details here. These skin lesion images were obtained from a historical sample of patients from several different institutions for skin cancer screening. The true label of the dataset for malignancy was obtained using histopathology. The true label of the dataset for non-malignancy was determined through one of the following methods -histopathology, reflectance confocal microscopy, expert consensus and observation in follow-up visits <ref type="bibr" target="#b69">(Tschandl et al., 2018)</ref>. That is, the lesion did not change during digital dermatoscopic follow up over two years with at least three images. The images were collected so that they reflected a large variation in the kind of skin types, imaging techniques, and lesions.</p><p>The dataset was divided into 7 different types of skin lesions -actinic keratosis (AKIEC), benign keratosis (BKL), basal cell carcinoma (BCC), dermatofibroma (DF), melanocytic nevi (NV), melanoma (MEL), and vascular lesions (VASC). MEL and BCC are cancerous, AKIEC is precancerous while NV, DF and VASC are non-cancerous. The data collected was subdivided into 10015 train images and 1195 test images. In an effort to diversify the images, an additional 316 images was added to the test set. Hence there was a total of 1511 test images by <ref type="bibr" target="#b69">Tschandl et al., 2018</ref>. The labels for the test set were obtained by contacting the authors of <ref type="bibr" target="#b69">Tschandl et al. (2018)</ref> after data collection. The distribution of the images was skewed as shown in <ref type="table" target="#tab_0">Table 1</ref>, with most of them belonging to the two dominant classes -NV and MEL. As shown in <ref type="table" target="#tab_0">Table 1</ref>, there were more benign cases in the dataset compared to malignant, which was reflective of the real world <ref type="bibr" target="#b69">(Tschandl et al., 2018)</ref>. However, compared to the real world, the number of malignant cases was over-represented in the dataset <ref type="bibr" target="#b69">(Tschandl et al., 2018)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants first signed up for the app and provided their demographic information. After this, they could do an optional short tutorial block. In the main task, participants saw a single image on each trial and had to classify it into one of the seven different classes. Participants saw a 20-second timer within which they had to classify the image. Responses with response times longer than 20 seconds or with invalid response times were discarded as a part of the data-cleaning pipeline (0.8% responses). The average time to classify an image was 8.5 sec.</p><p>Images were randomly sampled from the train and test sets.</p><p>The images from the train set were sampled such that they were counterbalanced across the seven classes. The images from the test set were randomly sampled and hence were not counterbalanced across the seven classes. Participants were not told whether the image belonged to the train or the test set at the beginning of the trial. The image belonged to the train set 75% of the time and test set 25% of the time. If the image belonged to the train set, they received feedback on the trial. If the image belonged to the test set, they did not receive feedback on the trial. Participants could label images for as long as they liked. They needed to label at least 100 images to be entered into the daily competition. They could exit the app at any time and could resume when they wanted to.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral Results</head><p>We now present the behavioral results. The results of the different aggregation algorithms will be described and presented in the next section.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of Dataset</head><p>A total of 143, 209 decisions were made in the task. Of these, 107, 506 decisions were made on training images and 35, 703 decisions on the test set. Each participant participated for a median of 2 days (Mean: 3.5; IQR: 1 − 4; Max: 14) and contributed a median of 100 (Mean: 130.4; IQR: 31 − 121; Max: 4, 218) decisions per day. Across the 14 days, they saw a median of 135 images (Mean: 454.6, IQR: 33.5-395; Max 13, 563). As shown in <ref type="figure">Figure 1</ref> and <ref type="table" target="#tab_1">Table 2, there</ref> was a large skew in the number of responses with a few individuals contributing a disproportionately large number of responses. For instance, 60 individuals made more than 500 decisions across the 14 days. These 60 individuals make up about 19% of all individuals who participated in the experiment and contributed 76.63% of responses. A single individual made more than 10000 decisions, which made up 9.5% of the data set. When analyzed at the image level, there was a large difference in the number of total decisions on train and test images. On the training set, there was a median of 3 responses per image with a large range in the number of responses (IQR: 1 − 13; Min: 1; Max= 156). On the test set, there was a median of 24 responses per image. Since the experiment was designed so that each of the test images had a similar number of responses, we observed a narrower range (IQR-23 − 24; Min= 21; Max= 25).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Accuracy</head><p>As shown in <ref type="figure">Figure 1</ref>, participants' average accuracy for the training data set was 41.6%</p><p>(IQR: 28.2% -57.1%) and the testing set was 42.7% (IQR: 24.4%-60.7%). This indicated that most participants performed the task with better accuracy than chance. However, this was much lower than the average accuracy of dermatologists of 74.7% (70.8% − 78.6%) <ref type="bibr" target="#b67">(Tschandl et al., 2019)</ref>. We also note the wide distribution of accuracy of the participants in our dataset.</p><p>As shown in <ref type="figure">Figure 1</ref>, the log of the number of decisions that individuals contributed was positively correlated with their accuracy; r(313) = .67 (p &lt; 0.001) for the train set and r(300) = .39 (p &lt; 0.001) for the test set. Hence, the more accurate individuals provided a larger number of decisions. The average accuracy of the train set was 61.2% and test set was 58.1%.</p><p>When the average accuracy of the data is calculated, and not at the individual level, the accuracy shifts closer to the accuracy of the individuals who contributed more responses. Since these individuals were also the more accurate ones, the average accuracy of the data is higher than the participants' average accuracy reported above.</p><p>We calculated the accuracy based on the lesion type. As observed in <ref type="figure">Figure 2</ref>, there was a large difference in the performance across the lesion types. Consider the panel on the top left.</p><p>This shows the confusion matrix for the training images. For example, participants were pretty good at identifying VASC and correctly identified it 91.6% of the time. Comparatively, participants were not very good at identifying AKIEC and identified it 48.3% of the time. We also observed that the types of errors were not random. For instance, NV was misclassified as MEL 13.8% of times but only 3.9% as AKIEC. We note that the confusion matrix for the train and test images were similar, but there were notable differences. For instance, the test set had elevated misses for low-frequency classes such as VASC and DF as compared to the train set. This pattern of errors is similar to low prevalence effects documented in other medical image domains <ref type="bibr" target="#b65">(Trueblood et al., 2021;</ref><ref type="bibr" target="#b80">Wolfe et al., 2005</ref>).</p><p>In the lower two panels, we compared the confusion matrices on the training data for the two participants with the most number of responses. While we note that the patterns of mistakes were similar, there were also some differences. For example, the participant with the second most number of responses also had a higher accuracy across all of the lesion types and overall made fewer errors. We also note that for instance, they correctly identify a similar number of MEL as the first participant (51.6% compared to 51.8%) but they do so at the cost of misidentifying 17.9% as opposed to 9.2% of NV as MEL.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We make the following observations. First, a substantial imbalance exists in participant responses, wherein a small number of individuals contribute a disproportionate quantity of responses. Second, those who provide a greater number of responses tend to also exhibit higher levels of accuracy. Third, we observe individual differences in performance, characterized by a diverse range of accuracy scores. Fourth, confusion matrices of lesion types indicate varying frequencies of specific errors. Fifth, although shared errors are observable across different individuals, individual differences in patterns of errors are also apparent.</p><p>We note that designing algorithms that address the substantial individual differences in accuracy and response patterns might be crucial to optimally aggregating decisions for the wisdom of the crowd approaches. Accounting for individual differences in accuracy where the decisions of more accurate individuals are given more weight might lead to higher accuracy in the crowd decision. Further, accounting for the specific patterns of errors of different individuals might help appropriately weight decisions for the different lesion types and lead to optimal use of information in each response.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Modeling Methods</head><p>In this paper, the goal was to comprehensively test different ways of arriving at the group decision when soliciting individual decisions from an app-based interface. We build on the two simple methods tested in <ref type="bibr" target="#b22">Duhaime et al. (2023)</ref> and comprehensively test different aggregation approaches. Specifically, we examine two types of aggregation approaches. First, we try selection where the responses from a set of top-performing individuals are used while others are discarded.</p><p>Second, we examine weight approaches, where we weigh individuals based on some function of their accuracy. Finally, we will also try hybrid approaches that combine selection and weighting.</p><p>We use the following notation throughout the paper. Let the set of lesion types be T. Let the 7 different lesion types AKIEC, BCC, BKL, DF, MEL, NV and VASC be T 1 , T 2 , ..T 7 ∈ T. Our goal is to define the weights for each of the decisions for the 7 different lesion types.</p><p>Different individuals saw different images and made decisions about them. Since we are aggregating decisions on a given test image, we define the crowd C i in terms of the i th test image.</p><formula xml:id="formula_0">Suppose participants P 1 , P 2 , ...P n have made decisions d i,1 , d i,2 ...d i,n on the i th test image to form the crowd C i . Hence, C i is a set of decisions on i.</formula><p>We define a weight function w T (d i, j ) which is a function of the individual decision d i, jfor each lesion type T k . The decision of the crowd D i on the i th test image is obtained by summing these weights for the decisions d i, j that are a part of the crowd C i and selecting the type with the largest weight.</p><formula xml:id="formula_1">D i = argmax T ∈T ∑ d i, j ∈C i w T (d i, j )</formula><p>In this paper, we first use the simple voting algorithm to establish a baseline. We then test two different methods of aggregating decisions. We first test algorithms where individuals are selected based on their training accuracy and then we test algorithms based on weighting decisions by training accuracy. Finally, we conduct a switchboard analysis where we test hybrid algorithms that combine both selection and accuracy weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simple Voting</head><p>The baseline algorithm that we consider is the majority-plurality rule <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b36">Hastie &amp; Kameda, 2005)</ref> or simple voting. This is the simplest algorithm where we retain all the decision-makers that form the crowd C i and give an equal weight of 1 to each of their votes.</p><formula xml:id="formula_2">w T (d i, j ) =        1 if d i, j = T 0 if d i, j ̸ = T</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms based on Selection Weighting</head><p>In this section, we describe the first set of algorithms that are based on selecting individuals based on their training performance. Individuals that are not selected are discarded during the aggregation process by setting their weight to zero. These algorithms are based on the idea that excluding participants with poor judgment improves the quality of the crowd and hence the accuracy (D. <ref type="bibr" target="#b26">Goldstein et al., 2014;</ref><ref type="bibr" target="#b51">Mannes et al., 2014)</ref>.</p><p>We define a subset S i of C i which is a subset of decisions made on the i th test image. We define the weights using the indicator function 1 S i . That is, if the decision d i, j is in the subset of decisions S i , then the weight is 1, else it is 0. If the subset S i includes everyone that has made a decision on the image i, then S i = C i and is equivalent to simple voting.</p><formula xml:id="formula_3">w T (d i, j ) =        1 S i if d i, j = T 0 if d i, j ̸ = T</formula><p>In this paper, we use the training accuracy of the individuals that made decisions d i, j in C i to define S i . Let the training accuracy of the j th individual that made decision d i, j in C i be a j . Let M r,i be the set of top r decisions made by individuals with the highest training accuracy who decided in C i . Since on every test image, we had between 21 and 25 decisions, we vary r from 1 to 20. That is, we set S i = M ri and vary r from 1-20. Thus, there was an equal number of decisions on each image.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms based on Accuracy Weighting</head><p>In this section, we describe the different algorithms that rely on weighting the decisions made by individuals based on their training performance. In this paper, we consider several different approaches to weighting decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simple Accuracy Weighting (SAW):</head><p>The weight of each individual decision is the training accuracy of the participant that made the decision, which is calculated as the fraction correct on the train data <ref type="bibr" target="#b22">(Duhaime et al., 2023)</ref>. This includes the decisions made on all of the 7 different types of skin lesions. Let the training accuracy of the j th participant P j be a j . In this algorithm, we summarize the performance of each participant using a simple metric that we use to weigh the decision.</p><formula xml:id="formula_4">w T (d i, j ) =        a j if d i, j = T 0 if d i, j ̸ = T Bayesian -Log Accuracy Weighting (LAW):</formula><p>Our goal is to estimate the probability that an image is of type T given decisions d i, j . Let D i, j be the random variable that encodes the decision of the j th person on the i th image. Using Bayes theorem for the first equality and independence assumption for the second equality, we have</p><formula xml:id="formula_5">P(T | D i,1 = d i,1 and D i,2 = d i,2 ) = P(D i,1 = d i,1 and D i,2 = d i,2 | T )P(T ) P(D i,1 = d i,1 and D i,2 = d i,2 ) = P(D i,1 = d i,1 | T )P(D i,2 = d i,2 | T )P(T ) P(D i,1 = d i,1 and D i,2 = d i,2 )</formula><p>.</p><p>The ratio of the probability for two types T 1 and T 2 is given as follows:</p><formula xml:id="formula_6">P(T 1 | D i,1 = d i,1 and D i,2 = d i,2 ) P(T 2 | D i,1 = d i,1 and D i,2 = d i,2 ) = P(D i,1 = d i,1 | T 1 )P(D i,2 = d i,2 | T 1 )P(T 1 ) P(D i,1 = d i,1 | T 2 )P(D i,2 = d i,2 | T 2 )P(T 2 )</formula><p>.</p><p>If the prevalence of the different types are equal, P(T 1 ) = P(T 2 ), then the priors are equal and selecting the type with the largest likelihood is equivalent to assigning the weights</p><formula xml:id="formula_7">w T (d i, j ) = log(P(D i, j = d i, j | T k )).</formula><p>Our goal is to estimate P(D i, j | T k ) for the decision makers and different image types. If we allow for the prevalence to be different (which is the case for the test images), then we need to include the prior term for each lesion type. If π T is the prevalence of T , we have the following expression.</p><formula xml:id="formula_8">D i = argmax T ∈T ∑ d∈C i log(P(D i, j = d i, j | T k )) + log(π T ) Equal Weighting (LAW-E)</formula><p>In the equal weighting algorithm, we use the mean training accuracy of the individual to estimate the probability of the different types. Suppose the accuracy of the participant P j is a j .</p><p>Suppose, this individual sees a test image of type T . Based on the training images, the probability that they are correct is a j . Hence, we estimate the probability that d i, j is T as a j . The probability</p><formula xml:id="formula_9">that d i, j is not T is 1 − a j .</formula><p>For this algorithm, we assume that it is equally likely for the decision to be any of the other ∥T∥ − 1 types. Note that ∥T∥ represents the number of image types, which is 7 in our case. Hence, we estimate the probability of the decisions to be one of the other</p><formula xml:id="formula_10">(non-selected) types as (1 − a j )/(∥T∥ − 1).</formula><p>Hence, we weigh the decision for the selected type by log(a j ) and for the types that were not selected by log((1 − a j )/(∥T∥ − 1)):</p><formula xml:id="formula_11">w T (d i, j ) =        log(a j ) if d i, j = T log((1 − a j )/(∥T∥ − 1))if d i, j ̸ = T</formula><p>We note that if the training accuracy a j is 0 or 1, either the top term or the bottom term becomes undefined. To fix this, we include a threshold parameter 0 &lt; τ &lt; 1. We constrain training accuracy to the range τ to 1 − τ by placing these as hard boundaries. That is, if the accuracy is lower than τ then we replace it by τ or greater than 1 − τ then we replace it by 1 − τ.</p><p>In the main paper, we set τ = 0.02, and we vary τ in supplement to show that unless τ is large (above 0.1), it does not change the results.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Confusion -All Weighting (LAW-CA)</head><p>In the confusion-all weighting algorithm, we incorporate information about the pattern of classification mistakes in training. For example, MEL and NV appear similar to each other and are often confused. For an NV image, one might respond MEL more often than AKIEC. Let</p><formula xml:id="formula_12">c d i, j</formula><p>,T represent the probability when the true class is T , the selected class is d i, j in training. These weights are identical to the ones depicted in the top left panel of <ref type="figure">Figure 2</ref>. For this algorithm, we calculate these values at the group level (see top panel of <ref type="figure">Figure 2</ref>). While estimating these numbers at the group level allows us to have accurate estimates for each of the terms of the confusion matrix, it ignores the individual differences in training accuracy and response styles.</p><p>We define the weights as follows:</p><formula xml:id="formula_13">w T (d i, j ) = log(c d i, j ,T )</formula><p>Confusion -Individual User Weighting (LAW-CI)</p><p>In the confusion -individual user weighting algorithm, we account for individual differences in the pattern of responses as illustrated in the bottom panels of <ref type="figure">Figure 2</ref>. For instance, a participant might be biased toward selecting one image type versus another because of biases in their training data, response style, or prior knowledge. Let c d i, j ,T represent the probability during training that when the true class is T , the selected class is d i, j , for participant P j and training image i. We define the weights as follows.</p><formula xml:id="formula_14">w T (d i, j ) = log(c d i, j ,T )</formula><p>As mentioned in the previous section, we constrain these values to stay in the range τ to 1 − τ. We conduct a sensitivity analysis in the supplement where we vary τ to show that as long as it is not too large (above 0.1), the results are similar.</p><p>While this algorithm accounts for the individual differences in training accuracy and response styles, these estimates might be noisy for each of the terms due to insufficient data.</p><p>Hence, we estimate these weights for the 51 individuals who made 100 decisions or more on the training data, which constitutes 95.15% of the train set. For the remaining individuals, we use the confusion matrix that was calculated at the group level. In the supplement, we restrict the data to the individuals who made 500 or more train decisions and the results are qualitatively the same.</p><p>We also include variants of these algorithms that account for the prevalence of different lesions. For the names of each of these algorithms, we use an additional P to indicate the use of the prevalence priors. That is, the variants of the algorithms that use priors are LAWP-E, LAWP-CA and LAWP-CI for LAW-E, LAW-CA and LAW-CI respectively. We estimate the prevalence of different lesions based on the training data as shown in <ref type="table" target="#tab_0">Table 1</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Switchboard Analysis</head><p>In the section above, we described algorithms based on two main techniques -selection and weighting. It is possible to combine both selection and weighting into a single algorithm. Let S i be the subset of selected participants for the i th image and w ′ be an accuracy-weighting scheme.</p><p>That is, if the individual is in the selected subset S i , then the decision is weighted based on the weighting scheme w ′ T .</p><formula xml:id="formula_15">w T (d) = w ′ T (d)1 S i</formula><p>In this paper, we conduct a full switchboard analysis where we investigate all of our different ways of selection and combine them with the different ways of accuracy weighting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics</head><p>Different metrics capture different aspects of the performance <ref type="bibr" target="#b31">(Hand, 2006</ref><ref type="bibr" target="#b32">(Hand, , 2012</ref>.</p><p>Depending on the real world application, one might consider a different performance metric that needs to be maximized. Following Tschandl et al., 2019, we capture the performance of the crowd with four different metrics:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics based on final decision</head><p>The first two metrics only look at the final decision of the algorithm.</p><p>• Accuracy: The first metric is the mean accuracy. This is the average probability that the crowd is correct. A response bias towards the classes with higher prevalence might increase the overall accuracy since it constitutes most of the test classes. Since our test dataset is imbalanced with one class, NV, having more images than the others, one might achieve a higher accuracy by performing well on NV but not on other classes. For example, a decision maker that responds 'NV' on all images will have an accuracy of 60.1% (equal to the prevalence of 'NV' in the test set) since they will get all of the 'NV' images correct and all other images incorrect.</p><p>• Balanced Accuracy (Mean Sensitivity): This is the mean sensitivity score for each class.</p><p>The sensitivity is the fraction of the lesions of Type T that have correctly been identified <ref type="bibr" target="#b29">(Grandini et al., 2020)</ref>. Specifically, if TP T is the number of true positive cases of type T and FN T is the number of false negative cases for lesion type T , the sensitivity for type T is given by TP T TP T +FN T . The balanced accuracy is given by:</p><formula xml:id="formula_16">Balanced Accuracy = ∑ T ∈T (Sensitivity T )/|T| = ∑ T ∈|T| TP T TP T + FN T /|T|</formula><p>The goal of the balanced accuracy metric is to give equal weight to decisions for all lesion types. For any given lesion class -T 1 , one can achieve a perfect sensitivity score of 1 by always responding T 1 . However, this impacts the sensitivity of all of the other classes. For instance, suppose a decision maker responds 'NV' on all of their trials, they will never be wrong with the images of type 'NV'. Hence, they will have a perfect sensitivity of 1.0 for the lesion of type 'NV'. However, they will have a sensitivity of 0 on all of the other classes since they are not 'NV'. Hence, their mean sensitivity in this case will be 1/7 = 14.2%</p><p>while maintaining an accuracy of 60.1%. In some real-world cases, the performance on rare lesions might not be as important as the performance on the more common lesions. Here, one might focus on the accuracy metric. In cases where the rare lesions are equally important as the more common ones, one might want to focus on the balanced accuracy metric.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Metrics based on weights of different classes</head><p>In medicine, not all the mistakes are equal. Thus, we might adaptively apply different thresholds to either be cautious about making misses or false alarms. Suppose the outputs of the algorithm for the seven different lesion types are (w 1 , w 2 , ...w 7 ). Hence, instead of restricting ourselves only to the final decision, or the lesion with the maximum weight, we might use the weight given to each lesion class to evaluate each of the algorithms. For this purpose, we introduce metrics that measure the algorithm's ability to tradeoff between false alarms and misses. We introduce two measures of the Area Under the Curve of the Receiver Operating Characteristic (ROC-AUC).</p><p>• Mean ROC-AUC: The mean ROC-AUC is the mean of the 7 ROC-AUC values which is calculated based on a one vs. the rest classification for the 7 different lesion types. Each of the 7 weights helps in making a tradeoff between false alarms and misses of the seven different classes. For a high mean ROC-AUC, each of these 7 terms needs to be informative about the tradeoff. Hence, the mean ROC-AUC metric captures the ability to trade-off between false alarms and misses of all seven different classification decisions.</p><p>• Malignant ROC-AUC: One might be interested only in the binary classification of lesions as malignant versus not malignant. We group the lesion types into malignant types -AKIEC, BCC and MEL and non-malignant types -BKL, DF, NV and VASC. We then calculate the ROC-AUC of the different algorithms. For this, the total weight given to the cancer types w cancer = w AKIEC + w BCC + w MEL and total weight given to the non-cancerous types w non-cancer = w BKL + w DF + w NV + w VASC are important but the distribution within each of the sub-classes is not important. Hence, the malignant ROC-AUC metric captures the ability to trade-off between false alarms and misses between malignant and non-malignant classification decisions. Discriminating between the specific kind of malignancy and non-malignancy is not as important.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>We present the results obtained from applying the modeling methods mentioned above.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Simple Voting</head><p>We estimated the performance of simple voting for a crowd of varying sizes (n) to obtain a baseline. We estimated the performance of simple voting for a given n by randomly choosing decisions such that there were n decisions on every image. We used this subset to estimate the performance of the group of size n. As shown in <ref type="figure">Figure 3</ref>, we observed that the performance improved across the different metrics as the group was made larger.</p><p>As shown in <ref type="figure">Figure 3</ref>, when one person's decision was considered, the accuracy was 56.9%. We note that this is slightly different from the mean accuracy reported on the test set since only one decision for every image was selected before making an estimate. Accuracy rose to 74.9% when 8 decisions were used, matching the performance of a single dermatologist at 74.7% <ref type="bibr" target="#b67">(Tschandl et al., 2019)</ref>. The crowd's performance exceeded expert performance when all of the decisions were used by achieving an accuracy of 78.2%. The results similarly improved balanced accuracy when more decisions were aggregated. When only one decision was considered, it was 53.9% which rose to 73.7% with 8 decisions and 78.2% when all of the decisions were aggregated.</p><p>The mean ROC AUC also increased from 0.731 when one decision was considered to 0.922 with 8 decisions and 0.945 when all of the decisions were aggregated. The malignant and non-malignant ROC AUC increased from 0.716 when one decision was considered to 0.902 with 8 decisions and to 0.928 when all of the decisions were used.</p><p>This shows that including more people dramatically improves performance across different metrics as in <ref type="bibr" target="#b22">Duhaime et al. (2023)</ref>. The high values for the ROC-AUC indicate that the crowd was not just able to classify images into the correct class but also had the ability to capture a measure of the uncertainty in the classification.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms based on Selection-Weighting</head><p>We tested the algorithms based on selection. We selected the top r individuals based on their accuracy on the training set and calculated their aggregated decisions on the test set. Our results are shown in <ref type="figure">Figure 4</ref>.</p><p>We observed that the accuracy when the top individual was selected was 78.0%. The accuracy slightly rose to a maximum of 80.3% when decisions from the top 7 people were aggregated. The accuracy slightly dropped to 78.4% when decisions from 21 people were selected. Hence, we see that the accuracy of the crowd might improve slightly when individuals are selected based on their training accuracy.</p><p>The balanced accuracy for only selecting the top-performing individual was 69.0% which is a lot lower than 78.2% with simple voting. Hence, we see that when the top one or two individuals are selected, the balanced accuracy is lower than keeping everyone in the crowd.</p><p>Balanced accuracy weights the performance on the rare classes as much as the performance for the more prevalent classes. We observed similar accuracy scores when retaining the entire crowd or when only the top 1 or 2 individuals were selected. However, we observed lower balanced accuracy scores when only the top 1 or 2 individuals were selected. This indicates a drop in the sensitivity of the rarer classes when only the top one or two individuals are selected to form the crowd. As more individuals were included, the balanced accuracy sharply rose to a maximum of 79.6% when decisions from 11 individuals were aggregated. The balanced accuracy dropped slightly to 77.9% when decisions from the top 21 people were selected. This indicates that there might be potential gains in balanced accuracy from selecting an optimal number of people.</p><p>The mean ROC-AUC and malignant ROC-AUC have a clear trend. We observed that the mean ROC-AUC was 0.822 when only the top individual was selected. The mean ROC-AUC consistently improved to 0.947 as more participants were included. Similarly, the malignant ROC-AUC started off at 0.784 and improved to a maximum of 0.938 when decisions from the top 13 people were aggregated and then gradually declined to 0.930 when decisions from 21 people were aggregated. Thus we see that when more individuals are selected, one is better able to make trade-offs between the false alarms and misses compared to when only the top 1 or 2 performers form the crowd.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithms Based on Accuracy-Weighting</head><p>We tested the algorithms that depended on weighting the decisions based on the training accuracy of individuals. Specifically, as described in the modeling methods section, we tested the simple accuracy weighting algorithm (SAW) and weighting based on the log accuracy (LAW).</p><p>When weighing by the log of the accuracy, we tested three different variants. The first one accounted for individual differences in accuracy but did not account for the patterns in the classification errors between the different types (LAW-E). The second one accounted for the pattern of errors between the different image types made at the group level but did not account for individual differences (LAW-CA). The third one accounted for the pattern of errors in the image type made at the individual level (LAW-CI).</p><p>First, we were interested in comparing how similar these algorithms were to each other.</p><p>We calculated the inter-algorithm disagreement rate which was the fraction of the test images on which the decisions made by the different algorithms were different from each other (see <ref type="figure">Figure   5</ref>). The SAW, LAW-E and LAW-CA were pretty similar to SV (simple voting) and disagreed only on 3.5%, 4.0% and 3.8% of the cases. LAW-CI was maximally dissimilar to SV on 6.0% of the cases.</p><p>Next, we compared the different accuracy weighting algorithms on the four key metrics as presented in <ref type="table">Tables 3 and 4</ref>. We bootstrapped over the test set and compared two algorithms to each other on the sampled subset to estimate the uncertainty in the improvement. We present comparisons between each algorithm and simple voting in the main paper. The full pairwise comparison between all algorithms is presented in the supplement. On the accuracy metric, we observed that algorithms that accounted for individual differences, SAW and LAW-E (both had an accuracy of 79.6%), performed better than simple voting. As shown in <ref type="figure">Figure 5</ref>, SAW and LAW-E were very similar to each other and disagreed only on 0.5% of the decisions. Hence, weighting by logs or directly by the training accuracy gave very similar results in terms of the final decision. LAW-CI also performed slightly better than simple voting and had an accuracy of 79.0% and balanced accuracy of 78.9%. We note that the difference in accuracy between LAW-CI and SV was only 0.8 percentage points , but the inter-algorithm disagreement rate was 6.0%.</p><p>Thus, the difference between LAW-CI and SV was not just due to the improvement in the performance of LAW-CI. Rather, these two algorithms arrive at different decisions. Finally, LAW-CA, which did not account for individual differences, performed similar to simple voting.</p><p>For the mean and malignant ROC-AUC score, the weighting algorithms performed better than simple voting. The mean ROC for simple voting was 0.945 and for SAW, LAW-E, LAW-CA and LAW-CI was 0.949, 0.953, 0.950 and 0.956 respectively. This indicates that the weighting algorithms might be able to provide a slightly more fine-grained ability to distinguish between the different skin lesion classes.</p><p>When we accounted for the prevalence of different image classes, using the modification described in the modeling methods, the decisions for LAW-E, LAW-CA and LAW-CI changed for 0.9%, 2.0% and 1.6% of the cases as shown in <ref type="figure">Figure 5</ref>. Compared to similar algorithms that exclude the prevalence terms, the accuracy increased and the balanced accuracy decreased.</p><p>Accounting for prevalence increases the response of image types with higher prevalence, which plays a larger role in the accuracy metrics. This decreases the correct identification of other lesion types, which plays a larger role in the balanced accuracy score. However, this effect is small since this extra term rarely overturns the decision of the entire crowd. The mean ROC-AUC and malignant ROC-AUC scores do not change too much indicating that the rate at which the tradeoff between false alarms and misses of the different lesion types remains similar to the algorithms that do not account for prevalence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Switchboard Analysis</head><p>We now conduct a full switchboard analysis to test the different hybrid algorithms. We present our results in <ref type="figure">Figure 6</ref>. We make the following observations.</p><p>We observe that the accuracy ranges from 77.6% to 80.5% and balanced accuracy ranges from 69.0% to 78.9% depending on the aggregation algorithm when no prevalence information is used. The worst-performing algorithms, especially in the balanced accuracy metric, select only the top performers and exclude the rest. Regardless of the weighting method, the optimal number of top-performing individuals for our task was about 4 − 10. Across the different weighting methods, the best-performing algorithms were a combination of selection and accuracy weighting. Compared to algorithms based on selection weighting alone, for some accuracy weighting methods like SAW or LAW-E, retaining participants beyond the optimal number does not depreciate the performance notably across both metrics. This suggests that when weighted appropriately, one might not need the additional step of selection.</p><p>Similar to the algorithms based on selection alone, the mean ROC-AUC and malignant ROC-AUC continue to remain high when a large number of people are included in the crowd.</p><p>The worst-performing algorithms were the ones that only used the top few performers. We observe that all the different accuracy weighting methods, especially the ones that used logarithmic weighting, had a higher mean ROC AUC score compared to the ones dependent on selection alone. For the malignant ROC-AUC, we observed that one can achieve a high score even with selection weighting alone and no accuracy weighting when one uses between 10-13 of the top performers. However, we note that the accuracy-based weighting methods were robust to the inclusion of more participants beyond the optimal number compared to the ones that relied on selection alone, where the performance decreased slightly.</p><p>When we accounted for the prevalence as described in the modeling methods, we observed that the accuracy increased and the balanced accuracy decreased. As described in the previous section, this is due to the fact that the high prevalence classes play a larger role in accuracy than in balanced accuracy. When decisions from a small number of individuals are selected before aggregating, we observe that this difference is larger since the priors play a bigger role in the final decision. As more and more individuals are added, the algorithm becomes increasingly similar to the ones that ignore the priors and weight the decision of the crowd.</p><p>However, we observe that the peak and decrease in performance suggests that the priors are being underweight compared to the decision when a large number of decisions are being aggregated.</p><p>We observe that this modification does not change the algorithm's ability to trade-off between false alarms and misses which is why the mean ROC-AUC and malignant ROC-AUC are similar to algorithms without the prevalence term.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>In this paper, we used decisions obtained from an app-based interface to study the value of wisdom of crowds in medical image annotation <ref type="bibr" target="#b22">(Duhaime et al., 2023)</ref>. Given the wide range of accuracy and individual differences in patterns of errors, we compared different aggregation algorithms to produce a wisdom of the crowds in medical image decision-making that accounted for these differences. Overall, we observed that a simple voting aggregation strategy resulted in higher accuracy (78.2%) than that of a single dermatologist (74.7%), corroborating previous findings that wisdom of the crowds is an effective approach to labeling medical images <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b38">Juni &amp; Eckstein, 2017;</ref><ref type="bibr" target="#b45">Kurvers et al., 2016;</ref><ref type="bibr" target="#b79">Wolf et al., 2015)</ref>.</p><p>We also found further improvements in crowd performance by using more sophisticated strategies that selected top performers and weighted decisions by training accuracy. Specifically, the best algorithms improved performance over simple voting by around 3-4 percentage points for accuracy and around 1-2 percentage points for balanced accuracy metrics and mean ROC-AUC and malignant ROC-AUC by 0.01 points. We observed that while one might achieve high performance with selection weighting alone, using accuracy weighting in conjunction with selection makes the gains more robust beyond the optimal number of people, which might be crucial in practical applications when one does not know the optimal number of decisions.</p><p>Although selecting a small crowd of top performers based on training images generally improved accuracy and balanced accuracy, we observed that selecting the top one or two performers hurt performance across different performance metrics. Finally, accounting for prevalence might help increase certain metrics such as accuracy but might hurt balanced accuracy, but not others such as the ROC-AUC, which is largely independent of the prevalence. Hence we see that different algorithms might perform slightly better or worse based on the metric used to evaluate them.</p><p>Depending on the specific use case, an individual might prefer one metric over another <ref type="bibr" target="#b31">(Hand, 2006</ref><ref type="bibr" target="#b32">(Hand, , 2012</ref> and thereby select the aggregation algorithm that is best suited for that metric.</p><p>The results of our paper have important consequences for the labeling of medical images.</p><p>First, using our approach, we obtained labels for a medical task at an accuracy that surpassed expert performance. Second, the data collection in our project took place over the span of 14 days, which is very quick for a dataset of this scale. If a single expert was to label the test set non-stop, assuming they take the median of 8.5 sec per decision, they would take 215 hours to label this dataset which amounts to more than 5 work weeks. Several such projects can take months to obtain high-quality labels <ref type="bibr" target="#b13">(Cocos et al., 2017)</ref>. Third, cost is a major factor in being able to determine the viability of such a project <ref type="bibr" target="#b41">(Kentley et al., 2023;</ref><ref type="bibr" target="#b53">Ørting et al., 2020)</ref>. By paying the crowd-sourced workers a total of $1, 750 in daily rewards over 14 days, Centaur Labs obtained 143,209 classification labels. This implies that the cost of an individual decision amounts to only $0.0122 per decision. The cost of 8 decisions per image which matches expert performance is $0.097, implying the dataset with 1,511 images can be labeled for $146.57.</p><p>Accounting for a 50-50 test train split, the cost is less than $300 to label the dataset with 1,511</p><p>images. Fourth, when creating a new dataset in a different medical domain, one will need to identify specialized experts and create a new platform for recruitment and data collection for each application. In our case, the users signed up on the app for one task, could also be trained and deployed in another task, leading to a scalable solution. Hence, the app-based platform is accurate, fast, cost-effective and scalable to other medical tasks.</p><p>In our task, as we increased the number of individuals during the aggregation processes (that is, adding individuals randomly to the crowd and not based on training performance), all crowd-based performance metrics (i.e., accuracy, balanced accuracy, mean ROC-AUC, and malignant ROC-AUC) increased, showing a robust wisdom of the crowd effect <ref type="bibr" target="#b22">(Duhaime et al., 2023)</ref>. The increase in performance metrics was rapid at first but slowed down as more decisions were included, which is similar to the patterns in many tasks <ref type="bibr" target="#b22">(Duhaime et al., 2023;</ref><ref type="bibr" target="#b23">Galesic et al., 2018;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b36">Hastie &amp; Kameda, 2005)</ref>. Consistent with <ref type="bibr" target="#b36">Hastie and Kameda, 2005,</ref> we find that simple voting performed well in our task. The best-performing algorithm that did not use prevalence information, improved accuracy by 2.3 percentage points (i.e.LAW-CI with top-4 individuals) and balanced accuracy by 1.4 percentage points (No Weight-Top 11) compared to simple voting when all decisions were used. In high-stakes fields such as medicine, this improvement could lead to significantly superior downstream consequences especially when such a system is deployed at scale.</p><p>On metrics such as the mean ROC-AUC and malignant ROC-AUC, we observe that these metrics increase and continue to remain high even when the entire crowd is retained. This suggests that there is valuable information in the decisions of the low-performing individuals.</p><p>This bolsters some of the wisdom of the crowd findings where novices, such as undergraduate psychology students, could learn to classify white blood cell images which when combined together exceeded expert performance <ref type="bibr" target="#b34">(Hasan et al., 2023)</ref>. Non-experts recruited in DiagnosUs with Centaur Labs showed that with a little training, crowds could identify complex lesion attributes <ref type="bibr" target="#b41">(Kentley et al., 2023)</ref>. This opens up the possibility of expanding the scope of citizen science projects <ref type="bibr" target="#b15">(Cohn, 2008;</ref><ref type="bibr" target="#b62">Sullivan et al., 2014)</ref>.</p><p>We observe that accuracy weighting improves performance across the different metrics, suggesting that it does well in our task, which is similar to previous research <ref type="bibr" target="#b5">(Atanasov et al., 2017;</ref><ref type="bibr" target="#b9">Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b12">Clemen, 1989;</ref><ref type="bibr" target="#b17">R. N. Collins et al., 2023;</ref>. The log accuracy weighting does slightly better in the mean ROC-AUC and the malignant ROC-AUC, especially when aggregating decisions over a smaller number of people. Since these algorithms often create similar final responses, this rarely changes the final decision and hence is better reflected in the mean ROC-AUC scores and not in the accuracy or balanced accuracy. As described in the methods the mean ROC-AUC score depends not just on the final decision of the crowd but also on the ability to capture the uncertainty in the classification by trading off the false alarms and misses. This suggests that our Bayesian probabilistic treatment of the problem helps refine the final weights on the classes that were not selected, despite not changing the final decision. This is important since having a well-calibrated grasp on the uncertainty of the true label could help in the subsequent training of superior machine learning algorithms (K. M. <ref type="bibr" target="#b16">Collins et al., 2022;</ref><ref type="bibr" target="#b55">Peterson et al., 2019;</ref><ref type="bibr" target="#b58">Schmarje et al., 2022;</ref><ref type="bibr" target="#b72">Uma et al., 2021)</ref>.</p><p>Algorithms based on selection alone fared well when the optimal number of people were selected and did not improve much more when reweighted by training accuracy. This is partially because the dispersion in performance in the selected subset is lower than that of the group, reducing the need for weighting. Unlike the algorithms based on selection alone, we see that with SAW, LAW-E and LAW-CI, the decrease in performance is only slight for accuracy and that there is no real decrease in the ROC metrics. This is unlike LAW-CA which does not account for individual differences. This suggests that using accuracy along with selection can make the wisdom of the crowd algorithm more robust.</p><p>Algorithms that took the prevalence information into account improved the accuracy.</p><p>Thus, accounting for the task environment helped improve the accuracy by boosting the weight of the more common classes. This is important since the prevalence of different classes is rarely equal in medical tasks and can result in decision-making biases <ref type="bibr" target="#b65">(Trueblood et al., 2021;</ref><ref type="bibr" target="#b80">Wolfe et al., 2005)</ref>. On the training data, the different lesions were randomized such that they were presented equally often. However, the test data had an unequal prevalence leading to certain decision-making biases as compared to the training set. Thus, intelligent aggregation algorithms should be able to take into account the task environment and related decision-making biases while keeping in mind the metric that needs to be optimized during the aggregation process <ref type="bibr" target="#b8">(Broomell &amp; Davis-Stober, 2023;</ref><ref type="bibr" target="#b23">Galesic et al., 2018)</ref>.</p><p>For effective deployment of AI algorithms in the real world, it is important for the algorithms to be trusted by the individuals that use them <ref type="bibr" target="#b25">(Glikson &amp; Woolley, 2020)</ref>. While the different wisdom of the algorithms have similar accuracy, the disagreement on their final decisions can be quite large. Thus, downstream AI trained based on this data will probably make different kinds of errors based on the training data. The kinds of errors made by an AI algorithm have important consequences for trust and continued reliance. When humans see algorithms err erroneously, they exhibit algorithm aversion, where they trust and use the algorithm less despite its overall accuracy <ref type="bibr" target="#b10">(Burton et al., 2020;</ref><ref type="bibr" target="#b20">Dietvorst et al., 2015)</ref>. For medical AI, it not just important to use procedures that lead to high accuracy but also to keep in mind the trust and utilization of algorithms for which some wisdom of the crowd algorithms might be better than others.</p><p>Finally, labels obtained using the wisdom of the crowd approach capture the human perceptual uncertainty in the classification. This has important consequences for downstream machine learning applications (K. M. <ref type="bibr" target="#b16">Collins et al., 2022;</ref><ref type="bibr" target="#b55">Peterson et al., 2019;</ref><ref type="bibr" target="#b58">Schmarje et al., 2022;</ref><ref type="bibr" target="#b72">Uma et al., 2021)</ref>. First, these uncertain labels allow machine learning algorithms to learn with fewer labels (K. M. <ref type="bibr" target="#b16">Collins et al., 2022)</ref>. Second, algorithms that were trained using labels that capture human uncertainty generalize better and are resistant to adversarial attacks <ref type="bibr" target="#b55">(Peterson et al., 2019)</ref>. Third, when algorithms are trained on discrete labels, they output overconfident scores <ref type="bibr" target="#b58">(Schmarje et al., 2022)</ref>. Finally, in medical situations where the real world is uncertain and ambiguous, capturing this uncertainty could be advantageous for human-AI collaborative decision-making. Developing algorithms for such applications is an active area of research <ref type="bibr" target="#b58">(Schmarje et al., 2022;</ref><ref type="bibr" target="#b72">Uma et al., 2021)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Future Directions</head><p>A key question is whether the algorithms based on the probabilistic approach, (i.e log accuracy weighting), are the optimal choice. This depends on the accuracy of our estimates and the strength of the assumptions. We see in the supplement that even when restricting the analyses to individuals with many training responses, the results are similar, suggesting that better estimates of the quantities may not improve the results. Furthermore, whether our approach is optimal or not is also influenced by how we have modeled the independence assumption.</p><p>The assumption of independence has important theoretical implications since it has been shown to moderate the effectiveness of the wisdom of the crowds <ref type="bibr" target="#b12">(Clemen, 1989;</ref><ref type="bibr" target="#b18">Davis-Stober et al., 2014;</ref><ref type="bibr" target="#b23">Galesic et al., 2018;</ref><ref type="bibr" target="#b51">Mannes et al., 2014;</ref><ref type="bibr" target="#b63">Surowiecki, 2005;</ref><ref type="bibr" target="#b78">Wilson &amp; Farrow, 2018</ref>).</p><p>Since individuals might use similar cues or have similar cognitive or perceptual biases, their decisions might be correlated <ref type="bibr" target="#b23">(Galesic et al., 2018;</ref><ref type="bibr" target="#b51">Mannes et al., 2014;</ref><ref type="bibr" target="#b78">Wilson &amp; Farrow, 2018)</ref>.</p><p>Modeling this correlation is a notoriously difficult problem <ref type="bibr" target="#b12">(Clemen, 1989;</ref><ref type="bibr" target="#b78">Wilson &amp; Farrow, 2018</ref>) and might require a large set of common images on which the same decision-makers have made decisions, unlike our set where every individual has made decisions on different images. It might be possible to parameterize inter-rater correlations to further improve aggregated decisions <ref type="bibr" target="#b59">(Soule et al., 2023;</ref><ref type="bibr" target="#b78">Wilson &amp; Farrow, 2018)</ref>.</p><p>The approach adopted in this paper was to use a switchboard analysis where we tested several different ideas that are relevant to our question <ref type="bibr" target="#b71">(Turner et al., 2018;</ref><ref type="bibr" target="#b81">Zhao et al., 2022)</ref>.</p><p>Other weighting approaches have weighted individuals based on their contribution by comparing the group performance with and without a given individual <ref type="bibr" target="#b9">(Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b11">Chen et al., 2016)</ref>. Using a optimization approach, one could find the best-performing algorithm by parameterizing different weight functions and maximizing the performance <ref type="bibr" target="#b56">(Peterson et al., 2021)</ref>. For instance, the ideal weight function could combine both selection and accuracy weighting in one function. R. N. <ref type="bibr" target="#b17">Collins et al. (2023)</ref> proposed the use of a sigmoid weight function with a slope and inflection point, where if decisions are sufficiently far below the inflection point, they are down-weighted and effectively removed from the aggregate decision.</p><p>The best-performing algorithm can be found by maximizing the metric of choice by varying the parameters. Future work can implement different approaches to find the optimal weights.</p><p>The reason we chose the switchboard analysis instead of the optimization approach was three-fold. One, our primary interest was to compare different wisdom of the crowd algorithms to understand overall trends. Using a switchboard analysis, we could 'lay out' all the algorithms we tested and look for systematic patterns. It is not easy to visualize results when one has three or more parameters. Second, the training set had a large variation in the number of decisions that were made on each image (IQR 1-13 decision per image), making it difficult to use our training data for parameter estimation. Thus, one would need to fit the test data, but such an approach might overfit the testing data. One would need to create a validation set that is distinct from the test set so that these parameters can be found. Third, in terms of real-world crowdsourcing applications, it is often the case that the training set (often called 'Gold Standards') is small and the unlabelled image set that needs crowdsourcing (equivalent to the test set in our paper) is large.</p><p>Of course, if one already has a large validated set, then our application may be irrelevant since it might be directly used to train a machine learning algorithm.</p><p>To further reduce the cost of labeling medical data, one might develop 'online' algorithms, which intelligently select the image that requires labeling. We do not need to keep collecting decisions on easy images and could instead spend more resources on hard images. If for instance, one observes consensus between the first few decision-makers on a given image, then it may not be necessary to collect a lot of decisions on that image since it is probably an easy image <ref type="bibr" target="#b46">(Kurvers et al., 2019)</ref>. On the other hand, for a difficult image, one might need to gather a lot of decisions to determine the true class. This could help further optimize resources and reduce the cost of data collection.</p><p>Further, the compensation framework could heavily impact the number and quality of decisions. In our task, the compensation framework predominantly favored top achievers, motivating their engagement with the app and subsequent image labeling. We also observed that the median number of daily responses per participant was around 100, which was the minimum number of decisions required to enter the tournament. It is also noteworthy that some individuals provided a lot more decisions than what was required to win the tournament, and provided a substantial portion of the responses. Future studies could look at alternative ways of incentivizing participation in the app, with the aim of improving engagement with the app and crowd-based performance metrics.</p><p>The gains from combining decisions from different sources is not limited only to aggregating human decisions. A similar framework for combining decisions from different machine algorithms has been developed <ref type="bibr" target="#b43">(Kuncheva, 2014;</ref><ref type="bibr" target="#b44">Kuncheva &amp; Rodriguez, 2014)</ref>. More recently, ensemble approaches have been useful when combining decisions from neural networks in medical decision-making <ref type="bibr" target="#b50">(Mahbod et al., 2020;</ref><ref type="bibr" target="#b54">Perez et al., 2019)</ref>. Since humans and machines are susceptible to different biases <ref type="bibr" target="#b60">(Steyvers et al., 2022;</ref><ref type="bibr" target="#b68">Tschandl et al., 2020)</ref>, one might obtain additional gains by combining decisions from humans and machines.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraints on Generality</head><p>The field of medical decision-making has many different kinds of tasks. The example that we studied in this paper was complex classification <ref type="bibr" target="#b34">(Hasan et al., 2023;</ref><ref type="bibr" target="#b45">Kurvers et al., 2016)</ref>.</p><p>However, one might also have a visual search task where one is looking for abnormalities in mammography for signs of cancer <ref type="bibr" target="#b21">(Drew et al., 2013)</ref>. Additionally, tasks might vary in format.</p><p>For instance, in an image segmentation task, individuals highlight the lesion portion of the skin <ref type="bibr" target="#b14">(Codella et al., 2019)</ref> or the task might be open-ended with different responses <ref type="bibr" target="#b47">(Kurvers et al., 2023)</ref>. Each of these tasks engages different cognitive processes and has a different pattern of errors. It is unclear to what extent our results might generalize across these different tasks.</p><p>When designing crowd-sourcing tasks for medical data annotation, the efficacy of different algorithms might depend on task features such as the number of training cases and the spread in performance. For instance, we simulated the case where one has fewer training samples to calculate individual-level factors and present them in the supplement. We find that when one has fewer training cases (1-5 decisions per person), the simple accuracy weighting is worse than simple voting. As one has increasingly accurate estimates of accuracy (upwards of 20 decisions per person), the performance matches and starts exceeds simple voting. For more complicated algorithms like LAW-CI, one needs even more samples (upwards of 500 decisions per person), or else its performance is worse than simple voting. This is a reflection of the bias-variance tradeoff <ref type="bibr" target="#b7">(Brighton &amp; Gigerenzer, 2015;</ref><ref type="bibr" target="#b24">Geurts, 2010)</ref>, where simpler models lack the flexibility to account for patterns in the training data, leading to sub-optimal weights for decision aggregation.</p><p>In contrast, more complex models might be over-sensitive to patterns in the training data, leading to inaccurate weights that hurt the crowd performance. Thus, in data-sparse environments, one might consider using simpler models and more complex algorithms in the data-rich environments.</p><p>Further, for cases where the training data is sparse, one might develop and test machine learning algorithms that are not oversensitive to patterns in the training data <ref type="bibr" target="#b52">(Moradi et al., 2020;</ref><ref type="bibr" target="#b77">Williams, 1995)</ref>. This is similar to the results from the simulations run for ensemble studies with machine learning algorithms, where algorithms with more parameters need more training data before being included in the ensemble <ref type="bibr" target="#b43">(Kuncheva, 2014;</ref><ref type="bibr" target="#b44">Kuncheva &amp; Rodriguez, 2014)</ref>. Further, if participants are recruited from similar sources with similar levels of skill, one might not gain by accounting for individual differences in performance. Thus our results can be interpreted in the context of task features such as having a large number of training samples and recruiting a diverse set of individuals from an app-based platform.</p><p>The task that we study is a multiclass classification problem in which individuals provide discrete responses. It is unclear whether these results will generalize to other response formats.</p><p>When individuals provide discrete categorical decisions, one outlier vote will not impact the decision of the entire crowd unless the crowd is split evenly across all possible responses.</p><p>However, if one is interested in creating a dataset with well-calibrated confidence or probability judgments that use a continuous response scale, even a few outliers can strongly impact the final answer of the crowd <ref type="bibr" target="#b9">(Budescu &amp; Chen, 2015;</ref><ref type="bibr" target="#b17">R. N. Collins et al., 2023;</ref><ref type="bibr" target="#b34">Hasan et al., 2023;</ref><ref type="bibr" target="#b49">Litvinova et al., 2022)</ref>. One might make substantial gains in calibration if these outlier values are removed before aggregation (R. N. <ref type="bibr" target="#b17">Collins et al., 2023)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In conclusion, we observe that simple voting performs well in our task despite the dispersion in individual performance. On a range of metrics, we observe that the best performing algorithms both select the top performers and weigh them by their training accuracy. Taking into account the task environment, by incorporating the prevalence rates of different images, further improves the accuracy. We also observe that wisdom of the crowd approaches perform well on ROC-AUC scores, which is essential to developing algorithms that account for the uncertainty in classification. Overall, we observe that an app-based platform can be used to obtain accurate, cost-effective, fast, and scalable labels for medical image datasets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Declaration Ethics approval and consent to participate</head><p>The data collection from <ref type="bibr" target="#b69">Tschandl et al., 2018</ref> was approved by the Medical University of Vienna and the University of Queensland. Participants in the Centaur Labs agreed to the terms of service agreement where they consented to their data being used for commercial and academic purposes <ref type="bibr" target="#b22">(Duhaime et al., 2023)</ref>. The Indiana University Institutional Review Board approved the subsequent data analysis (#20135).  3,000-5,000 3 0.95 % 9.57 % 73.33 % 65.59 % 5 5,000-10,000 1 0.32 % 4.90 % 70.45 % 70.07 % 6 10,000-1,000,000 1 0.32 % 9.49 % 62.08 % 59.89 % <ref type="table">Table 3</ref> Comparison of the different accuracy weighting algorithms on accuracy and balanced accuracy. The square brackets show the bootstrapped 95% confidence intervals for the improvement as compared to simple voting.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>The panels on the left and the middle show the distribution of mean accuracy of different individuals for the test and train images respectively across all images. The chance accuracy is calculated as 1/7 since there were 7 different classes. The panel on the right shows the relationship between the accuracy of an individual and the number of responses provided by the individual.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>The top two panels show the confusion matrices when we pool the decisions from all individuals for the test and the train set respectively. The bottom two panels show the confusion matrices for training for the individuals that provided the most and second most responses on the train set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3</head><p>The performance of simple voting on the different metrics based on the size of the crowd. The left panel shows the accuracy and balanced accuracy metrics and the right panel shows the mean ROC-AUC and malignant ROC-AUC. The 95% bootstrapped confidence intervals are depicted as transparent bands around the line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>The results of the algorithms based on selecting the top individuals using their training performance. The 95% bootstrapped confidence intervals are depicted as transparent bands around the line.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 5</head><p>Inter-algorithm disagreement rate for accuracy weighting algorithms</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 6</head><p>Switchboard analysis of all the different algorithms.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Distribution of Images based on their type from ISIC (2018).</figDesc><table><row><cell>Lesion</cell><cell>Abbreviation</cell><cell>No. of</cell><cell>Percentage of</cell><cell>No. of</cell><cell>Percentage of</cell></row><row><cell>Type</cell><cell></cell><cell cols="4">Train Images Total (Train) Test Images Total (Test)</cell></row><row><cell>Actinic Keratosis</cell><cell>AKIEC</cell><cell>327</cell><cell>3.5%</cell><cell>43</cell><cell>2.8%</cell></row><row><cell>Basal Cell Carcinoma</cell><cell>BCC</cell><cell>514</cell><cell>5.5%</cell><cell>93</cell><cell>6.2%</cell></row><row><cell>Benign Keratosis</cell><cell>BKL</cell><cell>1099</cell><cell>11.8%</cell><cell>217</cell><cell>14.4%</cell></row><row><cell>Dermatofibroma</cell><cell>DF</cell><cell>115</cell><cell>1.2%</cell><cell>44</cell><cell>2.9%</cell></row><row><cell>Melanoma</cell><cell>MEL</cell><cell>1113</cell><cell>11.9%</cell><cell>171</cell><cell>11.3%</cell></row><row><cell>Melanocytic Nevi</cell><cell>NV</cell><cell>6705</cell><cell>64.5%</cell><cell>908</cell><cell>60.1%</cell></row><row><cell>Vascular Lesion</cell><cell>VASC</cell><cell>142</cell><cell>1.5%</cell><cell>35</cell><cell>2.3%</cell></row><row><cell>Total</cell><cell>-</cell><cell>10015</cell><cell>100%</cell><cell>1511</cell><cell>100%</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>This Table showsthe number of responses contributed by participants as well as the mean train and test accuracy for the data contributed by them.</figDesc><table><row><cell></cell><cell>No. of</cell><cell>No. of</cell><cell>Perc. of</cell><cell cols="3">Perc. of Mean Train Mean Test</cell></row><row><cell></cell><cell cols="5">Train Decisions Individuals Individuals Decisions Accuracy</cell><cell>Accuracy</cell></row><row><cell>0</cell><cell>0-100</cell><cell>154</cell><cell>48.89 %</cell><cell>4.85 %</cell><cell>37.54 %</cell><cell>35.19 %</cell></row><row><cell>1</cell><cell>100-500</cell><cell>109</cell><cell>34.60 %</cell><cell>22.08 %</cell><cell>48.78 %</cell><cell>46.50 %</cell></row><row><cell>2</cell><cell>500-1,000</cell><cell>20</cell><cell>6.35 %</cell><cell>13.54%</cell><cell>56.79 %</cell><cell>55.41 %</cell></row><row><cell>3</cell><cell>1,000-3,000</cell><cell>26</cell><cell>8.25 %</cell><cell>35.47 %</cell><cell>71.31 %</cell><cell>65.43 %</cell></row><row><cell>4</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We are grateful to Kira Prentice for her expert data curation, Jeremy Wolfe for facilitating this collaboration and providing helpful comments, and Phillip Hegeman for his valuable feedback. We also thank our reviewers for their insightful comments which helped improve the manuscript.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Consent for publication</head><p>There is no identifiable media being published in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Availability of data and materials</head><p>Data will be made available upon reasonable request. The code is available on OSFhttps://osf.io/c37mf/   </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A simulation-based approach to understanding the wisdom of crowds phenomenon in aggregating expert judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Afflerbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Dun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Gimpel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Parak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Seyfried</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Business &amp; Information Systems Engineering</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="page" from="329" to="348" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A review on the applications of crowdsourcing in human pathology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Alialy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Tavakkol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Tavakkol</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghorbani-Aghbologhi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Ghaffarieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Shahabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of pathology informatics</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Scaling up fact-checking using the wisdom of crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Arechar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">36</biblScope>
			<biblScope unit="page">4393</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">Combining forecasts. PRINCIPLES OF FORECASTING: A HANDBOOK FOR RESEARCHERS AND PRACTITIONERS</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Armstrong</surname></persName>
		</author>
		<editor>J. Scott Armstrong</editor>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Kluwer Academic Publishers</publisher>
			<pubPlace>Norwell, MA</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Talent spotting in crowd prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Judgment in predictive analytics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023" />
			<biblScope unit="page" from="135" to="184" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Distilling the wisdom of crowds: Prediction markets vs. prediction polls</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rescober</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Stone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Swift</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Servan-Schreiber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tetlock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ungar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mellers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management science</title>
		<imprint>
			<biblScope unit="volume">63</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="691" to="706" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Comparative accuracy of diagnosis by collective intelligence of multiple physicians vs individual physicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Barnett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Boddupalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Nundy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Bates</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA network open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="190096" to="190096" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The bias bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Business Research</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1772" to="1784" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The strengths and weaknesses of crowds to address global problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Broomell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Davis-Stober</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Perspectives on Psychological Science</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Identifying expertise to extract the wisdom of crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management science</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="267" to="280" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">A systematic review of algorithm aversion in augmented decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Burton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-K</forename><surname>Stein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">B</forename><surname>Jensen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of behavioral decision making</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="220" to="239" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Validating the contribution-weighted model: Robustness and cost-benefit analyses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">K</forename><surname>Lakshmikanth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Mellers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Tetlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="152" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Combining forecasts: A review and annotated bibliography</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Clemen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International journal of forecasting</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="559" to="583" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Crowd control: Effectively utilizing unscreened crowd workers for biomedical data annotation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cocos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Qian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Callison-Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Masino</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of biomedical informatics</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="page" from="86" to="92" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Skin lesion analysis toward melanoma detection 2018: A challenge hosted by the international skin imaging collaboration (isic)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rotemberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Celebi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dusza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kalloo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liopyris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Marchetti</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.03368</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Citizen science: Can volunteers do real research?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Cohn</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BioScience</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="192" to="197" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Eliciting and learning with soft labels from every annotator</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Bhatt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Weller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Human Computation and Crowdsourcing</title>
		<meeting>the AAAI Conference on Human Computation and Crowdsourcing</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="40" to="52" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Performance-weighted aggregation: Ferreting out wisdom within the crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Judgment in predictive analytics</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2023" />
			<biblScope unit="page" from="185" to="214" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">When is a crowd wise?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">P</forename><surname>Davis-Stober</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Broomell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">79</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Imagenet: A large-scale hierarchical image database</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Deng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Dong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Socher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fei-Fei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE conference on computer vision and pattern recognition</title>
		<imprint>
			<date type="published" when="2009" />
			<biblScope unit="page" from="248" to="255" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Informatics in radiology: What can you see in a single glance and how might this guide visual search in medical images?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Drew</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Võ</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.-H</forename><surname>Jacobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Radiographics</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="263" to="274" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Nonexpert crowds outperform expert individuals in diagnostic accuracy on a skin lesion diagnosis task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">P</forename><surname>Duhaime</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Moulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Kurtansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Rotemberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">IEEE 20th International Symposium on Biomedical Imaging (ISBI)</title>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Smaller crowds outperform larger crowds and individuals in realistic task conditions. Decision</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Galesic</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Barkoczi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Katsikopoulos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<title level="m" type="main">Bias vs variance decomposition for regression and classification. Data mining and knowledge discovery handbook</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Geurts</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<biblScope unit="page" from="733" to="746" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Human trust in artificial intelligence: Review of empirical research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Glikson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">W</forename><surname>Woolley</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Academy of Management Annals</publisher>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="627" to="660" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">The wisdom of smaller, smarter crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Mcafee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Suri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the fifteenth ACM conference on Economics and computation</title>
		<imprint>
			<biblScope unit="page" from="471" to="488" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Goldstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Almenberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dreber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Emerson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Herschkowitsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Do more expensive wines taste better? evidence from a large sample of blind tastings</title>
	</analytic>
	<monogr>
		<title level="j">Journal of Wine Economics</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Metrics for multi-class classification: An overview</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Grandini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bagli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Visani</surname></persName>
		</author>
		<idno type="arXiv">arXiv:2008.05756</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Deepfake detection by human crowds, machines, and machine-informed crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Groh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Firestone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Picard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">2110013119</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Classifier Technology and the Illusion of Progress</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
		<idno type="DOI">10.1214/088342306000000060</idno>
		<ptr target="https://doi.org/10.1214/088342306000000060" />
	</analytic>
	<monogr>
		<title level="j">Statistical Science</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Assessing the performance of classification methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Hand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">International Statistical Review</title>
		<imprint>
			<biblScope unit="volume">80</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="400" to="414" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Improving medical image decision-making by leveraging metacognitive processes and representational similarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Eichbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Seegmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stratton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="400" to="413" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Harnessing the wisdom of the confident crowd in medical image decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Eichbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Seegmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stratton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note>Decision</note>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Representational smoothing to improve medical image decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Trueblood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page">44</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The robust beauty of majority rules in group decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kameda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">494</biblScope>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">The wisdom of many in few: Finding individuals who are as wise as the crowd</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Ho</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The wisdom of crowds for visual search</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Juni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">P</forename><surname>Eckstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Noise: A flaw in human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sibony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hachette UK</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The potential of collective intelligence in emergency medicine: Pooling medical students&apos; independent decisions improves diagnostic performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">E</forename><surname>Kämmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">E</forename><surname>Hautz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Kunina-Habenicht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical decision making</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="715" to="724" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Agreement between experts and an untrained crowd for identifying dermoscopic features using a gamified app: Reader feasibility study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kentley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Liopyris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Marghoob</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Quigley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Prentice</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Duhaime</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Halpern</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JMIR Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">38412</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">When are two heads better than one and why?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Koriat</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">336</biblScope>
			<biblScope unit="issue">6079</biblScope>
			<biblScope unit="page" from="360" to="362" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Combining pattern classifiers: Methods and algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>John Wiley &amp; Sons</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">A weighted voting framework for classifiers ensembles. Knowledge and information systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">I</forename><surname>Kuncheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Rodriguez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="259" to="275" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Boosting medical diagnostics by pooling independent judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bogart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zalaudek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="8777" to="8782" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">How to detect high-performing individuals and groups: Decision similarity predicts accuracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moussaid</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zalaudek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science advances</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">9011</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Nuzzolese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Russo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Barabucci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Trianni</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Automating hybrid collective intelligence in open-ended medical diagnostics</title>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="issue">34</biblScope>
			<biblScope unit="page">2221473120</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">How experts&apos; own inconsistency relates to their confidence and between-expert disagreement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Litvinova</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Herzog</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9273</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Transfer learning using a multi-scale and multi-network ensemble for skin lesion classification. Computer methods and programs in biomedicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mahbod</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schaefer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Dorffner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ellinger</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="volume">193</biblScope>
			<biblScope unit="page">105475</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">The wisdom of select crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Mannes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Soll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Larrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of personality and social psychology</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">276</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">A survey of regularization strategies for deep models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Moradi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Berangi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Minaei</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence Review</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3947" to="3986" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">A survey of crowdsourcing in medical image analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Ørting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Doyle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Van Hilten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hirth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Inel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Mavridis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Spiers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cheplygina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Human Computation</publisher>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="1" to="26" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Solo or ensemble? choosing a cnn architecture for melanoma classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Avila</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Valle</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</title>
		<meeting>the IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops</meeting>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Human uncertainty makes classification more robust</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Battleday</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Russakovsky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the IEEE/CVF International Conference on Computer Vision</title>
		<meeting>the IEEE/CVF International Conference on Computer Vision</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="9617" to="9626" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Using large-scale experiments and machine learning to discover theories of human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Bourgin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Agrawal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Reichman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">372</biblScope>
			<biblScope unit="issue">6547</biblScope>
			<biblScope unit="page" from="1209" to="1214" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Centaur labs gets $15 million to improve data for healthcare ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Press</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Forbes</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Is one annotation enough?-a data-centric image classification benchmark for noisy and ambiguous label estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmarje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Grossmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zelenka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Dippel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kiko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Oszust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pastell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Stracke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Valros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Volkmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Neural Information Processing Systems</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="33215" to="33232" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">A heuristic for combining correlated experts when there are few data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Soule</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Grushka-Cockayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Merrick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Bayesian modeling of human-ai complementarity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Tejeda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Kerrigan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smyth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page">2111547119</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Evaluating probabilistic forecasts with bayesian signal detection models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Wallsten</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Merkle</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Risk Analysis</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="435" to="452" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">The ebird enterprise: An integrated approach to development and application of citizen science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">L</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Aycrigg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Barry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Bonney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bruns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">B</forename><surname>Cooper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Damoulas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Dhondt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dietterich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Farnsworth</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biological conservation</title>
		<imprint>
			<biblScope unit="volume">169</biblScope>
			<biblScope unit="page" from="31" to="40" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title level="m" type="main">The Wisdom of Crowds</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Surowiecki</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<pubPlace>Anchor</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">Superforecasting: The art and science of prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Tetlock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gardner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>Random House</note>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title level="m" type="main">Disentangling prevalence induced biases in medical image decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Eichbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Seegmiller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Stratton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>O'daniels</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Holmes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">212</biblScope>
			<date type="published" when="104713" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title level="m" type="main">Comparison of the accuracy of human readers versus machine-learning algorithms for pigmented skin lesion classification: An open, web-based, international, diagnostic study. The lancet oncology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">N</forename><surname>Akay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Braun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cabo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Gutman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Helba</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hofmann-Wellenhof</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="page" from="938" to="947" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Human-computer collaboration for skin cancer recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rinner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Apalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Janda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lallas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malvehy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1229" to="1234" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">The ham10000 dataset, a large collection of multi-source dermatoscopic images of common pigmented skin lesions. Scientific data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Crowdsourcing in medical research: Concepts and applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Tucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bayus</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">6762</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Competing theories of multialternative, multiattribute preferential choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Schley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Muller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Tsetsos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological review</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">329</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Learning from disagreement: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Uma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fornaciari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hovy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Paun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Plank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Poesio</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Artificial Intelligence Research</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="1385" to="1470" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<analytic>
		<title level="a" type="main">Biological data annotation via a human-augmenting ai-based labeling system</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Van Der Wal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Jhun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Laklouk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Nirschl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Richer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rojansky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Theparee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wheeler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Sander</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Feng</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NPJ digital medicine</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">145</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Improving aggregated forecasts of probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Osherson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">45th annual conference on information sciences and systems</title>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="page" from="1" to="5" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Aggregating large sets of probabilistic forecasts by weighted coherent adjustment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Kulkarni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">V</forename><surname>Poor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Osherson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="128" to="144" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Elementary signal detection theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">D</forename><surname>Wickens</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Oxford university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Bayesian regularization and pruning using a laplace prior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="117" to="143" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title level="m" type="main">Combining judgements from correlated experts. Elicitation: The science and art of structuring judgement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Farrow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="211" to="240" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Collective intelligence meets medical decision-making: The collective outperforms the best radiologist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wolf</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Carney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bogart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Kurvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">134269</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Rare items often missed in visual searches</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Wolfe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Horowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Kenner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">435</biblScope>
			<biblScope unit="issue">7041</biblScope>
			<biblScope unit="page" from="439" to="440" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Process and content in decisions from memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J</forename><surname>Zhao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Richie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bhatia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">73</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
