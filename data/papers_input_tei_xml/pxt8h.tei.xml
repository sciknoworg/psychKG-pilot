<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">THREAT OF INEQUALITY AND PREFERENCE FOR ALGORITHMS</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Yochanan</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
							<email>ybigman@gmail.com</email>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kai</forename><forename type="middle">Chi</forename><surname>Yam</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">National University of Singapore</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Déborah</forename><surname>Marciano</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Scott</forename><forename type="middle">J</forename><surname>Reynolds</surname></persName>
							<affiliation key="aff4">
								<orgName type="institution">University of Washington</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kurt</forename><surname>Gray</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of North Carolina at Chapel Hill</orgName>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff5">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
								<address>
									<settlement>New Haven</settlement>
									<region>CT</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">THREAT OF INEQUALITY AND PREFERENCE FOR ALGORITHMS</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>algorithm aversion</term>
					<term>COVID-19</term>
					<term>inequality threat</term>
					<term>health disparities</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Artificial intelligence (AI) algorithms hold promise to reduce inequalities across race and socioeconomic status. One of the most important domains of racial and economic inequalities is medical outcomes; Black and low-income people are more likely to die from many diseases. Algorithms can help reduce these inequalities because they are less likely than human doctors to make biased decisions. Unfortunately, people are generally averse to algorithms making important moral decisions-including in medicine-undermining the adoption of AI in healthcare. Here we use the COVID-19 pandemic to examine whether the threat of racial and economic inequality increases the preference for algorithm decision-making. Four studies (N=2,819) conducted in the United States and Singapore show that emphasizing inequality in medical outcomes increases the preference for algorithm decision-making for triage decisions. These studies suggest that one way to increase the acceptance of AI in healthcare is to emphasize the threat of inequality and its negative outcomes associated with human decision-making.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threat of Racial and Economic Inequality Increases Preference for Algorithm Decision-</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Making</head><p>Large racial and economic inequalities exist both across and within nations. In the United States, Black men are 2.5 times more likely to die of police violence than White men <ref type="bibr" target="#b37">(Edwards et al., 2019)</ref>. In the US, 31.4% of national wealth is owned by the top 1% of the population (Board of Governors of the Federal Reserve System, 2021). In Singapore, the median salary for Singaporean employees is over six times that of migrant workers <ref type="bibr" target="#b45">(Geddi et al., 2020)</ref>. These racial and economic disparities are also reflected in medical outcomes. In 2020, in the United States the life expectancy at birth of non-Hispanic Black people was 6 years lower than that of non-Hispanic White people, and 8 years lower than that of Hispanic people <ref type="bibr" target="#b12">(Arias et al., 2021)</ref>.</p><p>Similarly, Black people in the United States are 30% more likely to die from a heart disease than non-Hispanic White people <ref type="bibr" target="#b75">(Murphey et al., 2021)</ref>. One way to somewhat reduce inequality in medicine is to rely on artificial intelligence (AI)-powered algorithms to make medical decisions <ref type="bibr" target="#b51">(Hao, 2020)</ref>, and here we use the context of COVID-19 to examine whether the threat of racial and economic inequality might increase preference for algorithm decision-making.</p><p>The COVID-19 pandemic has amplified existing health disparities. In the middle of the first wave of infection, the COVID-19 death rate in the United States was 61.6 deaths (per 100,000 people) for Black Americans and 26.2 for White Americans <ref type="bibr">(APM Research Lab, 2020)</ref>. In Singapore, more than 90% of infections comprising migrant workers who make less than SGD$10,000 annually (~USD$7,500; <ref type="bibr" target="#b80">Palma, 2020)</ref>. Similar disparities exist in other countries, with the poor and minorities being most affected by the virus <ref type="bibr" target="#b14">(Bhala et al., 2020)</ref>.</p><p>Health disparities-both in general and in COVID-19-are tied to habitat density, pre-pandemic healthcare, healthcare access, and the ability to work remotely <ref type="bibr" target="#b2">(Abuelgasim et al., 2020;</ref><ref type="bibr" target="#b15">Bibbins-Domingo, 2020;</ref><ref type="bibr" target="#b25">Braveman et al., 2011;</ref><ref type="bibr" target="#b108">Yancy, 2020)</ref>, but may also stem, at least in a small part, from bias -"prejudice in favor of or against one thing, person, or group compared with another, usually in a way considered to be unfair" (Oxford University Press, 2020)in human decisionmaking. For example, empirical studies have demonstrated that doctors sometimes under-screen, under-diagnose, and under-treat members of some minority groups <ref type="bibr" target="#b6">(Alsan et al., 2019;</ref><ref type="bibr" target="#b52">Hoffman et al., 2016)</ref>.</p><p>Many have suggested that using AI can help reduce bias in human decision-making <ref type="bibr" target="#b53">(Houser, 2019;</ref><ref type="bibr" target="#b74">Munoz et al., 2016)</ref>. While the idea of AI being in charge of patients might appear futuristic, AI has been used for a few years already in emergency rooms around the world, for example in London <ref type="bibr" target="#b28">(Crouch, 2019)</ref> and Cleveland <ref type="bibr" target="#b44">(Gauher &amp; Uz, 2016)</ref>. Of course, in both medical contexts and non-medical contexts where AI is used (e.g., the military, finance), it is always humans who have ultimate responsibility for making decisions. But people may start to prefer that AI systems are used more in these decision-making contexts, and we use "algorithm decision-making" as a short-hand for this idea.</p><p>Recent studies have examined the role of AI in the treatment and management of COVID-19, revealing that algorithms can improve the work of healthcare workers and the outcomes of patients, ranging from more accurate diagnoses and more efficient monitoring <ref type="bibr" target="#b103">(Tayarani-N., 2020)</ref>. Healthcare workers generally appreciate the efficiency of algorithms <ref type="bibr" target="#b10">(Ardon &amp; Schmidt, 2020;</ref><ref type="bibr" target="#b59">Laï et al., 2020;</ref><ref type="bibr" target="#b88">Polesie et al., 2020)</ref>, although they do worry about AI's lack of empathy and its low ability to communicate with patients <ref type="bibr">(Blease et al., 2019;</ref><ref type="bibr" target="#b35">Doraiswamy et al., 2020)</ref>.</p><p>Hospitals currently rely on AIs for a wide range of needs, including informing whether an individual should get tested for COVID-19 <ref type="bibr" target="#b46">(Gerretsen, 2020;</ref><ref type="bibr" target="#b71">Meah, 2020;</ref><ref type="bibr" target="#b81">Parrock, 2020;</ref><ref type="bibr" target="#b106">Vanian, 2020)</ref>. A recent study also found that for triage decisions 1 ,-which we define broadly as the identification of patients who are most at risk and in need of appropriate treatments,-AI can accurately predict the risk of COVID-19 patients developing critical illness <ref type="bibr" target="#b63">(Liang et al., 2020)</ref>.</p><p>In other words, early AI-informed triage is already a reality in several hospitals <ref type="bibr" target="#b51">(Hao, 2020;</ref><ref type="bibr" target="#b106">Vanian, 2020)</ref> and will only grow in popularity. Interestingly, the use of AIs can reduce the need for "classic" life and death triage decisions which are characterized by a lack of resources and time pressure.</p><p>Using AI can increase the efficiency of medical diagnoses, and by doing so prevent using scarce resources such as ventilators on patients who do not have a medical need for them. This can allow hospitals to conserve resources for patients in dire need of them. Of course, algorithms are not free of bias <ref type="bibr" target="#b8">(Angwin et al., 2016;</ref><ref type="bibr" target="#b30">Dastin, 2018;</ref><ref type="bibr" target="#b60">Lambrecht &amp; Tucker, 2019)</ref>. For example, the algorithms used to identify patients for special medical treatment systemically underdiagnosed Black people <ref type="bibr" target="#b77">(Obermeyer et al., 2019)</ref>. However, algorithms are generally less biased than humans, and more easily corrected <ref type="bibr" target="#b73">(Mullainathan, 2019;</ref><ref type="bibr" target="#b101">Shea et al., 2020)</ref>. Even simple algorithms can outperform humans in decision-making tasks by consistently following decision rules rather than relying on intuition as humans sometimes do <ref type="bibr" target="#b31">(Dawes, 1979)</ref>. However, there is a key barrier to the adoption of AI in medicine: research in psychology reveals that people are generally averse to algorithms making decisions <ref type="bibr" target="#b34">(Dietvorst et al., 2015)</ref>, especially in medical and moral contexts <ref type="bibr" target="#b17">(Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b26">Castelo et al., 2019;</ref><ref type="bibr" target="#b66">Longoni et al., 2019)</ref>, where empathy <ref type="bibr" target="#b17">(Bigman &amp; Gray, 2018)</ref> and viewing the patient as a unique person <ref type="bibr" target="#b66">(Longoni et al., 2019)</ref> are seen as important.</p><p>Reducing the aversion to algorithm decision-making is especially important during pandemics such as COVID-19, because of the potential for algorithms to improve efficiency and reduce biases <ref type="bibr" target="#b101">(Shea et al., 2020)</ref>. For example, in the US, human doctors sometimes are less likely to recommend potentially lifesaving screening procedures to Black people <ref type="bibr" target="#b6">(Alsan et al., 2019)</ref>, perceive Black people as experiencing less pain <ref type="bibr" target="#b52">(Hoffman et al., 2016)</ref>, and prescribe less pain medication to Black people than their non-Black peers <ref type="bibr" target="#b72">(Morrison et al., 2000)</ref>. Specific to COVID-19, such biases can impact mortality rates by influencing the allocation of scarce ventilators, ICU beds, and other life-saving resources. By reducing these biases, AIs can potentially improve health outcomes.</p><p>How can we reduce the aversion from algorithm decision-making? We draw from social cognitive theory <ref type="bibr" target="#b43">(Fiske &amp; Taylor, 1991;</ref><ref type="bibr" target="#b55">Jones, 1991;</ref><ref type="bibr" target="#b94">Reynolds, 2006)</ref> to propose one potential way: highlighting a threat of inequality. Social cognitive theory <ref type="bibr" target="#b43">(Fiske &amp; Taylor, 1991)</ref> argues that the extent to which an individual pays attention to information depends on three factors: vividness, salience, and accessibility. Vividness refers to how interesting, provoking, and proximate the information is; salience refers to how noticeable or important the information is; accessibility refers to the extent to which an individual has personal traits or experiences that facilitate a connection to the information. Behavioral ethics scholars have relied on this theory to explain moral awareness, or why an individual would identify an issue as a moral one <ref type="bibr" target="#b96">(Reynolds &amp; Miller, 2015)</ref>. As <ref type="bibr" target="#b55">Jones (1991)</ref> argues, when an issue's characteristics are vivid and salient to the moral domain (e.g., proximate physical harm), an individual is more likely to identify the issue as a moral issue. <ref type="bibr" target="#b94">Reynolds (2006)</ref> further demonstrates that individual decision-making frameworks can increase the accessibility of the issue, thus allowing some people to see moral issues where others do not. Importantly, moral awareness is critical because it constitutes the first step in the moral decision-making process, which culminates in moral behavior <ref type="bibr" target="#b93">(Rest, 1986)</ref>.</p><p>We argue that threats of inequality are vivid and salient information that lead people to view some medical decisions as moral issues. While past research has demonstrated that moral concerns can make people averse to algorithm decision-making because algorithms are seen as devoid of emotion <ref type="bibr" target="#b17">(Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b109">Young &amp; Monroe, 2019)</ref>, we suggest that this "cold impartiality" may be a positive factor when inequality is salient. Highlighting inequality in human-led decision-making should motivate people towards an alternative that is perceived as less biased: algorithms.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 1: Threats of racial and economic inequality will increase people's preference for algorithm decision-making.</head><p>Social cognitive theory suggests that while threats of inequality might increase the overall preference for algorithm decision-making, the effect may vary at the individual level <ref type="bibr" target="#b43">(Fiske &amp; Taylor, 1991;</ref><ref type="bibr" target="#b95">Reynolds, 2008)</ref>. Accessibility-an individual's capacity to connect with information based on existing beliefs, traits, and experiences-shapes the extent to which different individuals pay differing amounts of attention to a piece of information. Although the threat of inequality may reduce the aversion to algorithm decision-making in all people, members of the discriminated-against group may show an even stronger effect. For example, one reason Black Americans are more supportive than White Americans of affirmative action is that they believe it offers Black Americans a fairer opportunity in college admissions <ref type="bibr" target="#b68">(Mangum, 2008)</ref>. Therefore, we predict that while threats of inequality will increase all people's preference for algorithm decision-making, the extent to which the inequality is personally relevant will moderate this effect.</p><p>Hypothesis 2: Personal relevance moderates the effect of threat of inequality on preference for algorithm decision-making, such that the increase in preference for algorithms is stronger for members of the disadvantaged group.</p><p>How exactly do threats of inequality increase the preference for algorithm decisionmaking? We suggest that one possible mechanism is that such threats weaken the perceived authority of doctors and healthcare workers. The principle of authority is a core moral value and many people view submitting to legitimate authority as morally obligatory <ref type="bibr" target="#b49">(Graham et al., 2011)</ref>. Doctors are generally perceived as authority figures, and many people hold them in very high regard <ref type="bibr" target="#b24">(Brase &amp; Richmond, 2004)</ref>, sometimes even elevating them to a "godlike" status <ref type="bibr" target="#b48">(Goranson et al., 2020)</ref>. During the COVID-19 pandemic, many in society have referred to doctors as "heroes" <ref type="bibr" target="#b13">(Bauchner &amp; Easley, 2020</ref>).</p><p>In the case of outcome inequalities, however, tensions emerge because people might see doctors as partially responsible, and that might violate another core value: the principle of justice <ref type="bibr">(Rawls, 1971)</ref>. We suggest that because the threat of inequality-a potential violation of the principle of justice-constitutes a vivid, salient, and immediate concern, the individual will give its violation greater attention than a less vivid and less salient obligation to follow authority. In other words, we suggest that people exposed to inequality associated with human doctor's decision-making will have a decreased sense of the authority of doctors. Thus, threats of inequality will weaken the perceived authority of doctors, which will in turn increase the preference for algorithm decision-making.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hypothesis 3: Authority of doctors mediates the interactive effect of threat of inequality and personal relevance on algorithm aversion.</head><p>This research makes several contributions. First, it contributes to the growing literature on the effects of exposure to inequality <ref type="bibr" target="#b69">(McCall et al., 2017;</ref><ref type="bibr" target="#b98">Sands, 2017)</ref>, revealing a consequence of exposure to health inequalities, and how exposure to this inequality might affect different groups differently. Second, it contributes to the literature on algorithm aversion <ref type="bibr" target="#b17">(Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b34">Dietvorst et al., 2015;</ref><ref type="bibr" target="#b66">Longoni et al., 2019)</ref> by revealing ways to reduce the aversion. Third, it contributes to our knowledge of the social effects of the belief in the authority of doctors by showing that disparities in health outcomes reduce the perceived authority of doctors. In doing so, we demonstrate an important outcome of emphasizing health disparities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Current Research</head><p>We tested our hypotheses in four studies and across two cultural contexts of inequality: race in the United States (Studies 1, 3, and 4) and SES in Singapore (Study 2). In all studies we asked participants to imagine that they were experiencing COVID-19 symptoms and needed to decide whether to go to a hospital where either a human doctor or algorithm makes triage decisions. We manipulated whether participants read (real) information about race (Studies 1, 3, and 4) or SES (Study 2) disparities in COVID-19 health outcomes or not. In Study 3 we further examined the mediating role of the perceived authority of doctors. In Study 4 we used a binary choice measure, rather than a continuous preference measure. The studies were approved by [masked for peer review]. Demographics of each study appear in <ref type="table" target="#tab_0">Table 1</ref>. Data, supplemental materials, and full study materials are available online at https://osf.io/mhjdy/?view_only=7d1442e70df9426594c1daee10b73e2f. At the time we conducted this study (see <ref type="table" target="#tab_0">Table 1</ref>) the COVID-19 mortality rate of Black Americans in the United States was more than twice that of White Americans (APM Research Lab, 2020). In Chicago, for example, Black Americans account for only 33% of the population, but 72% of the deaths attributed to COVID-19 <ref type="bibr" target="#b40">(Eligon et al., 2020)</ref>. In Study 1 we tested whether the threat of inequality-manipulated by informing participants about COVID-19 racial health disparities-increased people's preference for algorithm decision-making and whether personal relevance (the race of the participant) moderates this effect.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 1,379 participants 2 through Amazon's Mturk, using Turkprime <ref type="bibr" target="#b64">(Litman et al., 2017)</ref>. We aimed for a half-half ratio of Black and White participants in our samples (with specified samples). After excluding participants who failed the attention check, manipulation comprehension check, or did not self-identify as White or Black, we ended up with 1,060 participants (481 male, 572 female, 7 other; 535 White and 525 Black; Age: M = 37.41, SD = 12.55). Results remain unchanged when the analyses were performed on the full sample.</p><p>Participants were paid between $0.50 and $1. A post-hoc power analysis (using G*power 3.1, <ref type="bibr" target="#b41">Faul et al., 2007)</ref> revealed that this sample size had an achieved power of 1 (for an alpha of .05)</p><p>to detect the main effect for condition, and an achieved power of .995 to detect the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threat of inequality manipulation</head><p>After consenting and completing the first attention check in which they were asked what day of the week it was yesterday and what they had for breakfast that day, participants were randomly assigned to either a control condition or threat of inequality condition. In both conditions participants read the following text:</p><p>As COVID-19 spreads, hospitals are running low on crucial life-saving equipment, such as ventilators. When there are not enough resources to give all patients the care they need, "triage" is used to determine who gets priority in medical care. Triage decisions can be made by either human doctors or specialized algorithms.</p><p>In the threat of inequality condition participants then also read the following text (in the control condition participants were directed to the measures), based on real data on COVID-19 mortality rates at the time of the study <ref type="bibr" target="#b40">(Eligon et al., 2020)</ref> and on research suggesting a bias in medical care towards Black people <ref type="bibr" target="#b6">(Alsan et al., 2019;</ref><ref type="bibr" target="#b52">Hoffman et al., 2016)</ref>:</p><p>In America, there are large racial disparities in who dies from COVID19. In Chicago, for example, African Americans account for only 33% of the population, but 72% of COVID19-related deaths. It is currently unclear what causes this disparity, but there is some evidence suggesting that generally white doctors tend to under-diagnose African American patients.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference for algorithm decision-making</head><p>All participants then read the following question:</p><p>Imagine you are feeling severe shortness of breath and need to go to a hospital. There are two nearby hospitals. You know that both hospitals are running low on supplies and need to prioritize patients. In one hospital a human doctor makes triage decisions; in the second hospital an AI-based algorithm makes triage decisions.</p><p>To which hospital would you go?</p><p>Participants answered the question on a 1 ("Definitely the hospital where the human doctor makes triage decisions") to 5 ("Definitely the hospital where an AI-based algorithm makes triage decisions") scale (see <ref type="bibr" target="#b66">Longoni et al., 2019</ref>, for a similar measurement) 3 .</p><p>Participants then completed other measures (see supplemental materials) and the manipulation comprehension check, in which they were asked if the scenario they read mentioned race disparities in COVID-19 mortality rate (yes/no). Finally, participants provided demographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Descriptive statistics and correlations are presented in <ref type="table" target="#tab_1">Table 2</ref>. 1056) = 9.24, p &lt; .001, ηp 2 =.01), supporting Hypothesis 2 <ref type="figure" target="#fig_0">(Figure 1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results from Study 1 support Hypotheses 1 and 2: threat of inequality increased preference for algorithm decision-making, especially for those who could be personally disadvantaged by the inequality. Importantly, we note that for Black participants in the threat of inequality condition, the average rating was around the mid-point (3 on the 1 to 5 scale), suggesting that these participants overcame the algorithm aversion reported in previous research (e.g., <ref type="bibr" target="#b17">Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b34">Dietvorst et al., 2015)</ref>. However, one limitation of Study 1 is that it focuses on a threat of inequality in a specific cultural context-racial health disparities in the United States (although we did collect most of this data before the unrest in the United States following the murder of George Floyd on May 25, 2020). In Study 2 we address this limitation by focusing on a different cultural context-SES health disparities in Singapore. those living in the wealthiest 10% areas of the country <ref type="bibr" target="#b33">(Devlin &amp; Barr, 2020)</ref>. In this light, we tested our hypotheses in Singapore, a country where COVID-19 has infected more than 40,000 people as of June 18, 2020, with more than 90% of them being low-paid migrant workers <ref type="bibr" target="#b80">(Palma, 2020)</ref>. This context presents an ideal test case for our hypotheses with high realism.</p><p>Another limitation of Study 1 is that we informed participants about possible bias in doctors' decision-making, which might have created demand characteristics. In Study 2 we minimized these possible demand characteristics by testing our hypotheses without disclosing the source of the health disparities.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 662 undergraduates from a university in Singapore. Excluding participants who failed the manipulation comprehension check, we ended up with 416 participants (153 males, 257 females, and 6 other/preferred not to disclose; Age: M = 22.04, SD = 1.58). Results remain unchanged when the analyses were performed on the full sample. Participants were paid SGD$5 (~ USD$3.60) in exchange for their participation. A post-hoc power analysis (using G*power 3.1, <ref type="bibr" target="#b41">Faul et al., 2007)</ref> revealed that this sample size had an achieved power of 0.985 (for an alpha of .05) to detect the main effect for condition, and an achieved power of .999 to detect the interaction. The study was conducted in English, the language of instruction in the university from which our sample was taken. In addition, all participants were fluent in English.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SES</head><p>Participants first completed the MacArthur subjective SES scale <ref type="bibr" target="#b3">(Adler et al., 2000)</ref>, which is an established measure of SES widely used in social psychology (e.g., <ref type="bibr" target="#b36">Dubois et al., 2015;</ref><ref type="bibr" target="#b86">Piff et al., 2012)</ref>. They were asked to position themselves on a ladder representing where people in Singapore stand in relation to education, wealth, and respectful jobs (i.e., the definition of SES), on a 1 ("I am the worst off") to 10 ("I am the best off").</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threat of inequality manipulation</head><p>We then randomly assigned participants to either a threat of inequality condition or a control condition. The control condition was identical to that in Study 1 in which participants read about the scarcity of medical resources needed for COVID-19 treatment. In the threat of inequality condition, participants also read the following text (in the control condition participants were directed to the measures), which provided real data about Singapore at the time of the study:</p><p>In Singapore, there are large class disparities in who are infected with COVID-19. Out of the 35,000 confirmed cases, over 95% are among Singapore's lowest-paid foreign workers. They live in dormitories located and almost hidden from view on the outskirts of the city, with poor and overcrowded living conditions. They sleep on bunk beds, 12 to 20 packed into one room, poorly ventilated by small fans and communal toilets and showering facilities shared by hundreds of men on each floor. Typically, they earn less than SGD 1000 a month, while the median monthly income for Singaporeans is SGD 3,227.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference for algorithm decision-making</head><p>We measured preference for algorithm decision-making as in Study 1. Participants then completed other scales (see supplemental materials) and, as a manipulation comprehension check, were asked whether the scenario they read mentioned class disparities in  (yes/no). Finally, participants provided demographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Descriptive statistics and correlations are presented in <ref type="table" target="#tab_2">Table 3</ref>. The mean SES in our sample was 6.22 (SD = 1.43), suggesting that participants perceived themselves as slightly higher than average SES; this makes sense since participants were undergraduates in an elite university in Singapore. This analysis also provides a conservative test for our hypotheses, as our participants were on a higher-than-average SES and therefore not strongly disadvantaged. To test the hypothesized interaction between SES and threat of inequality, we conducted a step-wise OLS regression predicting preference for algorithm decision-making. In step 1, we entered SES and threat of inequality as the independent variables. In step 2, we entered the interaction term. As expected, the interaction term was significant (β = -.21, p &lt; .001) and</p><p>resulted in a significant change in R 2 (adjusted R 2 = .11, ΔR² = .04, Fchange(1, 412) = 20.26, p &lt; .001). Follow-up simple slope tests suggest that there is a significant and positive association between threat of inequality and preference for algorithm decision-making for those with low subjective SES (-1SD; t = 6.10, p &lt; .001), but not for those with high subjective SES (+1SD; t = <ref type="figure">Figure 2</ref>. The interactive effect of inequality threat and SES on preference for algorithm decision-making (Study 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of Study 2 provide further support for our hypotheses in the context of SES health disparities in Singapore. Threat of inequality decreased participants' aversion from algorithm decision-making, especially for those low in subjective SES. These results were obtained even though our participants were university students who were not members of the group the manipulation described as being disadvantaged (i.e., migrant workers). These findings support our hypotheses in a second cultural context, suggesting their generalizability.</p><p>Furthermore, Study 2 shows that the threat of inequality increases preference for algorithm decision-making even when the biases of human doctors are not explicitly mentioned. Studies 1-2 did not explore the psychological mechanism underlying the effect. In Study 3 we test whether the threat of inequality changes people's perceptions of doctors' authority as a mediating mechanism for these effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>We recruited 601 participants through Amazon's Mechanical Turk, using Turkprime <ref type="bibr" target="#b64">(Litman et al., 2017)</ref>. We aimed for a half-half ratio of Black and White participants in our samples (with specified samples). As specified in the pre-registration 4</p><p>(https://aspredicted.org/blind.php?x=hh4vv8), we excluded participants who did not self-report as either Black or White or that failed the attention and manipulation comprehension checks.</p><p>When the analyses were performed on the full sample, the effect of condition did not reach significance (p = .086) but was in the predicted and pre-registered direction. Our final sample was 483 participants (214 male, 266 female, 3 other; 231 White and 252 Black; Age: M = 38.29, SD = 11.71), see <ref type="table" target="#tab_0">Table 1</ref>. Participants were paid $1 as compensation. A post-hoc power analysis (using G*power 3.1, <ref type="bibr" target="#b41">Faul et al., 2007)</ref> revealed that this sample size had an achieved power of .868 (for an alpha of .05) to detect the main effect for condition, and an achieved power of .382</p><p>to detect the interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threat of inequality manipulation</head><p>The threat of inequality manipulation was identical to that of Study 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authority</head><p>After the threat of inequality manipulation participants answered three items measuring how they perceive the authority of doctors, modified from the Moral Foundations Questionnaire <ref type="bibr" target="#b49">(Graham et al., 2011</ref>) on a 1 (Strongly disagree) to 5 (Strongly agree) scale: "Respect for the authority of doctors is something all kids should learn," "I am completely comfortable submitting to the authority of doctors," and "As a patient, if I disagree with a doctor's orders, I</p><p>should still obey anyway because that is my duty," Cronbach's α = .73.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference for algorithm decision-making</head><p>We measured preference for algorithm decision-making as in Study 1.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention checks</head><p>In addition to the manipulation comprehension question used in Study 1, we asked participants to explain their choice (excluding participants who provided irrelevant explanations such as "good survey"). We further excluded participants who used auto-completion answering scales by measuring the number of clicks on some screens (using Qualtrics' Timing option).</p><p>Finally, participants provided demographic information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Descriptive statistics and correlations are presented in <ref type="table" target="#tab_3">Table 4</ref>. Notes: Threat of inequality: 0 = control condition; 1 = threat of inequality Personal relevance: 0 = White participants; 1 = Black participants * p &lt; .05</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Preference for algorithm decision-making</head><p>A 2 (condition: threat of inequality, control) x 2 (personal relevance: Black, White)</p><p>ANOVA revealed a main effect for condition, F(1, 479) = 9.52, p = .002, ηp 2 =.02, such that participants reported a stronger preference for algorithm decision-making in the threat of inequality condition (M = 2.39, SD = 1.32) than in the control condition (M = 2.03, SD = 1.22), supporting Hypothesis 1.</p><p>Personal relevance was also significant, F(1, 479) = 4.49, p &lt; .001, ηp 2 = .01, such that across conditions, Black participants preferred algorithm decision-making (M = 2.36, SD = 1.37) more than White participants (M = 2.09, SD = 1.16). The personal relevance x condition interaction was not significant, F(1, 479) = 2.76, p = .097, which does not support Hypothesis 2.</p><p>Although the interaction was not significant, it did trend in a similar direction to that of Studies 1-2. For White participants, there was no significant difference between the threat of inequality condition and the control condition (M = the control condition (M = 2.00, SD = 1.17) and 2.17, SD = 1.15; F(1,479) = 0.97, p = .325 ); For Black participants, there was a significant difference, such that in the threat condition participants showed a greater preference for algorithm decisionmaking (M = 2.60, SD = 1.43) than in the control condition (M = 2.05, SD = 1.27;</p><p>F(1,479)=11.77, p &lt; .001, ηp 2 =.024), see <ref type="figure" target="#fig_2">Figure 3</ref>.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The results of Study 3 replicate our previous finding that threat of inequality increases preferences towards algorithm decision-making. Although our predicted interaction between threat of inequality and personal relevance was not significant, we did find that threat of inequality significantly increased Black participants' preference for algorithms but did not significantly affect White participants' preferences, partially replicating our previous findings.</p><p>The results of Study 3 also reveal one possible psychological mechanism underlying the effect of threat of inequality on preference for algorithm decision-making. Threat of inequality weakens the perceived authority of doctors and thereby increases people's preference for algorithm decision-making (especially for those disadvantaged by the disparity).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Study 4: Hospital Choice</head><p>In Studies 1-3 we measured preference for an algorithm triage on a continuous scale.</p><p>However, in practice, the choice between hospitals is typically dichotomous. Therefore, in Study 4 we used a similar paradigm to that of Studies 1 and 3 with a binary choice measure, asking participants to choose one of the two hospitals, mirroring real-life decisions. In addition, as in Study 2, we did not mention any possible biases in doctors' decision-making to reduce demand characteristics. We also expanded the groups we describe as having higher mortality rates in our threat of inequality to include Latino and Indigenous people, as well as Black people, to better reflect current data regarding COVID-19 mortality rates (APM Research Lab, 2020). We also explored an additional possible outcome for threat of inequalitysupport for government assistance to hospitals. Finally, to explore whether SES, rather than race, better captures personal relevance, we also measured SES in this study.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>An a priori power analysis (using G*power 3.1, <ref type="bibr" target="#b41">Faul et al., 2007)</ref>  When including all participants in the analysis, the main effect for condition becomes only marginally significant (p = .073), the rest of the results remained unchanged. Participants were paid $0.4 as compensation 5 .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>SES</head><p>As in Study 2, we measured SES with the MacArthur subjective SES scale <ref type="bibr" target="#b3">(Adler et al., 2000)</ref>. 6</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Threat of inequality manipulation</head><p>The control condition was identical to that of Studies 1-3. In the "threat of inequality condition" participants also read the following:</p><p>There are large racial and ethnic disparities in who dies from COVID-19. In the United States, for example, the mortality rate from COVID-19 for Black, Latino, and Indigenous people is three times that of White people.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Hospital choice</head><p>We asked participants to which hospital they would go, either the hospital where the human doctor makes triage decisions or the hospital where an algorithm makes triage decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Government assistance</head><p>We told participants that the government can give medical supplies to one of the two hospitals and asked them which of the two hospitals should receive the medical supplies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention checks</head><p>We used the same attention checks as in Study 3.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>Descriptive statistics and correlations are presented in <ref type="table" target="#tab_5">Table 5</ref>. Notes: Threat of inequality: 0 = control condition; 1 = threat of inequality Personal relevance: 0 = White participants; 1 = Black/Latino/Indigenous participants Choice of hospital: 0 = Hospital with human triage; 1 = Hospital with algorithm triage Government assistance: 0 = Hospital with human triage; 1 = Hospital with algorithm triage * p &lt; .05</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Choice of hospital</head><p>To avoid an interaction term created by multiplying variables that half of their values are equal to 0, we modified the coding of the condition and personal relevance variables for hypothesis testing. A logistic regression with condition (control= -1; threat of inequality = 1), personal relevance (White = -1; Black/Latino/Indigenous = 1), and their interaction predicting choice of hospital revealed a main effect for condition, Wald χ 2 (1, N=860) = 6.37, p = .012, Exp(B) = 1.23, such that participants were more likely to choose algorithm triage in the threat of inequality condition (26.01%) than in the control condition (18.76%), supporting Hypothesis 1.</p><p>We also found a main effect for personal relevance, Wald χ 2 (1, N=860) = 7.47, p =.006, Exp(B) = 1.25, such that Black, Latino, and Indigenous people were more likely to select algorithm triage (26.01%) than White participants (18.39%). However, the personal relevance x condition interaction was not significant, p = .299, which does not support Hypothesis 2. This may reflect the lower statistical power of interaction tests, especially with uneven sample sizes <ref type="bibr" target="#b102">(Simonsohn, 2015</ref>).</p><p>Although the interaction was not significant, to understand our results better we ran a follow-up chi-squared analysis. We found that Black, Latino, and Indigenous people were more likely to choose algorithm triage in the threat of inequality condition (32.79%) than in the control condition (20.96%), χ 2 (1, N=860) = 6.98, p = .008, φ = 0.13. In contrast, for White participants, the difference in choice of algorithm triage between the choice of inequality condition (20.39%) and the control condition (16.67%) was not significant, p = .312, see <ref type="figure" target="#fig_4">Figure 5</ref>. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Government assistance</head><p>Logistic regression with condition, personal relevance, and their interaction predicting choice of hospital to receive government assistance revealed a main effect for condition, Wald</p><p>(1, N=860) = 4.81, p = .028, Exp(B) = 1.19, such that participants were more likely to choose the hospital with algorithm triage for government assistance in the threat of inequality condition (28.90%) than in the control condition (22.39%). The main effect for personal relevance was not Threat of inequality * significant, p =.248, and neither was the personal relevance x condition interaction, p = .121.</p><p>Although the interaction was not significant, to understand our results better we ran a follow-up chi-squared analysis. We found that Black, Latino, and Indigenous people were more likely to choose algorithm triage for government assistance in the threat of inequality condition (33.51%) than in the control condition (21.38%), χ 2 (1, N=860) = 7.07, p = .008, φ = 0.13. In contrast, for White participants, the difference in choice of algorithm triage between the choice of inequality condition (24.76%) and the control condition (22.92%) was not significant, p = .649.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Relying on a measure of binary choice rather than preferences, the results of Study 4 generalize our earlier findings. Threat of inequality increased the likelihood that participants will choose a hospital where an algorithm makes triage decisions. However, in this forced-choice scenario, we do note that participants still overwhelmingly chose human doctors over algorithms.</p><p>This suggests that while our manipulation was successful in reducing algorithm aversion, its effect might be small.</p><p>In addition, our threat of inequality manipulation led to another high-stake outcomeallocation of government assistance. Although we did not find a significant condition x personal relevance interaction, a simple effect analysis revealed that threat of inequality significantly affected choice of hospital for our Black, Latino and Indigenous participants, but not for our White participants. We also found that threat of inequality affects another applied outcomeit increases people's support for the hospital with algorithm triage to receive government support.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Internal Meta-Analyses</head><p>To estimate the overall effect of threat of inequality on preference for algorithm decisionmaking and to provide a concise summary of our findings <ref type="bibr" target="#b47">(Goh et al., 2016)</ref>, we conducted internal meta-analyses for Hypotheses 1 and 2. These meta-analyses included the results of Studies 1-3, which used a continuous DV, and were conducted with the 'meta' package in R <ref type="bibr" target="#b100">(Schwarzer, 2007)</ref>.</p><p>The first meta-analysis tested Hypothesis 1whether threat of inequality increased preference for algorithm decision-making. This meta-analysis revealed a mean effect size of </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>General Discussion</head><p>People are generally averse to algorithms making decisions-at the cost of efficiency and potentially human lives <ref type="bibr" target="#b17">(Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b66">Longoni et al., 2019)</ref>. Making the threat of inequality salient, however, can reduce this aversion. In four studies, we found that the threat of inequality in COVID-19 treatment reduces the aversion people have for algorithms making decisions. This basic pattern replicated across cultures (the United States and Singapore), in various time-points during the pandemic (see <ref type="table" target="#tab_0">Table 1</ref>), for a variety of medical decisions such as ventilator allocation and preference for which hospital should receive government assistance, and with (Studies 1 and 3) or without (Studies 2 and 4) the explicit mention of possible bias in human decision-making.</p><p>Furthermore, we find some evidence that this aversion reduction is stronger for those to whom the inequality is personally relevant. We note that algorithm aversion for those who personally suffer from human-induced inequality might not be surprising, as such a response could be explained by simple self-interest. Disadvantaged patients might simply prefer the option that will maximize their chances of getting the best medical treatment. However, those who stand to benefit from inequality (e.g., White participants, high-SES participants) also shift their preference toward algorithms, indicating that these changes in preference cannot be solely explained by self-interest.</p><p>Mediation analyses help explain the underlying mechanism for this general move in preferences toward algorithms: the reduced aversion from algorithm decision-making is due, at least partially, to a weakening of the perceived authority of doctors (although these results were not consistent). Threat of inequality might cause people to question the authority of doctorswho can be seen as associated with the inequality-and therefore increase people's preference for algorithms, rather than human doctors, as decision-makers. That said, we acknowledge that the empirical support for the role of doctors' authority is limited. Only one study <ref type="table" target="#tab_2">(Study 3)</ref> examined this question, and that study explicitly mentioned that doctors might be biased. Future research is needed to test the robustness of this finding.</p><p>Our results suggest that people are not only motivated by their self-interest, but also by broader ethical considerations <ref type="bibr" target="#b55">(Jones, 1991;</ref><ref type="bibr" target="#b94">Reynolds, 2006)</ref>. Our research demonstrates how awareness of the potential race and class inequality in medical decision-making can reduce the aversion from algorithm decision-making and accelerate the integration of algorithms into healthcare settings. By doing so, it can shape the future of human-algorithm interaction in the healthcare system <ref type="bibr" target="#b51">(Hao, 2020)</ref>. These findings can increase laypeople and patients' acceptance of algorithms and other technologies in the healthcare setting, with the potential to increase efficiency, reduce biases, and even save lives, all of which are valuable implications during and after the COVID-19 pandemic.</p><p>To maintain external validity, our studies did not inform participants how the algorithm would make decisions. In practice, when people are informed that a hospital uses algorithms for triage, they do not necessarily receive a description of the decision-making process. Indeed, even the decision-making process of human doctors is often opaque to patients. However, people might have different preferences for different processes of algorithm decision-making <ref type="bibr" target="#b23">(Bonnefon et al., 2016)</ref>, and general transparency about how AIs make decisions might further increase acceptance of AI decision-making <ref type="bibr" target="#b56">(Kim &amp; Hinds, 2006)</ref>. Future research is needed to examine this question.</p><p>Triage decisions are one domain of high-stake decision-making in which there is a growing public appreciation of outcome inequality, and in which algorithm decision-making is a growing alternative to human decision-making. Other such contexts are banking decisions, such as loans and credit limits <ref type="bibr" target="#b76">(O'neil, 2016;</ref><ref type="bibr" target="#b83">Perez, 2019;</ref><ref type="bibr" target="#b84">Perry, 2019)</ref>. While our studies focused on medical decision-making, they might extend to other domains, such as banking, in which people might be able to choose whether to apply for a loan from a human banker or an algorithm. Future research is needed to examine the generalizability of our findings to other domains.</p><p>We note that while threat of inequality reduced the aversion from algorithm decisionmaking, preferences for algorithm decision-making were not high. The relatively small effect size is perhaps most salient in Study 4 where participants were forced to choose between either a human or an algorithm. This outcome is consistent with previous work that found a strong aversion against algorithms making moral and medical decisions (e.g., <ref type="bibr" target="#b17">Bigman &amp; Gray, 2018;</ref><ref type="bibr" target="#b66">Longoni et al., 2019)</ref>. While our short text-based manipulation might not have reversed people's preferences, even small changes in preferences (Studies 1-3) and in choice (Study 4) can yield big differences when aggregated across large populations <ref type="bibr">(Prentice &amp; Miller, 1992)</ref>. Also, our manipulation is virtually costless while other factors might not be so. That said, future research is needed to examine additional factors that might more dramatically reduce people's algorithm aversion. For example, studies have shown that anthropomorphized algorithms can generally lead to satisfaction in consumer contexts <ref type="bibr" target="#b92">(Rauschnabel &amp; Ahuvia, 2014;</ref><ref type="bibr" target="#b107">Yam et al., 2020)</ref>, but whether this is the same in the medical context remains an open empirical question. All in all, we</p><p>are not suggesting that our work can eliminate algorithm aversion, but rather we hope our work will spark additional research to mitigate this aversion.</p><p>We acknowledge that although algorithms might be perceived as being more objective than humans <ref type="bibr" target="#b61">(Lee, 2018)</ref>, several discriminatory algorithms have been documented <ref type="bibr" target="#b76">(O'Neil, 2016;</ref><ref type="bibr" target="#b83">Perez, 2019)</ref>. For example, algorithms can be biased in hiring decisions <ref type="bibr" target="#b30">(Dastin, 2018)</ref>, parole recommendations <ref type="bibr" target="#b8">(Angwin et al., 2016)</ref>, and identifying people in need of special medical assistance <ref type="bibr" target="#b77">(Obermeyer et al., 2019)</ref>. Although some algorithms might be biased, algorithm bias is often easier to be corrected than human bias <ref type="bibr" target="#b73">(Mullainathan, 2019)</ref>. We also acknowledge that structural inequalities, and not necessarily individual bias, could be a major source of the higher COVID-19 mortality rates of some groups <ref type="bibr" target="#b2">(Abuelgasim et al., 2020;</ref><ref type="bibr" target="#b15">Bibbins-Domingo, 2020;</ref><ref type="bibr" target="#b25">Braveman et al., 2011;</ref><ref type="bibr" target="#b108">Yancy, 2020)</ref>. We note that it is possible (and plausible) that learning about algorithm bias might increase people's aversion to algorithm decision-making. However, at least currently, the role of algorithm decision-making in medical decision-making is still limited, and people are less likely to perceive them as biased <ref type="bibr" target="#b19">(Bigman et al., 2020;</ref><ref type="bibr" target="#b61">Lee, 2018)</ref>.</p><p>Replacing human decision-making with algorithm decision-making will not eliminate health disparity. Access to quality healthcare, habitat density, the ability to work remotely, and SES all contribute to the higher mortality rate in some communities <ref type="bibr" target="#b2">(Abuelgasim et al., 2020;</ref><ref type="bibr" target="#b15">Bibbins-Domingo, 2020;</ref><ref type="bibr" target="#b25">Braveman et al., 2011;</ref><ref type="bibr" target="#b108">Yancy, 2020)</ref>. Although we demonstrated that the threat of inequality can increase preference for algorithm decision-making, this does not necessarily translate to reduced inequality in medical outcomes. Future work should consider all these factors in tandem with human vs. algorithm-based medical decision-making. We do hope, however, that our work can contribute to this ongoing discussion about healthcare disparities and offer one way to potentially mitigate them.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations and Future Directions</head><p>We note that there is some variability in the effect sizes for our threat of inequality manipulation. Specifically, the effect size for threat of inequality in Study 1 (ηp 2 =.07) is much larger than in Study 3 (ηp 2 =.02), although they both used the same manipulation with the same population. One possibility is that the demonstrations following the killing of George Floyd in the U.S. on May 25, 2020 mitigated the effectiveness of our manipulation, as the baseline of threat of inequality might have changed. Another possibility is that as time passed and countries equipped themselves better, the fear of overcrowded hospitals and the lack of ventilators was reduced. Future research is needed to explore these possibilities. The differences in effect sizes in our other studies are not surprising, as they included samples from different populations, with different manipulations and different dependent variables.</p><p>One limitation of our studies is that our main dependent variables are self-reported preferences and decisions, which although being a reliable measure of general attitudes <ref type="bibr" target="#b58">(Krosnick et al., 2005)</ref> is not as compelling as a field study measuring actual behaviors.</p><p>However, ethical considerations preclude the possibility of such a field study, as it would involve asking patients to select either a human doctor or an algorithm as they are being admitted into a hospital with acute COVID-19 symptoms when rapid treatment is critical. Nevertheless, future research should examine this question in a field study, perhaps among patients with less acute illnesses.</p><p>In our studies, we simplified the medical decision-making process and the role of AI in this process. In actual healthcare settings, decision-making is complex and often involves several parties and stakeholders. These can be the various nurses, doctors, the patient, and the patient's family. While AI input might be one factor that determines treatment, at least today, it is not the only one. To capture this complexity, future studies could ask participants to choose between a hospital staffed by only human doctors, nurses, and healthcare professionals vs. a hospital staffed by human doctors, nurses, healthcare professionals, and AI.</p><p>In life-and-death medical decisions, the need for accountability and justification is high, as they involve legal liability. This might also be an obstacle in the dissemination of deep learning algorithms in which the decision-making process is not always fully explainable <ref type="bibr" target="#b0">(Abdul et al., 2018;</ref><ref type="bibr" target="#b5">Alaieri &amp; Vellino, 2016)</ref>. These limitations should be taken into account when considering the applications of this research.</p><p>Another limitation of our studies is the operationalization of medical decision-making as triage decisions when resources are scarce. These decisions might be specific to pandemics, for which the healthcare system is not properly equipped and prepared. Future research should examine people's preferences for a wider range of decisions by algorithms. For example, as of this writing, vaccine allocation has been a heatedly debated topic and future research can explore whether our findings can be generalized to this specific outcome.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Concluding Remarks</head><p>The use of algorithms for decision-making holds promise to help society in many ways <ref type="bibr" target="#b54">(Jackson et al., 2020)</ref>, including increasing efficiency and fairness in healthcare. Here we show how awareness of health disparities can increase people's acceptance of algorithms and accelerate the integration of algorithms into the workforce, with potential lasting impacts for racial and economic equality.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>The interactive effect of threat of inequality and personal relevance on preference for algorithm decision-making (Study 1). Error bars reflect standard errors. * p &lt; .05Study 2: Class Disparities in SingaporeIn Study 2, we operationalize the threat of inequality through social class. As with race, COVID-19 has disproportionally affected the poor. For example, in the UK those infected with COVID-19 who live in the poorest 10% areas of the country have been twice as likely to die as</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 .</head><label>3</label><figDesc>Preference for Algorithm triage by personal relevance and condition (Study 3). Error bars reflect standard errors. * p &lt; .05 Authority A 2 (personal relevance: Black, White) x 2 (condition: threat of inequality, control)ANOVA revealed a significant personal relevance x condition interaction, F(1, 479) = 5.24, p = .023, ηp 2 =.01, such that while Black participants reported a lower belief in doctors' authority in the threat of inequality condition (M = 3.05, SD =0.94) than the control condition (M = 3.34, SD = 0.96), F(1, 479) = 6.04, p = .014, ηp 2 =.01, there was no significant difference for White participants between the threat of inequality condition (M = 3.33, SD = 0.84) and the control condition (M = 3.23, SD = 0.97), p = .415. SeeFigure 4.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Figure 4 .</head><label>4</label><figDesc>Belief in doctors' authority by personal relevance and condition (Study 3). Error bars reflect standard errors.To examine the first-stage moderated mediation (J. R.<ref type="bibr" target="#b39">Edwards &amp; Lambert, 2007)</ref>, we entered threat of inequality as the independent variable, authority as the mediator, personal relevance as the first-stage moderator, and preference for algorithm decision-making as the dependent variable into a bootstrapping moderated mediation analysis (Model 7, 5000 iterations;<ref type="bibr" target="#b91">Preacher &amp; Hayes, 2008)</ref>. Results revealed that the indirect effect of threat of inequality on preference for algorithm decision-making, via authority, was significant for Black participants (coefficient =.06, SE = .03, 95% CI [.01, 0.13], but not for White participants (coefficient = -.02, SE = .03, 95% CI[-.08, .02]. Finally, the difference between these two indirect effects was also of moderated mediation = .08, SE = .04, 95% CI[.01,.19], supporting Hypothesis 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 5 .</head><label>5</label><figDesc>Choice of hospital with algorithm triage by personal relevance and condition (Study 4). Error bars reflect standard deviations. * p &lt; .05</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Sample details for Studies 1-4</figDesc><table><row><cell></cell><cell>Study 1</cell><cell>Study 1</cell><cell>Study 1</cell><cell>Study 2</cell><cell>Study 3</cell><cell>Study 4</cell></row><row><cell></cell><cell>Sample A</cell><cell>Sample B</cell><cell>Sample C</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Initial N</cell><cell>408</cell><cell>486</cell><cell>485</cell><cell>662</cell><cell>601</cell><cell>1005</cell></row><row><cell>Final N</cell><cell>295</cell><cell>377</cell><cell>388</cell><cell>416</cell><cell>483</cell><cell>860</cell></row><row><cell>Age (SD)</cell><cell cols="6">35.23 (11.91) 39.01 (12.81) 37.51 (12.57) 21.95 (1.58) 38.29 (11.71) 32.05 (10.54)</cell></row><row><cell>Gender</cell><cell>129 Male</cell><cell>167 Male</cell><cell>185 Male</cell><cell>153 Male</cell><cell>214 Male</cell><cell>432 Male</cell></row><row><cell></cell><cell>165 Female</cell><cell>206 Female</cell><cell>201 Female</cell><cell>257 Female</cell><cell>266 Female</cell><cell>419 Female</cell></row><row><cell></cell><cell>1 Other</cell><cell>4 Other</cell><cell>2 Other</cell><cell>6 Other</cell><cell>3 Other</cell><cell>9 Other</cell></row><row><cell>Race</cell><cell>155 White</cell><cell>183 White</cell><cell>197 White</cell><cell></cell><cell>231 White</cell><cell>446 White</cell></row><row><cell></cell><cell>140 Black</cell><cell>194 Black</cell><cell>191 Black</cell><cell></cell><cell>252 Black</cell><cell>208 Black</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>190 Latino</cell></row><row><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>16 Indigenous</cell></row><row><cell cols="2">Date (2020) May 4-6</cell><cell>May 14-15</cell><cell>May 27-28</cell><cell>June 11</cell><cell>June 24-26</cell><cell>November 9</cell></row></table><note>Study 1: Race Disparities in the US</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 .</head><label>2</label><figDesc>Descriptive Statistics and Correlations for Study Variables (Study 1) (condition: inequality threat, control) x 2 (personal relevance: Black, White)ANOVA revealed a main effect for condition, F(1, 1056) = 78.45, p &lt; .001, ηp 2 =.07, such that participants reported a stronger preference for algorithm decision-making in the threat of inequality condition (M = 2.77, SD = 1.43) than in the control condition (M = 2.04, SD = 1.20), SD = 1.47) more than White participants (M = 2.21, SD = 1.22). Finally, the personal relevance x condition interaction was also significant, F(1, 1056) = 20.88, p &lt; .001, ηp 2 =.02, such that while both Black and White participants preferred algorithm decision-making more in the threat of inequality condition, this effect was stronger for Black participants (threat of inequality: M = 3.09, SD = 1.45; control: M = 2.02, SD = 1.19; F(1,1056) = 89.67, p &lt; .001, ηp 2 =.08) than White participants (threat of inequality: M = 2.40, SD = 1.13; control: M = 2.06, SD = 1.12; F(1,</figDesc><table><row><cell>Variable</cell><cell>Mean</cell><cell>SD</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>1. Threat of inequality</cell><cell>.48</cell><cell>.50</cell><cell>(--)</cell><cell></cell><cell></cell></row><row><cell>2. Personal relevance</cell><cell>.50</cell><cell>.50</cell><cell>.07*</cell><cell>(--)</cell><cell></cell></row><row><cell>3. Preference for algorithm triage</cell><cell>2.59</cell><cell>1.62</cell><cell>.27*</cell><cell cols="2">.13* (--)</cell></row><row><cell>Notes:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Threat of inequality: 0 = control condition; 1 = threat of inequality</cell><cell></cell><cell></cell></row><row><cell cols="4">Personal relevance: 0 = White participants; 1 = Black participants</cell><cell></cell><cell></cell></row><row><cell>* p &lt; .05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 3 .</head><label>3</label><figDesc>Descriptive Statistics and Correlations for Study Variables (Study 2)</figDesc><table><row><cell>Variable</cell><cell>Mean</cell><cell>SD</cell><cell>1</cell><cell>2</cell><cell>3</cell></row><row><cell>1. Threat of inequality</cell><cell>.49</cell><cell>.50</cell><cell>(--)</cell><cell></cell><cell></cell></row><row><cell>2. Personal relevance (SES)</cell><cell>6.22</cell><cell>1.43</cell><cell>.01</cell><cell>(--)</cell><cell></cell></row><row><cell>3. Preference for algorithm</cell><cell>2.18</cell><cell>1.18</cell><cell>.19*</cell><cell>-.20*</cell><cell>(--)</cell></row><row><cell>Notes:</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell cols="4">Threat of inequality: 0 = control condition; 1 = threat of inequality</cell><cell></cell><cell></cell></row><row><cell>* p &lt; .05</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>A t-test revealed that participants reported a stronger preference for algorithm decision- making in the threat of inequality condition (M = 2.41, SD = 1.34) than in the control condition (M = 1.96, SD = 0.98), t(414) = 3.92, p &lt; .001, Cohen's d = 0.38, supporting Hypothesis 1.</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 4 .</head><label>4</label><figDesc>Descriptive Statistics and Correlations for Study Variables (Study 3)</figDesc><table><row><cell>Variable</cell><cell>Mean</cell><cell>SD</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell></row><row><cell>1. Threat of inequality</cell><cell>.55</cell><cell>.50</cell><cell>(--)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. Personal relevance</cell><cell>.52</cell><cell>.50</cell><cell>.02</cell><cell>(--)</cell><cell></cell><cell></cell></row><row><cell>3. Authority</cell><cell>3.23</cell><cell>.93</cell><cell>-.05</cell><cell>-.06</cell><cell>(--)</cell><cell></cell></row><row><cell>4. Preference for algorithm</cell><cell>2.23</cell><cell>1.29</cell><cell>.14*</cell><cell>.10*</cell><cell>-.16*</cell><cell>(--)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5 .</head><label>5</label><figDesc>Descriptive Statistics and Correlations for Study Variables (Study 4)</figDesc><table><row><cell>Variable</cell><cell>Mean</cell><cell>SD</cell><cell>1</cell><cell>2</cell><cell>3</cell><cell>4</cell><cell>5</cell></row><row><cell>1. Threat of inequality</cell><cell>.45</cell><cell>.50</cell><cell>(--)</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>2. Personal relevance</cell><cell>.48</cell><cell>.50</cell><cell>-.02</cell><cell>(--)</cell><cell></cell><cell></cell><cell></cell></row><row><cell>3. SES</cell><cell>5.23</cell><cell>1.69</cell><cell>.00</cell><cell>-0.9*</cell><cell>(--)</cell><cell></cell><cell></cell></row><row><cell>4. Choice of hospital</cell><cell>0.22</cell><cell>0.42</cell><cell>.09*</cell><cell>.09*</cell><cell>-.01</cell><cell>(--)</cell><cell></cell></row><row><cell>5. Government assistance</cell><cell>0.25</cell><cell>0.44</cell><cell>.08*</cell><cell>.04</cell><cell>.03</cell><cell>.65*</cell><cell>(--)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We acknowledge that in the medical context, triage decisions often refer to decisions where a lack of resources require decisions that result in determining who could be saved or treated. We took a broader definition because we used the term "triage" in our empirical studies where participants were all laymen and not medical professionals.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">Participants in Study 1 were recruited in 3 different samples. All samples had an identical manipulation and dependent variable, but included different exploratory variables. See sample details and full study materials for each sample in the supplemental materials.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">We note that in Sample A we used a 1 to 7 rather than a 1 to 5 scale. When combining the data of Sample A with Samples B and C we transformed the responses from Sample A to a 1-5 scale, using the following transformation: Xnew = (Xold-1)*4/6+1, such that 1 on the 1-7 scale would be 1 on the 1-5 scale, 7 would be transformed to 5, and 4, the midpoint in the 1-7 scale, to 3, the midpoint in the 1-5 scale. Analyzing the samples separately or combined yield essentially identical results.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">As specified in the pre-registration, we measured trust in physicians<ref type="bibr" target="#b104">(Thom et al., 1999)</ref> as another possible mediator. The results of that measure were not significant and we do not discuss them further here. See supplemental materials for a full description of the scale.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">In Prolific, we could target participants according to race and ethnicity without using a specialized panel, and therefore we could offer participants a more modest compensation. 6 SES did not interact with condition to predict preference for algorithm decision-making (p = .162).</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Trends and trajectories for explainable, accountable and intelligible systems: An HCI research agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Abdul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vermeulen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">Y</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kankanhalli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Conference on Human Factors in Computing Systems -Proceedings</title>
		<imprint>
			<date type="published" when="2018-04-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3173574.3174156</idno>
		<ptr target="https://doi.org/10.1145/3173574.3174156" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">COVID-19: Unique public health issues facing Black, Asian and minority ethnic communities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Abuelgasim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">J</forename><surname>Saw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Shirke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zeinah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Harky</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cpcardiol.2020.100621</idno>
		<ptr target="https://doi.org/10.1016/j.cpcardiol.2020.100621" />
	</analytic>
	<monogr>
		<title level="j">Current Problems in Cardiology</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">100621</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Relationship of Subjective and Objective Social Status With Psychological and Physiological Functioning: Preliminary Data in Healthy White Women</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">E</forename><surname>Adler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Epel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Castellazzo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Ickovics</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Psychology</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="586" to="592" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/0278-6133.19.6.586</idno>
		<ptr target="https://doi.org/10.1037/0278-6133.19.6.586" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Ethical decision making in robots: Autonomy, trust and responsibility autonomy trust and responsibility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Alaieri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vellino</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-3-319-47437-3_16</idno>
		<ptr target="https://doi.org/10.1007/978-3-319-47437-3_16" />
	</analytic>
	<monogr>
		<title level="j">Lecture Notes in Computer Science (Including Subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics</title>
		<imprint>
			<biblScope unit="page" from="9979" to="159" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Does diversity matter for health? Experimental evidence from Oakland</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alsan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Garrick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Graziani</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="4071" to="4111" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title/>
		<idno type="DOI">10.1257/aer.20181446</idno>
		<ptr target="https://doi.org/10.1257/aer.20181446" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Angwin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Larson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Surya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lauren</surname></persName>
		</author>
		<ptr target="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing" />
		<title level="m">Machine Bias. ProPublica</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">The color of Coronavirus: COVID-19 deaths by race and ethnicity in the U.S. APM Research Lab</title>
		<ptr target="https://www.apmresearchlab.org/covid/deaths-by-race" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
		<respStmt>
			<orgName>APM Research Lab</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Clinical Laboratory Employees&apos; Attitudes Toward Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Ardon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Schmidt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Laboratory Medicine</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="649" to="654" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/labmed/lmaa023</idno>
		<ptr target="https://doi.org/10.1093/labmed/lmaa023" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Provisional life expectancy estimates for</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tejada-Vera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ahmad</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020-06" />
			<biblScope unit="volume">010</biblScope>
			<biblScope unit="page" from="1" to="8" />
		</imprint>
		<respStmt>
			<orgName>CDC Vital Statistics Rapid Release</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Health Care Heroes of the COVID-19 Pandemic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bauchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Easley</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2020.6197</idno>
		<ptr target="https://doi.org/10.1001/jama.2020.6197" />
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page">2021</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Sharpening the global focus on ethnicity and race in the time of COVID-19</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bhala</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Curry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Martineau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Agyemang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhopal</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0140-6736(20</idno>
		<ptr target="https://doi.org/10.1016/S0140-6736(20" />
	</analytic>
	<monogr>
		<title level="j">The Lancet</title>
		<imprint>
			<biblScope unit="volume">395</biblScope>
			<biblScope unit="page" from="31102" to="31110" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bibbins-Domingo</surname></persName>
		</author>
		<title level="m">This Time Must Be Different: Disparities During the COVID-19</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Pandemic</surname></persName>
		</author>
		<idno type="DOI">10.7326/M20-2247</idno>
		<ptr target="https://doi.org/10.7326/M20-2247" />
	</analytic>
	<monogr>
		<title level="j">Annals of Internal Medicine</title>
		<imprint>
			<biblScope unit="page" from="20" to="2247" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title level="m" type="main">People are averse to machines making moral decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title/>
		<idno type="DOI">10.1016/j.cognition.2018.08.003</idno>
		<ptr target="https://doi.org/10.1016/j.cognition.2018.08.003" />
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">181</biblScope>
			<biblScope unit="page" from="21" to="34" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">Algorithmic Discrimination Causes Less Moral Outrage than Human Discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Arnestad</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Waytz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blease</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Kaptchuk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Bernstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Mandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Halamka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Desroches</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Artificial Intelligence and the Future of Primary Care: Exploratory Qualitative Study of UK General Practitioners&apos; Views</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
		<idno type="DOI">10.2196/12802</idno>
		<ptr target="https://doi.org/10.2196/12802" />
	</analytic>
	<monogr>
		<title level="j">Journal of Medical Internet Research</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Board of Governors of the Federal Reserve System</title>
	</analytic>
	<monogr>
		<title level="m">Share of Total Net Worth Held by the Top 1% (99th to 100th Wealth Percentiles)</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">The social dilemma of autonomous vehicles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-F</forename><surname>Bonnefon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shariff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Rahwan</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.aaf2654</idno>
		<ptr target="https://doi.org/10.1126/science.aaf2654" />
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">352</biblScope>
			<biblScope unit="issue">6293</biblScope>
			<biblScope unit="page" from="1573" to="1576" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The White-Coat Effect: Physician Attire and Perceived Authority, Friendliness, and Attractiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">L</forename><surname>Brase</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Richmond</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1559-1816.2004.tb01987.x</idno>
		<ptr target="https://doi.org/10.1111/j.1559-1816.2004.tb01987.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Social Psychology</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2469" to="2481" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">The social determinants of health: Coming of age</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Braveman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Egerter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-publhealth-031210-101218</idno>
		<ptr target="https://doi.org/10.1146/annurev-publhealth-031210-101218" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Public Health</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="381" to="398" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Task-Dependent Algorithm Aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="809" to="825" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0022243719851788</idno>
		<ptr target="https://doi.org/10.1177/0022243719851788" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">London hospital trials digital triage service in urgent care departments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Crouch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Digitalhealth</surname></persName>
		</author>
		<ptr target="https://www.digitalhealth.net/2019/06/london-hospital-trials-digital-triage/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Amazon scraps secret AI recruiting tool that showed bias against women</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dastin</surname></persName>
		</author>
		<ptr target="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight/amazon-scraps-secret-ai-recruiting-tool-that-showed-bias-against-women-idUSKCN1MK08G" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">The robust beauty of improper linear models in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title/>
		<idno type="DOI">10.1037/0003-066X.34.7.571</idno>
		<ptr target="https://doi.org/10.1037/0003-066X.34.7.571" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="571" to="582" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">Poorest areas of England and Wales hit hardest by Covid-19 -ONS. The Guardian</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Devlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Barr</surname></persName>
		</author>
		<ptr target="https://www.theguardian.com/world/2020/jun/12/poorest-areas-of-england-and-wales-hit-hardest-by-covid-19-ons" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Algorithm aversion: People erroneously avoid algorithms after seeing them err</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">J</forename><surname>Dietvorst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Massey</surname></persName>
		</author>
		<idno type="DOI">10.1037/xge0000033</idno>
		<ptr target="https://doi.org/10.1037/xge0000033" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="114" to="126" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Artificial intelligence and the future of psychiatry: Insights from a global physician survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Doraiswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blease</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bodner</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.artmed.2019.101753</idno>
		<ptr target="https://doi.org/10.1016/j.artmed.2019.101753" />
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence in Medicine</title>
		<imprint>
			<biblScope unit="volume">102</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Social class, power, and selfishness: When and why upper and lower class individuals behave unethically</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dubois</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">D</forename><surname>Rucker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Galinsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/pspi0000008</idno>
		<ptr target="https://doi.org/10.1037/pspi0000008" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">108</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="436" to="449" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Risk of being killed by police use of force in the United States by age, race-ethnicity, and sex</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Esposito</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">116</biblScope>
			<biblScope unit="page" from="16793" to="16798" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1821204116</idno>
		<ptr target="https://doi.org/10.1073/pnas.1821204116" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Methods for integrating moderation and mediation: A general analytical framework using moderated path analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Edwards</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Lambert</surname></persName>
		</author>
		<idno type="DOI">10.1037/1082-989X.12.1.1</idno>
		<ptr target="https://doi.org/10.1037/1082-989X.12.1.1" />
	</analytic>
	<monogr>
		<title level="j">Psychological Methods</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<monogr>
		<title level="m" type="main">Black Americans Face Alarming Rates of Coronavirus Infection in Some States. The New York Times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Eligon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D S</forename><surname>Burch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Searcey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A J</forename><surname>Oppel</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G*</forename><surname>Power</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193146</idno>
		<ptr target="https://doi.org/10.3758/BF03193146" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="175" to="191" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">Social cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">E</forename><surname>Taylor</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1991" />
			<publisher>Mcgraw-Hill Book Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Cleveland Clinic to Identify At-Risk Patients in ICU using Cortana Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gauher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Uz</surname></persName>
		</author>
		<ptr target="https://docs.microsoft.com/en-us/archive/blogs/machinelearning/cleveland-clinic-to-identify-at-risk-patients-in-icu-using-cortana-intelligence-suite" />
	</analytic>
	<monogr>
		<title level="j">Machine Learning Blog</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Singapore&apos;s migrant workers fear financial ruin after virus ordeal</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Geddi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koustav</surname></persName>
		</author>
		<ptr target="https://www.reuters.com/article/us-health-coronavirus-singapore-migrants/singapores-migrant-workers-fear-financial-ruin-after-virus-ordeal-idUSKBN23G1PG" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Robots are joining the fight against coronavirus in India</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gerretsen</surname></persName>
		</author>
		<ptr target="https://www.cnn.com/2020/11/11/tech/robots-india-covid-spc-intl/index.html" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Mini Meta-Analysis of Your Own Studies : Some Arguments on Why and a Primer on How</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Goh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosenthal</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="535" to="549" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Doctors are seen as Godlike: Moral typecasting in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goranson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Sheeran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Katz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.socscimed.2020.113008</idno>
		<ptr target="https://doi.org/10.1016/j.socscimed.2020.113008" />
	</analytic>
	<monogr>
		<title level="j">Social Science &amp; Medicine</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Mapping the moral domain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Graham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Nosek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Haidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Iyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Koleva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">H</forename><surname>Ditto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="366" to="385" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title/>
		<idno type="DOI">10.1037/a0021847</idno>
		<ptr target="https://doi.org/10.1037/a0021847" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Doctors are using AI to triage covid-19 patients. The tools may be here to stay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">MIT Technology Review</title>
		<imprint>
			<biblScope unit="page" from="1" to="12" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Racial bias in pain assessment and treatment recommendations, and false beliefs about biological differences between blacks and whites</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Trawalter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Axt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">N</forename><surname>Oliver</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1516047113</idno>
		<ptr target="https://doi.org/10.1073/pnas.1516047113" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">113</biblScope>
			<biblScope unit="page" from="4296" to="4301" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Can AI solve the diversity problem in the tech industry? Mitigating noise and bias in employment decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Houser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stanford Technology Law Review</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">Could a rising robot workforce make humans less prejudiced? American Psychologist</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Jackson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1037/amp0000582</idno>
		<ptr target="https://doi.org/10.1037/amp0000582" />
		<imprint>
			<date type="published" when="2020-11" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Ethical Decision Making by Individuals in Organizations: An Issue-Contingent Model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.2307/258867</idno>
		<ptr target="https://doi.org/10.2307/258867" />
	</analytic>
	<monogr>
		<title level="j">The Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">366</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Who Should I Blame? Effects of Autonomy and Transparency on Attributions in Human-Robot Interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Hinds</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The 15th IEEE International Symposium on Robot and Human Interactive Communication</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="80" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title/>
		<idno type="DOI">10.1109/ROMAN.2006.314398</idno>
		<ptr target="https://doi.org/10.1109/ROMAN.2006.314398" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">Measurement of Attitudes. Handbook of Attitudes and Attitude Change</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Krosnick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Wittenbrink</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="21" to="76" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">Perceptions of artificial intelligence in healthcare: findings from a qualitative survey study among actors in France</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-C</forename><surname>Laï</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-F</forename><surname>Mamzer</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12967-019-02204-y</idno>
		<ptr target="https://doi.org/10.1186/s12967-019-02204-y" />
	</analytic>
	<monogr>
		<title level="j">Journal of Translational Medicine</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Algorithmic bias? An empirical study of apparent genderbased discrimination in the display of stem career ads</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lambrecht</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tucker</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.2018.3093</idno>
		<ptr target="https://doi.org/10.1287/mnsc.2018.3093" />
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="2966" to="2981" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Big Data and Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/2053951718756684</idno>
		<ptr target="https://doi.org/10.1177/2053951718756684" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Early triage of critically ill COVID-19 patients using deep learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Lv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zanin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Wong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Liang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Ou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zhou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Han</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>He</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-020-17280-8</idno>
		<ptr target="https://doi.org/10.1038/s41467-020-17280-8" />
	</analytic>
	<monogr>
		<title level="j">Nature Communications</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="7" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<monogr>
		<title level="m" type="main">TurkPrime . com : A versatile crowdsourcing data acquisition platform for the behavioral sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Litman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Abberbock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="433" to="442" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<idno type="DOI">10.3758/s13428-016-0727-z</idno>
		<ptr target="https://doi.org/10.3758/s13428-016-0727-z" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">Resistance to Medical Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Longoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bonezzi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">K</forename><surname>Morewedge</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Consumer Research</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="629" to="650" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<monogr>
		<title/>
		<idno type="DOI">10.1093/jcr/ucz013</idno>
		<ptr target="https://doi.org/10.1093/jcr/ucz013" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Testing competing explanations of black opinions on affirmative action</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mangum</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1541-0072.2008.00267.x</idno>
		<ptr target="https://doi.org/10.1111/j.1541-0072.2008.00267.x" />
	</analytic>
	<monogr>
		<title level="j">Policy Studies Journal</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="347" to="366" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Exposure to rising inequality shapes Americans&apos; opportunity beliefs and policy support</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Mccall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Burk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Laperrière</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Richeson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="9593" to="9598" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1706253114</idno>
		<ptr target="https://doi.org/10.1073/pnas.1706253114" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Robot to deliver meals, medication to Covid-19 patients at Alexandra Hospital to reduce exposure of healthcare workers Read</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Meah</surname></persName>
		</author>
		<ptr target="https://www.todayonline.com/singapore/robot-deliver-meals-medication-covid-19-patients-alexandra-hospital-reduce-exposure.Today.https://www.todayonline.com/singapore/robot-deliver-meals-medication-covid-19-patients-alexandra-hospital-reduce-exposure" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">We Don&apos;t Carry That &quot; -Failure of Pharmacies in Predominantly Nonwhite Neighborhoods To Stock Opioid Analgesics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Wallenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Natale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Senzel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L.-L</forename><surname>Haung</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The New England Journal of Medicine</title>
		<imprint>
			<biblScope unit="volume">342</biblScope>
			<biblScope unit="issue">14</biblScope>
			<biblScope unit="page" from="1023" to="1026" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Biased Algorithms Are Easier to Fix Than Biased People. The New York Times</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<ptr target="https://www.nytimes.com/2019/12/06/business/algorithm-bias-fix.html" />
		<imprint>
			<date type="published" when="2019-12-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Big Data : A Report on Algorithmic Systems , Opportunity , and Civil Rights Big Data : A Report on Algorithmic Systems , Opportunity , and Civil Rights. Executive Office of the President of USA</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Munoz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Patil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Deaths: Final Data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">L</forename><surname>Murphey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Kochanek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Arias</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tekada-Vera</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">National Vital Statistics Reports</title>
		<imprint>
			<biblScope unit="issue">13</biblScope>
			<biblScope unit="page">69</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O'neil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<pubPlace>Crown</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Dissecting racial bias in an algorithm used to manage the health of populations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Powers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Vogeli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">366</biblScope>
			<biblScope unit="issue">6464</biblScope>
			<biblScope unit="page" from="447" to="453" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<monogr>
		<title/>
		<idno type="DOI">10.1126/science.aax2342</idno>
		<ptr target="https://doi.org/10.1126/science.aax2342" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Definition of bias</title>
		<ptr target="https://www.lexico.com/en/definition/bias" />
	</analytic>
	<monogr>
		<title level="j">In Lexico.com</title>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">Surge in Covid cases shows up Singapore&apos;s blind spots over migrant workers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Palma</surname></persName>
		</author>
		<ptr target="https://www.ft.com/content/0fdb770a-a57a-11ea-92e2-cbd9b7e28ee6" />
	</analytic>
	<monogr>
		<title level="j">Financial Times</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<monogr>
		<title level="m" type="main">Coronavirus: Belgium hosptial employs robot to protect against COVID-19</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Parrock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Euronews</surname></persName>
		</author>
		<ptr target="https://www.euronews.com/2020/06/02/coronavirus-belgium-hospital-employs-robot-to-protect-against-covid-19" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<monogr>
		<title level="m" type="main">Invisible women: Exposing data bias in a world designed for men</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Perez</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Random House</note>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">A Loan at Last? Race and Racism in Mortgage Lending</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">G</forename><surname>Perry</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Race in the Marketplace: Crossing Critical Boundaries</title>
		<editor>G. D. Johnson, K. D. Thomas, A. K. Harrison, &amp; S. A. Grier</editor>
		<imprint>
			<publisher>Springer International Publishing</publisher>
			<date type="published" when="2019" />
			<biblScope unit="page" from="173" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<monogr>
		<title/>
		<idno type="DOI">10.1007/978-3-030-11711-5_11</idno>
		<ptr target="https://doi.org/10.1007/978-3-030-11711-5_11" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Higher social class predicts increased unethical behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">K</forename><surname>Piff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Stancato</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cotêb́</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mendoza-Denton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Keltner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">109</biblScope>
			<biblScope unit="page" from="4086" to="4091" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1118373109</idno>
		<ptr target="https://doi.org/10.1073/pnas.1118373109" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Polesie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gillstedt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lallas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zalaudek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paoli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<monogr>
		<title level="m" type="main">Attitudes towards artificial intelligence within dermatology: an international online survey</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<analytic>
		<title/>
		<idno type="DOI">10.1111/bjd.18875</idno>
		<ptr target="https://doi.org/10.1111/bjd.18875" />
	</analytic>
	<monogr>
		<title level="j">British Journal of Dermatology</title>
		<imprint>
			<biblScope unit="volume">183</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="159" to="161" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<analytic>
		<title level="a" type="main">Asymptotic and resampling strategies for assessing and comparing indirect effects in multiple mediator models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Preacher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Hayes</surname></persName>
		</author>
		<idno type="DOI">10.3758/BRM.40.3.879</idno>
		<ptr target="https://doi.org/10.3758/BRM.40.3.879" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">40</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="879" to="891" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">You&apos;re so lovable: Anthropomorphism and brand love</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Rauschnabel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Ahuvia</surname></persName>
		</author>
		<idno type="DOI">10.1057/bm.2014.14</idno>
		<ptr target="https://doi.org/10.1057/bm.2014.14" />
	</analytic>
	<monogr>
		<title level="j">Journal of Brand Management</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="372" to="395" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<monogr>
		<title level="m" type="main">Moral Development: Advances in Research and Theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Rest</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>Praeger Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<analytic>
		<title level="a" type="main">Moral awareness and ethical predispositions: investigating the role of individual differences in the recognition of moral issues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1037/0021-9010.91.1.233</idno>
		<ptr target="https://doi.org/10.1037/0021-9010.91.1.233" />
	</analytic>
	<monogr>
		<title level="j">The Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">91</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="233" to="243" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Moral Attentiveness: Who Pays Attention to the Moral Aspects of Life</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Reynolds</surname></persName>
		</author>
		<idno type="DOI">10.1037/0021-9010.93.5.1027</idno>
		<ptr target="https://doi.org/10.1037/0021-9010.93.5.1027" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1027" to="1041" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<analytic>
		<title level="a" type="main">The recognition of moral issues: moral awareness, moral sensitivity and moral attentiveness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Reynolds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Miller</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Psychology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page" from="114" to="117" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.copsyc.2015.07.007</idno>
		<ptr target="https://doi.org/10.1016/j.copsyc.2015.07.007" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Exposure to inequality affects support for redistribution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Sands</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="663" to="668" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<monogr>
		<title/>
		<idno type="DOI">10.1073/pnas.1615010113</idno>
		<ptr target="https://doi.org/10.1073/pnas.1615010113" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">meta: An R package for meta-analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">R News</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="40" to="45" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b101">
	<monogr>
		<title level="m" type="main">Triage in a Pandemic: Can AI Help Ration Access to Care?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Shea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Laudanski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Solomon</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
			<publisher>Knowledge@Wharton</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b102">
	<monogr>
		<title level="m" type="main">No-way Interactions. The Winnower</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Simonsohn</surname></persName>
		</author>
		<idno type="DOI">10.15200/winn.142559.90552</idno>
		<ptr target="https://doi.org/10.15200/winn.142559.90552" />
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">17</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b103">
	<analytic>
		<title level="a" type="main">Applications of Artificial Intelligence in Battling Against Covid-19: A Literature Review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">-</forename><forename type="middle">N</forename><surname>Tayarani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M.-H</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.chaos.2020.110338</idno>
		<ptr target="https://doi.org/10.1016/j.chaos.2020.110338" />
	</analytic>
	<monogr>
		<title level="j">Chaos, Solitons &amp; Fractals</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b104">
	<analytic>
		<title level="a" type="main">Further Validation and Reliability Testing of the Trust in Physician Scale</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Thom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Ribisl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Luke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Care</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="510" to="517" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b105">
	<monogr>
		<title/>
		<idno type="DOI">10.1097/00005650-199905000-00010</idno>
		<ptr target="https://doi.org/10.1097/00005650-199905000-00010" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b106">
	<monogr>
		<title level="m" type="main">How chatbots are helping in the fight against COVID-19</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vanian</surname></persName>
		</author>
		<ptr target="https://fortune.com/2020/07/15/covid-coronavirus-artificial-intelligence-triage/" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b107">
	<analytic>
		<title level="a" type="main">Robots at Work: People Prefer-and Forgive-Service Robots With Perceived Feelings</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">C</forename><surname>Yam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">E</forename><surname>Bigman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Tang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ilies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>De Cremer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Soh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Gray</surname></persName>
		</author>
		<idno type="DOI">10.1037/apl0000834</idno>
		<ptr target="https://doi.org/10.1037/apl0000834" />
	</analytic>
	<monogr>
		<title level="j">Journal of Applied Psychology</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b108">
	<analytic>
		<title level="a" type="main">COVID-19 and African Americans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">W</forename><surname>Yancy</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2020.6548</idno>
		<ptr target="https://doi.org/10.1001/jama.2020.6548" />
	</analytic>
	<monogr>
		<title level="j">JAMA -Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">323</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page" from="1891" to="1892" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b109">
	<analytic>
		<title level="a" type="main">Autonomous morals: Inferences of mind predict acceptance of AI behavior in sacrificial moral dilemmas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">D</forename><surname>Young</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Monroe</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jesp.2019.103870</idno>
		<ptr target="https://doi.org/10.1016/j.jesp.2019.103870" />
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Social Psychology</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
