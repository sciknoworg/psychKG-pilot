<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">A Psychometric Framework for Evaluating Fairness in Algorithmic Decision Making: Differential Algorithmic Functioning</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-04-08">April 8, 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Youmi</forename><surname>Suk</surname></persName>
							<email>ysuk@tc.columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Teachers College</orgName>
								<orgName type="institution">Columbia University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Kyung</forename><forename type="middle">T</forename><surname>Han</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Graduate Management Admission Council</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">A Psychometric Framework for Evaluating Fairness in Algorithmic Decision Making: Differential Algorithmic Functioning</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-04-08">April 8, 2023</date>
						</imprint>
					</monogr>
					<note type="submission">This article has been accepted for publication in Journal of Educational and Behavioral Statistics,</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>As algorithmic decision making is increasingly deployed in every walk of life, many researchers have raised concerns about fairness-related bias from such algorithms. But there is little research on harnessing psychometric methods to uncover potential discriminatory bias inside decisionmaking algorithms. The main goal of this paper is to propose a new framework for algorithmic fairness based on differential item functioning (DIF), which has been commonly used to measure item fairness in psychometrics. Our fairness notion, which we call differential algorithmic functioning (DAF), is defined based on three pieces of information: a decision variable, a &quot;fair&quot; variable, and a protected variable such as race or gender. Under the DAF framework, an algorithm can exhibit uniform DAF, nonuniform DAF, or neither (i.e., non-DAF). For detecting DAF, we provide modifications of well-established DIF methods: Mantel-Haenszel test, logistic regression, and residual-based DIF. We demonstrate our framework through a real dataset concerning decision-making algorithms for grade retention in K-12 education in the United States.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Introduction</head><p>As algorithmic decision making is increasingly used in every walk of life (e.g., hiring, lending, online advertising, online learning, criminal justice), many researchers have raised fairnessrelated concerns with such algorithms <ref type="bibr" target="#b10">(Corbett-Davies &amp; Goel, 2018)</ref>. A significant concern surrounding automated decision-making algorithms is that they may produce unconscious bias in decision making against vulnerable subgroups <ref type="bibr" target="#b37">(Mehrabi et al., 2021)</ref>. That is, an algorithm may give an unfair advantage to one subgroup, such as whites, over another subgroup, such as blacks. Detecting and resolving such fairness-related biases in machine learning algorithms have motivated an area of research now called algorithmic fairness <ref type="bibr" target="#b39">(Mitchell et al., 2021)</ref>. Broadly speaking, this rapidly emerging literature provides formal, quantifiable measures of fairness, such as statistical parity and separation, which can be used either to diagnose existing algorithms or to inform designs of new algorithms <ref type="bibr" target="#b4">(Barocas et al., 2019;</ref><ref type="bibr" target="#b11">Corbett-Davies et al., 2017;</ref><ref type="bibr" target="#b13">Dwork et al., 2012;</ref><ref type="bibr" target="#b14">Feldman et al., 2015;</ref><ref type="bibr" target="#b39">Mitchell et al., 2021;</ref><ref type="bibr" target="#b42">Pessach &amp; Shmueli, 2022)</ref>; see details in Section 2. The overarching goal of this paper is to propose a new theoretical and practical framework for evaluating algorithmic fairness based on differential item functioning (DIF), which has been commonly used to measure item bias in test development and psychometrics.</p><p>Although discussions on algorithmic fairness are recent, the concept of test fairness was formulated in the 1960s and has evolved over the past six decades. Psychometricians have developed DIF frameworks and relevant methods to measure the fairness and validity of tests at the item level <ref type="bibr" target="#b2">(Angoff &amp; Sharon, 1974;</ref><ref type="bibr" target="#b9">Cleary &amp; Hilton, 1968;</ref><ref type="bibr" target="#b12">Crocker &amp; Algina, 1986;</ref><ref type="bibr" target="#b43">Pine, 1977)</ref>. Briefly, an item is considered to exhibit DIF if the item behaves or functions differently across groups of examinees (often, focal versus reference groups) after accounting for examinees' ability; see equation <ref type="formula" target="#formula_5">5</ref>for a formal definition. Group categories considered in DIF often include gender, race, or ethnicity in the social equality context, and common methods to detect the presence of DIF include the Mantel-Haenszel test <ref type="bibr" target="#b48">(Shealy &amp; Stout, 1993)</ref>, logistic regression <ref type="bibr" target="#b51">(Swaminathan &amp; Rogers, 1990)</ref>, and item-response-theory-based methods, e.g., area measures <ref type="bibr" target="#b27">(Kim &amp; Cohen, 1991;</ref><ref type="bibr" target="#b46">Raju, 1988)</ref> and residual-based DIF <ref type="bibr" target="#b33">(Lim et al., 2022)</ref>. When an item is detected to have DIF, the item is typically reviewed by content experts for revision or removal from the item pool. DIF analysis is an essential component of standardized tests developed in the United States, such as the SAT, ACT, Graduate Record Examinations (GRE), and Graduate Management Admissions Test (GMAT). But, to the best of our knowledge, there is no research on harnessing the concept of DIF and its detection methods to uncover potential fairness-related harms in modern, automated algorithms.</p><p>In this paper, we propose a DIF-based approach to assess algorithmic fairness in modern, machine learning algorithms. In a nutshell, our approach, which we call differential algorithmic functioning (DAF), expands existing DIF to encompass algorithmic fairness based on three pieces of information typically available from a modern algorithm: (i) a decision variable, (ii) a "fair" variable, and (iii) a protected variable such as race, ethnicity, or gender. With these pieces of information, an algorithm can exhibit what we call uniform DAF, nonuniform DAF, or neither (i.e., non-DAF, fair). We also modify existing DIF detection methods, notably the Mantel-Haenszel test, logistic regression, and residual-based DIF, to assess the presence of DAF in algorithms; see Section 4 for details of the proposed DAF framework.</p><p>Throughout the manuscript, we use an example concerning student grade retention where an automated algorithm assists teachers' decisions on whether a student is retained or promoted. Typically, grade retention is recommended if students make inadequate progress in academic achievement or show developmental immaturity <ref type="bibr" target="#b17">(Greene &amp; Winters, 2006;</ref><ref type="bibr" target="#b24">Jackson, 1975)</ref>. We measure the fairness of such decision-making algorithms using DAF and compare DAF to other notions of algorithmic fairness, notably statistical parity.</p><p>The remainder of this paper is organized as follows. Sections 2 and 3 briefly review algorithmic fairness and DIF, respectively. Section 4 discusses our DAF framework. Section 5 shows the empirical results about designing a new, fair algorithm that assists teachers' decisions to retain a student or not. Discussion and conclusions are in Section 6.</p><p>2 Review: Algorithmic Fairness</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Notation</head><p>Suppose we have a classification algorithm that is trained on data from N study units, indexed by i = 1, 2, . . . , N . Each study unit's data consists of features/covariates V i ∈ V and a binary outcome Y i . For evaluating algorithmic fairness, the covariates are partitioned into protected variables G i and unprotected variables X i , i.e., V i = (G i , X i ). We define a decision rule δ : V → {0, 1} which takes on two possible actions based on</p><formula xml:id="formula_0">V i , i.e., D i = δ(V i ). If a correct decision is made, Y i = D i .</formula><p>The goal for a classification algorithm is to find a decision rule that makes correct decisions.</p><p>For example, in the case of grade retention, Y would be a student's retention status where 0 indicates that he/she/they were promoted and 1 indicates that he/she/they were retained. V would be a student's characteristics in the kindergarten year, and D would be the algorithm's decision to retain or promote a student based on V where 0 corresponds to promoting him/her/them to the next grade and 1 corresponds to retaining him/her/them in the same grade.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Notions of Algorithmic Fairness</head><p>We review four common measures of algorithmic fairness: (i) statistical parity, (ii) conditional statistical parity, (iii) separation, and (iv) sufficiency <ref type="bibr" target="#b4">(Barocas et al., 2019;</ref><ref type="bibr" target="#b11">Corbett-Davies et al., 2017;</ref><ref type="bibr" target="#b14">Feldman et al., 2015;</ref><ref type="bibr" target="#b39">Mitchell et al., 2021)</ref>. Statistical parity requires that an algorithm's decision be independent of protected group membership, and in the case of binary classification, it is defined as:</p><formula xml:id="formula_1">P r(D = 1|G = g) = P r(D = 1|G = g ′ ).</formula><p>(1)</p><p>In our retention example, statistical parity means that retention decision rates are equal across sub-populations such as gender or racial groups. Statistical parity is often referred to as demographic parity, disparate impact, or independence <ref type="bibr" target="#b4">(Barocas et al., 2019;</ref><ref type="bibr" target="#b11">Corbett-Davies et al., 2017;</ref><ref type="bibr" target="#b39">Mitchell et al., 2021)</ref>. Statistical parity pursues equality of outcomes/results and does not account for intrinsic characteristics of each individual, which may ultimately decrease the overall prediction performance (e.g., accuracy, recall) of the algorithm for all groups <ref type="bibr" target="#b56">(Xu et al., 2022)</ref>. For example, among racial groups, if black students were more likely to be retained than white students during kindergarten for some reasons, it would be reasonable to consider the actual racial differences for the retention predictions in the kindergarten year. But statistical parity may prevent an algorithm from reflecting this intrinsic difference. Conditional statistical parity requires that an algorithm's decision be independent of protected group membership after controlling for a set of "legitimate" risk factors L = l(X) <ref type="bibr" target="#b11">(Corbett-Davies et al., 2017)</ref>. Formally, it is defined as:</p><formula xml:id="formula_2">P r(D = 1|L, G = g) = P r(D = 1|L, G = g ′ )<label>(2)</label></formula><p>This notion aims to treat people who are similar in their legitimate risk factors similarly regardless of group membership. For example, among students who had the same developmental immaturity, black and white students are retained at equal rates. It should be noted that achieving conditional statistical parity does not always guarantee statistical parity (and vice versa), in particular if legitimate risk factors are correlated with protected variables. Separation requires that an algorithm's decision should be independent of protected group membership conditional on the outcome. Formally, it is defined as:</p><formula xml:id="formula_3">P r(D = 1|Y = y, G = g) = P r(D = 1|Y = y, G = g ′ ), y ∈ {0, 1}.<label>(3)</label></formula><p>Here, P r(D = 1|Y = 1, G = g) represents the true positive rate among group g and P r(D = 1|Y = 0, G = g) represents the false positive rate among group g. Separation is also called error rate balance or equalized odds <ref type="bibr" target="#b8">(Chouldechova, 2017;</ref><ref type="bibr" target="#b19">Hardt et al., 2016)</ref>, and there are relaxed versions of separation, say satisfying equation <ref type="formula" target="#formula_3">3</ref>only with y = 1 (or y = 0) ( <ref type="bibr" target="#b4">Barocas et al., 2019)</ref>. Separation would treat people with the same outcomes similarly regardless of group membership. In our retention example, separation is satisfied when black students and white students have the same false positive rates.</p><p>Sufficiency requires that the outcome be independent of the group conditional on the algorithmic decision:</p><formula xml:id="formula_4">P r(Y = 1|D = d, G = g) = P r(Y = 1|D = d, G = g ′ ), d ∈ {0, 1}<label>(4)</label></formula><p>Here, P r(Y = 1|D = 1, G = g) represents the positive predictive value among group g and P r(Y = 1|D = 0, G = g) represents the false discovery rate among group g. For example, a retention algorithm will satisfy sufficiency when black and white students who are recommended retention are actually retained at the same rate. We also make some general remarks about existing fairness criteria in the literature. First, it is impossible to satisfy all the fairness notions simultaneously because some are inherently in conflict; see <ref type="bibr" target="#b8">Chouldechova (2017)</ref>, <ref type="bibr" target="#b5">Berk et al. (2021)</ref>, and <ref type="bibr" target="#b28">Kleinberg et al. (2017)</ref>. Second, there is no consensus as to what notion of fairness should be used in each context. Instead, researchers need to select fairness notion(s) that are the most appropriate in their own context <ref type="bibr" target="#b56">(Xu et al., 2022)</ref>.</p><p>3 Review: Differential Item Functioning DIF has been widely used to detect items that exhibit discriminatory bias in assessments <ref type="bibr" target="#b33">(Lim et al., 2022)</ref>. DIF refers to different functioning of items across different groups of examinees <ref type="bibr">(Holland &amp; Wainer, 1993)</ref>, and it typically means the difference in the probabilities of endorsing an item between groups conditional on ability <ref type="bibr" target="#b36">(Magis et al., 2010;</ref><ref type="bibr" target="#b43">Pine, 1977)</ref>, i.e.,</p><formula xml:id="formula_5">P r(Y = 1|θ, G = g) ̸ = P r(Y = 1|θ, G = g ′ ),<label>(5)</label></formula><p>Here, Y represents whether an examinee's response to the test item is correct (i.e., Y = 1) or incorrect (i.e., Y = 0); θ represents ability scores, and G represents group membership that consists of a focal group (i.e., G = g) and a reference group (i.e., G = g ′ ). In the DIF literature, the focal group represents the particular group of interest who is expected to be disadvantaged by the test, whereas the reference group represents the group who is expected to have an advantage <ref type="bibr">(Holland &amp; Wainer, 1993)</ref>. Typically, test developers investigate the presence of DIF to create a test where the performance of examinees is only affected by their abilities and not by other factors like examinees' demographics <ref type="bibr" target="#b0">(Ackerman, 1992)</ref>. They assume that if there exists DIF, the item discriminates the examinees mainly (or partially) based on their group membership <ref type="bibr">(Holland &amp; Wainer, 1993)</ref>. There are two common types of DIF: uniform DIF and nonuniform DIF <ref type="bibr" target="#b38">(Mellenbergh, 1982;</ref><ref type="bibr" target="#b51">Swaminathan &amp; Rogers, 1990)</ref>. A test item exhibits uniform DIF when the item is always more advantageous to one group (e.g., whites) than another group (e.g., blacks), showing a higher probability of correctly answering the item at any ability level. In contrast, a test item exhibits nonuniform DIF when the advantage in the item depends on ability level, and it often results in an interaction between ability and group membership.</p><p>A wide array of statistical methods have been developed to evaluate the presence and impact of DIF. They can be categorized into two streams depending on whether the methods rely on item response theory (IRT) or not <ref type="bibr" target="#b36">(Magis et al., 2010)</ref>. Non-IRT-based methods match examinees based on their test scores, and some of the most popular methods include the Mantel-Haenszel test <ref type="bibr" target="#b21">(Holland &amp; Thayer, 1986)</ref>, logistic regression <ref type="bibr" target="#b51">(Swaminathan &amp; Rogers, 1990)</ref>, and simultaneous item bias test <ref type="bibr" target="#b48">(Shealy &amp; Stout, 1993)</ref>. In contrast, IRT-based methods estimate examinees' latent ability, and some of the most popular methods include Lord's χ 2 <ref type="bibr" target="#b34">(Lord, 1980)</ref>, area measures <ref type="bibr" target="#b27">(Kim &amp; Cohen, 1991;</ref><ref type="bibr" target="#b46">Raju, 1988)</ref>, and most recently, residual-based DIF method <ref type="bibr" target="#b33">(Lim et al., 2022)</ref>.</p><p>To better illustrate our procedures in later sections, we review three DIF detection methods: the Mantel-Haenszel test, logistic regression, and residual-based DIF. First,the Mantel-Haenszel test is based on a contingency table where the rows of the table correspond to group membership (focal group G = g versus reference group G = g ′ ) and the columns correspond to correct (Y = 1) or incorrect (Y = 0) responses. After discretizating ability scores into K non-overlapping strata (k = 1, 2, . . . , K), the Mantel-Haenszel test computes the differences in the responses between the two groups at each k-th stratum of ability. Under the null hypothesis that the item is non-DIF, the Mantel-Haenszel test has a chi-squared null distribution with one degree of freedom, and if the test statistic exceeds a critical value based on the null distribution, an item exhibits DIF <ref type="bibr" target="#b21">(Holland &amp; Thayer, 1986;</ref><ref type="bibr" target="#b36">Magis et al., 2010)</ref>.</p><p>Second, the detection method based on logistic regression regresses the item response Y i on ability/test scores θ i , group membership G i , and their interaction (i.e., θ i G i ) <ref type="bibr" target="#b51">(Swaminathan &amp; Rogers, 1990</ref>) as:</p><formula xml:id="formula_6">logit(π i ) = β 0 + β 1 θ i + β 2 G i + β 3 θ i G i (6)</formula><p>where π i is the probability of getting the studied item correct. The term β 2 represents the main effect coefficient of G i , and the term β 3 represents the coefficient of the interaction effect between G i and θ i . The null hypothesis that the item is non-DIF (i.e., β 2 = 0 and β 3 = 0) is rejected if either β 2 or β 3 is significant through a likelihood ratio test. Unlike the Mantel-Haenszel test, the logistic regression can differentiate uniform DIF and nonuniform DIF by individually testing β 2 and β 3 via Wald or likelihood ratio tests. The item is uniform DIF if β 2 ̸ = 0 and β 3 = 0 and is nonuniform DIF if β 3 ̸ = 0 regardless of the value of β 2 . Finally, Lim et al. <ref type="formula">2022</ref>propose a residual-based DIF (RDIF) procedure to detect the presence of DIF by using an IRT model. Specifically, first, the residual-based DIF procedure fits an IRT model. 1 Second, it obtains examinee i's residuals from the estimated IRT model r i = Y i − Y i where Y i is the prediction from the fitted IRT model. Third, the residuals are used to compute three different statistics: RDIF R , RDIF S , and RDIF RS . The first DIF statistic RDIF R is the difference of mean raw residuals between the focal group and the reference group, and it follows asymptotically a normal distribution. RDIF R has (statistical) power to detect uniform DIF as <ref type="bibr" target="#b33">Lim et al. (2022)</ref> showed via the simulations. The second DIF statistic RDIF S is the difference of mean squared residuals between the two groups and also follows asymptotically a normal distribution. RDIF S has power to detect nonuniform DIF. The third DIF statistic RDIF RS is a weighted combination of the two test statistics RDIF R and RDIF S , and it follows asymptotically a chi-squared distribution with two degrees of freedom. RDIF RS is designed to detect any type of DIF <ref type="bibr" target="#b33">(Lim et al., 2022)</ref>; see <ref type="bibr" target="#b33">Lim et al. (2022)</ref> for more details. 4 Our Proposal: Differential Algorithmic Functioning</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Definitions</head><p>We propose a DAF framework to assess the fairness of algorithmic decision making by modifying the notion of DIF and its detection methods. Under the DAF framework, a fair algorithm should not make discriminatory decisions based on protected variables (e.g., gender, race/ethnicity) after accounting for fair attribute W , where W is some function of X, i.e. W = h(X), h : R px → R pw . The fair attribute W means a set of justifiable variables that are important and valid in decision making processes, and it can be continuous or discrete.</p><p>We define DAF as conditional dependence of algorithmic decision D and group membership G given fair attribute W . Following the DIF literature, we refer to the focal group (G = g) as the group anticipated to be disadvantaged by the algorithm and the reference group (G = g ′ ) as the group who is anticipated to have an advantage, though the designation does not affect a DAF analysis. Formally, DAF and non-DAF are written as:</p><formula xml:id="formula_7">DAF : P r(D = 1|W, G = g) ̸ = P r(D = 1|W, G = g ′ ),<label>(7)</label></formula><p>Non-DAF :</p><formula xml:id="formula_8">P r(D = 1|W, G = g) = P r(D = 1|W, G = g ′ ).<label>(8)</label></formula><p>In words, an algorithm exhibits DAF if the probability of receiving the treatment decision is different across groups after accounting for the fair attribute; otherwise, the algorithm is non-DAF. Our DAF notion does not pursue fairness of outcomes/results (i.e., the objective of statistical parity). Rather, it aims to highlight the fairness of the process with respect to decision allocations by treating individuals with the same fair attribute similarly. Also, the DAF notion is related to the negation of an existing fairness notion known as conditional statistical parity <ref type="bibr" target="#b11">(Corbett-Davies et al., 2017)</ref>. Specifically, DAF and conditional statistical parity are identical if legitimate risk factors for conditional statistical parity are the same as the fair attributes identified in DAF analysis. However, DAF provides a more detailed description of disparity patterns by defining different types of DAF; see <ref type="table" target="#tab_0">Table 1</ref>. Borrowing from the DIF literature (e.g., <ref type="bibr" target="#b18">Hanson, 1998)</ref>, we define two types of DAF, uniform DAF and nonuniform DAF. Uniform DAF exists when the statistical relationship between D and G is constant for all levels of W . For example, a statistical relationship between D and G can be expressed using odd ratios: ∆(W ) := P r(D=1|W,G=g)(1−P r(D=1|W,G=g ′ ))</p><p>(1−P r(D=1|W,G=g))P r(D=1|W,G=g ′ ) . In such a case, uniform DAF is defined to exist if ∆(W ) = c ̸ = 1 for every value of W where c is a constant but not equal to one; note that ∆(W ) = 1 achieves the conditional independence of D and G given W , i.e., non-DAF. In contrast, nonuniform DAF is DAF that is not uniform DAF; see <ref type="figure">Figure  1</ref> for illustrations based on simulated data. When an algorithm is uniform DAF, the algorithm is consistently more advantageous to one group than the other group by recommending more <ref type="figure">Figure 1</ref>: Illustrations of decision characteristic curves for the reference group (whites) and focal group (blacks) with different types of differential algorithmic functioning (DAF) favorable decisions to one group across the entire range of the fair attribute; that is, it shows static disparity with respect to decision allocations. In contrast, an algorithm is nonuniform DAF when the advantage for one group in the algorithm depends on the fair attribute. That is, a decision may favor one group within a certain range of the fair attribute, but may favor the other group within another range of the attribute. As shown in <ref type="figure">Figure 1</ref>, nonuniform DAF would have different steepness between the decision curves of the two groups and result in dynamic disparity in decision allocations. 2</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2">Methods</head><p>An important advantage of DAF is that it can be easily tested by borrowing existing test statistics in the DIF literature. To detect the presence of DAF in algorithms, we adopt the aforementioned methods for DIF: the Mantel-Haenszel test, logistic regression, and residualbased DIF. First, we use the Mantel-Haenszel test by discretizing the fair attribute into K strata (k = 1, 2, . . . , K) and creating a contingency table where the rows of the table correspond to group membership and the columns correspond to treatment decision (D = 1) or control decision (D = 0) for each k-th stratum of the fair attribute: </p><formula xml:id="formula_9">D = 1) Control Decision (D = 0) Focal (G = g) N g1k N g0k Reference (G = g ′ ) N g ′ 1k N g ′ 0k</formula><p>Here, N (••)k denotes observed cell frequencies within the k-th stratum of the fair attribute. For example, N g ′ 1k denotes the number of study units who have D = 1 in the reference group at the k-th stratum. Then, the Mantel-Haenszel test computes the differences in the decisions between the focal and reference groups at each k-th stratum of the fair attribute. Under the null hypothesis that the algorithm is non-DAF, the Mantel-Haenszel test for detecting DAF is:</p><formula xml:id="formula_10">χ 2 M H = | K k=1 N g ′ 1k − K k=1 E(N g ′ 1k )| − .5 2 K k=1 V (N g ′ 1k ) .<label>(9)</label></formula><p>Here, E(N g ′ 1k ) and V (N g ′ 1k ) represents the expectation and variance of N g ′ 1k . 3 If the test statistic exceeds a critical value based on the chi-squared null distribution (e.g., 3.84 for α = 0.05 and one degree of freedom), the algorithm has DAF. Second, the logistic regression procedure requires fitting the following model:</p><formula xml:id="formula_11">logit(e i ) = α 0 + α 1 W i + α 2 G i + α 3 W i G i ,<label>(10)</label></formula><p>where e i is the conditional probability of unit i's receiving the treatment decision given W and G. The term α 2 represents the effect of the group membership on the decision and α 3 represents the interaction effect between the fair attribute and group membership. We can detect the presence of DAF in a decision-making algorithm by testing the null hypothesis that the algorithm is non-DAF (i.e., α 2 = α 3 = 0) via a likelihood ratio test. We can also detect uniform DAF by testing the null hypothesis α 2 = 0, α 3 = 0 versus the alternative α 2 ̸ = 0, α 3 = 0, with a Wald 2 We note that the slight differences observed in the far left plot of non-DAF are due to sampling variability.</p><p>3</p><formula xml:id="formula_12">E(N g ′ 1k ) = (N g ′ 1k +N g ′ 0k )(N g ′ 1k +N g1k ) N k ; V (N g ′ 1k ) = (N g ′ 1k +N g ′ 0k )(N g ′ 1k +N g1k )(N g1k +N g0k )(N g ′ 0k +N g0k ) N 2 k (N k −1)</formula><p>. test or a likelihood ratio test. Furthermore, we can detect nonuniform DAF by testing the null hypothesis α 3 = 0 versus the alternative α 3 ̸ = 0. Third, we revise the existing residual-based DIF method <ref type="bibr" target="#b33">(Lim et al., 2022)</ref> to detect DAF. We replace the first step in residual-based DIF based on an IRT model with a more flexible, ensemble learning algorithm from machine learning and use the residuals from the ensemble learning algorithm in the subsequent steps. Note that an IRT model is not suitable in our setting because our outcomes of interest are not item responses. Algorithm 1 summarizes the steps of the residual-based DAF method. A bit more formally, in the first step, we estimate E[D|W ] via machine learning and in particular, the SuperLearner algorithm <ref type="bibr" target="#b52">(van der Laan et al., 2007)</ref> that combines predictions from different supervised learning models. We use a super learning algorithm because an ensemble estimator of functionals like E[D|W ] will perform at least as well as the best individual estimator in terms of the cross-validated error, thereby increasing the prediction performance <ref type="bibr" target="#b44">(Porter et al., 2011;</ref><ref type="bibr" target="#b50">Suk &amp; Kang, 2022;</ref><ref type="bibr" target="#b52">van der Laan et al., 2007)</ref>. Then, the proposed residual-based DAF method computes three statistics, RDAF R , RDAF S , and RDAF RS , which, similar to their RDIF counterparts in <ref type="bibr" target="#b33">Lim et al. (2022)</ref>, are able to detect different types of DAF. The three test statistics are written as:</p><formula xml:id="formula_13">RDAF R = N i=1 r i I(G i = g) N i=1 I(G i = g) − N i=1 r i I(G i = g ′ ) N i=1 I(G i = g ′ ) (11) RDAF S = N i=1 r 2 i I(G i = g) N i=1 I(G i = g) − N i=1 r 2 i I(G i = g ′ ) N i=1 I(G i = g ′ )<label>(12)</label></formula><formula xml:id="formula_14">RDAF RS = Q ′ Σ −1 Q (13) Here, r i represents an individual i's residual, i.e., r i = D i − D i .</formula><p>Q represents a 2 × 1 matrix that contains differences between the first two test statistics and their respective population means, i.e., Q =</p><formula xml:id="formula_15">RDAF R − µ R</formula><p>RDAF S − µ S , and Σ represents a 2 × 2 covariance matrix of RDAF R and RDAF S , i.e., Σ =</p><formula xml:id="formula_16">σ 2 R σ R,S σ R,S σ 2 S .</formula><p>Likewise, the first test statistic RDAF R follows asymptotically a normal distribution and is designed to detect uniform DAF. The second test statistic RDAF S follows asymptotically a normal distribution and is designed to detect nonuniform DAF. The third test statistic RDAF RS follows asymptotically a chi-squared distribution with two degrees of freedom and is designed to detect any type of DAF. The residual-based DAF method using software R (R Core Team, 2021) is available in the first author's GitHub repository. 4</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Algorithm 1 Residual-based differential algorithmic functioning (RDAF)</head><p>Input: Decision D i , fair attribute W i , and group membership G i 1: Fit a super learning algorithm 5 that regresses decision D i on fair attribute W i , and compute its prediction We summarize strengths and limitations of three methods to detect DAF; see also the results of our simulation study that investigated the Type-1 error and power rates of each method in Appendix A. Overall, the Mantel-Haenszel test is a non-parametric test that does not depend on a model and hence, has valid Type-1 error control irrespective of the potentially complex relationship between D, W , and G <ref type="bibr" target="#b49">(Sireci &amp; Rios, 2013)</ref>; note that the Type-1 error control does not depend on how the strata are defined so long as they are non-overlapping. But the use of the Mantel-Haenszel test requires discretization of the fair attribute, and it has low power to detect nonuniform DAF. In contrast, the tests based on logistic regression or residual-based DAF have power to detect different types of DAF (i.e., uniform and nonuniform DAF). However, for the tests based on logistic regression, the asymptotic distributions of these tests rely on the correctness of the logistic regression model, which if mis-specified, can lead to Type-1 error inflation. The residual-based DAF method can alleviate concerns for model mis-specification by using ensemble, super learning algorithms. But it is certainly not as simple as the tests based on logistic regression.</p><formula xml:id="formula_17">D i (i.e., D i = E[D i |W i ]) 2: Compute the residuals, r i = D i − D i . 3</formula><p>Lastly, we make a few remarks about DAF analysis. First, researchers must use subject matter knowledge to determine which variables are fair attributes. If, however, there is limited subject matter knowledge, researchers may resort to more data-driven measures to choose fair attributes, say those based on changes in R-squared, Gini index, or classification accuracy. Second, DAF, by definition, allows multi-dimensional fair attributes, and the DAF methods above can easily accommodate multiple fair attributes. For example, the Mantel-Haenszel test just needs to create strata (k = 1, 2, ..., K) that are non-overlapping based on the multiple fair attributes. The logistic regression and residual-based DAF approaches need to add multiple fair attributes as predictors in the models. Third, researchers can reduce the dimension of fair attributes using dimensionality reduction tools (e.g., factor analysis, principle component analysis) in particular when multiple fair attributes are highly correlated. As we will see below in Section 5, we use kindergarten year's test scores from the Early Childhood Longitudinal Study-Kindergarten cohort (ECLS-K) as fair attributes. Specifically, tests about math, reading, and general knowledge were conducted in the fall and spring of their kindergarten year, thus producing six test scores during the kindergarten year. To account for multicollinearity among the observed fair attributes, we used factor analysis <ref type="bibr" target="#b16">(Gorsuch, 1983;</ref><ref type="bibr" target="#b29">Lawley &amp; Maxwell, 1962)</ref> in our empirical example; see the next section. Fourth, our DAF detection methods can be applied to detect other notions of group fairness, such as separation (i.e., equalized odds). Specifically, by replacing the use of W as a conditioning variable with Y , the DAF methods can be used to evaluate whether an algorithm achieves separation or not.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Empirical Example: Retention in ECLS-K</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1">Data and Methods</head><p>Decisions to retain students in grade have historically been based on teachers' assessment or test-based assessment <ref type="bibr" target="#b23">(Huddleston, 2014)</ref>. But recent algorithmic decision making can be used to assist teachers' decision making processes. Grade retention is typically considered a last-resort option and recommended to students who make inadequate progress in academic achievement or show developmental immaturity <ref type="bibr" target="#b7">(Cannon &amp; Lipscomb, 2011;</ref><ref type="bibr" target="#b17">Greene &amp; Winters, 2006;</ref><ref type="bibr" target="#b24">Jackson, 1975)</ref>. Prior research found that there are disparities in grade retention where retention has been skewed towards male, ethnic minority, or low-income students <ref type="bibr" target="#b23">(Huddleston, 2014;</ref><ref type="bibr" target="#b55">Xia &amp; Kirby, 2009)</ref>. Given these existing disparities in retention, it is of paramount importance to consider a fairness constraint in a new algorithm for grade retention. We consider DAF as our fairness notion of interest to ensure fairness of the process in algorithmic decision making.</p><p>Specifically, we used the ECLS-K data for a retention decision-making algorithm. ECLS-K, sponsored by the National Center for Education Statistics, is a national longitudinal study to examine the school achievement and student experiences from kindergarten to middle school. ECLS-K selected a nationally representative sample of kindergarteners in the fall of 1998 and followed them until the spring of 2007 <ref type="bibr" target="#b53">(Walston &amp; McCarroll, 2010)</ref>. For data analysis, we used the data collected in the fall and the spring of the kindergarten year (i.e., the fall in 1998 and the spring in 1999) to obtain covariates. We also used the data collected in the spring of 2000 when most of the students were in the first grade to find whether a student was actually retained or not, which is our outcome of interest. Our analytic sample included 11,532 students that allowed for kindergarten retention.</p><p>We selected 60 covariates (i.e., V ) that are expected to affect whether a student is retained or promoted to design a decision-making algorithm for retention based on prior works <ref type="bibr" target="#b7">(Cannon &amp; Lipscomb, 2011;</ref><ref type="bibr" target="#b17">Greene &amp; Winters, 2006;</ref><ref type="bibr" target="#b22">Hong &amp; Raudenbush, 2006;</ref><ref type="bibr" target="#b24">Jackson, 1975)</ref>; see Appendix B for a list of covariates used in our data analysis. Among them, protected variables included gender (GENDER), race (RACE), ethnicity (WKHISP), and poverty (W1POVRTY), and fair attributes included prior achievement scores in math, reading, and general knowledge, all collected in the kindergarten year (C1RSCALE, C1MSCALE, C1GSCALE, C2RSCALE, C2MSCALE, and C2GSCALE). We summarized the fairness attributes into one variable by using factor analysis to account for multicollinearity and make it easier to demonstrate our DAF framework. This was also done as grade retention should be based on a student's general ability, rather than their performance in a specific subject. Specifically, we conducted the factor analysis using maximum likelihood estimation. The factor scores were used in their original form for the logistic regression and residual-based DAF methods, whereas for the Mantel-Haenszel test, they were categorized into 20 non-overlapping categories based on quantiles. Note that we imputed any missing values in the covariates with predictive mean matching <ref type="bibr" target="#b54">(White et al., 2011)</ref>.</p><p>To develop a retention algorithm, we fitted random forests <ref type="bibr" target="#b6">(Breiman, 2001)</ref> with 60 covariates as predictors and actual retention status Y i as the outcome of interest. Then, we used unit i's prediction P i to make a decision, i.e., whether to give retention or not. To account for the small number of retained students reported in prior works (e.g., <ref type="bibr" target="#b22">Hong &amp; Raudenbush, 2006;</ref><ref type="bibr" target="#b58">Zill et al., 1997)</ref> and in our sample, we considered a wide range of threshold values below 0.5 in our analysis to assess which threshold value would exhibit DAF in algorithmic decision making. In particular, we used a set of threshold values, ranging from 0.25 to 0.50 with an increment of 0.05. For example, based on a threshold value of 0.25, our decision is made as: D i = I(P i ≥ 0.25). Then, we assessed the presence of DAF in each working algorithm using three DAF detection methods (i.e., Mantel-Haenszel test, logistic regression, and residual-based DAF) regarding the four protected variables. Our three DAF methods have total seven test statistics: one from the Mantel-Haenszel test (denoted as MH), three from logistic regression, and three from residual-based DAF. The logistic regression procedure in (10) include the following three statistics: Wald statistic for α 2 (denoted as LR α 2 ), Wald statistic for α 3 (denoted as LR α 3 ), and likelihood ratio test statistic for α 2 and α 3 (denoted as LR α 2 ,α 3 ). The residual-based DAF method has three RDAF statistics: RDAF R , RDAF S , and RDAF RS . As a comparison, we considered the statistical parity notion to assess a marginal difference in decision proportions where a two proportion Z-test is conducted (denoted as Z-test).</p><p>As for software, we used the R package randomForest <ref type="bibr" target="#b32">(Liaw &amp; Wiener, 2002)</ref> for developing a random-forests-based algorithm, the R package psych <ref type="bibr" target="#b47">(Revelle, 2021)</ref> for factor analysis, and the R package mice (van Buuren &amp; Groothuis-Oudshoorn, 2011) for predictive mean matching.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Results</head><p>We include the results of DAF analysis with four protected variables: gender, race, ethnicity, and poverty. <ref type="figure" target="#fig_0">Figure 2</ref> summarizes the p-values of three detection methods for DAF and one detection method (i.e., a two proportion Z-test) for statistical parity, with different threshold values. Each row of <ref type="figure" target="#fig_0">Figure 2</ref> represents protected variables of interest, and the x-axis within each subplot varies the threshold values used in algorithmic decision making. The red dashed line indicates the p-value of 0.05. If the p-value is below 0.05, there is sufficient evidence of DAF for DAF detection methods (or the marginal difference in decision proportions for statistical parity). As seen from <ref type="figure" target="#fig_0">Figure 2</ref>, the statistical parity notion that seeks fairness of overall outcomes/results is not satisfied for all combinations of the threshold values and different protected variables. This means that there is the marginal difference in the proportions of retention decisions between the focal group and the reference group within each protected variable. But satisfying statistical parity is not of much interest in designing this retention algorithm, and as mentioned before, we aim to make the working algorithm DAF-free.</p><p>DAF results depend on the threshold values, protected variables, and DAF detection methods. All the DAF detection methods detect DAF if the threshold value is less than or equal to 0.40 except for the Mantel-Haenszel test and logistic regression with the poverty variable. More specifically, logistic regression and residual-based DAF methods detect the presence of nonuniform DAF with respect to gender, race, and ethnicity if the threshold value is below or at 0.4; see the results of LR α 3 and RDAF RS . Regarding the poverty level, the residual-based DAF detects the presence of nonuniform DAF if the threshold value is below 0.4, whereas logistic regression does not detect any type of DAF across different threshold values. This difference may be partly due to different power rates of detecting nonuniform DAF between two methods.</p><p>Furthermore, we investigated the decision characteristic curves from logistic regression to better understand the presence of DAF between the threshold value of 0.25 (Decision 0.25 ) and 0.45 (Decision 0.45 ). <ref type="figure" target="#fig_1">Figure 3</ref> visualizes the decision characteristic curves from logistic regression. Note that omitting the fair attribute of above 2.3 permitted clearer comparison of the logistic regression curves. Regarding gender, race, and ethnicity, the line for the reference group (in gray) does not agree with the line for the focal group (in black) at the threshold value of 0.25. That is, DAF exists, and in particular, nonuniform DAF is clearly shown for the gender variable. But in <ref type="figure" target="#fig_1">Figure 3</ref> there seems no DAF in the poverty level at the threshold value of 0.25, which is confirmed from <ref type="figure" target="#fig_0">Figure 2</ref> with the logistic regression procedure. At the threshold value of 0.45, the two curves in each subplot generally agree with each other (i.e., show non-DAF), though we observe a somewhat departure at the low extreme for race and poverty. Based on all our findings, we conclude that the working algorithm exhibits nonuniform DAF at some threshold values, and using a threshold of above 0.4 can make it DAF-free.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Discussion and Conclusions</head><p>This paper presents a novel framework for evaluating fairness in algorithmic decision making, referred to as DAF. The framework is based on DIF and places emphasis on the fairness of the decision-making process rather than the fairness of the outcomes or results by considering a fair attribute. We define DAF as conditional dependence of algorithmic decision D and group membership G given fair attribute W . Compared to other fairness notions, one of the key innovations of this framework is the ability to distinguish between two subtypes of DAF: uniform DAF and nonuniform DAF. This distinction is made by examining disparities in decision allocations, where uniform DAF exhibits static disparity and nonuniform DAF shows dynamic disparity. This differentiation is crucial as it helps in understanding the underlying disparity mechanisms of algorithms over fair attributes, the impact of unfair bias, and the connection to other fairness concepts such as statistical parity. Moreover, to detect the presence of DAF, we provide three different DAF detection methods: Mantel-Haenszel test, logistic regression, and residual-based DAF. Unlike the Mantel-Haenszel test, logistic regression and residual-based DAF are capable of distinguishing between uniform DAF and nonuniform DAF. The effectiveness of the DAF framework is demonstrated through an application to assess the presence of DAF in an algorithm for grade retention.</p><p>Tradeoffs between different fairness notions may be inherent because they fulfill different objectives and are often in conflict. As mentioned above, when comparing statistical parity with DAF, the statistical parity notion pursues the long-term goal of fairness in outcomes or results from algorithms, whereas the DAF notion underscores the fairness in the process of algorithmic decision making by incorporating the fair attribute. Obviously, satisfying the outcome equity via the statistical parity notion does not guarantee satisfying process fairness via the DAF notion (as can be inferred from our simulation study in Appendix A). Therefore, researchers should prioritize a fairness notion that is of most importance depending on their contexts.</p><p>While satisfying a particular notion of fairness restricts a set of decision rules in algorithmic decision making, multiple rules may satisfy the given fairness notion. Thus, researchers have to determine which rule is optimal among those satisfying the fairness constraint. In general, one seeks to maximize a certain notion of the prediction performance (e.g., accuracy, area under curve, F1 score) or utility (i.e., a function of the benefit and cost) in designing an algorithm and thus, they can choose an optimal decision rule by accounting for metrics on both fairness and prediction performance (or utility). Also, researchers should avoid designing a fair but ineffective algorithm which is of little use in practice. A working algorithm, despite achieving the fairness, can still give poor results when evaluated against prediction performance or utility metrics.</p><p>In choosing a decision rule, a single threshold value might not be a solution to ensure that an algorithm is fair. In this case, researchers may consider setting different thresholds for different groups as in prior works (e.g., <ref type="bibr" target="#b11">Corbett-Davies et al., 2017;</ref><ref type="bibr" target="#b30">Lee &amp; Kizilcec, 2020)</ref>. However, under the DAF framework, using group-specific thresholds may not be justifiable if using group-specific thresholds decreases the perceived fairness of the decision-making process. That is, if individuals who receive decisions view the algorithmic decision-making process unfavorably due to the use of group-specific thresholds, it would go against the objective of DAF notion. Also, it should be noted that using group-specific threshold values is at odds with other fairness criteria such as anti-classification (Corbett-Davies &amp; Goel, 2018) because the decision rule depends on protected group membership.</p><p>Based on all the findings of this paper, we provide some suggestions for future research concerning our proposed DAF framework. First, we did not consider intersectionality, i.e., systematic disadvantages along intersecting dimensions, which contain not only gender, but also race, ethnicity, or disability status <ref type="bibr" target="#b15">(Foulds et al., 2020)</ref>. Further research will investigate how to consider intersectionality in DAF analysis. Second, while we briefly discussed an optimal decision rule above, we did not formalize how to choose the optimal decision. Future research will examine how to choose an optimal decision rule by considering tradeoffs between DAF and prediction performance or utility metrics. Third, among many other DIF methods, we utilize three DIF methods for DAF analysis. Future research would examine how to modify other DIF methods like simultaneous item bias test <ref type="bibr" target="#b48">(Shealy &amp; Stout, 1993)</ref> for DAF analysis and evaluate their Type-1 error and power. Fourth, we only used the conditional independence tests within the DIF literature and did not consider other statistical methods proposed elsewhere (e.g., <ref type="bibr" target="#b3">Azadkia &amp; Chatterjee, 2021;</ref><ref type="bibr" target="#b41">Neykov et al., 2021)</ref>. Future work could consider these alternative methods. Fifth, DIF is a necessary but not sufficient condition for bias and fairness <ref type="bibr" target="#b1">(Angoff, 1993)</ref>. Likewise, algorithms flagged as DAF only have the potential to be unfair. A holistic approach spanning technical and non-technical solutions would be required to scrutinize fairness-related biases inside algorithms, such as <ref type="bibr" target="#b40">Mulligan et al. (2019)</ref>'s fairness analytic and <ref type="bibr" target="#b35">Madaio et al. (2020)</ref>'s co-designed checklist for AI fairness. Sixth, we applied an imputation technique to handle missing values in the covariates in the nationally representative ECLS-K data. This imputation may have introduced unwanted bias if the imputed values reinforced any unfair dependencies between the protected attributes, fair attributes, and decisions. Thus, future studies would examine solutions to handle missing data when evaluating fairness in algorithmic decision making. Lastly, in the literature from industrial and organizational (I/O) psychology, ethical decision making is one of the most important research areas (e.g., <ref type="bibr" target="#b25">Jarrahi, 2018;</ref><ref type="bibr" target="#b26">Jones, 1991;</ref><ref type="bibr" target="#b31">Lefkowitz, 2017)</ref>. Future research would enrich our findings on algorithmic fairness by identifying biases in decision making from the I/O psychology literature and borrowing associated methodology.</p><p>While no one-size-fits-all definition suits all systems and contexts, our DAF framework highlights the fairness of decision allocations and provides insights on different patterns of decision disparities from the lens of psychometric testing. We believe that our DAF framework will serve as a useful tool to assess fairness in algorithmic decision making and can be a meaningful starting point that connects the concept of test fairness and algorithmic fairness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Simulation Study</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.1 Designs and Evaluation</head><p>We conduct simulation studies to assess the performance of three DAF methods with total seven test statistics: one from the Mantel-Haenszel test (denoted as MH), three from logistic regression, and three from residual-based DAF. For the logistic regression procedure in (10), we use the following three statistics: Wald statistic for α 2 (denoted as LR α 2 ), Wald statistic for α 3 (denoted as LR α 3 ), and likelihood ratio test statistic for α 2 and α 3 (denoted as LR α 2 ,α 3 ). For the residual-based DAF method, we use three RDAF statistics: RDAF R , RDAF S , and RDAF RS . As a comparison, we include the statistical parity metric where a test statistic is based on a two proportion Z-test that compares two independent population proportions (denoted as Z-test).</p><p>Our simulation study is categorized into four designs; see <ref type="figure">Figure 4</ref> for illustrations of our simulation designs. Design 1 assumes a non-DAF case where α 2 = 0 and α 3 = 0 in equation (10). Design 2 assumes a uniform DAF case where α 2 ̸ = 0 and α 3 = 0. Design 3 assumes a "balanced" nonuniform DAF case where the group advantage is balanced across the fair attribute, i.e., α 2 = 0 and α 3 ̸ = 0. Design 4 assumes a "unbalanced" nonuniform DAF case where the group advantage is not balanced across the fair attribute i.e., α 2 ̸ = 0 and α 3 ̸ = 0. Specifically, we set α 2 and α 3 to be 0.4 if they are not equal to zero. For each design, we varied the measurement scale of the fair attribute with three different levels: a continuous scale, a discrete scale with 15 unique values, and a discrete scale with 5 unique values. We did this to consider that a fair attribute may not be measured on the continuous scale. Also, for the three scale levels, we formed 20, 9, and 5 intervals in the Mantel-Haenszel procedure, respectively. As for the sample size, we used the fixed value of 2,000 that consists of 1,000 in the focal group and 1,000 in the reference group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4: Simulation Designs</head><p>For all the designs, we examined the performance of DAF methods by repeating the simulation 1,000 times, and we evaluated the performance of each method by measuring average detection rates ( I(P-value ≤ 0.05)/1, 000). A DAF test statistic that is significant at the 5% alpha level indicates evidence of DAF, and a test statistic for statistical parity is significant at the 5% alpha level indicates evidence of the marginal difference in decisions. Specifically, the average detection rates indicate the power rates if a test statistic is designed for detecting a particular type of DAF (or marginal difference for statistical parity); otherwise, they indicate Type-1 error rates. <ref type="table" target="#tab_3">Table 3</ref> summarizes the average detection rates under Designs 1, 2, 3, and 4. If the average detection rates can be interpreted as Type-1 error, we highlight them in gray in the table. Under Design 1 that assumes non-DAF, the performances of all DAF detection methods-the Mantel-Haenszel test, logistic regression, and residual-based DAF-are similar across different measurement scales of the fair attribute, and they show very low detection rates of DAF, i.e., well controlled Type 1 error rates (.¡07). The statistical parity test (i.e., Z test), which focuses on a marginal difference in decision between groups, also shows very low detection rates under this design.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A.2 Results</head><p>Design 2 assumes uniform DAF, and in this design, all the DAF methods generally perform as expected. DAF test statistics that specialize in detecting uniform DAF or any type of DAF show high detection rates (i.e., ¿.9 power rates) across measurement scales of the fair attribute. When we focus on logistic regression and residual-based DAF methods, test statistics for detecting uniform DAF (i.e., LR α 2 and RDAF R ) show slightly higher power rates than test statistics for detecting any type of DAF (i.e., LR α 2 ,α 3 and RDAF RS ). In contrast, test statistics for detecting nonuniform DAF (i.e., LR α 3 and RDAF S ) show low detection rates, which are desirable, but RDAF S shows somewhat over-estimated Type-1 error rates. The statistical parity test shows high detection rates of the marginal difference, but its power rates are smaller than those from any DAF methods.</p><p>For Design 3 with balanced unnonuniform DAF, logistic regression and residual-based DAF methods perform well; the test statistics that specialize in detecting nonuniform DAF (i.e., LR α 3 and RDAF S ) show large power rates (¿.8) regardless of the measurement scales, and have higher power rates than the test statistics for detecting any type of DAF (i.e., LR α 2 ,α 3 and RDAF RS ). Also, the test statistics for detecting uniform DAF (i.e., LR α 2 and RDAF R ) show well-controlled Type-1 error rates. However, the Mantel-Haenszel statistics fail to detect nonuniform DAF. This is because the Mantel-Haenszel procedure is not able to detect DAF in particular when the group advantage is cancelled out across the levels of the fair attribute. Also, the statistical parity test shows very low retention rates because no marginal difference is expected under the balanced nonuniform design. Our last design of Design 4 assumes unbalanced nonuniform DAF, and under this design, all the average detection rates are high, ranging from 88.1% to 99.5%. We also find that RDAF S shows high power rates than LR α 3 , and DAF methods generally higher power rates compared to the statistical parity test.</p><p>Overall, the logistic regression and residual-based DAF methods perform well by detecting both uniform DAF and nonuniform DAF. Using the Mantel-Haenszel procedure may not be desirable when balanced nonuniform DAF exhibits where the group advantage is cancelled out over the levels of the fair attribute. We also find that satisfying statistical parity does not guarantee achieving DAF-free; specifically, the statistical parity is met even when DAF (in particular, balanced uniform DAF) is present. Note. MH = Mantel-Haenszel, LR = logistic regression, and RDAF = residual-based differential algorithmic functioning (DAF) statistics. The average detection rates are interpreted as power rates when test statistics are designed for detecting a particular type of DAF (or a marginal difference); otherwise, they are interpreted as Type-1 error (highlighted in gray in the table). The true effect size for α on odds ratio scale is 1.49.</p><p>56 Spring, K principal report of school being successful in providing help to low achievers S2SUCC7 57 Spring, K principal report of raising performance level of low-achieving students influencing evaluation of principal performance S2PRFLVL 58 Spring, K principal report of teacher and staff support influencing evaluation of principal performance S2STFSPP 59 Spring, K school safety rating K2Q3 60 Spring, K school with decorated hallways K2Q6 A</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 :</head><label>2</label><figDesc>P-values of fairness measures about differential algorithmic functioning (DAF) and statistical parity with four protected variables: gender, race, ethnicity, and poverty. For DAF detection methods, p-values below 0.05 provide sufficient evidence of DAF, whereas p-values of 0.05 or above do not provide sufficient evidence.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 3 :</head><label>3</label><figDesc>Decision characteristic curves from logistic regression between the threshold value of 0.25 (Decision 0.25 ) and of 0.45 (Decision 0.45 ) with four protected variables: gender, race, ethnicity, and poverty.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 :</head><label>1</label><figDesc>Types of Differential Algorithmic Functioning (DAF)</figDesc><table><row><cell>Type</cell><cell>Definition</cell><cell>Allocation Pattern</cell></row><row><cell>Uniform DAF</cell><cell>The statistical relationship (e.g., odd ratios)</cell><cell>Static disparity</cell></row><row><cell></cell><cell>between D and G is constant for all levels of W .</cell><cell></cell></row><row><cell cols="2">Nonuniform DAF if it is not uniform DAF, but is still DAF</cell><cell>Dynamic disparity</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2 :</head><label>2</label><figDesc>A Contingency Table by Group Membership G and Algorithmic Decision D Within the k-th Stratum of Fair Attribute W</figDesc><table><row><cell>Treatment Decision (</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>: Compute the three test statistics RDAF R , RDAF S , and RDAF RS and their p-values. Output: RDAF R , RDAF S , RDAF RS , and p-values.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 3 :</head><label>3</label><figDesc>Average detection rates under Designs 1, 2, 3, and 4</figDesc><table><row><cell>Continuous</cell><cell>Discrete: 15</cell><cell>Discrete: 5</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">An IRT model for the residual-based DIF procedure is a three-parameter model and formalized as:P (Y i = 1; θ i ) = c + 1−c 1+exp(−a(θi−b)). The parameter θ i represents examinee i's ability parameter. The item parameters a, b, and c represent the item discrimination, difficulty/location, and pseudo guessing parameters, respectively.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">https://github.com/youmisuk/DAF 5 We include generalized linear models, random forests, and neural network, as default individual estimators for our residual-based DAF approach. If we only select a generalized linear model as an individual estimator insides the super learning method, the predictions are made based solely on the parametric model.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors thank Dan Bolt for his valuable feedback on the manuscript. This research was partly funded by the National Science Foundation under Grant No. 2225321. The opinions, findings, conclusions, or recommendations expressed in this work are solely those of the authors and do not necessarily reflect the views of the National Science Foundation.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>B A list of Covariates</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A didactic explanation of item bias, item impact, and item validity from a multidimensional perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Ackerman</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1745-3984.1992.tb00368.x</idno>
		<ptr target="https://doi.org/10.1111/j.1745-3984.1992.tb00368.x" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="67" to="91" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Perspectives on differential item functioning methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Angoff</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Differential item functioning</title>
		<editor>P. W. Holland &amp; H. Wainer</editor>
		<imprint>
			<date type="published" when="1993" />
			<biblScope unit="page" from="3" to="24" />
		</imprint>
	</monogr>
	<note>Routledge</note>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">The evaluation of differences in test performance of two or more groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Angoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">T</forename><surname>Sharon</surname></persName>
		</author>
		<idno type="DOI">10.1177/001316447403400408</idno>
		<ptr target="https://doi.org/10.1177/001316447403400408" />
	</analytic>
	<monogr>
		<title level="j">Educational and Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="807" to="816" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">A simple measure of conditional dependence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Azadkia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chatterjee</surname></persName>
		</author>
		<idno type="DOI">10.1214/21-aos2073</idno>
		<ptr target="https://doi.org/10.1214/21-aos2073" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="3070" to="3102" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Fairness and machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanan</surname></persName>
		</author>
		<ptr target="http://www.fairmlbook.org" />
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Fairness in criminal justice risk assessments: The state of the art</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Berk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Heidari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jabbari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kearns</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1177/0049124118782533</idno>
		<ptr target="https://doi.org/10.1177/0049124118782533" />
	</analytic>
	<monogr>
		<title level="j">Sociological Methods &amp; Research</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="3" to="44" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Random forests</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Breiman</surname></persName>
		</author>
		<idno type="DOI">10.1023/a:1010933404324</idno>
		<ptr target="https://doi.org/10.1023/a:1010933404324" />
	</analytic>
	<monogr>
		<title level="m">Machine Learning</title>
		<imprint>
			<date type="published" when="2001" />
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page" from="5" to="32" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Early grade retention and student success: Evidence from Los Angeles</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Cannon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lipscomb</surname></persName>
		</author>
		<ptr target="http://www.ppic.org/main/publication.asp?i=910" />
		<imprint>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
	<note>Public Policy Institute of California</note>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Fair prediction with disparate impact: A study of bias in recidivism prediction instruments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chouldechova</surname></persName>
		</author>
		<idno type="DOI">10.1089/big.2016.0047</idno>
		<ptr target="https://doi.org/10.1089/big.2016.0047" />
	</analytic>
	<monogr>
		<title level="j">Big Data</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="153" to="163" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">An investigation of item bias. Educational and Psychological Measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Cleary</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Hilton</surname></persName>
		</author>
		<idno type="DOI">10.1177/001316446802800106</idno>
		<ptr target="https://doi.org/10.1177/001316446802800106" />
		<imprint>
			<date type="published" when="1968" />
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="61" to="75" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<title level="m" type="main">The measure and mismeasure of fairness: A critical review of fair machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Corbett-Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goel</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.1808.00023</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.1808.00023" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Algorithmic decision making and the cost of fairness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Corbett-Davies</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Pierson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Feller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Goel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Huq</surname></persName>
		</author>
		<idno type="DOI">10.1145/3097983.3098095</idno>
		<ptr target="https://doi.org/10.1145/3097983.3098095" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 23rd ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page" from="797" to="806" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title level="m" type="main">Introduction to classical and modern test theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Crocker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Algina</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
			<publisher>ERIC</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fairness through awareness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Dwork</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pitassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Reingold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zemel</surname></persName>
		</author>
		<idno type="DOI">10.1145/2090236.2090255</idno>
		<ptr target="https://doi.org/10.1145/2090236.2090255" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 3rd innovations in theoretical computer science conference</title>
		<meeting>the 3rd innovations in theoretical computer science conference</meeting>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="page" from="214" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Certifying and removing disparate impact</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Friedler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Moeller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Scheidegger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venkatasubramanian</surname></persName>
		</author>
		<idno type="DOI">10.1145/2783258.2783311</idno>
		<ptr target="https://doi.org/10.1145/2783258.2783311" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 21th ACM SIGKDD international conference on knowledge discovery and data mining</title>
		<meeting>the 21th ACM SIGKDD international conference on knowledge discovery and data mining</meeting>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="259" to="268" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">An intersectional definition of fairness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Foulds</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Islam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">N</forename><surname>Keya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Pan</surname></persName>
		</author>
		<idno type="DOI">10.1109/icde48307.2020.00203</idno>
		<ptr target="https://doi.org/10.1109/icde48307.2020.00203" />
	</analytic>
	<monogr>
		<title level="m">IEEE 36th International Conference on Data Engineering (ICDE)</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1918" to="1921" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title level="m" type="main">Factor analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Gorsuch</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1983" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Getting ahead by staying behind: An evaluation of florida&apos;s program to end social promotion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Greene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Winters</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Education Next</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="65" to="70" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Uniform DIF and DIF defined by differences in item response functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Hanson</surname></persName>
		</author>
		<idno type="DOI">10.2307/1165247</idno>
		<ptr target="https://doi.org/10.2307/1165247" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational and Behavioral Statistics</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="244" to="253" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Equality of opportunity in supervised learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Srebro</surname></persName>
		</author>
		<ptr target="https://proceedings.neurips.cc/paper/2016/file/9d2682367c3935defcb1f9e247a97c0d-Paper.pdf" />
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<editor>D. Lee, M. Sugiyama, U. Luxburg, I. Guyon, &amp; R. Garnett</editor>
		<imprint>
			<publisher>Curran Associates, Inc</publisher>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Differential item functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<idno type="DOI">10.4324/9780203357811</idno>
		<ptr target="https://doi.org/10.4324/9780203357811" />
		<editor>Wainer, H.</editor>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Differential item functioning and the mantel-haenszel procedure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Holland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">T</forename><surname>Thayer</surname></persName>
		</author>
		<idno type="DOI">10.1002/j.2330-8516.1986.tb00186.x</idno>
		<idno>i-24</idno>
		<ptr target="https://doi.org/10.1002/j.2330-8516.1986.tb00186.x" />
	</analytic>
	<monogr>
		<title level="j">ETS Research Report Series</title>
		<imprint>
			<biblScope unit="issue">2</biblScope>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Evaluating kindergarten retention policy: A case study of causal inference for multilevel observational data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Raudenbush</surname></persName>
		</author>
		<idno type="DOI">10.1198/016214506000000447</idno>
		<ptr target="https://doi.org/10.1198/016214506000000447" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Statistical Association</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">475</biblScope>
			<biblScope unit="page" from="901" to="910" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Achievement at whose expense? a literature review of test-based grade retention policies in US schools. Education Policy Analysis Archives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">P</forename><surname>Huddleston</surname></persName>
		</author>
		<idno type="DOI">10.14507/epaa.v22n18.2014</idno>
		<ptr target="https://doi.org/10.14507/epaa.v22n18.2014" />
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="1" to="31" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The research evidence on the effects of grade retention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">B</forename><surname>Jackson</surname></persName>
		</author>
		<idno type="DOI">10.3102/00346543045004613</idno>
		<ptr target="https://doi.org/10.3102/00346543045004613" />
	</analytic>
	<monogr>
		<title level="j">Review of Educational Research</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="613" to="635" />
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Artificial intelligence and the future of work: Human-ai symbiosis in organizational decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">H</forename><surname>Jarrahi</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.bushor.2018.03.007</idno>
		<ptr target="https://doi.org/10.1016/j.bushor.2018.03.007" />
	</analytic>
	<monogr>
		<title level="j">Business Horizons</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="577" to="586" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Ethical decision making by individuals in organizations: An issue-contingent model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.5465/amr.1991.4278958</idno>
		<ptr target="https://doi.org/10.5465/amr.1991.4278958" />
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="366" to="395" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A comparison of two area measures for detecting differential item functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S.-H</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Cohen</surname></persName>
		</author>
		<idno type="DOI">10.1177/014662169101500307</idno>
		<ptr target="https://doi.org/10.1177/014662169101500307" />
	</analytic>
	<monogr>
		<title level="j">Applied Psychological Measurement</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="269" to="278" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Inherent trade-offs in the fair determination of risk scores</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kleinberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raghavan</surname></persName>
		</author>
		<idno type="DOI">10.4230/LIPIcs.ITCS.2017.43</idno>
		<ptr target="https://doi.org/10.4230/LIPIcs.ITCS.2017.43" />
	</analytic>
	<monogr>
		<title level="m">8th innovations in theoretical computer science conference</title>
		<editor>C. H. Papadimitriou</editor>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="1" to="43" />
		</imprint>
	</monogr>
	<note>:23). Schloss Dagstuhl-Leibniz-Zentrum fuer Informatik</note>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Factor analysis as a statistical method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">N</forename><surname>Lawley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Maxwell</surname></persName>
		</author>
		<idno type="DOI">10.2307/2986915</idno>
		<ptr target="https://doi.org/10.2307/2986915" />
	</analytic>
	<monogr>
		<title level="j">Journal of the Royal Statistical Society. Series D (The Statistician)</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="209" to="229" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Evaluation of fairness trade-offs in predicting student success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Kizilcec</surname></persName>
		</author>
		<idno type="DOI">10.48550/ARXIV.2007.00088</idno>
		<ptr target="https://doi.org/10.48550/ARXIV.2007.00088" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Ethics and values in industrial-organizational psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lefkowitz</surname></persName>
		</author>
		<idno type="DOI">10.4324/9781315628721</idno>
		<ptr target="https://doi.org/10.4324/9781315628721" />
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Classification and regression by randomForest</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Liaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Wiener</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/doc/Rnews/" />
	</analytic>
	<monogr>
		<title level="j">R News</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="18" to="22" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">A residual-based differential item functioning detection framework in item response theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">M</forename><surname>Choe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Han</surname></persName>
		</author>
		<idno type="DOI">10.1111/jedm.12313</idno>
		<ptr target="https://doi.org/10.1111/jedm.12313" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<imprint>
			<biblScope unit="volume">59</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="80" to="104" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title level="m" type="main">Applications of item response theory to practical testing problems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Lord</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1980" />
			<publisher>Lawrence Erlbaum Associates</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Co-designing checklists to understand organizational challenges and opportunities around fairness in ai</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Madaio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wortman Vaughan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wallach</surname></persName>
		</author>
		<ptr target="http://www.jennwv.com/papers/checklists.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2020 CHI Conference on Human Factors in Computing Systems</title>
		<meeting>the 2020 CHI Conference on Human Factors in Computing Systems</meeting>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="1" to="14" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">A general framework and an r package for the detection of dichotomous differential item functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Magis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Béland</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Tuerlinckx</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Boeck</surname></persName>
		</author>
		<idno type="DOI">10.3758/brm.42.3.847</idno>
		<ptr target="https://doi.org/10.3758/brm.42.3.847" />
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="847" to="862" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">A survey on bias and fairness in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3457607</idno>
		<ptr target="https://doi.org/10.1145/3457607" />
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="volume">54</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1" to="35" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Contingency table models for assessing item bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">J</forename><surname>Mellenbergh</surname></persName>
		</author>
		<idno type="DOI">10.2307/1164960</idno>
		<ptr target="https://doi.org/10.2307/1164960" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Statistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="105" to="118" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Algorithmic fairness: Choices, assumptions, and definitions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mitchell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Potash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Barocas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>D'amour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lum</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-statistics-042720-125902</idno>
		<ptr target="https://doi.org/10.1146/annurev-statistics-042720-125902" />
	</analytic>
	<monogr>
		<title level="j">Annual Review of Statistics and Its Application</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="141" to="163" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">This thing called fairness: Disciplinary confusion realizing a value in technology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Mulligan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Kroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Kohli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">Y</forename><surname>Wong</surname></persName>
		</author>
		<idno type="DOI">10.1145/3359221</idno>
		<ptr target="https://doi.org/10.1145/3359221" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="36" />
			<date type="published" when="2019" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Minimax optimal conditional independence testing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Neykov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Balakrishnan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Wasserman</surname></persName>
		</author>
		<idno type="DOI">10.1214/20-aos2030</idno>
		<ptr target="https://doi.org/10.1214/20-aos2030" />
	</analytic>
	<monogr>
		<title level="j">The Annals of Statistics</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="2151" to="2177" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A review on fairness in machine learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pessach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Shmueli</surname></persName>
		</author>
		<idno type="DOI">10.1145/3494672</idno>
		<ptr target="https://doi.org/10.1145/3494672" />
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys (CSUR)</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="1" to="44" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Applications of item characteristic curve theory to the problem of test bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Pine</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Applications of computerized adaptive testing: Proceedings of a symposium presented at the 18th annual convention of military testing association</title>
		<editor>D. J. Weiss</editor>
		<imprint>
			<publisher>Psychometric Methods Program</publisher>
			<date type="published" when="1977" />
			<biblScope unit="page" from="37" to="43" />
		</imprint>
		<respStmt>
			<orgName>University of Minnesota, Department of Psychology</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The relative performance of targeted maximum likelihood estimators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Porter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gruber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Sekhon</surname></persName>
		</author>
		<idno type="DOI">10.2202/1557-4679.1308</idno>
		<ptr target="https://doi.org/10.2202/1557-4679.1308" />
	</analytic>
	<monogr>
		<title level="j">The International Journal of Biostatistics</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">31</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing. R Foundation for Statistical Computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">The area between two item characteristic curves</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">S</forename><surname>Raju</surname></persName>
		</author>
		<idno type="DOI">10.1007/bf02294403</idno>
		<ptr target="https://doi.org/10.1007/bf02294403" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="495" to="502" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Psych: Procedures for psychological, psychometric, and personality research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Revelle</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=psych" />
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Evanston, Illinois</pubPlace>
		</imprint>
		<respStmt>
			<orgName>Northwestern University</orgName>
		</respStmt>
	</monogr>
	<note>R package version 2.1.9</note>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A model-based standardization approach that separates true bias/DIF from group ability differences and detects test bias/DTF as well as item bias/DIF</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Shealy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Stout</surname></persName>
		</author>
		<idno type="DOI">10.1007/bf02294572</idno>
		<ptr target="https://doi.org/10.1007/bf02294572" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="159" to="194" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Decisions that make a difference in detecting differential item functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Sireci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Rios</surname></persName>
		</author>
		<idno type="DOI">10.1080/13803611.2013.767621</idno>
		<ptr target="https://doi.org/10.1080/13803611.2013.767621" />
	</analytic>
	<monogr>
		<title level="j">Educational Research and Evaluation</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">2-3</biblScope>
			<biblScope unit="page" from="170" to="187" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Robust machine learning for treatment effects in multilevel observational studies under cluster-level unmeasured confounding</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Suk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kang</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11336-021-09805-x</idno>
		<ptr target="https://doi.org/10.1007/s11336-021-09805-x" />
	</analytic>
	<monogr>
		<title level="j">Psychometrika</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="310" to="343" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Detecting differential item functioning using logistic regression procedures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Swaminathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Rogers</surname></persName>
		</author>
		<idno type="DOI">10.18637/jss.v045.i03</idno>
		<ptr target="https://doi.org/10.18637/jss.v045.i03" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Measurement</title>
		<editor>Buuren, S., &amp; Groothuis-Oudshoorn, K.</editor>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="67" />
			<date type="published" when="1990" />
		</imprint>
	</monogr>
	<note>Journal of Statistical Software</note>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Super learner. Statistical Applications in</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Van Der Laan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Polley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Hubbard</surname></persName>
		</author>
		<idno type="DOI">10.2202/1544-6115.1309</idno>
		<ptr target="https://doi.org/10.2202/1544-6115.1309" />
	</analytic>
	<monogr>
		<title level="j">Genetics and Molecular Biology</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<monogr>
		<title level="m" type="main">Eighth-grade algebra: Findings from the eighth-grade round of the early childhood longitudinal study, kindergarten class of 1998-99 (ECLS-K). statistics in brief. NCES 2010-016</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Walston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Mccarroll</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
		</imprint>
		<respStmt>
			<orgName>National Center for Education Statistics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Multiple imputation using chained equations: Issues and guidance for practice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">R</forename><surname>White</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Royston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Wood</surname></persName>
		</author>
		<idno type="DOI">10.1002/sim.4067</idno>
		<ptr target="https://doi.org/10.1002/sim.4067" />
	</analytic>
	<monogr>
		<title level="j">Statistics in Medicine</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="377" to="399" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">Retaining students in grade: A literature review of the effects of retention on students&apos; academic and nonacademic outcomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Xia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">N</forename><surname>Kirby</surname></persName>
		</author>
		<ptr target="http://www.rand.org/pubs/technicalreports/TR678/" />
		<imprint>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xiao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">H</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Ning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Shenkman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Bian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Wang</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Algorithmic fairness in computational medicine</title>
		<idno type="DOI">10.1101/2022.01.16.21267299</idno>
		<ptr target="https://doi.org/10.1101/2022.01.16.21267299" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">The elementary school perfor mance and adjustment of children who enter kindergarten late or repeat kindergarten: Findings from national surveys (statistical analysis report NCES 98-097)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">S</forename><surname>Loomis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>West</surname></persName>
		</author>
		<ptr target="http://www.rand.org/pubs/technicalreports/TR678/" />
		<imprint>
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
