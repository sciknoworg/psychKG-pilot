<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Deep latent variable joint cognitive modeling of neural signals and human behavior</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Khuong</forename><surname>Vo</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Computer Science</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Qinhua</forename><forename type="middle">Jenny</forename><surname>Sun</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cog-nitive Sciences</orgName>
								<orgName type="department" key="dep2">Irvine</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Michael</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Psychological Methods</orgName>
								<orgName type="institution">University of Amsterdam</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joachim</forename><surname>Vandekerckhove</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cog-nitive Sciences</orgName>
								<orgName type="department" key="dep2">Irvine</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Statistics</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ramesh</forename><surname>Srinivasan</surname></persName>
							<affiliation key="aff1">
								<orgName type="department" key="dep1">Department of Cog-nitive Sciences</orgName>
								<orgName type="department" key="dep2">Irvine</orgName>
								<orgName type="institution">University of California</orgName>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Department of Biomedical Engineering</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Irvine</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Deep latent variable joint cognitive modeling of neural signals and human behavior</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:15+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract/>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>As the field of computational cognitive neuroscience continues to expand and generate new theories, there is a growing need for more advanced methods to test the hypothesis of brain-behavior relationships. Recent progress in Bayesian cognitive modeling has enabled the combination of neural and behavioral models into a single unifying framework. However, these approaches require manual feature extraction, and lack the capability to discover previously unknown neural features in more complex data. Consequently, this would hinder the expressiveness of the models. To address these challenges, we propose a Neurocognitive Variational Autoencoder (NCVA) to conjoin high-dimensional EEG with a cognitive model in both generative and predictive modeling analyses. Importantly, our NCVA enables both the prediction of EEG signals given behavioral data and the estimation of cognitive model parameters from EEG signals. This novel approach can allow for a more comprehensive understanding of the triplet relationship between behavior, brain activity, and cognitive processes.</p><p>EEG | Decision making | Neurocognitive model | Drift-diffusion model | Variational Bayes | Deep learning | Latent-variable models Current approaches to understanding brain function emphasize the search for statistical relationships between human behavior and individual physiological measures (EEG, fMRI, fNIRS, etc.; e.g. <ref type="bibr" target="#b6">Itthipuripat et al., 2019)</ref>. Behavioral measures, such as accuracy and speed of responses, reflect latent cognitive processes that underlie decision making that are not observed directly and must be inferred by cognitive models <ref type="bibr" target="#b11">(Lee &amp; Wagenmakers, 2014</ref>). An ongoing challenge in computational cognitive neuroscience research is formulating the link between brain activity and latent cognitive processes. Here, we present a novel approach that allows a theoretical account of the cognitive process of decisionmaking, and artificial neural networks to estimate a joint latent space to link cognitive parameters to both neural signals and behavioral measures. This joint latent space model is a valuable new framework for computational cognitive neuroscience, allowing for new forms of inference and hypothesis generation.</p><p>Previous work has focused on neurocognitive relationships between human neural data and behavioral data in decision-making tasks <ref type="bibr" target="#b16">(Nunez et al., 2015</ref><ref type="bibr" target="#b17">(Nunez et al., , 2017</ref><ref type="bibr" target="#b15">(Nunez et al., , 2019</ref><ref type="bibr" target="#b12">Lui et al., 2021;</ref><ref type="bibr" target="#b23">Turner et al., 2013</ref><ref type="bibr" target="#b24">Turner et al., , 2016</ref>. The hierarchical Bayesian models used in these projects make strong predictions about the relationships between brain activity and the speed of decision-making. These models typically make use of the drift-diffusion model (DDM; <ref type="bibr" target="#b18">Ratcliff &amp; McKoon, 2008</ref>), a widely-used cognitive model in decision-making, as their generative model of choice and reaction time data.</p><p>To integrate neural signals, these models require knowledge of previously discovered features of the neural data (e.g., known functional signals in the cognitive neuroscience literature) that are then linked by prescribed (usually linear) relationships to the latent cognitive variables in a Bayesian hierarchical model. The resulting neurocognitive models test the relationship between neural signals and cognitive variables, and enhance the accuracy of predictions of behavior directly from brain signals <ref type="bibr" target="#b24">(Turner et al., 2016;</ref><ref type="bibr" target="#b17">Nunez et al., 2017)</ref>. This can be thought of as one domain of the larger field of model-based cognitive neuroscience <ref type="bibr" target="#b1">(Forstmann &amp; Wagenmakers, 2015)</ref>.</p><p>A limitation of this approach is that we must know in advance which brain signals are possibly linked to cognitive functions. However, advances in frameworks and tools for neuroscience allow for the discovery of previously unknown neural features that we could use to explain latent cognitive variables. Ideally, such frameworks operate across observations, experimental manipulations, and individual differences. Deterministic models that leverage deep learning have been proposed for learning feature representation of EEG data to analyze and decode brain activity <ref type="bibr" target="#b19">(Roy et al., 2019)</ref>. As a notable example, <ref type="bibr" target="#b21">Sun et al. (2022)</ref> have proposed a SincNet-based neural network that made use of EEG signals to learn the latent cognitive variables of the DDM on individual decisions. This approach identifies time windows of information processing and frequency bands that can be used to predict latent processes directly from EEG data as a trial-level association between neural features, choice, and response time.</p><p>This work aims to develop a deep probabilistic method for linking neural data from EEG to the latent parameters of flows of operations. Red arrows: loss functions. MSE and WFPT stand for Mean Squared Error and Wiener First Passage Time, respectively. The heatmaps represent the probability distributions in the latent spaces. Plasma color maps are for the drift-diffusion variables (z C ∈ R 3 ), while greenery color maps are for residual neural variables (z N ∈ R 32 ). Blue blocks contain µ and σ, which are the parameters of the multivariate Gaussian latent spaces. Gray blocks contain z sampled (∼) from the distributions. The variables x and y represent EEG signals and choice-RTs, respectively. Each trapezoid represents a different convolutional neural network (see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Neurocognitive Variational Autoencoders</head><p>Generative EEG Modeling with VAEs. Consider first a data set P</p><formula xml:id="formula_0">def = {D 1 , . . . , D M } containing M subjects, where each subject D m def = {x 1 , . . . , x I } consists of I trials x i ∈ R C×T</formula><p>that are EEG signals of C channels by T time samples. Throughout the paper, the subscript m is omitted when we refer to only one subject or when it is clear from the context. </p><formula xml:id="formula_1">arg min θ KL (p D (x) p θ (x)) = arg max θ E p D (x) [log p θ (x)] [1]</formula><p>where </p><formula xml:id="formula_2">p θ (x) = Z p θ (x | z)p(z)dz</formula><formula xml:id="formula_3">L(x; θ, φ) def = log p θ (x) − KL (q φ (z | x) p θ (z | x)) = E q φ (z|x) [log p θ (x | z)] − KL (q φ (z | x) p(z)) [2]</formula><p>Taking the likelihood model p θ (x | z) to be a decoder and the inference model q φ (z | x) to be an encoder, a variational autoencoder (VAE; <ref type="bibr" target="#b10">Kingma &amp; Welling, 2013;</ref><ref type="bibr" target="#b20">Sohn et al., 2015)</ref> considers this objective from a deep probabilistic autoencoder perspective. Here, θ and φ are neural network parameters, and learning takes place via stochastic gradient ascent using unbiased estimates of</p><formula xml:id="formula_4">∇ θ,φ 1 n n i=1 L (x i ; θ, φ).</formula><p>In the following sections, we extend the traditional VAE to create the Neurocognitive VAE (NCVA) ( <ref type="figure" target="#fig_0">Figure 1</ref>). This model allows us to model a joint distribution of neural and behavioral data. Instead of a training technique that encourages disentanglement, as in β-VAE <ref type="bibr" target="#b3">(Higgins et al., 2016)</ref>, NCVA imposes restrictions on latent space by using a cognitive model that provides interpretability and controllable generation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Disentangled Cognitive Latent Space of EEG. Now consider the data</head><formula xml:id="formula_5">D m def = {(x 1 , y 1 ) , . . . , (x I , y I )},</formula><p>consisting, on the one hand, of N trials of the EEG data x i and, on the other hand, of the corresponding choice response times (choice-RT) y i . Both x i and y i are associated with a context vector c i (where the applicable context might be an experimental condition; say, noise conditions c i ). For mathematical simplicity, the context vector c is not mentioned when we refer to one of the data modalities.</p><p>Crucially, we propose a generative model with two sources of variation: z C , which is cognitively specific, and z N , which captures any residual neural variations left in x. We assume the approximate posterior q φ (z N , z C | x) has the following fully factorized form:</p><formula xml:id="formula_6">q φ (z N , z C | x) = q φ N (z N | x) q φ C (z C | x) q φ N (z N | x) = N z N | µ φ N (x), diag σ 2 φ N (x) q φ C (z C | x) = N z C | µ φ D (x), diag σ 2 φ D (x)<label>[3]</label></formula><p>A Gaussian prior over latent variables p(z C ) can be chosen for each subject. We use subject priors obtained from a Bayesian hierarchical fitting of a DDM using the Markov chain Monte Carlo (MCMC) <ref type="bibr" target="#b15">(Nunez et al., 2019)</ref>.</p><p>We learn the generative model by maximizing the lower bound on log p θ (x, y) as:</p><formula xml:id="formula_7">L(x, y; θ, φ N , φ C ) = E q φ (z N ,z C |x) [log p θ (x | z N , z C ) + log p(y | z C )] − KL (q φ N (z N | x) p(z N )) − KL (q φ C (z C | x) p(z C )) [4] where p θ (x | z N , z C ) = N (x | µ θ (z N , z C ), I) and p(y|z C )</formula><p>can be any neurocognitive likelihood. This work applies the Wiener First Passage Time distribution (WFPT; <ref type="bibr" target="#b13">Navarro &amp; Fuss, 2009)</ref> corresponding to the lower boundary:</p><formula xml:id="formula_8">p(y|z C ) = Wiener (RT | α, τ, δ) = π α 2 e − 1 2 (αδ+δ 2 (RT −τ )) × +∞ k=1 k sin πk 2 e − k 2 π 2 2α 2 (RT −τ ) [5]</formula><p>The probability at the upper boundary is obtained by setting δ = −δ. z C comprises of three parameters including drift rate δ, boundary α, non-decision time (ndt) τ . The bias towards correct or incorrect responses is fixed at 0.5, that is, the starting point is always unbiased. The joint inference is performed using only EEG x to ensure that encoder θ C would learn to extract neural features that are tailored to cognitive parameters, without relying on choice-RT y. This has the advantage of providing more accurate trial-level parameter estimates that are associated with the EEG data.</p><p>Note that the dimension of the cognitive space is significantly lower than that of the residual neural space. This facilitates the representation of the variation in neural signals only through flexible z N . Maximizing the likelihood of observing neural signals does not guarantee decoder θ utilizing z C to output x. In the next section, we present an approach to capture the correlation between behavior and cognition, as well as the mapping of the variability of behavior and cognition to neural signals.</p><p>Structured EEG Modeling from Behavior. Here, we propose a discriminative model regularized by the generative model learned in the previous section. We aim to discriminatively learn the distribution of the cognitive parameters conditioned on behaviors, and the distribution of the neural latent variables conditioned on cognitive parameters. The joint latent space inferred from the behavior can be factorized into the two-level latent space as follows:</p><formula xml:id="formula_9">q φ B (z N , z C | y i ) = q φ 2 B (z N | z C ) q φ 1 B (z C | y i ) [6]</formula><p>Inspired by <ref type="bibr" target="#b22">Suzuki et al. (2016)</ref>, we learn the following approximations, w.r.t parameter φ 1</p><p>B : </p><formula xml:id="formula_10">E p D KL q φ C (z C | x) | q φ 1 B (z C | y)<label>[7</label></formula><formula xml:id="formula_11">E p D KL q φ N (z N | x) | q φ 2 B (z N | z C ) [8]</formula><p>By decomposing the KL divergences as in <ref type="bibr" target="#b4">Hoffman &amp; Johnson (2016)</ref>; Vedantam et al. <ref type="formula">2017</ref>, we ef-</p><formula xml:id="formula_12">fectively minimize KL q avg φ C (z C | x) | q φ 1 B (z C | y) and KL q avg φ N (z N | x) | q φ 2 B (z N | z C ) , where q avg φ (z | x) = E p(x|y) [q φ (z | x)].</formula><p>As there is little posterior uncertainty once conditioned on an EEG signal x i , the approximations are close to the average posterior induced by each of the EEG x i associated with similar y.</p><p>Having fit both the generative and discriminative models, we can now explore the three-way relationship between behavior, brain activity, and cognitive processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments</head><p>EEG and Behavioral Datasets. We used behavioral and EEG data collected while participants performed a twoalternative forced-choice task where they had to decide whether a Gabor patch presented with added dynamic noise is higher or lower spatial frequency (for details, see Experiment 2 by <ref type="bibr" target="#b15">Nunez et al., 2019)</ref>. Task difficulty was manipulated by adding spatial white noise to manipulate the quality of the perceptual evidence available to make the discrimination. The signal and the noise flickered at 40 and 30 Hz frequencies, respectively. 4 participants performed the task in blocks of trials at 3 added noise levels (low, medium, and high). Each subject performed approximately 3000 trials over 7 experimental sessions, while 128 channels of EEG and behavioral data were recorded. The independent component analysis (ICA)-based artifact rejection method was used on EEG data to remove eyeblinks, electrical noise, and muscle artifacts. A subset of 98 EEG channels were selected, excluding channels located in the outer ring. EEG data were bandpass filtered to 1 to 45 Hz in the frequency domain and then downsampled from 1000 Hz to 250 Hz in the time domain prior to data analysis. The data for each subject were divided into 80% for training and validation and the remaining 20% for testing.  Results. To validate the neurocognitive modeling approach, we first examine the trial-by-trial variability of the parameters within each subject and the generalization of the model to unseen data. <ref type="figure" target="#fig_5">Figures 2a and 2c</ref> show the trial-by-trial correlations between estimated DDM posteriors and observed choice-RTs in the training data from neural signals and behavior, respectively. Spearman correlations between fitted drift rates (δ) and choice-RTs are negatively strong. At the same time, there are strong positive correlations between boundaries (α) and choice-RTs, as well as between nondecision time and choice-RTs. The estimates in NCVA are regularized by the subject priors obtained from a Bayesian hierarchical fitting of a DDM using <ref type="bibr">MCMC Nunez et al. (2019)</ref>. The model was individually fitted for each subject using choice-RT and accuracy only and accounted for betweencondition variability within subjects. Clear clusters of drift rates and non-decision-time estimates depending on the noise conditions can be seen, though boundary estimates are highly overlapped. It is worth noting that uncertainties in the estimates can be inspected from the figures through the posterior covariance. Understandably, the uncertainties in the estimations from choice-RTs are significantly higher than from EEG signals, which agree with the theoretical derivations in Section . <ref type="figure" target="#fig_5">Figures 2b and 2d</ref> also demonstrate a satisfactory generalization to unseen data. The drift rates positively correlate with choice-RTs, whereas the boundaries and non-decision time negatively correlate with choice-RTs. The model successfully learns to extract the neural features that account for the choice-RT variability at each trial. To evaluate whether obtaining trial estimates of cognitive parameters improved the model of choice and choice-RT data, <ref type="table">Table 1</ref> presents the Wiener likelihood test for the neurocognitive generalization ability to unseen data. The results show that the use of single-trial predictions of cognitive parameters ω i provides higher likelihood than the median estimatesω fitted from the training data. This implies that single-trial estimates better account for new data compared to median estimates. <ref type="figure" target="#fig_7">Figure 3a</ref> shows the average of signals generated by the neurocognitive autoencoder when given a set of approximately 800 test choice-RTs compared to the average of actual signals associated with the same choice-RTs. At the selected electrodes, the window of interest is 100 ms pre-stimulus to 500 ms post-stimulus, which captures the N200 waveform. The generated and original signals appear visually similar in the timing and amplitudes of the peaks and troughs. <ref type="figure" target="#fig_7">Figures 3b, 3c</ref>, and 3d depict the trial-averaged frequency spectra and corresponding ERP waveforms of the reconstructed signals. Regarding the frequency spectra, the most important features are the 40 and 30 Hz peaks, which correspond to the flicker frequency of the signal (Gabor patch) and spatial white noise, respectively. Interestingly, the generative model learns to structure output the steady-state visually evoked potentials (SSVEPs) that occur in response to a visual stimulus flickering at different frequencies, even though it was never explicitly encoded in the model. Moreover, in the low noise condition (b), the 30 Hz peak is large and the 40 Hz is small, while in the high noise condition (d), the 30 Hz peak is reduced and the 40 Hz peak is enhanced. In terms of ERP waveforms, the model captures the relationships of the N200 peak latencies with respect to the additive noise conditions. Higher additive white noise in the stimulus effectively increases the latency and decreases the amplitude of the N200. We focus on the N200 signal because the original study <ref type="bibr" target="#b15">(Nunez et al., 2019)</ref> found strong relationships between N200 latency and choice-RT, and thus the N200 is a good validation of our model. These prove the convergence of the model in optimizing the lower bound of the conditional likelihood mapping from behavioral data to EEG features, which effectively encodes differences in the stimuli presented to the subjects in the latent variable space. In addition to evaluating traditional ERP estimates (trialaveraged), we also assess the single-trial ERP estimate (channel-averaged). To increase the signal-to-noise ratio to better detect the N200, the first singular-value decomposition (SVD) component obtained from the ERP response is taken as a channel weighting function. More details of the SVD method can be seen at <ref type="bibr" target="#b15">(Nunez et al., 2019)</ref>. <ref type="figure">Figure 4</ref> shows the performance of the model in learning the N200 feature in each trial. As shown in <ref type="figure">Figure 4</ref>, the distributions of the single-trial N200 peak latencies, as well as the amplitudes calculated from the generated signals, closely match those of the original signals at three different noise levels. The peak amplitude distribution is somewhat broader than the original data's generated distribution. Importantly, the model can generate the variability of the N200 latency with the experimental manipulation of low, medium, and high noise, systematically increasing the N200 latency in the generated signals. <ref type="figure" target="#fig_9">Figure 5</ref> represents the sensitivity analysis of the choice-RT and drift-diffusion parameters regardless of the noise conditions. In the left column, we examine the sensitivity of the neural signals generated by the choice-RTs. We can see similar patterns across subjects where the increases in choice-RTs lead to significant declines in the 30 Hz and the rises of the N200 latencies. This confirms the minimization approach of the KL divergence between the latent spaces inferred from the behavioral data and the neural signals. Power at 40 Hz reflecting the neural response to the noise also changes according to the choice-RTs, though the pattern is not as strong as the subjects suppressed the noise signal in all conditions.</p><p>One of the powerful tools for exploring the relationship between cognitive processes is to examine the sensitivity of neural signals to cognitive parameters. The middle and right columns of <ref type="figure" target="#fig_9">Figure 5</ref> depict the effect of hypothetical modulations of drift rates and non-decision time on the generated neural signals. The results show that our model reveals the intricate interactions between cognitive parameters and neural signals, which is consistent with prior discoveries in the cognitive modeling literature. As the non-decision time is faster, the N200 latencies are shorter, and the 30 Hz peaks are larger. Accordingly, the amplitudes of the N200 peaks are more prominent, though not shown in the figures for clar-ity. The same interactions are observed with the increase in drift rates, representing evidence accumulation. Again, the effects on 40 Hz peaks are weaker and depend on the subjects. We did not observe the effects of the boundary separation (caution) on the neural signals. The effect can be reversed with slower non-decision times and lower drift rates. The strongest effects can be seen when both parameters influence neural signals. This demonstrates the effectiveness of the designs of the hierarchical latent variables inferred from choice-RTs and the disentangled latent space produced by the EEG data.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>In this work, we proposed a joint behavioral and EEG modeling approach driven by a cognitive model of decision making. The experimental results demonstrate the effectiveness of our Neurocognitive VAE in simultaneously modeling highdimensional EEG signals and low-dimensional behavioral data. Remarkably, the model learns essential task-relevant neural features, e.g. N200 peaks and SSVEP, without explicit specification in the optimization objective. Furthermore, the model captures how these features modulate behavior, specifically discovering relationships between brain activity and behavior consistent with other models based on prior knowledge. This suggests that the Neurocognitive VAE helps uncover neural signals linked to behavioral data by mapping to a structured latent space. Compared to the aforementioned published joint models <ref type="bibr" target="#b16">(Nunez et al., 2015</ref><ref type="bibr" target="#b17">(Nunez et al., , 2017</ref><ref type="bibr" target="#b15">(Nunez et al., , 2019</ref><ref type="bibr" target="#b12">Lui et al., 2021;</ref><ref type="bibr" target="#b23">Turner et al., 2013</ref><ref type="bibr" target="#b24">Turner et al., , 2016</ref>, our end-to-end model is capable of inferring task-relevant EEG features from behavior without prior knowledge of which features to optimize. The structured latent space allows the learning of behavioral variability to drive the EEG data generation process, leading to the prediction of the structure of EEG features in relation to the stimuli used in the experiments (N200 and SSVEP) and the behavioral performance (choice-RT). In addition, the model allows us to directly map the variability of cognitive parameters to neural signals, allowing for theoretical predictions that guide future experimental studies. It should be noted that our framework does not serve to refine the functional form of process-oriented computational models. Instead, it presumes a set of fixed assumptions; in the DDM, a constant drift rate and boundary separation within trials. Importantly, our framework can be generalized to encompass any other neural measures combined with any cognitive model to explain behavior, provided that the cognitive model expresses a closed-form likelihood of behavioral data. Importantly, by parameterizing the likelihood by a deep neural network receiving neural data as input, trial-level parameter inferences are made possible. In this research, we assume a DDM posterior with a diagonal covariance matrix. This could lead to an overestimation of the variance of the marginal posteriors if the true posterior has dependencies. It would be beneficial to investigate the use of a full covariance matrix as an alternative. It is  colored line corresponds to one reconstructed EEG channel. In low-noise conditions, the spectra show a strong peak at the Gabor flicker frequency of 30 Hz, and the ERP waveform shows a shorter N200 latency and larger peak amplitude. Under high-noise conditions, the spectra show a strong peak at the noise flicker frequency of 40 Hz, and the ERP waveform shows a longer N200 latency and a smaller peak amplitude.  <ref type="figure">4</ref>. Performance of the model in reconstructing single-trial N200 peaks from choice-RTs in four subjects. The dotted lines are references to the original data. The distributions of (left) single-trial N200 peak latencies across three noise conditions and (right) the N200 peak amplitude statistics are shown. Single-trial observations of the peak latency of N200 are found using the SVD method <ref type="bibr" target="#b15">(Nunez et al., 2019)</ref> for each subject and noise condition. important to mention that our validation process focused on correct responses. Due to the low number of incorrect responses compared to correct ones, we lack confidence in interpreting the results in this study for the incorrect trials, although the direction of the trial-level parameter fits was consistent with the results for correct trials. We anticipate future research to explore strategies to address the class imbalance problem in deep learning models <ref type="bibr" target="#b7">(Johnson &amp; Khoshgoftaar, 2019)</ref>. Further work with a larger dataset is needed to demonstrate that we can extend the model to new individuals. In principle, this would potentially allow us to predict brain activity in clinical populations with known behavioral differences.  accurately recover the original distributions of trial-specific parameters. In particular, the generating and recovered distributions strongly overlap, and the correlation plots indicate that our single-trial estimates of cognitive parameters exhibit good correlations with the reference parameters. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Fig. 1 .</head><label>1</label><figDesc>The Neurocognitive VAE. After the generative process (a) learns the joint latent neurocognitive variables (Section ), the regularized discriminative process (b) retrofits its hierarchical latent space to the joint latent space (Section ). Inference networks q and Generation networks p contain neural network parameters θ and φ. Black arrows:</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>For</head><label></label><figDesc>each subject m, we aim to learn an EEG generative process with a latent-variable model comprising of a fixed Gaussian prior over latent variables p(z) = N (z | 0, I), where I is the identity covariance matrix, and a parametric non-linear Gaussian likelihood p θ (x | z). The learning process finds θ such that the Kullback-Leibler (KL) divergence is minimized between the true data generating distribution the model p θ :</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>Table 1 .</head><label>1</label><figDesc>Comparison of the sum of Wiener negative loglikelihood (− log Wiener (RTi | ωi)) of four subjects on the test sets.ω represents the median fitted cognitive parameters from the training set.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Fig. 2 .</head><label>2</label><figDesc>Predicted from EEG (test data) (c) Fitted from choice-RTs (training data) (d) Predicted from choice-RTs (test data) Drift-diffusion single-trial parameter estimations from correct responses of subject s1. The parameters are constrained by the subject priors resulting from a Bayesian MCMC modeling (without EEG data). Scatter plots illustrate the relationship between the parameters and the observed choice-RTs for each trial. The top two rows are posterior inferences from neural signals, while the bottom two are from behaviors. The left column shows the drift-rate (δ) estimates, the middle column shows boundary (α) estimates, and the right column presents non-decision time (ndt) estimates. The correlations between the choice-RTs and the inferred DDM parameters are consistent with what is expected. On top of each panel are the Spearman correlation coefficients (ρ). The covariances of the inferred parameters are indicated by circles, which correspond to contours having one standard deviation. For clarity, each circle is magnified 300 times.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig. 3 .</head><label>3</label><figDesc>Performance of the model in reconstructing 98 EEG channels of subject s1 by averaging ≈ 800 predicted EEG trials from ≈ 800 choice-RTs in the test set. Time point zero denotes the time point of stimulus onset. The first row displays the original (blue) and generated (orange) trial-averaged EEG data at the pooled electrodes. The x-axis denotes the time in milliseconds from stimulus onset, and the y-axis denotes the signal amplitude. The second, third, and fourth rows are (left) frequency spectra and (right) EEG signals averaged over all test choice-RT trials (≈ 800/3 per condition). The signals on the right are low-pass filtered at 15 Hz for clarity of N200 peaks. Each</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>Fig. 4. Performance of the model in reconstructing single-trial N200 peaks from choice-RTs in four subjects. The dotted lines are references to the original data. The distributions of (left) single-trial N200 peak latencies across three noise conditions and (right) the N200 peak amplitude statistics are shown. Single-trial observations of the peak latency of N200 are found using the SVD method (Nunez et al., 2019) for each subject and noise condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Fig. 5 .</head><label>5</label><figDesc>Sensitivity analysis of choice-RTs and latent drift-diffusion parameters on EEG signal generation in four subjects. The left column presents the effects of choice-RTs on the output neural signals. The blue bars represent the power at 30 Hz, while the red bars represent the power at 40 Hz. The orange bars show the N200 latencies. The middle column shows the changes in the single-trial N200 distribution w.r.t to hypothetical changes in the cognitive parameters. The yellow distribution represents the reference data, while the blue and red ones correspond to modified parameter settings that decrease or increase the N200 latencies, respectively. The modification in subject s4 (ndt ± 0.05, δ± 0.3) is different from other subjects. The right column characterizes the changes in 30 Hz and 40 Hz peaks w.r.t to the changes in the same cognitive parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Fig. 6 .</head><label>6</label><figDesc>Drift-diffusion parameter estimates from neural signals in a simulation of trial-level choice RTs and EEG signals. The top panels show the overlap between the recovered and the original distributions of trial-specific drift-rate and NDT. The reference values for the drift rate and NDT are drawn from the normal distributions N (1.5, 0.2) and N (0.3, 0.05), respectively. The bottom scatter plots illustrate the relationship between the recovered parameters and the original parameters each trial. ρ are the Spearman correlation coefficients.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell>for detailed</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head>Table 2 . Neural network parametrization EncoderN</head><label>2</label><figDesc>− q φ N (zN | x) Encoder C − q φ C (zC | x) Decoder -p θ (x | zN , zC )</figDesc><table><row><cell>maps EEG signals to neural latents</cell><cell></cell><cell>maps EEG signals to cognitive latents</cell><cell>reconstructs EEG signals</cell></row><row><cell>Dropout(0.3)</cell><cell></cell><cell></cell><cell>Get zC</cell></row><row><cell>Conv 1, lReLU, 128 x 250</cell><cell></cell><cell>Conv 1, lReLU, 128 x 250</cell><cell>Linear 128, lReLU</cell></row><row><cell>Conv 6, BN, lReLU Conv 6, Stride 2, BN, lReLU</cell><cell>X 2</cell><cell>Conv 6, BN, lReLU, Dropout(0.7) Conv 6, Stride 2, BN, lReLU, Dropout(0.7)</cell><cell>Linear 32, lReLU Concat zN , c</cell></row><row><cell>Self Attention</cell><cell></cell><cell>Self Attention</cell><cell>Conv Transp 8, Stride 4, 512 Channels, BN, lReLU</cell></row><row><cell>Conv 6, BN, lReLU Conv 6, Stride 2, BN, lReLU</cell><cell>X 2</cell><cell>Conv 6, BN, lReLU, Dropout(0.7) Conv 6, Stride 2, BN, lReLU, Dropout(0.7)</cell><cell>Conv Transp 8, Stride 4, 256 Channels, BN, lReLU Self Attention</cell></row><row><cell>Reshape 2048, Concat c</cell><cell></cell><cell>Reshape 2048, Concat c</cell><cell>Conv Transp 6, Stride 3, 128 Channels, BN, lReLU</cell></row><row><cell>Linear 32 (mean zN )</cell><cell></cell><cell>Linear 1 (mean δ), Linear 1 (logvar δ)</cell><cell>Conv Transp 6, Stride 3, 128 Channels, BN, lReLU</cell></row><row><cell>Linear 32 (logvar z N )</cell><cell></cell><cell>Linear 1, Softplus (mean α)</cell><cell>Self Attention</cell></row><row><cell></cell><cell></cell><cell>Linear 1 (logvar α)</cell><cell>Conv Transp 10, Stride 2, 98 Channels</cell></row><row><cell></cell><cell></cell><cell>Linear 1, Softplus (mean ndt)</cell><cell></cell></row><row><cell></cell><cell></cell><cell>Linear 1 (logvar ndt)</cell><cell></cell></row><row><cell>Encoder 2 β − q 2 β (zN | zC )</cell><cell></cell><cell>Encoder 1 β − q 1 β (zC | yi)</cell><cell></cell></row><row><cell>maps cognitive latents to neural latents</cell><cell></cell><cell>maps behaviors to cognitive latents</cell><cell></cell></row><row><cell>Linear 128, lReLU</cell><cell></cell><cell>Linear 128, lReLU</cell><cell></cell></row><row><cell>Linear 128, lReLU</cell><cell></cell><cell>Linear 128, lReLU</cell><cell></cell></row><row><cell>Concat c</cell><cell></cell><cell>Concat c</cell><cell></cell></row><row><cell>Linear 64</cell><cell></cell><cell>Linear 6</cell><cell></cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">of 12 Vo et al.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">of 12 Vo et al.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Vo et al.   </note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>This research was supported by grants #1658303, #1850849, #2051186, and #2126976 from the United States (US) National Science Foundation (NSF). We thank Erik Sudderth for his insight into the NVCA. All reviewers are appreciated for their constructive suggestions and comments.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics Statement</head><p>All participants gave written informed consent, and all data was collected at the University of California, Irvine with approval from the Institutional Review Board.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data and Code Availability Statement</head><p>The dataset analyzed during the current study is available on https://zenodo.org/record/8381751, and the implementation of the model is in the following repository https://github.com/khuongav/neurocognitive_vae. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix</head><p>Neural Network Architectures and Training Hyperparameters. The inferential and generative processes are parameterized by deep neural networks, as shown by the flows in <ref type="figure">Figure 1</ref>. <ref type="table">Table 2</ref> details the architectures of the five networks. The input EEG signals are of size 98 x 250 (1 second of data of 98 channels at 250 Hz). The feature extraction layers in the EEG and cognitive encoders are similar to <ref type="bibr" target="#b26">Vo et al. (2022)</ref>. All the feature maps have 128 channels. Leaky ReLU (lReLU) activation functions are applied to all layers, with a slope of 0.1 to stimulate easier gradient flow. Batch normalizations (BN) <ref type="bibr" target="#b5">(Ioffe &amp; Szegedy, 2015)</ref> are used in each convolutional layer of the encoders and decoders. Self-attention layers <ref type="bibr" target="#b27">(Zhang et al., 2019)</ref> are applied in the encoders and decoders to better account for long-range relationships in time series. c are noise condition embeddings as one-hot vectors (size 3). The size of z N is set at 32 as increasing the dimension did not lead to any improvement in performance on a validation set.</p><p>In Equation <ref type="formula">4</ref>, the term log p(y | z C ) is weighted by λ = 2 to scale up the likelihood of low-dimensional behavior. The KL terms are weighted by β = 20. The KL terms are normalized to balance the KL divergence loss and the reconstruction loss. Please refer to Sections 4.2 and A6 of <ref type="bibr" target="#b3">(Higgins et al., 2016)</ref> for further information. The optimization of q φ C (z C | x) is divided into two stages. We first optimize the network w.r.t drift rate δ and boundary α, while non-decision time τ is set to 0.93 • RT min for each subject, approximating the results of the Bayesian MCMC modeling <ref type="bibr" target="#b15">Nunez et al. (2019)</ref>. Having trained φ C for δ and α, we can proceed to train only the last fully connected layer that predicts τ . This procedure is to circumvent the difficulty of simultaneously optimizing the network for the boundary and the non-decision time on the experimental data. We used Adam <ref type="bibr" target="#b8">(Kingma &amp; Ba, 2014)</ref> for optimizations, with a learning rate of 5e-4 and exponential decay rates β 1 = 0.9 and β 2 = 0.999. Simulation Studies. We assessed our ability to recover true non-decision time (NDT) and drift rate by simulating response time data and EEG signals. Response time data were simulated from a drift-diffusion model with trial-to-trial variability in NDT and evidence accumulation rate (i.e., drift rate). To simulate EEG signals with a known relationship with DDM parameters, we specifically focused on N200 due to the significant associations between N200 latency and NDT reported by <ref type="bibr" target="#b15">Nunez et al. (2019)</ref>. In our new experiments, we additionally observed a substantial relationship between drift rate and N200 latency, which we included in the simulation. Boundary separation was not included in the simulation, as we did not find any neural correlates of variability in boundary separation, and those are usually only found in tasks with trial-level accuracy feedback <ref type="bibr" target="#b0">(Cavanagh &amp; Frank, 2014;</ref><ref type="bibr" target="#b14">Nunez et al., 2024)</ref>.</p><p>To simulate single-trial EEG signals, we shifted the true averaged ERP waveform based on each sample of trial-level NDT, using a linear regression slope of 1, as in <ref type="bibr" target="#b15">Nunez et al. (2019)</ref>. EEG noise was obtained from the original data, using independently sampled segments that did not include responses to stimuli. The resulting ERP and EEG waveforms were then combined to generate artificial EEG signals for each trial that carried the N200 latency information and was associated with choice and response time.</p><p>It is evident from the results in <ref type="figure">Figure 6</ref> that the model can</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Frontal theta as a mechanism for cognitive control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Cavanagh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in cognitive sciences</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="414" to="421" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Wagenmakers</surname></persName>
		</author>
		<editor>E.-J.</editor>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">An Introduction to Model-Based Cognitive Neuroscience</title>
		<imprint>
			<publisher>Springer</publisher>
			<pubPlace>New York, NY; New York. doi</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<monogr>
		<title level="m" type="main">beta-vae: Learning basic visual concepts with a constrained variational framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Matthey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Burgess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Glorot</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Lerchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note>International conference on learning representations</note>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Elbo surgery: yet another way to carve up the variational evidence lower bound</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Hoffman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop in advances in approximate bayesian inference, nips</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Batch normalization: Accelerating deep network training by reducing internal covariate shift</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ioffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Szegedy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="page" from="448" to="456" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Functional MRI and EEG index complementary attentional modulations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Itthipuripat</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">C</forename><surname>Sprague</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Serences</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">31</biblScope>
			<biblScope unit="page" from="6162" to="6179" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Survey on deep learning with class imbalance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Khoshgoftaar</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Big Data</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="54" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Adam: A method for stochastic optimization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ba</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1412.6980</idno>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Cognition and Individual Differences lab | University of California, Irvine | cidlab</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Vo</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024-12-24" />
			<biblScope unit="page">11</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">P</forename><surname>Kingma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Welling</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1312.6114</idno>
		<title level="m">Auto-encoding variational bayes</title>
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Bayesian cognitive modeling: A practical course</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Cambridge university press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Timing of readiness potentials reflect a decision-making process in the human brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">K</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Cassidy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Cramer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Computational Brain &amp; Behavior</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="264" to="283" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Fast and accurate calculations for first-passage times in wiener diffusion models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">G</forename><surname>Fuss</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical psychology</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="222" to="230" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">A tutorial on fitting joint models of m/eeg and behavior to understand cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Fernandez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
	<note type="report_type">PsyArXiv . doi</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The latency of a visual evoked potential tracks the onset of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gosai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">197</biblScope>
			<biblScope unit="page" from="93" to="108" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Individual differences in attention influence perceptual decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in psychology</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">18</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">How attention influences perceptual decision making: Single-trial EEG correlates of drift-diffusion model parameters</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of mathematical psychology</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="117" to="130" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The diffusion decision model: theory and data for two-choice decision tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Ratcliff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Mckoon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural computation</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="873" to="922" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Deep learning-based electroencephalography analysis: a systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Banville</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Albuquerque</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gramfort</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Falk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Faubert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of neural engineering</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">51001</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning structured output representation using deep conditional generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Sohn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Yan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2015" />
			<biblScope unit="volume">28</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Decision sincnet: Neurocognitive models of decision making that predict cognitive processes from neural signals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><forename type="middle">J</forename><surname>Sun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Nunez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Vandekerckhove</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">2022 international joint conference on neural networks (ijcnn)</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1" to="9" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Joint multimodal learning with deep generative models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Suzuki</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Nakayama</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Matsuo</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1611.01891</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">A bayesian framework for simultaneously modeling neural and behavioral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">U</forename><surname>Forstmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Sederberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">72</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Why more is better: Simultaneous modeling of EEG, fMRI, and behavioral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A</forename><surname>Rodriguez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Norcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">NeuroImage</title>
		<imprint>
			<biblScope unit="volume">128</biblScope>
			<biblScope unit="page" from="96" to="115" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Vedantam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Fischer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Murphy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1705.10762</idno>
		<title level="m">Generative models of visually grounded imagination</title>
		<imprint>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Composing graphical models with generative adversarial networks for EEG signal modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Vo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vishwanath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Srinivasan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Dutt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Cao</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Icassp 2022-2022 ieee international conference on acoustics, speech and signal processing (icassp)</title>
		<imprint>
			<date type="published" when="2022" />
			<biblScope unit="page" from="1231" to="1235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Self-attention generative adversarial networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goodfellow</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Metaxas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Odena</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">International conference on machine learning</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="7354" to="7363" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
