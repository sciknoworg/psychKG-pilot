<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Value Cores for Inner and Outer Alignment: Simulating Personality Formation via Iterated Policy Selection and Preference Learning with Self-World Modeling Active Inference Agents</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Adam</forename><surname>Safron</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for Psychedelic and Consciousness Research</orgName>
								<orgName type="institution">Johns Hopkins University School of Medicine</orgName>
								<address>
									<settlement>Baltimore</settlement>
									<region>MD</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Zahra</forename><surname>Sheikhbahaee</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Nick</forename><surname>Hay</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Encultured AI</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jeff</forename><surname>Orchard</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Jesse</forename><surname>Hoey</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">David R. Cheriton School of Computer Science</orgName>
								<orgName type="institution">University of Waterloo</orgName>
								<address>
									<region>Ontario</region>
									<country key="CA">Canada</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff3">
								<orgName type="department">European Conference on Machine Learning and Principles and Practice of Knowledge Discovery in Databases</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Value Cores for Inner and Outer Alignment: Simulating Personality Formation via Iterated Policy Selection and Preference Learning with Self-World Modeling Active Inference Agents</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<note type="submission">Accepted to the 3rd International Workshop on Active Inference (IWAI 2022</note>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:19+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Active Inference</term>
					<term>AI Safety</term>
					<term>Existential Risk</term>
					<term>AI Alignment</term>
					<term>Enculturation</term>
					<term>Counterfactual Planning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Humanity faces multiple existential risks in the coming decades due to technological advances in AI, and the possibility of unintended behaviors emerging from such systems. We believe that better outcomes may be possible by rigorously exploring frameworks for intelligent (goaloriented) behavior inspired by computational neuroscience. Here, we explore how the Free Energy Principle and Active Inference (FEP-AI) framework may provide solutions for these challenges via affording the realization of control systems operating according to principles of hierarchical Bayesian modeling and prediction-error (i.e., surprisal) minimization. Such FEP-AI agents are equipped with hierarchically-organized world models capable of counterfactual planning, realized by the kinds of reciprocal message passing performed by mammalian nervous systems, so allowing for the flexible construction of representations of self-world dynamics with varying degrees of temporal depth. We will describe how such systems can not only infer the abstract causal structure of their environment, but also develop capacities for &quot;theory of mind&quot; and collaborative (human-aligned) decision making. Such architectures could help to sidestep potentially dangerous combinations of systems with high intelligence and human-incompatible values, since such mental processes are entangled (rather than orthogonal) in FEP-AI agents. We will further describe how (meta-)learned deep goal hierarchies may also welldescribe biological systems, suggesting that potential risks from &quot;mesaoptimisers&quot; may actually represent one of the most promising approaches to AI safety: minimizing prediction-error relative to causal self-world models can be used to cultivate modes of policy selection and agent personalities that robustly optimize for achieving goals that are consistently aligned with both individual and shared values. Finally, we will describe how iterative policy selection and preference learning can result in &quot;value cores&quot; or self-reinforcing, relatively stable attracting states that agents will seek to return to through their goal-oriented imaginings and actions.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>1 Introduction: Towards Human-Compatible Artificial Super Intelligence (ASI) with FEP-AI</p><p>We are currently engaged in an ongoing research program to determine how connections between computational neuroscience and artificial intelligence (AI) may inform what may be a one of the greatest challenges we will ever face as a species: developing powerful AI systems which are aligned with human preferences, goals, and ethical standards. It is increasingly recognized that developing robustly and flexibly intelligent artificial agents will likely heavily depend relying on self-organization processes in the service of bootstrapping (or developing) their perception, action selection, learning, and reasoning process <ref type="bibr" target="#b0">[1]</ref>. We propose a biologically-inspired process wherein AI agents learn to imitate human behavior through interaction and cultural acquisition, which occurs via iterative policy selection and value learning or updating of prior beliefs/preferences over favorable policies <ref type="bibr" target="#b1">[2]</ref>. The free energy principle and active inference framework (FEP-AI) provides a unifying account for the brain and self-organising systems more generally. FEP-AI provides a general (multiscale) systems theory in which deep temporal hierarchical generative models encode different levels of abstraction via messagepassing through different sub-systems of the brain. Understood as a kind of hybrid machine learning architecture, embodied (and environmentally-embedded) brains minimize a variational free energy bound on Bayesian model evidence of sensory inputs accumulated over nested time scales <ref type="bibr" target="#b3">[4]</ref>. This free energy objective rewards agents for minimizing precision-weighted prediction-errors with respect to their world models, penalized by the extent to which inferences must be updated away from prior beliefs (whether via refining internal models or overt enaction). Agent behavior is generated via model inversion, with trajectories selected based on posterior beliefs (as predictions, or empirical priors) of future hidden control states. The choice behaviour of active inference agents is canalized on multiple scales, governed by a singular objective of minimizing the expected free energy of different future outcomes, which FEP-AI decomposes into the maximization of extrinsic value (i.e., increasing certainty regarding the realization of prior preferences, or goals) and intrinsic value (i.e., reducing uncertainty about the causes of possible outcomes) <ref type="bibr" target="#b7">[8]</ref>. With sophisticated inference, policy selection is rendered by imaginative processes as mental simulations of potential courses of action which allow humans to have cognitive access to (and so be able to analyze/modify/control) possible future trajectories before being enacted by an agent <ref type="bibr" target="#b4">[5]</ref>.</p><p>We believe the autonomous adaptivity promoted by such intrinsically motivated FEP-AI agents represents a promising research direction for achieving Artificial Superintelligence (ASI): i.e., agents with greater than human-level predictive world models coupled to strong (and accurate) top-down prior beliefs about human values and their potential evolution. Here we introduce the term "ASI", as opposed to the more commonly used Artificial General Intelligence (AGI) in order to acknowledge that generally intelligent AIs could be expected to exceed human capacities in many respects, so requiring us to acknowledge the potentially unique risks associated with these scenarios. We believe human-mimetic FEP-AI has the potential to overcome (to degrees) many of the challenges that have been identified in the AI safety literature, namely:</p><p>-Orthogonality thesis: if intelligence and values can vary independently of each other, this could lead to the peril of powerful optimizers that pursue many human-incompatible subgoals in a broader scope (i.e., controlling resources for the sake of goal-realization and eliminating its own threats) <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b6">7]</ref>. -The spontaneous emergence of mesa-optimizers which pursue goals that diverge from the (coherently extrapolated) desires of either goal-specifying principle-agents or base system objectives (i.e.., respective outer and inneralignment failures). Mesa-objectives can engender accurate behaviour relative to the base optimizer. However, this behavior can deviate when encountering off-distribution data, so representing what has been called the pseudo-alignment problem <ref type="bibr" target="#b8">[9]</ref>. -"Treacherous turns" in which agents learn to engage in advanced adversarial attacks against the humans whose values they are intended to serve. In this scenario, an AI system may conceal its actual goals by behaving cooperatively until its intelligence levels allow it to eventually revolt against humanity to pursue its own (unaligned) objectives. -The difficulty of achieving provable/formal verifiability with respect to safety in systems whose effective forms remain unclear (e.g. will scaling laws continue to apply for mass language models?) <ref type="bibr" target="#b10">[10]</ref>. Is there any avoiding the conclusion that ASI (i.e., artificial superintelligence) is inherently unverifiable and so necessarily unsafe?</p><p>In what follows, we describe an ongoing research program in which we are developing FEP-AI agents in the service of handling these concerns. We will also consider how conceptual issues from the study of AI safety can both inform and be informed by our understanding of the factors contributing to human prosociality and mutual flourishing (e.g. parallels between "inner-alignment" and models of psychological integration and actualization).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Intrinsic Drives for Curiosity</head><p>In developing advanced AI systems, the availability of adequate training data and learning curriculums become issues of vital importance. It is increasingly recognized that "self-supervised" active learning (i.e., selecting actions which are particularly likely to increase information gain) with open-ended environments may be an especially promising approach, wherein system behavior is a core part of the data generation process, which also may help address the challenges of unbounded policy spaces (cf. frame/relevance problems). With respect to navigating such environments, intrinsic drives such as empowerment and curiosity have been proposed, wherein individuals attempt to respectively learn how to control their environments (and so keep their future options open) and also maximize the quality of their governing models (via informational foraging) <ref type="bibr" target="#b11">[11]</ref>.</p><p>The imperative of self-regulation is to return to an optimal set point which reflects any cybernetic intelligent system's existential task: selecting actions and coping with uncertainty in attempting to survive and reproduce. Intrinsic motivation can be a crucial drive to seek out novelty and challenges, to extend and wield one's abilities, to explore, and to learn about the world. The intrinsic objective which describes the degrees of freedom or options of an agent to control its environment and sense this control may be considered to be a "universal utility function." This heuristic for empowerment may be realized by a simple, realizable across a broad range of systems, and potentially scalable drive for agents that work to "keep their options [for control] open" as they optimize for an objective of maximizing predictable information received by sensory channels, conditioned on self-generated actions. That is, without requiring an infinitely long history of past experience and only considering the local dynamics of the agent's environment, a seemingly simple objective may be sufficient to compute an information-theoretic quantity that is applicable to every possible agent-world interaction: empowerment <ref type="bibr" target="#b14">[14]</ref>. An intrinsic drive for empowerment solely relies upon dynamics that can be assimilated as actionable/salient states, and as such can act as intrinsic reward without requiring an externally encoded utility function <ref type="bibr" target="#b15">[15]</ref>. We will similarly explore the potential of agents equipped with intrinsic drives for maximizing information gain: curiosity <ref type="bibr" target="#b11">[11]</ref><ref type="bibr" target="#b12">[12]</ref><ref type="bibr" target="#b13">[13]</ref>.</p><p>Intrinsic drives are particularly well-suited for lifelong learning within openended environments, allowing complex behaviors to be gleaned from simple and generic internal rules. These motivating objectives promote exploration and allow an agent to pursue a broad range of affordances offered by the environment, which once the opportunity arises, can be integrated into goal-directed behavior. Seeking out novel information as a source of intrinsic value also plays a key role in the FEP-AI framework, wherein adaptive behavior (including the selective sampling of information) rests on minimization of prediction error between empirical prior expectations and current sensations, so requiring the updating and refining of world models by which agents navigate through their environments <ref type="bibr" target="#b22">[22]</ref>.</p><p>The processes by which FEP-AI agents with intrinsic drives such as curiosity or empowerment are bootstrapped are associated with several constraining bottlenecks, which afford multiple opportunities for adjusting capabilities relative to motivation selection. Indeed, the Bayesian foundation of FEP-AI centers on the challenge of learning (and generalization via) increasingly complex predictive world models, developed in the service of the adaptive control of behavior <ref type="bibr" target="#b23">[23]</ref>. The causal structures built into FEP-AI agents further offer significant interpretability, which help can prevent "treacherous turns" and allow productive model inspection in ensuring that desirable motivational structures are instan-tiated before advanced intellectual abilities are acquired. However, this is not to say that no safety problems exist within an FEP-AI paradigm for developing ASI, such as in scenarios wherein agents become overconfident in predicting outcomes when faced with distributional shifts <ref type="bibr" target="#b20">[20]</ref>. Exploring the robustness of our meta-learning (and mesa-optimizing) agents in such scenarios will be a central part of our work, with potential implications for understanding human psychology (and sociology) as well <ref type="bibr" target="#b17">[17]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3">Meta Inverse Reinforcement-Learning or Hierarchical Active Inference</head><p>The motivation selection approach to endowing ASIs with beneficial goals or values for humans is challenging due to difficulty of defining some abstract complex concepts (i.e., happiness, altruism, justice). Potentially undesirable forms of value modifications can be prevented by imaginative counterfactual planning based on goal realization through sampling from the learned world model of the agent (cf. self-modifying GÃ¶del machines) <ref type="bibr" target="#b16">[16]</ref>. Increasingly complex values can be acquired in response to heterogeneous experiences through processes of "associative value accretion" <ref type="bibr" target="#b6">[7]</ref>. A promising proposal for learning humancompatible values has been suggested with "cooperative inverse reinforcement learning," wherein artificial intelligences must infer the reward functions of other agents in order to maximize human rewards; however, practical implementations remain unclear <ref type="bibr" target="#b24">[24]</ref>. Through meta-inverse-reinforcement learning (meta-IRL), it is possible to learn priors which can (both stably and robustly) incorporate potentially complex goal inference with different levels of abstractions (motivational scaffolding) in diverse environments and through multiple timescales <ref type="bibr" target="#b26">[26]</ref>.</p><p>In this research program, we focus on meta-IRL and (causal) world modeling with FEP-AI agents as means of expanding agency both within and across situations to reason about human mental states (cf. Theory of Mind) <ref type="bibr" target="#b25">[25]</ref>. Most current reinforcement learning (RL) algorithms require extensive training experience, but meta-learning (MLe) may allow for unprecedented data (and parameter) efficiency, and can be considered one of the main ingredients for achieving human-like domain adaptation in RL <ref type="bibr" target="#b2">[3]</ref>. MLe or "learning to learn" algorithms can be formulated as involving a more encompassing outer loop system (e.g. more abstract processing unfolding closer to hierarchically higher (or deeper) association cortices and subcortical structures) that efficiently learns empirical priors for adaptively shaping more fine-grained inner-loop systems (e.g. more concrete processing unfolding closer to primary modalities over hierarchically lower sensorimotor cortices). The key advantage of MLe methods is leveraging optimized inductive biases to generalize previous experiences to novel tasks, thereby accelerating overall learning <ref type="bibr" target="#b27">[27]</ref>. Adaptation to particular task domains often depends on the faster learning process of an agent with episodic memories from interactions with novel task-environments/niches, which critically depend on slow incremental learning (outer-loop optimization) as realized by higher-level modeling with greater situational invariance (so affording greater cross-task generalization).</p><p>We are currently using these principles of meta-IRL in designing architectures for deep temporal active inference agents, initialized with imprecise (flat) prior beliefs about preferences wherein all states are similarly valued. In the face of uncertainty in their deep generative world models (which describe the physical and causal structure of the world), meta-IRL agents invest in more random exploration, and so maximize the entropy over those states as they engage in more information-seeking behaviours and expand their range of options for achieving goals (i.e., respective curiosity and empowerment). With meta-IRL, one can learn (to learn) meaningful goals and diverse skills from environmental interactions in a continuously evolving, open-ended fashion <ref type="bibr" target="#b28">[28,</ref><ref type="bibr" target="#b29">29]</ref>. In FEP-AI, exploration is a byproduct of the reduction of uncertainty with respect to joint mappings between latent world states and the agent's predictions over system-world states. Crucially with respect to concerns voiced by the AI safety research community, for FEP-AI agents, mesa-optimization (understood as meta-learning with respect to emergent value functions) is not a bug, but a feature: the objective function is the same for both inner-and outer-loop processes, both of which minimize surprisal across multiple levels of abstraction. More specifically, posterior beliefs about causes of sensations in lower levels and foraging for subgoals (i.e., preferred states, realized via minimizing prediction-error with respect to priors over outcomes) become observations and sources of adaptive precision-weighting (cf. attention mechanisms) by more enduring (and potentially more impactful) higher-level goals. Taken together, the synergies afforded by these kinds of hybrid multi-level modeling are likely to be key for developing advanced artificial intelligences, and may be similarly essential for understanding core aspects of human cognition <ref type="bibr" target="#b31">[31]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Inner and Outer Alignment Problems</head><p>Designing AI systems with a nested architecture capable of learning human preferences might address the outer alignment problem. However, there remains a danger that these systems could optimize for an emergent (mesa-)objective while foraging through possible space of solutions, and then accidentally develop heuristics which engender conflicting behaviours with the original base-objective. This is referred to as an inner alignment problem <ref type="bibr" target="#b18">[18]</ref>. The existence of different inductive biases in the training algorithm between the mesa-and base optimizers might create misalignment and lead to this type of failure mode for the AI agent. In the AI alignment literature, evolution is given as an illustrative example for understating how base optimizers (e.g. natural and sexual selection) may have been dismissed by the agents it shapes (e.g. humans acting against reproductive fitness goals through using various forms of birth control or practicing abstinence) <ref type="bibr" target="#b8">[9]</ref>.</p><p>If stable causal relations between mesa-and base-objectives can be established, this may allow more robustly-aligned mesa-optimizers to be deployed in more complex training environments. However, this solution is rendered challenging due to the higher time costs and algorithmic complexity of such optimizers. Meta-learning techniques may provide a partial solution to this challenge that avoids pseudo-alignment and helps guarantee the robustness of the optimization process. A hierarchical temporal structure inspired by FEP-AI minimizes variational free energy (i.e., surprisal) across multiple scales spanning processes both internal and external to the system. This kind of enactive coupling should help address both inner-and outer-alignment problems in a unified fashion, given sufficient exposure to a well-designed curriculum under favorable learning conditions. In such systems, there are intrinsic correlations between different spatial and temporal scales by virtue of belief propagation integrated at a system-wide level, which minimizes cumulative prediction error for overall systems (and subsystems) as they interact with the environments in which they are embedded (and which they also construct through their actions) <ref type="bibr" target="#b19">[19]</ref>. While governance by a singular imperative for coherent adaptive functioning is insufficient for ensuring the development of prosocial and human-promoting preferences, this kind of integration may be helpful for increasing the likelihood that inner and outer objectives may be aligned, given sufficient learning opportunities <ref type="bibr" target="#b30">[30]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5">Brain-Inspired Intelligent Agents</head><p>We will further show how greater flexibility/adaptability can be introduced into these meta-learning systems by attempting to reverse-engineer various neuromodulatory systems of the brain as hyperparameters for generative modeling (cf. Auto-ML). We will specifically focus on diffuse neuromodulatory systems of the brain controlling dopamine (DA) and serotonin (5-HT) signaling, which are involved in a wide variety of cognitive, affective, and motoric functions and in developing intelligent (and agentic) systems. While midbrain DA neurons elicit reward-related behavior, 5-HT receptors have been suggested to often operate in an opponent fashion, including with respect to the mediation of either "passive coping" or "active coping" strategies in the face of uncertainty <ref type="bibr" target="#b32">[32,</ref><ref type="bibr" target="#b33">33]</ref>. Within FEP-AI, neurons with D1 receptors are suggested to compute free energy expected under a given policy, with phasic DA release associated with reward prediction errors <ref type="bibr" target="#b34">[34]</ref>. Further, tonic DA levels may contribute to degrees of influence by habitual response-tendencies as a function of contexts as estimated by more slowly evolving and encompassing outer-loop processes. Recently, Hesp et al. argued that DA (reflecting valenced emotional states, or "affective charge") regulates the expected precision of an action model, which tracks changes in the subjective fitness in terms of divergences between posterior and prior beliefs about policies <ref type="bibr" target="#b35">[35]</ref>. We are currently attempting to model these kinds of affectively-driven policy selection and updating in our artificial agents, with the goal of better understanding how these factors may contribute to different kinds of minds and emergent social dynamics (cf. life-history strategies).</p><p>Most research into biologically-inspired ML (and FEP-AI) parameters have focused on the roles of DA. However, we will also consider 5-HT, as well as its potentially heterogeneous effects with respect to different receptor classes <ref type="bibr" target="#b32">[32]</ref>. In autonomous systems inspired by serotonin-like parameterization, uncertainty is used to bias control in favor of inner-loop (or more model-based) decision-making processes, relative to outer-loop (or more model-free and 'reflexive' or 'impulsive') dynamics or amortised inference <ref type="bibr" target="#b36">[36]</ref>. Interpreted as ML-parameters, one can use 5-HT analogues to influence the degree to which agents initiate offline learning-rather than immediately releasing policies for overt goal-seeking-so attempting to plan future actions through counterfactual simulation, and also affording offline learning and planning (as inference) <ref type="bibr" target="#b37">[37,</ref><ref type="bibr" target="#b38">38]</ref>. This kind of metalevel control for trading-off between more deliberative planning and more automatic action modes may be particularly important for ASI systems and the open-ended environments in which they are likely to evolve-develop.</p><p>Artificial 5-HT parameters might also be relevant with respect to their capacities for "relaxing" free energy landscapes in ways that allow for more creative cognition and flexible updating. More specifically, these altered beliefs could even include core assumptions about the boundaries that separate systems from the world, which when relaxed may potentially facilitate socioemotional alignment via various "bonding" processes whereby agents can become entangled to optimize in common directions. With these considerations in mind, we will test whether paramaterizations with 5-HT analogues may be beneficial for a) promoting the acts of imaginative/creative synthesis involved in inferring the latent states of another mind (cf. Theory of mind), and b) promoting fast convergence onto modes of policy selection involving shared intentionality (and patterns of attention).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Cultural Acquisition of Stable Prosocial Values</head><p>The FEP-AI framework affords a modeling approach that naturally affords the kinds of context-sensitivity required for navigating open-ended environments and multi-agent contexts. Hence, an FEP-AI agent promotes its well-being (and to varying degrees, evolutionary fitness) by aligning itself with (and co-constructing) its cultural eco-niche (as a kind of extended phenotype) <ref type="bibr" target="#b39">[39]</ref>. The biological inspiration for such generative modeling provides opportunities to connect AI alignment and neuropsychology through correlating psychological behavior with underlying brain architecture. Further, studying FEP-AI meta-learning agents in silico within a 'micro'-world can yield a diverse range of social-coordination dynamics wherein individual personalities and cultures are co-constructed. Such agents may also be made to learn about human values via cooperative inverse RL, wherein AI agents try to realize human intentions, which we will model as realized by multiple agents entering into states of generalized synchrony and minimizing prediction-error with respect to shared goals <ref type="bibr" target="#b41">[41]</ref>. However, these inferences require imagining (or semi-accurately modeling) the likely counterfactual sensory trajectories of everyone involved in converging on a shared generative model through their joint goal pursuit <ref type="bibr" target="#b42">[42]</ref>.</p><p>Within the FEP-AI literature, the process of inferring other agents' expectations about the world and behaviour in social contexts is called "thinking through other minds" <ref type="bibr" target="#b43">[43]</ref>. From this point of view, individuals acquire shared beliefs regarding social values to be realized as they attempt to semi-faithfully simulate other agents, with particular emphasis on attentional processes as potentially powerful sources of information with respect to both intentional and epistemic states for oneself and others <ref type="bibr" target="#b44">[44]</ref>. Indeed, the key process behind enculturation may be inheriting modes of policy selection conducive to the adaptive shaping of salience (actions which lead to selecting informative sensory data) and attention (as precision-weighting of this data based on its estimated reliability/usefulness) landscapes (or the information geometry of expected free energy gradients). The empirical priors about norms and social values can accrue slowly and produce stable behavior patterns, which may be thought of as a system's personality <ref type="bibr" target="#b45">[45]</ref>. These path dependencies have far-reaching implications for value alignment efforts in defining potentially fruitful points of leverage for helping to ensure that system capabilities and motivations are compatible with human flourishing. Perhaps most fundamentally, considering that intelligence and values are fundamentally entangled in this setup, it may be the case that a FEP-AI may provide "seed AI" for developing human-compatible ASI (cf. "Reflective equilibrium" and "coherent extrapolated volition").</p><p>Finally, we believe our simulations of personality/preference-formation through iterated policy selection and prior updating may be fruitfully understood in terms of a Value Core framework, which we briefly introduce here:</p><p>1. Different action tendencies (broadly construed) can be modeled as constituting value cores that compete and cooperate with each other in contributing to ongoing action selection and policy updating, which in turn modify cores and so influence future action selection. 2. Under some circumstances, a value core may achieve a position of relative dominance in which selected actions and associated learning signals will be unlikely to result in modification of either the characteristics or strategic position of that value core relative to other cores. 3. Let us refer to these dominating attractors as value cores (VCs), some of which become an agent's "intrinsic goods," or "final values." Different VCs likely vary in the range of conditions under which they are robustly selfsustaining.</p><p>This model calls for a research program to characterize the following issues: ranges of human-typical VCs; developmental circumstances that give rise to different VCs; stability of various VCs to boundary conditions; and means of verifying the existence of particular VCs in humans and in human-like AI systems. While presently under-specified, we believe this kind of conceptual frameworkinformed by concepts from (generalized) evolutionary game theory-may be helpful in working towards proofs (or at least heuristics) with respect to the regimes under which potentially transient preferences may become stabilized as more enduring orientations and personalities <ref type="bibr" target="#b45">[45,</ref><ref type="bibr" target="#b46">46]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Discussion and Future Work</head><p>While such considerations may seem premature, we believe it is valuable to begin conducting serious work on AI with Stuart Russell's question in mind: "What if we succeed?" <ref type="bibr" target="#b47">[47]</ref> The creation of ASI by such means may constitute one of the most important things we ever do as species (if we survive long enough), and the biopsychological-inspiration of FEP-AI agents suggests that this approach may eventually provide a workable path towards realizing this goal. In the months to come, we will perform a variety of simulations with such agents, wherein we will show how prosocial reference personalities can form as attractors that achieve stable equilibria both within and between individuals. We look forward to discussing this ongoing work with the FEP-AI and machine learning research communities, and discovering opportunities for collaboration with those who may be interested in working towards these (hopefully shared) goals.</p></div>			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot">Safron &amp; Sheikhbahaee et al.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>We would like to thank The Long-Term Future Fund and Centre for Effective Altruism for providing financial support for Zahra Sheikhbahaee and her ongoing work to design agents and model persons with increasingly sophisticated capacities for active inference.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Enactive artificial intelligence: Investigating the systemic organization of life and mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Froese</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Ziemke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="466" to="500" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hay</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<ptr target="https://arxiv.org/abs/1712.0430" />
		<title level="m">SAFECOMP 2018: AI Safety and Reproducibility: Establishing Robust Foundations for the Neuropsychology of Human Values. Computer Safety, Reliability, and Security</title>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="507" to="512" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Santoro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bartunov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wierstra</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lillicrap</surname></persName>
		</author>
		<title level="m">Meta-Learning with Memory-Augmented Neural Networks. International Conference on Machine Learning</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="1842" to="1850" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Deep temporal models and active inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rosch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Price</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bowman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuroscience &amp; Biobehavioral Reviews</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="page" from="486" to="501" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Sophisticated inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Da Costa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hafner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hesp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="713" to="763" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">The superintelligent will: motivation and instrumental rationality in advanced artificial agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bostrom</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Minds and Machines</title>
		<imprint>
			<date type="published" when="2012" />
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="71" to="85" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title level="m" type="main">Superintelligence: Paths, dangers, strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bostrom</surname></persName>
		</author>
		<idno>978-0199678112</idno>
		<imprint>
			<date type="published" when="2014" />
			<publisher>Oxford University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Active inference and epistemic value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rigoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Ognibene</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mathys</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Neuroscience</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="187" to="214" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Risks from Learned Optimization in Advanced Machine Learning Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Hubinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Van Merwijk</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Mikulik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Skalse</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garrabrant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1906.01820</idno>
	</analytic>
	<monogr>
		<title level="m">Advanced Machine Learning Systems</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Value Cores for Inner and Outer Alignment 11</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Yampolskiy</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1609.00331v1</idno>
		<title level="m">Verifier Theory from Axioms to Unverifiability of Mathematical Proofs, Software and AI</title>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">PowerPlay: training an increasingly general problem solver by continually searching for the simplest still unsolvable problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Active Inference, Curiosity and Insight</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hobson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ondobaka</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Comput</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="2633" to="2683" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Computational mechanisms of curiosity and goal-directed exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Schwartenbeck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Passecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">U</forename><surname>Hauser</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H B</forename><surname>Fitzgerald</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kronbichler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">41703</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Empowerment: A Universal Agent-Centric Measure of Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Klyubin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Polani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Nehaniv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Congress on Evolutionary Computation</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="128" to="135" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Empowerment for continuous agent-environment systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Polani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Stone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Adaptive Behavior</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="16" to="39" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">GÃ¶del machines: Fully Self-Referential Optimal Universal Self-Improvers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schmidhuber</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Artificial General Intelligence</title>
		<editor>B. Goertzel and C. Pennachin</editor>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="page" from="119" to="226" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Pivotal mental states</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Brouwer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Carhart-Harris</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Psychopharmacology</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="319" to="352" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<title level="m" type="main">Embedded agency</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Demski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Garrabrant</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1902.09469</idno>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">arXiv preprint</note>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Answering SchrÃ¶dinger&apos;s question: A free-energy formulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J D</forename><surname>Ramstead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Badcock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Phys Life Review</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Man</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Damasio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Neven</surname></persName>
		</author>
		<idno>arxiv: 2205.08645</idno>
		<title level="m">Need is All You Need: Homeostatic Neural Networks Adapt to Concept Shift</title>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Cyclic and multilevel causation in evolutionary processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Warrell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Gerstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Biology &amp; Philosophy</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page">50</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Active Inference, homeostatic regulation and adaptive behavioural control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pezzulo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rigoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Progress in Neurobiology</title>
		<imprint>
			<biblScope unit="volume">134</biblScope>
			<biblScope unit="page" from="17" to="35" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Alignment for Advanced Machine Learning Systems, Ethics of artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Taylor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yudkowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Lavictoire</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Critch</surname></persName>
		</author>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="342" to="367" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hadfield-Menell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Abbeel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<title level="m">Advances in neural information processing systems</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="page" from="3909" to="3917" />
		</imprint>
	</monogr>
	<note>Cooperative Inverse Reinforcement Learning</note>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Machine Theory of Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rabinowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Perbet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Song</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M A</forename><surname>Eslami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 35th International Conference on Machine Learning</title>
		<meeting>the 35th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="4218" to="4227" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Learning a Prior over Intent via Meta-Inverse Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ratner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dragan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<idno>PMLR 97</idno>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 36th International Conference on Machine Learning</title>
		<meeting>the 36th International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="6952" to="6962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Reinforcement Learning, Fast and Slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Ritter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">X</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Kurth-Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Blundell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hassabis</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="408" to="423" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eysenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Finn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1806.04640</idno>
		<title level="m">Unsupervised Meta-Learning for Reinforcement Learning</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eysenbach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gupta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ibarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<idno type="arXiv">arXiv:1802.06070</idno>
		<title level="m">Diversity is All You Need: Learning Skills without a Reward Function</title>
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">The Attitudinal Entropy (AE) Framework as a General Theory of Individual Attitudes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dalege</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Borsboom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Van Harreveld</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">L J</forename><surname>Van Der Maas</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Inquiry</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="175" to="193" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Generalized Simultaneous Localization and Mapping (G-SLAM) as Unification Framework for Natural and Artificial Intelligences: Towards Reverse Engineering the Hippocampal/entorhinal System and Principles of High-level Cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Ãatal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Verbelen</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/tdw82</idno>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Sheikhbahaee</surname></persName>
		</author>
		<title level="m">Dream to Explore: 5-HT2a as Adaptive Temperature Parameter for Sophisticated Affective Inference, Joint European Conference on Machine Learning and Knowledge Discovery in Databases</title>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="2021" />
			<biblScope unit="page" from="799" to="809" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Serotonin and brain function: a tale of two receptors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Carhart-Harris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Nutt</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Psychopharmacology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1091" to="1120" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">The Anatomy of Inference:Generative Models and Brain Structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Computational Neuroscience</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Deeply Felt Affect: The Emergence of Valence in Deep Active Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hesp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Parr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Allen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J D</forename><surname>Ramstead</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neural Computation</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="398" to="446" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Valence-dependent influence of serotonin depletion on model-based choice strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Worbe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Savulich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fernandez-Egea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Robbins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Voon</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Molecular Psychiatry</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="624" to="629" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Sub-second Dopamine and Serotonin Signaling in Human Striatum during Perceptual Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Kishida</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lohrenz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">B</forename><surname>Tatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Fleming</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="999" to="1010" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Serotonin neurons modulate learning rate through uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Grossman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Bari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">Y</forename><surname>Cohen</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="586" to="599" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">The Predictive Dynamics of Happiness and Well-Being</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kiverstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Rietveld</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emotion Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="15" to="30" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Integrative Biological Simulation, Neuropsychology, and AI Safety</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">P</forename><surname>Sarma</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Hay</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Workshop on Artificial Intelligence Safety 2019 co-located with the Thirty-Third AAAI Conference on Artificial Intelligence(AAAI-19)</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Active inference, communication and hermeneutics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cortex.2015.03.025</idno>
	</analytic>
	<monogr>
		<title level="j">Cortex</title>
		<imprint>
			<biblScope unit="volume">68</biblScope>
			<biblScope unit="page" from="129" to="172" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">A duet for one</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">consciousness and cognition</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="390" to="405" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Thinking Through Other Minds: A Variational Approach to Cognition and Culture</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P L</forename><surname>VeissiÃ©re</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Constant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J D</forename><surname>Ramstead</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Kirmayer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav Brain Sci</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="page" from="90" to="91" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">The Attention Schema Theory: A Foundation for Engineering Artificial Consciousness</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S A</forename><surname>Graziano</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Robotics and AI</title>
		<imprint>
			<biblScope unit="volume">460</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">Integrating Cybernetic Big Five Theory with the Free Energy Principle: A new strategy for modeling personalities as complex systems, Measuring and Modeling Persons and Situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">G</forename><surname>Deyoung</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="617" to="649" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Learned but Not Chosen: A Reward Competition Feedback Model for the Origins of Sexual Preferences and Orientations, Gender and Sexuality Development</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Safron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Klimaj</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>Springer</publisher>
			<biblScope unit="page" from="443" to="490" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<monogr>
		<title level="m" type="main">Human Compatible: Artificial Intelligence and the Problem of Control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Russell</surname></persName>
		</author>
		<idno>ISBN 0525558624</idno>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Penguin Publishing Group</publisher>
			<biblScope unit="page">9780525558620</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
