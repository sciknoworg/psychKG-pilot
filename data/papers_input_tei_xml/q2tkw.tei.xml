<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Blinded versus unblinded review: A field study on the equity of peer-review processes</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Timothy</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Indiana University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ellie</forename><surname>Kyung</surname></persName>
							<affiliation key="aff1">
								<orgName type="institution">Babson College</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gretchen</forename><surname>Chapman</surname></persName>
							<affiliation key="aff2">
								<orgName type="institution">Carnegie Mellon University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Oleg</forename><surname>Urminsky</surname></persName>
							<affiliation key="aff3">
								<orgName type="institution">University of Chicago</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Blinded versus unblinded review: A field study on the equity of peer-review processes</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:40+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>peer review</term>
					<term>double blind</term>
					<term>single blind</term>
					<term>field study</term>
					<term>metascience Characteristic Variable Description</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Blinded review is often proposed as a solution to inequities in merit-based evaluations. We tested this claim in a high-stakes field experiment comparing single-blind review (reviewer identities withheld) and double-blind review (reviewer and author identities withheld) for 530 academic conference submissions. On reliability, both processes showed moderate reliability, leading to only 40% overlap among top-rated submissions. This low overlap indicates that differences between review systems partly stem from noise in the review system. In terms of fairness, our analysis indicates that single-blind reviews favored more senior coauthors and first authors who were Ph.D. students or research scientists, while disfavoring Asian (vs. White) first authors. Meanwhile, male first authors received slightly higher ratings in both conditions (especially under double-blind), but the greater the proportion of male coauthors, the lower the review ratings were under double-blind (vs. singleblind). On validity, we find that for submissions accepted and presented as a talk, neither review ratings nor author characteristics predicted talk quality, number of questions, or attendance. However, review ratings from both systems similarly predicted judged poster presentation quality (for a subset of submissions) and eventual publication (for all submissions). These findings highlight limitations in both single-and double-blind approaches. Doubleblind review is not a cure-all for inequities that might arise via single-blind. Yet, including author identities does not appear to enhance reliability or validity enough to justify the risks this information poses in potentially advantaging a particular individual or group.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Blind review-whether for job, credit or loan applications, legal procedures, or scientific peer review-is often seen as an effective means to help create an equitable merit-based evaluation system <ref type="bibr" target="#b46">(Robertson &amp; Kesselheim, 2016;</ref><ref type="bibr" target="#b38">MacCoun, 2020)</ref>. Generally, blind review occurs when applicant identities like name, position, gender, race, and age, are not provided to the evaluators. But does blinding actually achieve this goal? In hiring decisions, blind review sometimes seems to create a more equitable selection process, helping women and minorities advance in the interview process <ref type="bibr">(Åslund &amp; Skans, 2012;</ref><ref type="bibr" target="#b20">Goldin &amp; Rouse, 2000)</ref>. In peer review, double-blind review-in which both reviewer and author identities are withheld-has been associated with an increase in the representation of women <ref type="bibr" target="#b3">(Budden et al., 2008)</ref> and scientists from less prestigious institutions or organizations <ref type="bibr" target="#b10">(Crane, 1967;</ref>. However, in other cases, blinding has not resulted in broader representation. In some job selection settings, female applicants fared worse with blinded applications compared to non-anonymous applications <ref type="bibr">(Behaghel et al., 2015;</ref><ref type="bibr" target="#b35">Krause et al., 2012)</ref>. Similarly, in peer review, double-blind review does not always promote broader representation compared to single-blind review <ref type="bibr" target="#b9">(Cox &amp; Montgomerie, 2019;</ref><ref type="bibr" target="#b24">Hammerschmidt et al., 2008;</ref><ref type="bibr" target="#b52">Whittaker, 2008)</ref>. These inconclusive patterns persist even in the limited body of randomized experimental research on blind review <ref type="bibr">(Blank, 1991;</ref><ref type="bibr" target="#b42">Okike et al., 2016)</ref>.</p><p>The degree to which a merit-based evaluation avoids systematically disadvantaging any individual or group (fairness) is only one facet of the equity in peer-review-or in any merit-based evaluation system. <ref type="bibr">12</ref> An equitable merit-based evaluation should also yield consistent results across repeated assessments under similar conditions (reliability), and it</p><p>The preregistration for the study can be found on OSF here. De-identified survey data and analyses are at the Open Science Framework: OSF Anonymous Peer Review Link. Due to identifiability concerns, we cannot make the submission data publicly available. We thank Matthew Paronto for helping administer the study, Bob Burnham for programming the submission system, Abigail Bergman for helping collect the publication data, Deepti Poluru for assistance with coding, the anonymous faculty, post-docs, and graduate students who evaluated the talks, and the undergraduate research assistants that diligently collected data on the talks. We greatly appreciate Naveen Vardhineni's work in developing software to count the appearances of authors and institutions in past Society for Judgment and Decision Making conferences and for Apramay Mishra's work in helping check the reliability of those counts. We also thank the Executive Board of the Society for Judgment and Decision Making for the permission to run this study. Our gratitude goes to Drs. Donna Ginther, Ralph Hertwig, and Thomas Wallsten for critical feedback on early drafts of this paper. This project was funded by the National Science Foundation MMS 1824259 to E.K. &amp; T.J.P. T.J.P. was also supported by the Institute for Policy &amp; Social Research at the University of Kansas. Author contributions: Conceptualization: E.K., G.C., O.U., &amp; T.J.P.; Investigation: E.K., G.C., O.U., &amp; T.J.P.; Formal analysis: T.J.P.; Writing: E.K., G.C., O.U., &amp; T.J.P. Correspondence concerning this article should be addressed to Timothy J. Pleskac (e-mail: tpleskac@iu.edu). Version 9.0, <ref type="bibr">03/20/2025.</ref> should accurately measure what they are intended to assess <ref type="bibr">(validity)</ref>. In other words, an equitable merit-based evaluation ought to be fair, reliable, and valid.</p><p>Does anonymous evaluation come at the cost of reliability or validity? Indeed, in discussions about whether to blind reviewers, some may argue that partiality towards specific identities might be justified if those author characteristics are valid proxies of merit-an argument consistent with a belief-or statistical-based model of discrimination <ref type="bibr">(Aigner &amp; Cain, 1977;</ref><ref type="bibr">Arrow, 1973;</ref><ref type="bibr">Bohren et al., 2019;</ref><ref type="bibr" target="#b14">H. Fang &amp; Moro, 2011;</ref><ref type="bibr" target="#b43">Phelps, 1972)</ref>. Beliefs driving these evaluations may reflect accurate statistical associations <ref type="bibr" target="#b30">(Jussim et al., 2016)</ref>. If these beliefs are accurate, then blinding could make merit-based evaluations less valid and potentially less reliable. Alternatively, these beliefs about the validity of specific characteristics being associated with merit may be inaccurate <ref type="bibr">(Bordalo et al., 2016;</ref><ref type="bibr" target="#b16">Fryer et al., 2008;</ref><ref type="bibr" target="#b29">Judd &amp; Park, 1993)</ref>. If these beliefs are inaccurate, then blinding reviewers should not reduce evaluations' validity and reliability. Blinding reviewers might even yield evaluations with greater validity and reliability if reviewers then put more weight on more accurate cues. A third possibility is that partiality toward particular characteristics is preference-based, stemming from in-group biases or negative attitudes toward certain groups <ref type="bibr">(Becker, 1957)</ref>. In that case, assuming preference is not tied to a valid statistical association, blinding again should not affect validity or reliability. In sum, to be complete, an equity assessment in a merit-based evaluation system must consider fairness, reliability, and validity. Yet, when it comes to deciding whether to blind reviewers, there are no published findings on how blinding affects all three of these components within the same evaluations. We set out to address this limitation.</p><p>We report a unique large-scale pre-registered field experiment with conference submissions for the Society for Judgment and Decision Making's (SJDM) 39th Annual Conference. The setting enabled a unique experimental design in which each reviewer was randomly assigned to review submissions in either a single-blind review system or a double-blind review system. Each submission was then randomly assigned to at least three double-blind and three single-blind reviewers, creating a repeated-measures structure that controlled for author and submission characteristics in the single-vs. double-blind comparison. We compared these two review systems on three criteria: reliability, fairness, and validity.</p><p>A head-to-head comparison using our collected data is informative regarding all three criteria. By comparing multiple assessments of the same submission, we can determine how much "noise" is present in the system, how it affects the evaluations, and its ultimate impact on the conference selections. Establishing whether and how one review type might advantage particular groups or individuals can reveal whether and how author characteristics potentially influence evaluations directly (in single-blind) or indirectly (in double-blind). Finally, using relevant outcome data-such as judged quality, talk attendance, and whether the submission was ultimately published-we can test which review system, if either, better predicts those outcomes.</p><p>Our multi-faceted comparison provides a more comprehensive assessment of the equity of single-vs. double-blind review systems than prior research. If single-blind review systematically favors a particular author characteristic while also being more accurate in predicting relevant outcomes than a double-blind review, then this finding would imply the characteristic is a valid proxy for merit (thus favoring single-blind review). Conversely, if a characteristic is favored in single-blind review but there is no difference in the evaluation accuracy between the two systems, that would indicate inequities arising from single-blind review.</p><p>It is also helpful to determine the extent to which author characteristics predict the relevant outcomes. If none do, there is little justification for making individuating information available during the review process. Testing whether these author characteristics are predictive can help clarify the degree to which any differential treatment of author characteristics may reflect accurate beliefs about the statistical association between author characteristics and a submission's merit.</p><p>The setting of our study makes the comparison of single-and double-blind review informative. The SJDM organization is an international society of about 1,800 psychologists, economists, marketing and organizational researchers, decision analysts, and others dedicated to studying judgment and decision making. Thus, the reviewers' expertise and the conference domain make it a near-ideal context to examine how blinding affects expert judgment.</p><p>At the time of the study, the conference used single-blind review to select submissions for talks, but anecdotal evidence suggested that many SJDM members preferred doubleblind review. A voluntary survey of society members supported this belief (see SM Section 2.1 for details on the survey). 3 Overall, when asked to rate their preference on a 1 (strongly prefer single-blind) to 7 (strongly prefer double-blind) point scale, respondents reported a preference for double-blind review from the viewpoint of a prospective author <ref type="bibr">(M = 5.8, [5.5, 6</ref>.1]), reviewer <ref type="bibr">(M = 5.6, [5.3, 5.8]</ref>), or conference attendee <ref type="bibr">(M = 5.4, [5.1, 5.7]</ref>). <ref type="bibr">4</ref> In discussions about why SJDM might persist with single-blind review, some suggested that additional author information might make single-blind review more effective. We suspect similar situations and debates arise in many other organizations that use meritbased evaluations. Our study was designed to address this unresolved question by collecting relevant outcome data and implementing a method to assess the reliability of different review systems.</p><p>The domain of peer review for conference submissions provides an informative setting to study blinding more generally. Merit-based reviews are used in various managerially relevant contexts <ref type="bibr" target="#b38">(MacCoun, 2020;</ref><ref type="bibr" target="#b46">Robertson &amp; Kesselheim, 2016)</ref>. Although our field study took place in the specific context of an academic society's conference, many of its features also appear in other peer-review environments. These features include a group of peer subject-matter experts who evaluate others' work, such as during performance evaluations or project reviews within large businesses or non-profit organizations. Another common feature is that the peer group comes from a relatively large community with many interconnected relations. Consequently, non-anonymized peer review often involves assumptions about demographic characteristics inferred from names, as well as reviewers' impressions of individuals. This situation is common in numerous management contexts. For instance, when an organization solicits outside proposals for a project like developing marketing ma-terials, its marketing personnel may already have professional connections with the outside agencies and their employees.</p><p>Furthermore, our study also included factors such as reputation, professional stature, and prestige, which have been less studied in these contexts. We, therefore, designed this study to identify generalizable principles about the strengths and weaknesses of employing either single-or double-blind review in these evaluative settings. In the discussion, we consider these strengths and weaknesses and offer evidence-based recommendations for organizations interested in using peer review for merit-based evaluations, particularly-but not exclusively-in the context of scientific work.</p><p>An important factor in our setting is that reviewers worked with limited relevant information. Each reviewer evaluated around thirty 600-word submissions within three weeks, typically as an additional responsibility on top of their regular workload. Under these conditions, we might expect reviewers to rely on heuristic cues-such as identities and credentials-to infer work quality <ref type="bibr">(Hertwig et al., 2019)</ref>. Another notable aspect of the setting is the interdisciplinary nature: international scholars with backgrounds in economics, management, marketing, psychology, and other related areas reviewed for the conference and were randomly assigned to submissions (instead of being matched by topic or discipline). Moreover, some topics, like probability theory, utility theory, statistics, and methodology, are mathematically intensive, a characteristic often associated with disparities by gender and race <ref type="bibr" target="#b5">(Ceci et al., 2014)</ref>. As a result, we expect results from our single-vs. doubleblind review comparison to generalize to a wide range of related domains, including those historically marked by such disparities.</p><p>The conference setting also represented a high-stakes environment. With N = 530 submissions for just 108 speaking slots (a 20% acceptance rate), competition for a talkan opportunity with potential career implications-was tight. Presenting at a high-impact conference can increase the chance of publishing the work <ref type="bibr" target="#b21">(Gorodnichenko et al., 2021)</ref> and, for work that is published, ultimately lead to more citations <ref type="bibr" target="#b12">(de Leon &amp; McQuillin, 2020)</ref>. Moreover, many submissions were from authors on the job market, for whom being selected for a talk can be an important signal.</p><p>Finally, the setting also allowed us to address a key methodological challenge in comparing single-and double-blind review: the variability among submissions. Rather than trying to match submissions between single-and double-blind review conditions as is done in a typical audit study <ref type="bibr">(Bertrand &amp; Duflo, 2017)</ref>, or creating artificially matched submissions, as in a correspondence test <ref type="bibr" target="#b28">(Jowell &amp; Prescott-Clarke, 1970)</ref>, we leveraged the fact that multiple reviewers evaluated each submission. We randomly assigned each reviewer to conduct all of their reviews in either the single-blind condition or the doubleblind condition. We then randomly assigned each submission to at least three single-and three double-blind reviewers. Altogether, this design enabled us to directly control for heterogeneity across submissions while using random assignment to isolate the causal effects of single-vs. double-blind review.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>The SJDM Executive Board and the Dartmouth Institutional Review Board approved the study. The preregistration for the study is listed on OSF here. The SMs (SM) document the deviations from the preregistration. De-identified survey data and analyses are available at the Open Science Framework: Blinded OSF Anonymous Peer Review Link. More detailed information on the methods, including the measures used and collected and the procedures are in the SM.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Submissions</head><p>There were N = 530 submissions for possible presentation at the meeting. Submissions had between one and six authors, with an average of 2.8 (SD = 1.0). A total of 26 (5%) submissions had one author, while two-author submissions were the most prevalent, at 218 (41%) submissions. SM <ref type="table" target="#tab_6">Table 3</ref> summarizes the characteristics of submitting authors. In the past, no information was collected beyond authors' names and institutions, so authors submitting work were not expecting to have to enter additional information. To maintain a submission process that was similar to the process of previous years and not raise suspicions of authors, we asked for detailed demographic information of only the corresponding author. For the corresponding authors, we asked for information on gender, race, citizenship, year of Ph.D., area of Ph.D., and position. For the co-authors, we asked for gender and position, and we also have the institution for each author. Asking a corresponding author to submit all of this information on all co-authors would have been a substantial change from previous years. The SM contain a complete listing of all measures and observations that were collected at the time of the submission (SM Section 2.4.1).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reviews</head><p>A total of N = 113 reviewers, selected to be representative of the society's faculty membership, were recruited to evaluate the submissions (see SM <ref type="table" target="#tab_6">Table 3</ref>). One reviewer did not complete their reviews, leaving N = 112 reviewers. The society sent its standard review invitation, which contained no information about the study. Because a larger than usual set of reviewers was recruited, many reviewers had not previously reviewed for the conference (N = 50). Prior reviewers had mostly reviewed between 1 and 2 times previously for the conference (M = 1.5; SD = 1.7). Reviewers were randomly assigned to either the single-or double-blind condition. Each reviewer was asked to review 30 randomly assigned submissions within three weeks of the assignment. Consistent with precedent in the society, in both conditions, reviewers rated each abstract on a nine-point scale from 1 (Poor) to 9 (Excellent). For all analyses, we standardized ratings within each reviewer, consistent with standard SJDM reviewing practice. The SM contain a complete listing of all measures and observations collected from the reviewers (SM Section 2.4.3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Talk Ratings</head><p>We recruited N = 18 faculty and N = 12 doctoral students and post-doctoral researchers (henceforth students) to rate the N = 108 conference talks. We attempted to recruit talk raters who were representative of the society membership (see SM <ref type="table" target="#tab_11">Table 5</ref>). The conference had nine sessions, each with three tracks of four talks per session. Our goal was to have two faculty and two student raters attend each of the talks, giving us full coverage of all the talks. Each faculty member was randomly assigned to rate three sessions to achieve this goal. Specifically, we randomly assigned faculty to one of the three tracks in three of the nine sessions during the conference. Students and post-doctoral researchers were randomly assigned to rate the talks in one of the tracks, in either the first five sessions or the last four sessions of the conference. The SM contain a complete listing of all measures and observations collected by the raters (Section ??).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>We designed the study to keep the submission process consistent with the typical process for the annual meeting (e.g., same abstract length, call for submissions, and review criteria and instructions), adding only the step of randomly assigning half the reviewers to double-blind review. To maintain the experiment's integrity, only the authors of this paper, the SJDM executive board, the NSF program officers, and the NSF grant reviewers were aware of the field experiment. The field experiment was revealed to attendees on the last day of the conference during the morning business meeting.</p><p>The call for submissions was issued on Monday, June 4, 2018, with a deadline of June 22, 2018. Reviewers were recruited soon after the submission deadline. We assigned submissions to reviewers on July 6, with a deadline of July 26, 2018, to submit their reviews. We randomly assigned submissions to reviewers so that at least three double-blind and three single-blind reviewers reviewed each submission. To assess reliability in the different review processes, we randomly assigned N = 53 of the submissions (10%) to three additional double-blind and three additional single-blind reviewers. This design resulted in reviewers rating an average of M = 31 (SD = 1.6) submissions.</p><p>The conference chair (Urminsky) selected 108 talks for presentation at the annual conference based primarily on the average rating (across the single-and double-blind ratings). For the subset of submissions with two sets of single-and double-blind reviews, the chair randomly selected one set of three single-blind and one set of three double-blind reviews to include in the average. Consistent with past conferences, the talks occurred during nine sessions, each consisting of three parallel tracks, composed of four talks each. We assigned two students and two faculty raters to each talk. They independently rated each talk on its significance, methods, results, innovation, and uniqueness, which we, in turn, used to form a composite measure of overall judged quality. We also had two research assistants assigned to each talk. They counted attendance (at five minutes into the talk), the number of hands raised to ask a question throughout the talk, and the number of questions answered.</p><p>Finally, we tracked the publication status of all the submissions via Google Scholar searches and by emailing contact authors for submissions. For each submission, we identified whether a submission had been published in a peer-reviewed journal and the impact factor of the journal as of March 13, 2025 (over 6 years after the conference). For more details on the procedures and all the measures collected, please see the SM (Section 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis</head><p>In general, we take a quantitative approach, focusing on the effect sizes for all the collected variables. Unless otherwise noted, the predictors and outcome variables used in all the regressions were standardized to facilitate interpretation and comparison between regression coefficients. When appropriate, we also report the effects in non-standardized units to help the reader appreciate the practical significance of the effect. We used Bayesian estimation methods for data analysis. We report the posterior predicted mean of the parameter of interest and, in brackets, the 95% Credible Interval (CI). The CI summarizes the posterior distribution, excluding the 2.5% of the distribution at each tail. The values in the CI are the probable values of the effect conditional on the observed data and thus convey the uncertainty around the effects. To highlight particular results, we use the term credible when the 95% CI excludes 0.</p><p>We used model comparison methods using leave-one-out cross-validation (LOO) to make more aggregate-level inferential decisions <ref type="bibr" target="#b50">(Vehtari et al., 2017a)</ref>. These decisions include whether there was evidence of omnibus differential item functioning and differences between single-and double blind review as well as if there were interactions between reviewer characteristics and peer-review condition. The model comparison compared the difference in the expected log pointwise predictive density for a new dataset (elpd loo ) between including a variable (e.g., author seniority) or not. This statistic quantifies the difference between the models in predicting a held-out observation. Generally, we consider |∆elpd loo | &gt; 1 SE to be evidence for a particular model. Thus, for instance, if a model with the interaction between a measured variable and the reviewer condition is favored over a model that does not have the interaction term, then the LOO implies that the interaction term helps predict the difference between single-and double-blind review. In all cases, we used the weakly informative default priors. That is, the priors carried a little information into the analysis, only moderately biasing the parameter of interest toward a particular value, typically 0. This property (i.e., priors skeptical of extreme parameter values) provides moderate regularization of the estimates, which reduces the risk of over-fitting. We inspected MCMC chains for representation and accuracy and sought to have all reported parameters based on an effective sample size of 10,000. Because posterior distributions are independent of the number of planned or unplanned tests, there is no need to correct for the number of posterior distribution tests <ref type="bibr" target="#b17">(Gelman et al., 2012;</ref><ref type="bibr">?)</ref>.</p><p>Further details on the analysis are available in the SM (Section 2.12). All scripts and output from our final analyses are posted on the Open Science Framework.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Power</head><p>Our goal in the field study was a quantitative approach focusing on the effect sizes for all the collected variables. This quantitative approach, combined with our Bayesian methods, implies we are not relying on null hypothesis significance testing but instead focusing on the posterior distribution of effects of interest. To highlight particular results, we used the term credible when the 95% CI excludes 0. Thus, a typical null hypothesis significance testing power analysis where the probability of obtaining a p-value less than .05 is not appropriate. Nevertheless, one can estimate the probability of achieving a particular goal in a Bayesian generalized power-analysis .</p><p>All of our primary analyses and conclusions are based on Bayesian multi-level regressions, which are more powerful than analysis of simple correlations. A power analysis with multi-level regression is not straightforward and entails many assumptions. Thus, we carried out a power-analysis on our lowest-powered statistic: the Pearson correlation r. This power analysis with the Pearson r correlations represents a lower bound to the power in our study. To carry out our power analysis, we simulated datasets with a given population correlation ρ and sample size. We then estimated the posterior distribution over the statistic of interest (either the Pearson r or the difference in Pearson r's) for that simulated dataset. We repeated that 10,000 times. We then tabulated the proportion of times that statistic was identified as credible. We used this proportion as the estimated probability of identifying a statistic as credible for a given sample size and a given correlation ρ or set of ρ's.</p><p>The SM provides a full description of the power analyses we conducted for the Pearson correlations and the difference in the Pearson correlations (see SM Section 2.1). The latter is relevant as we were interested in the differences between single-and double-blind review. Our power analyses revealed that for the analyses focused on the larger set of submissions (e.g., the relationship between a particular author characteristic and the reviewer ratings), samples of data generated with correlations of ρ ≈ 0.15 had approximately an 80% probability or larger of being labeled as credible. For analyses focused on the submissions given as a talk where the sample size was n = 108, the corresponding correlation was ρ ≈ 0.27. Thus, our field study was adequately powered to detect small to moderate associations with our least powerful statistic.</p><p>Many of our questions and hypotheses focused on the difference between single-and double-blind review. With the Pearson correlation, this comparison is at the level of the difference between correlations (∆ρ). Our power analyses revealed that for the analyses focused on the larger set of submissions, samples of data generated with differences in correlations of ∆ρ ≈ 0.20 had approximately an 80% probability or larger of being labeled as credible. For analyses focused on the submissions given as a talk where the sample size was n = 108 the corresponding correlation was ∆ρ ≈ 0.35. Thus, our field study was adequately powered to detect what we might consider small to moderate differences between correlations with our least powerful statistic (see SM Section 2.1).</p><p>To reemphasize, most of our analyses and conclusions are based on more powerful regressions that increase the power of detecting if a variable was credibly associated with a dependent variable of interest. There were several aspects by which our regressions increased the power. First, we used simultaneous regressions controlling for 14 author and submission characteristics and five reviewer characteristics. Second, each submission received at least three single-blind and three double-blind reviews. This property created a within-submission comparison of single-and double-blind review. In our statistical models, we accounted for this via multi-level regressions with submission as a random effect (a random intercept). Because each reviewer reviewed approximately 30 submissions, we also treated the reviewer as a random intercept. Similarly, in the outcome data, the models accounted for the random effects of the session and other variables. Third, we used vague but informed priors to regularize our regressions and results to help guard against overly sensitive analyses of extreme data. Interaction effects in multiple regressions are essentially differences in correlations, so these statements also hold for the interaction effects. For more details on the power analyses, please see the SM (Section 2).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head><p>The first author was also the corresponding author for 456 of the 530 submissions. Because data for many variables (including nationality, race, and Ph.D. area) were only available for the corresponding author, our primary analyses focus on these 456 submissions. When our analyses are not based on author characteristics, we have confirmed that our conclusions with the full set of data are consistent with this subset of data. SM <ref type="table" target="#tab_6">Table 3</ref> presents summary statistics of the authors. We compare single-and double-blind review on three dimensions: (1) review rating reliability, (2) the differential impact of author and submission characteristics, and (3) predictive validity for relevant outcomes such as judged presentation quality, talk attendance, and publication in a peer-reviewed journal.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Reliability</head><p>Reliability of the Average Ratings. We began by analyzing reliability at the submission level, quantifying agreement both within and between single-and double-blind ratings. According to the society's procedures, reviewers were randomly assigned to a subset of submissions, each reviewing an average of 31 SD = 1.6) out of the 530 submissions. Consequently, every submission received at least three single-blind and three double-blind reviews. Also, following conference procedures, decisions were based on the average rating across each submission's assigned reviewers (after standardizing each rater's scores). We, therefore, first examined the reliability of these average overall ratings.</p><p>Between Condition. Across all 530 submissions, the correlation between the average double-blind and single-blind ratings was r = 0.54 [0.48, 0.61] , indicating a moderate level of agreement ( <ref type="figure" target="#fig_5">Figure 1</ref>). However, this agreement depended on the submission's overall quality. A median split on the single-blind rating revealed greater agreement for the bottom half of submissions (r = 0.45, [0.35, 0.54]) than the top half (r = 0.19, [0.06, 0.30]; a credible difference: <ref type="bibr">26, [0.17, 0.29]</ref>). This lower agreement among stronger submissions has practical implications. Of the top 108 submissions-the number ultimately accepted for talks-only 43 submissions (40%, <ref type="bibr">[31,</ref><ref type="bibr">49]</ref>) would have been recommended for talks under both single-and double-blind review, suggesting the conference lineup could differ if the process switched from single-to double-blind. In contrast, there was greater consistency among the bottom 108 submissions (58 submissions in common, 54%, <ref type="bibr">[44,</ref><ref type="bibr">63]</ref>; M diff = 14% <ref type="bibr">[1,</ref><ref type="bibr">27]</ref>), indicating more agreement between reviewers in identifying weaker submissions than stronger ones.</p><formula xml:id="formula_0">M diff = 0.</formula><p>Within Condition. Recall that 10% of the submissions (N = 53) were randomly selected for review by six single-blind reviewers and six double-blind reviewers. We designed the study in this way to evaluate the aggregate-level reliability within each review-type condition. The conference's standard procedure-which also applied here-relies on the average of three reviewers' ratings to make final recommendations. Accordingly, for both single-and double-blind sets that received six reviews, we randomly split the six reviews into two groups of three (Set A and Set B) and calculated an average rating for each. <ref type="figure" target="#fig_5">Figures 1B and 1C</ref> plot these average ratings, again showing a moderate level of reliability. There is not a credible difference between these two correlations (M diff = 0.06 [−0.17, 0.29]), implying the two review processes do not differ in reliability.</p><p>Crucially, the moderate agreement between review systems means that fewer than half of the submissions recommended for a talk under one system would be recommended under the other. The same holds within a single system if the set of reviewers changes. To illustrate, we simulated 530 pairs of normally distributed random variables correlated at r = .63 (the observed agreement in the single-blind condition) and at r = .57 (the observed agreement in the double-blind condition). We then calculated how often each pair fell into the top 108 values for both variables, repeating the simulation 10,000 times. On average, <ref type="figure">Figure .</ref> A: Correlation between ratings from the two review processes. B: Relationship between the reviews for the subset of 53 submissions reviewed by two teams of reviewers in the single-blind condition (inter-rater reliability). C: Relationship between the reviews for the subset of 53 submissions (same set as in B) that were reviewed by two teams of reviewers in the double-blind condition (inter-rater reliability). There is no credible difference between the two conditions. 49% of the pairs in the single-blind scenario and 46% in the double-blind scenario landed in the top 108 for both measures. Given these moderate agreement levels, the conference program could look quite different if the same system were used but the reviewer subset changed. We discuss the implications of this moderate agreement in the Discussion.</p><p>Reliability of the Individual Reviewer Ratings. So far, our reliability analyses have focused on average ratings per submission. Because each reviewer was randomly assigned to only a subset of the 530 submissions, it is challenging to estimate within-system reliability at the individual reviewer level. Indeed, the number of overlapping submissions between any two reviewers ranged from 0 (the median) to 29. Nevertheless, to approximate individual-level reliability, we proceeded as follows. Within each review condition (singleor double-blind), for each submission, we randomly selected two reviews, creating N = 530 pairs per condition. We then computed the correlation between these pairs and repeated this entire procedure 100 times, recording the posterior distribution of correlations at each iteration. In the single-blind condition, the average correlation between individual review scores was M = 0.34, and the average 95% CI was [0.26, 0.41]. For the double-blind review condition, the average correlation between reviews was M = 0.28, and the average 95% CI was [0.20, 0.35]. When we compared the posterior distributions, single-blind review showed a slightly higher correlation on average M diff = 0.06, but these were not credible differences. The average 95% CI for that difference was [−0.05, 0.17].</p><p>Summary. Overall, the averaged reviewer ratings used to evaluate conference submissions showed moderate reliability in both single-and double-blind conditions. At the individual level, reliability was relatively low. We did not find credible differences between the two conditions in terms of overall reliability, but both showed more consensus on lowerrated than on higher-rated submissions, suggesting weaker submissions are identified more consistently than stronger ones.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Fairness</head><p>Our next set of analyses sought to assess whether different review systems might advantage particular individuals or groups. To investigate this, we examined whether author and submission characteristics functioned differently in the two review systems. This analysis drew on the fourteen different characteristics for each submission <ref type="table" target="#tab_0">(Table 1)</ref>. One set of characteristics involved author-related information: the authors' gender, nationality, race, position, number of times the author had appeared in the SJDM program over the past ten years, institutional prestige, years since Ph.D., and Ph.D. area. Institutional prestige was measured using a combination of citation data, the number of times an institution had appeared in the SJDM program in the past 10 years, and survey ratings of the prestige of each institution (see SM 2.8) .</p><p>The second set of characteristics focused on the submitted abstract, drawn from natural language processing tools (see SM Section 3 for details). Briefly, we estimated the abstract's sentiment, which ranged from -1 (negative) to 1 (positive), and identified the abstract's topic using a model based on the Wiley-Blackwell Handbook of Judgment and Decision Making ). The topic model yielded three overarching topics:</p><p>(1) theories, (2) empirical phenomena, and (3) psychology of judgment and decision making. Each abstract was assigned to the topic with the highest posterior probability. We included these characteristics because double-blind reviewers, who lack information about authors, might rely more on the submission's content. If so, submission topics could correlate more strongly with review scores in double-blind than in single-blind conditions. Additionally, including these textual variables helps control for differences in topic or sentiment that might otherwise confound author characteristics.</p><p>Correlations Between Author Characteristics and Review Ratings. The first way we assessed differential item functioning was by examining correlations between the review ratings and each author or submission characteristic in both review conditions. The first two columns of <ref type="figure" target="#fig_0">Figure 2</ref> show similar correlational patterns between review ratings and individual characteristics across the two systems. The only credible difference was that the correlation between average coauthor seniority and review ratings was higher in the single-blind condition than in the double-blind condition (M diff = 0.19 [0.07, 0.33]). This pattern suggests that coauthor seniority functioned differently between the review conditions. Perhaps reviewers partially relied on coauthor seniority, which was unavailable to double-blind reviewers. Next, we examine whether this difference remains once we account for the other author and submission characteristics.</p><p>Simultaneous Regression Analyses. To further examine whether review systems may advantage particular types of individuals or groups, we fit a Bayesian hierarchical re- The correlations with overall talk rating, attendance, and total potential questions were corrected for indirect restriction of range <ref type="bibr" target="#b39">(Mendoza &amp; Mumford, 1987)</ref>. The journal impact factor was log-transformed before computing the correlation. Academic position was treated as a numerical variable in these correlations but categorical in regressions. Correlations for Asian, White, Other, Under Represented, and No Answer were calculated by comparing each group to all others. Under Represented corresponds to Black, Hispanic, and Native American authors-categories with very low numbers of authors (SM <ref type="table" target="#tab_6">Table 3</ref>). The area of Ph.D. and topic from a topic model analyses are categorical variables and are not in these matrices but were entered into the regressions. Empty gray cells indicate that no observations were available to calculate the correlation.</p><p>gression model with the rating of each submission by each reviewer as the outcome variable. This model included review type (single vs. double), all fourteen author and submission characteristics, and the interaction of each characteristic with review type. We treated submission and reviewer as random intercepts. We also controlled for six reviewer charac-teristics (e.g., gender, position, experience; see <ref type="table" target="#tab_0">Table 1</ref>) as covariates. <ref type="bibr">5</ref> Of the N = 530 submissions, N = 26 were single-author, so we replaced coauthor-specific variables with variables for all authors (e.g., the proportion of male authors rather than male coauthors) to include them. 6 Ultimately, N = 440 submissions had complete data for these regression analyses. <ref type="bibr">7</ref> .</p><p>Differences in Item Functioning Between Review Conditions Across Characteristics. We first tested for evidence of any overall difference between review systems across all fourteen characteristics. Specifically, we compared a model that allowed for interactions between each characteristic and review type (DIF Model) to one that did not (No DIF Model). We then compared their LOO statistics. This constitutes a strong test, asking whether it is necessary to jointly account for any systematic difference across all characteristics when predicting the divergence between single-and double-blind reviews. The difference between the No DIF Model and the DIF Model was ∆elpd loo = 6.7; SE = 7.4, favoring the No DIF Model but within the margin of error. Hence, we find little support for an overall difference in item functioning across all fourteen characteristics. However, there may still be differences for specific characteristics, which we examine next.</p><p>Differences in Item Functioning Between Review Conditions for Specific Submission Characteristics. We next tested for differential item functioning at the level of each individual or submission characteristic, while controlling for the others (SM <ref type="table" target="#tab_0">Table 11</ref>). The key statistics of interest were the interactions between each characteristic and the review condition. Five author characteristics showed differential relationships across single-and double-blind review: first-author gender, proportion of male coauthors, firstauthor race, first-author position, and coauthor seniority.</p><p>Regarding first-author gender, we found a credible interaction between the author being male (vs. female) and the review condition (β = 0.225, [0.043, 0.408]). To clarify this weak interaction, we ran separate regressions for single-and double-blind reviews (SM <ref type="table" target="#tab_0">Table 13</ref>). In single-blind review, male first authors received a 0.172 [−0.008, 0.352] higher rating (in SD units) than female first authors. In double-blind review, this difference was 0.383 <ref type="bibr">[0.197, 0.567]</ref>. Thus, in both review conditions, male first-authored submissions received higher ratings, but the difference was larger in double-blind review. Although these effects are not large, we note that they control for factors such as sentiment, topic, prestige, and other author attributes. Nevertheless, we urge caution in over-interpreting this effect. We did not anticipate this slight boost for male-first-authored submissions in double-blind review and return to this issue in the Discussion. Moreover, the pattern for coauthors differs from that of first authors, as discuss next.</p><p>In terms of the proportion of male authors, there was a credible interaction with review condition (β = −0.107, [−0.200, −0.016]), indicating that the proportion of male authors functioned differently between single-and double-blind reviews. When we looked exclusively at multi-author papers <ref type="table" target="#tab_0">(Table 12)</ref>, the interaction persisted but was smaller. Separate regressions showed that, under double-blind review, there was a negative relationship between the proportion of male authors and review ratings (β = −0.145 [−0.237, −0.050]), whereas in single-blind review, this relationship was weaker and non-credible (β = −0.045 [−0.137, 0.047]). 8 Again, revisit these gender-related findings in the Discussion.</p><p>First-author race/ethnicity also functioned differently across conditions. We coded the first author's race/ethnicity into seven categories (Asian, Black, White, Hispanic, Native American, Other, Race Not Available). We entered race as a categorical variable, with White as the reference group. The analysis revealed a credible interaction between the review condition and whether the first author identified as Asian (vs. White) (β = 0.166, [0.005, 0.328]). Separate regressions for single-and double-blind review reveal that the interaction arises because Asian first authors received, in SD units, 0.101 [−0.068, 0.268] higher ratings than White authors under double-blind review but were rated −0.070 [−0.234, 0.090] SD lower under single-blind review. As we will discuss later, these differences for Asian first authors are consistent with past results where Asian first authors were less likely to receive federal grants <ref type="bibr" target="#b19">(Ginther et al., 2011)</ref> and potentially fewer call backs in inquiries about graduate study <ref type="bibr" target="#b41">(Milkman et al., 2012)</ref>.</p><p>We also found that first-author position (rank) operated differently between review conditions. Specifically, there was a credible interaction for Ph.D. students (vs. Lastly, coauthor seniority functioned differently across conditions, in line with the correlations shown in <ref type="figure" target="#fig_0">Figure 2</ref>. There was a credible interaction between the review condition and the average seniority of authors (β = −0.088, [−0.168, −0.007]). This interaction was also present for multiauthor submissions. The interaction arises because in single-blind review, for every rank increase among coauthors (e.g., from Associate to Full Professor), there was a 0.192 [0.091, 0.293] SD increase in the review rating. Under double-blind review, this effect was smaller and non-credible (M = 0.071, [−0.033, 0.173]). These estimates control for other author attributes (gender, prestige), submission sentiment, topic, and reviewer characteristics. We revisit the implications of these seniority effects in the Discussion.</p><p>Summary. Comparing single-and double-blind review revealed that, although there was no overall (omnibus) evidence of differential item functioning across all four- Bolded values indicated that credible intervals exclude 0. Num. Questions are the number of hands raised for questions during the talk. All continuous variables were standardized, and the impact factor was log-transformed. When analyzing conference outcomes, the conference session was entered as a covariate. When analyzing publication outcomes, conference presentation (1 or 0) was entered as a covariate. The coefficient for the Rating × Condition Interaction is from a model where the outcome was regressed onto the review rating, the condition, and the interaction. The regressions predicting "published" as an outcome are logistic regressions, while all other regressions use a normal link function.</p><p>teen characteristics, certain characteristics did indeed function differently. In particular, single-blind review appeared to favor submissions with more senior coauthors, as well as first authors who were Ph.D. students or research scientists, while disfavoring Asian (vs. White) first authors. Meanwhile, male first authors received somewhat higher ratings in both conditions (more so in double-blind), but proportion of male coauthors had a stronger negative relationship with ratings under double-blind than under single-blind. These review ratings inform decisions about whether a submission is presented as a talk, a poster, or is rejected. A pertinent question is whether these evaluations effectively identify high-quality submissions. Another is whether any of these author or submission characteristics correlate with overall quality, which might explain their relationships with review scores when provided to reviewers. We turn next to an assessment of how both single-and double-blind ratings, as well as these author/submission characteristics, predict relevant outcomes such as judged talk quality, talk popularity, and subsequent publication.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Validity</head><p>Predictive Validity of Review Ratings. Our final set of analyses focused on the predictive validity of review ratings for outcome variables reflecting the judged quality of the conference talk and future publication potential. Specifically, we collected talk attendance, number of audience questions, expert assessments of talk quality, expert evaluations of a subset of posters (N = 56) in the student-poster competition, and publication status six years later. We first tested whether submission reviews (single-or double-blind) predicted conference talk outcomes. After excluding one canceled talk, we analyzed 107 accepted talks. We accounted for conference session differences by entering session as a predictor in these models. Among these, submission ratings did not credibly discriminate between higher-and lower-quality talks in terms of expert-judged talk quality, attendance, or number of audience questions <ref type="table" target="#tab_1">(Table 2</ref>; bottom two rows of <ref type="figure" target="#fig_0">Figure 2</ref>). 9</p><p>Because talks were primarily selected based on these review ratings, a range restriction issue arises, limiting our ability to assess predictive validity using the talks themselves. We worked to address this in several ways. The correlations in <ref type="figure" target="#fig_0">Figure 2</ref>, which adjust for range restriction, suggest that restricted range does not fully explain the lack of predictive validity. However, looking at other outcome measures reveals some predictive validity. Both singleand double-blind ratings credibly predicted poster ratings to a similar degree. Because posters and talks were evaluated with similar measures, we combined expert judgments of both to produce a larger sample of evaluated submissions. Both single-and double-blind ratings credibly predicted these combined judgments, and their predictive validity did not differ ( <ref type="table" target="#tab_1">Table 2)</ref>.</p><p>We also examined whether submissions were published within six years of the conference. Of the 530 submissions, 276 (52%) were published in a peer-reviewed journal. Controlling for conference presentation, both single-and double-blind ratings credibly predicted whether a submission was eventually published. However, there was no credible difference between review types in predicting publication <ref type="table" target="#tab_1">(Table 2)</ref>. Among the published papers, we also asked whether review scores predicted the (logged) Web of Science journal impact factor. Neither single-blind ratings nor double-blind ratings credibly predicted the impact factor. Thus, we did not find any credible difference in predictive validity between single-and double-blind review scores for any of our measured outcomes.</p><p>Predictive Validity of Author and Submission Characteristics. Finally, we tested whether any author or submission characteristics predicted these outcomes. A common rationale for single-blind review is that author identities or credentials may provide valid predictive information. For instance, if submissions with senior coauthors represent better research, incorporating such signals could enhance conference quality. Yet, no single author characteristic exhibited a strong, consistent predictive relationship across all outcomes (see the top 16 rows of <ref type="figure" target="#fig_0">Figure 2</ref> and SM <ref type="table" target="#tab_0">Table 16</ref>). One noteworthy finding emerged for average author seniority: for every rank increase (e.g., Associate to Full Professor), there were 11.8 [2, 21.5] fewer attendees (SM <ref type="table" target="#tab_0">Table 17</ref>). This decrease in attendance for higherranked coauthors is notable given that single-blind review tended to favor submissions with more senior coauthors.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Blind review is often discussed as a mechanism to level the playing field, creating more equitable, merit-based evaluations across a range of domains, including employment, legal cases, and science <ref type="bibr" target="#b46">(Robertson &amp; Kesselheim, 2016)</ref>. However, prior studies examining the effectiveness of blind review have produced mixed results-even in the few randomized experiments that have been conducted. Moreover, none have tested the impact of blinding on the validity and reliability of merit-based evaluations. Our high-stakes field experiment addressed these gaps by comparing single-and double-blind review head-to-head in a realworld context. Specifically, we assigned reviewers and submissions randomly to one of the two review systems, thus allowing us to account for heterogeneity among submissionsan issue that has limited past comparisons-and to pinpoint similarities and differences between the processes in situ.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Similarities Between Single-and Double-blind Review</head><p>Overall, our field study revealed that single-and double-blind review were similar in many respects. Both review systems exhibited comparable predictive validity. Each was quite limited in terms of predicting conference outcomes like judged talk quality and attendance. But both also showed some ability to predict a limited set of poster ratings and publication six years later. In addition, the two review systems showed similar levels of reliability. At the individual-reviewer level, reliability was low-consistent with some prior findings <ref type="bibr" target="#b0">(Bornmann et al., 2010;</ref><ref type="bibr" target="#b15">Fiske &amp; Fogg, 1992</ref>; Lawrence, 2015)-but not as low as others have suggested <ref type="bibr" target="#b44">(Pier et al., 2018)</ref>. Recognizing that reliability improves when judgments are averaged, the society's standard procedure uses the mean of three reviewer ratings for each submission. Nevertheless, these averaged ratings displayed only moderate reliability in both single-and double-blind conditions.</p><p>This moderate reliability level still carries significant implications. Single-and doubleblind reviews were only moderately correlated, such that the two systems agreed on 40% of the submissions recommended for acceptance as a presentation. Within each system, the agreement was only slightly higher; as we showed, if the conference repeated the same review process (e.g., single-blind) but with different reviewers, fewer than 50% of the same submissions would receive consistent acceptance recommendations. In other words, due purely to random noise in the process, either switching from single-to double-blind or re-running reviews under the same system could lead to over half of the conference presentations changing.</p><p>One perhaps underappreciated implication of this level of reliability is that it implies that observed differences in review outcomes may sometimes reflect general noise in the evaluation process rather than systematic biases or methodological flaws. In other words, it underscores how crucial it is for any merit-based evaluation to measure its reliability and develop strategies to mitigate noise <ref type="bibr">(Arkes et al., 2006;</ref><ref type="bibr" target="#b31">Kahneman et al., 2021)</ref>. While human judgment is frequently blamed for such noise, there are additional sources. For example, in our setting, reviewers each encountered distinct subsets of submissions, which may itself introduce variability that is not purely attributable to the subjectivity of individual reviewers. Pinpointing these different sources of noise is critical to improving the consistency-and ultimately the fairness-of merit-based reviews.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Differences Between Single-and Double-blind Review</head><p>The low-to-moderate overall reliability may help explain why we found clear evidence of differences in only a few author characteristics between single-and double-blind review. Nonetheless, five such variables did function differently across the two systems: first-author gender, coauthor gender, first-author race, first-author position, and coauthor seniority or position. Together, these patterns suggest a more nuanced picture of single-and double-blind review. In particular, our data indicate that the same characteristic (e.g., gender or position) can operate differently for first authors than it does for coauthors, underscoring both the strengths and the weaknesses of each review condition. Moreover, these differences-especially those involving first authors versus coauthors-may highlight some limitations of our study. We discuss these issues next in terms of three broad characteristics that showed meaningful variation between single-and double-blind review: race, gender, and seniority.</p><p>Race. Controlling for 13 other author and submission characteristics, including whether the author was a U.S. citizen or not, Asian first authors received a higher review rating (0.17 SD units) than submissions with White first authors in double-blind review compared to single-blind review. These results are consistent with other evidence that scientific submissions by Asian authors may be disadvantaged in unblinded evaluations. For instance, grant applications to the National Institutes of Health with Asian investigators were 3.9 percentage points less likely to be funded than those by White investigators <ref type="bibr" target="#b19">(Ginther et al., 2011)</ref>. Similarly, hypothetical prospective doctoral students with Chinese or Indian names were substantially less likely to get a response and/or a meeting from a prospective faculty mentor, especially when requested at a later date <ref type="bibr" target="#b41">(Milkman et al., 2012)</ref>. A strength of our study is that we also have outcome data for at least some of the submissions, allowing us to better understand the potential mechanisms behind these differences and the consequences. Across the board, papers with Asian first authors did not have better or worse conference or publication outcomes than papers with any other race of first author. This pattern of results implies that single-blind reviews may be impacted by miscalibrated beliefs or a dispreference for submissions by Asian first-authors, while double-blind review may result in more equitable merit-based evaluation.</p><p>However, more data is needed to assess the consequences of review type by race more thoroughly. Our initial pre-registration did not include race and ethnicity as a predictor because we did not expect to have enough diversity in submissions to examine this question. Indeed, there were only a few submissions at this conference from authors who identified as Black, Hispanic, or Native Americans (SM <ref type="table">Table ?</ref>?). The wide posterior distributions of the effect sizes reflect the low numbers for these race and ethnicity groups (see for example SM Tables ??, ??). These low numbers of submissions reveal a potentially deeper issue, the limited diversity of the people actively engaged in the science of judgment and decision making. This is a general issue throughout science, sometimes referred to as the pipeline problem (Allen-Ramdial &amp; Campbell, 2014; <ref type="bibr" target="#b2">Brown et al., 2016;</ref><ref type="bibr" target="#b18">Gibbs Jr et al., 2014)</ref>. The results of our study suggest that double-blind review may help by reducing inequities that may occur in single-blind peer review, and because people may perceive double-blind review as fairer (as our survey results suggest), can promote engagement with an organization.</p><p>Gender. We also found that gender functioned differently in the review ratings for single-and double-blind review. Male first authors received higher ratings than female first authors under double-blind review relative to single-blind review. Meanwhile, the proportion of male coauthors showed a distinct pattern. Across both review systems, submissions received lower average ratings as the proportion of male coauthors increased, an effect that was strongest in the double-blind condition. There is no strong evidence of a correlation between first-author gender and the proportion of male coauthors such that male first authors tended to team with female coauthors or vice versa, if anything, the correlation is slightly positive (r = 0.08 [−0.01, 0.17]; see SM <ref type="figure">Figure ?</ref>?). <ref type="bibr">10</ref> We urge caution in interpreting specific gender effects. The magnitudes of these gender-related differences were small and, given the opposing directions for authors and coauthors, could be spurious. Moreover, past work has also yielded mixed findings: in some contexts, such as journal peer review, female authors fared better under double-blind review than under single-blind <ref type="bibr" target="#b3">(Budden et al., 2008)</ref>, whereas in others-including grant applications <ref type="bibr" target="#b33">(Kolev et al., 2019)</ref> and job applications <ref type="bibr">(Behaghel et al., 2015;</ref><ref type="bibr" target="#b35">Krause et al., 2012)</ref>-women fared worse under double blind than under single blind evaluation.</p><p>With these cautions in mind, our results may help narrow in on the underlying mechanism. We did not find that gender predicted any positive outcome measure, which would tend to rule out a "calibrated belief" interpretation of differential functioning in the reviews. Instead, our results tentatively point toward a preference-based account. One explanation builds on the notion of masculine defaults, in which certain perspectives or approaches are more highly valued in the field <ref type="bibr" target="#b7">(Cheryan &amp; Markus, 2020)</ref>. Because first authors typically drive the project (e.g., developing research questions, executing the study, writing the submission), these defaults may yield an overall positive impression across review conditions. Yet single-blind reviewers might attempt to offset gender inequities by tempering their ratings for male first authors, potentially motivated by a goal of balanced representation (see also <ref type="bibr" target="#b53">Williams &amp; Ceci, 2015)</ref>.</p><p>If this dynamic, where reviewers offset potential inequities, is in play, double-blind review could inadvertently reduce the visibility of certain perspectives or work correlated with gender, potentially hindering attempts at improving equity. These considerations underscore the importance of carefully designing and implementing review systems. Above all, our complex pattern of results indicates that far more research is needed to understand how gender might shape merit-based evaluations, and it tempers broad claims in favor of either review system.</p><p>Position and rank. A third set of variables that functioned differently between single-and double-blind review involves position and rank. Similar to gender, we found that these effects varied by the author's specific role. In particular, single-blind review favored submissions with more senior coauthors, whereas under double-blind review there was no credible relationship between coauthor seniority and review ratings. At the same time, compared to full professors, first-author Ph.D. students and research scientists received more favorable evaluations under single-blind (vs. double-blind) review. Notably, the different functioning of coauthor seniority between single-and double-blind emerged in both simple correlations and in regressions controlling for other factors (e.g., gender, years since Ph.D., institutional prestige, number of past conference appearances). Still, the differing patterns for first authors and coauthors warrant caution in interpreting these findings.</p><p>The seemingly parallel results for gender suggest that similar mechanisms may be at work, wherein seniority-and the perspectives or approaches it represents-is more highly valued. This dynamic can lead to a Matthew Effect <ref type="bibr" target="#b40">(Merton, 1968)</ref>, in which submissions involving eminent scientists as co-authors receive disproportionate credit. Conversely, the more favorable ratings for Ph.D. students and research scientists as first authors may, as with our gender findings, reflect an attempt by single-blind reviewers to counter potential inequities and foster a broader range of voices.</p><p>Overall, these results underscore that deciding between single-or double-blind review for merit-based evaluations is not straightforward. In the case of position and rank, adopting double-blind review might avoid systematically favoring senior coauthors, but it could also disadvantage more junior first authors. As we discuss later, better understanding the mechanisms behind these effects can help inform the choice of review system. We also emphasize that our test was conducted in a single field study conducted in a specific context, and further research is needed before drawing strong conclusions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Constraints on Generality and Limitations</head><p>Our study and results stem from a single, unique field experiment comparing singleand double-blind review for selecting talks at the Society for Judgment and Decision Making's annual meeting. Several features make these findings potentially informative beyond this conference. First, the 20% acceptance rate and associated benefits of presenting (e.g., career implications, higher publication likelihood) underscore the high stakes of the selection process. Second, the interdisciplinary nature of the conference-which includes mathematically intensive topics (e.g., statistics, computational modeling, game theory)-is often linked with gender disparities <ref type="bibr" target="#b5">(Ceci et al., 2014)</ref>, making our results relevant for other fields with similar challenges. Third, we addressed common limitations in prior studies by measuring a range of factors (e.g., reputation, professional stature, prestige) and by collecting both single-and double-blind reviews for every submission, thus controlling for variability across submissions.</p><p>For these reasons, we believe our findings hold relevance for the peer review of scientific work, particularly in the social, behavioral, and economic sciences, and may generalize to other merit-based evaluations in managerial contexts. As discussed earlier, our field setting involved a community of subject-matter experts who are relatively large in number yet interconnected-features present in many evaluation processes (e.g., product reviews, job or credit applications, legal cases).</p><p>Nonetheless, important limitations remain. Our field experiment was conducted at one specific academic society's conference in judgment and decision making at one point in time (2018); different disciplines, conference sizes, or types of evaluations could yield other patterns. We measured numerous author, submission, reviewer, and presentation characteristics <ref type="table" target="#tab_0">(Table 1)</ref>, but unmeasured factors (e.g., social networks, methodological features, writing style) may also influence ratings. Our study is, to our knowledge, the first to examine the predictive validity of different review systems. This imposes its own constraints: certain outcomes (e.g., talk quality, attendance) were only observable for accepted submissions, limiting variance and possibly masking stronger effects if every submission had been presented. We addressed this in part via range-restriction corrections and by examining poster ratings and publication outcomes, yet the restricted sample remains a concern.</p><p>Finally, the outcome measures themselves have limits. Judgments of talk and poster quality are subjective, though we attempted to mitigate bias via structured rubrics, rater training, and multiple assigned reviewers. Moreover, while attendance, expert ratings, and publication are meaningful measures, they do not capture other important dimensions such as methodological rigor, theoretical novelty, or long-term impact. As with any single-context field study, our findings should be interpreted with these caveats in mind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Evidence-based Recommendations for Blinding Merit-based Evaluations</head><p>Acknowledging the study's limitations, we highlight two surprising findings that call for rethinking how peer review, particularly blinded review, should inform decision making. First, single-and double-blind review were more similar than expected in terms of validity and reliability. Second, we did not anticipate that single-blind reviews would show less favoritism toward male-first-authored submissions while simultaneously favoring some earlycareer researchers. These results suggest that, despite the greater perceived fairness of blinding, its practical consequences may be more nuanced than its advocates presume. Some might even argue that our findings support the use (or continued use) of non-anonymous (single-blind) review: not only were single-and double-blind reviews similar, but doubleblind review may prevent reviewers from adjusting for potential partialities toward specific groups (e.g., a slight bias favoring men in our data).</p><p>We urge caution, however. First, some evidence indicates that reviewers' ability to correct or counteract a partiality for a given characteristic may fail to materialize if that characteristic is perceived as a valid predictor of merit (e.g., senior coauthors) <ref type="bibr" target="#b45">(Rabinovitch et al., 2020)</ref>. Second, single-blind review in our study did favor submissions with more senior coauthors and disadvantage Asian authors-patterns not justified by our outcome data. Third, even if single-blind review continues, our survey found that some society members viewed single-blind review as less fair than double-blind review (β = 0.54, [0.42, 0.65]), suggesting that such perceptions of unfairness can undermine organizational satisfaction, commitment, and citizenship behaviors <ref type="bibr" target="#b34">(Konovsky, 2000)</ref>. In contrast, evaluations perceived as fairer can help organizations attract underrepresented groups and address persistent demographic challenges <ref type="bibr" target="#b1">(Branscombe et al., 1999;</ref><ref type="bibr" target="#b6">Chapman et al., 2005;</ref><ref type="bibr" target="#b47">Ryan &amp; Ployhart, 2000)</ref>.</p><p>Fourth, if single-blind review is justified on the grounds that it allows reviewers to correct for partialities, there may be better methods to achieve those goals than relying on ad hoc reviewer adjustments. For instance, more transparent processes-such as invited submissions or speakers-can be deliberately structured to promote gender or advance other under-represented groups. Finally, since the author information visible during single-blind review did not consistently predict the set of measured outcomes we collected, it is unclear why reviewers should consider data that do not improve the identification of merit but could enable biases <ref type="bibr">(Biernat et al., 1991)</ref>. It is possible that other information related to an author's reputation may be predictive, such as the rigor of an author's past work or their ability to give good talks. Due to data limitations in our setting, these questions are left for future work.</p><p>Our results also imply that double-blind review is not a cure-all for the limitations of single-blind peer review. The slight boost that male-authored submissions received under double-blind review illustrates how blinding can leave certain systemic hurdles unaddressed and, at times, disadvantage particular perspectives. Consequently, organizations adopting double-blind procedures might also track demographic and outcome data to identify and mitigate lingering biases. When the goal is to enhance equity, not merely equality, organizations could begin with a double-blind process, then make targeted adjustments for individuals or groups at a disadvantage due to systemic factors.</p><p>A more novel approach would be to deploy double-blind review in tandem with considerations of the evaluation's reliability. If a review system exhibits minimal reliability, one could forgo peer review altogether and rely on a lottery <ref type="bibr" target="#b48">(Thorngate et al., 2010)</ref>. However, we observed moderate reliability, including a credible link between review ratings and publication outcomes six years later. Further, reviewers agreed more readily on weaker submissions than on stronger ones (see also <ref type="bibr" target="#b8">Cortes &amp; Lawerence, 2021)</ref>. This pattern suggests a hybrid or informed lottery approach: use double-blind review to identify "meritorious" submissions-those clearly above a threshold-while filtering out uninformative or biased indicators, then randomly select final acceptances from among these meritorious submissions (see also F. C. <ref type="bibr" target="#b13">Fang &amp; Casadevall, 2016)</ref>. Such a design leverages double-blind peer review's relative strength in identifying weaker work, fosters a more equitable playing field for scholars, and could even foster scientific evolution <ref type="bibr" target="#b27">(Hull, 1988)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>Adjusted double-blind review and an informed lottery are certainly not the only possible mechanisms for merit-based selection. Other processes may rely on statistical models, either standalone or integrated with human judgment in a hybrid framework <ref type="bibr" target="#b11">(Dawes et al., 1989)</ref>. Nonetheless, our study underscores the value of moving beyond default selection practices. Instead, we recommend an evidence-based approach, using head-to-head comparisons of alternatives-ideally supported by experimentation in the specific setting where they will be adopted <ref type="bibr" target="#b22">(Goswami &amp; Urminsky, 2020)</ref>. Policy decisions should weigh each procedure's validity, reliability, and fairness to reduce unwarranted barriers to equity. This may require periodic revision of the review process. Indeed, at the Society for Judgment and Decision Making, our findings led to new demographic data collection for author submissions and society membership, along with a transition from single-to double-blind review for conference submissions. We encourage all organizations employing merit-based evaluations to conduct a similar appraisal of their own practices.</p><p>Although our investigation focused on a relatively formal and structured peer-review system, it can also inform less formal evaluation settings where interconnected peers assess future performance with limited information. Our findings suggest that these processes often contain considerable noise, meaning that outcomes that appear linked to structural changes may, in fact, stem from low reliability. Moreover, both anonymized and non-anonymized peer review entail distinct tradeoffs. Non-anonymized (single-blind) review can produce multiple, simultaneous effects: favoring individuals and institutions with established reputations, disadvantaging certain underrepresented groups that may be inaccurately deemed lower in quality, yet not disadvantaging-or even favoring-other groups whose equitable treatment is more salient. Such differential treatment can grow extensive enough that subsequent outcomes, even with more complete information, might not justify it. Meanwhile, anonymized (double-blind) review can limit reviewers' ability to adjust for partialities they wish to correct. Overall, our findings highlight the fundamental limitations of evaluations based on partial information: accuracy is likely to be low, and incorporating individuating details that do not improve predictive validity risks impacting fairness without meaningfully enhancing accuracy. Supplementary Material for "Blinded versus unblinded review: A field study on the equity of peer-review processes"</p><p>Timothy J.    </p><formula xml:id="formula_1">Contents 1 Preregistration 2 1.1 Deviation 1 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.2 Deviation 2 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.3 Deviation 3 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.4 Deviation 4 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1">Preregistration</head><p>The study was pregistered. We filed it on July 18, 2018. This was done after the submissions were collected, but before sending the submissions out for review. It can be found at the OSF at this link: OSF Peer Review Link. There are eight deviations from the pre-registration that we should note here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1">Deviation 1</head><p>The first deviation was in analyzing the reviewer ratings. We planned to use the following abstract characteristics in the analyses: disciplinary area, number of studies included, word count, and keywords. We deviated from the plan as the disciplinary area was not asked, and it was not feasible to classify authors ex-post. The number of studies was not a useful statistic due to the heterogeneity in the submissions: some studies had zero studies and some were not empirical studies. In terms of word count, nearly all the abstracts were 600 words, and thus, there was little to no variability. Finally, in terms of keywords, although authors were given a list of keywords, authors often chose their own unique set of keywords. Moreover, to use the keywords, we needed a method to group and classify them. To do this, we turned to methods from Natural Language Processing, and once we did this, it seemed a better measure of the topics was to model the text of the long abstract directly. Thus, we used the topics model of the abstract as an indicator of key topics (Section 3). We also included a measure of the sentiment of the abstract. The results reported in the paper are unchanged with the sentiment variable excluded from the models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2">Deviation 2</head><p>The second deviation was in the measure of the judged talk quality. Our initial plan was to have the talks rated on importance, methodological quality, persuasiveness, originality, organization, and degree of match between short and long abstracts. As we finalized the talk rating instrument, we modified the dimensions to include significance, methods, results, conclusion, innovation, and uniqueness. We found these dimensions to be more straightforward to rate. Moreover, in the final analysis, we averaged across these ratings and across all the raters to achieve a reliable measure of judged talk quality. By collapsing across raters, we did not include rater characteristics in the ratings. However, all ratings were standardized among raters, which should help minimize differences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.3">Deviation 3</head><p>The third deviation was that initially, we did not plan to include race and ethnicity of the authors in the regressions as we did not expect sufficient numbers in each race and ethnicity category, though we did collect this information. Our expectation was due to the fact that our race and ethnicity categories had to reflect the international status of the society, and thus, there were many categories. After the first round of review of the paper, reviewers suggested that this variable be included. To include the variable, we grouped different categories. For instance, we created one group we referred to as Asian or of Asian descent that included people who reported being "Arab, Caucasian, White or European", or "Asian, Caucasian, White or European", "Asian", "Asian, Caucasian, White or European, Other (please specify)", or "Asian, Other (please specify)". In total, we created 7 groups: "Asian", "Black, African, or African American", "Hispanic or Latino Origin", "Native American or Alaska Native", "Caucasian, White, or European", "Other", and "Prefer not to answer."</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.4">Deviation 4</head><p>The fourth deviation was our measure of author prestige. Similar to Tomkins et al., we planned to use the count of the number of talks in the previous 5 years of the SJDM conference. Due to the number of early career researchers, we extended this measure to include the count of the number of talks and posters at SJDM. Furthermore, we were able to extend the measure to include the counts over the previous 10 years. We also stated we would explore using the citation counts from Web of Science and Google Scholar as a measure of prestige. However, it was impractical to obtain these measures across all the authors (approximately 1,100). Therefore, we used the author counts as our measure of prestige for the author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.5">Deviation 5</head><p>The fifth deviation was our measure of the institutional prestige for all the authors. Our initial plan was to use the count of the number of talks in the previous 5 years of the SJDM conference for the respective institution. We expanded this count to cover the previous 10 years and include talks and posters. We did this because this variable was highly skewed with a few institutions having most of the talks and many other institutions with very few to no talks. To further address this issue, we obtained two other measures of prestige. One measure was the average citation rate for psychology, economics, business, and social science departments at the institutions. This number was extracted from the Web of Science on on August 29, 2019. The other measure we collected was reviewers' subjective ratings of the prestige of the institutions. To do this, in the Spring of 2023 we contacted the reviewers and asked them to rate the prestige of a random subset of the institutions. We aggregated across reviewers to obtain a single measure of prestige per institution. These three statistics were correlated (M = 0.55, SD = 0.17). Therefore, after standardizing the three different prestige statics we averaged across them to form an overall measure of prestige and used it as our measure of prestige.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.6">Deviation 6</head><p>A sixth deviation was the use of Pearson correlations as a measure of reliability instead of a rank-order correlation. As the ratings were standardized within each reviewer, using a rank order or Pearson correlation made little difference. We chose the latter as it was mathematically and statistically more feasible to work with.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.7">Deviation 7</head><p>A seventh deviation was to use Bayesian regression models with weakly informative priors. As our primary focus was on quantifying effect sizes this Bayesian approach facilitates this better providing moderate regularization to the estimates and helping reduce errant estimates. We report credible intervals around mean posterior estimates instead of maximum likelihood estimate effects with confidence intervals. Posterior distributions do not change based on the number of planned or unplanned tests. Thus, there is no correction for the number of tests as the statistics and inferences from them are based on the posterior distribution <ref type="bibr" target="#b64">Gelman et al. (2012a)</ref>; . Another reason we adopted a Bayesian approach as it permitted a more rigorous model comparison approach based on leave-one-out cross-validation <ref type="bibr" target="#b75">(Vehtari et al., 2017)</ref>. Note the posted primary regression analyses on OSF have a frequentist version of the multi-level model posted for the key analyses in terms of bias. The conclusions remain the same with conventional p-values based on our planned comparisons, but if we include corrections for multiple comparisons, the following interactions are not significant: the interaction between gender and review condition, the interaction between senior coauthorship and review condition, and the interaction between first author race and review condition. Again, our focus is not on null hypothesis significance testing but on quantifying the effects; thus, we focus on the posterior distribution of the effects.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.8">Deviation 8</head><p>An eight deviation is that when writing the pre-registration, we failed to account for the fact that singleauthor submissions, by definition, do not have characteristics for co-authors. Thus, to include single-author submissions in the regression analyses, for all the submissions, we replaced the coauthor variables with variables for all authors (e.g., the proportion of male authors instead of male coauthors). However, this had the effect of losing a clean measure of coauthor characteristics (e.g., the proportion of co-author males). Thus, we also ran a second set of all of our regression analyses with multiauthor submissions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2">Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1">Power Analyses</head><p>There are several issues to consider for a power analysis for our study. All of our primary analyses and conclusions are based on Bayesian multi-level regressions. An a priori power analysis with multi-level regression is not straightforward, entailing many assumptions. Moreover, our goal in the field study was a quantitative approach focusing on the effect sizes for all the collected variables. This quantitative approach combined with our Bayesian methods implies we are not relying on null hypothesis significance testing but focusing on the posterior distribution. To highlight particular results, we asked whether the 95% CI excludes 0 and used the term credible to describe the effect. These credible effects are the ones we focus on in the paper. Finally, as our study was a field study, we had little control over the sample size, with our only goal being to maximize the number of observations that we could use in our analyses given the number of submissions that were entered and the number of talks at the conference.</p><p>Given these qualifiers, we conducted a Bayesian power analysis focusing on our lowest powered test: the Pearson r correlation. We designed the power analysis in line with  evaluating the probability of obtaining a particular goal. In this case, the goal was if a 95% credible interval for a given posterior distribution excluded 0.</p><p>One set of analyses focused on the posterior distribution over the Pearson correlation r and the probability that a 95% credible interval would exclude 0. To estimate this probability, simulated data were created by generating bivariate normally distributed random values each with a mean of 0 and a standard distribution of 1. We varied the correlation between the two variables between ρ = 0.10 and ρ = 0.40. In calculating the posterior distribution of the Pearson r for a given dataset, we used the R package correlationBF <ref type="bibr" target="#b71">(Morey &amp; Rouder, 2018)</ref> This is the function we used in all of our analyses to calculate correlations. Noninformative priors are assumed for the population means and variances of the two populations. A beta distribution (shifted) is assumed for the population correlation ρ. The 2 parameters of the beta distribution were set to 1.0000 1.0000 1.0000 0.30 0.8786 1.0000 1.0000 1.0000 1.0000 0.31 0.8990 1.0000 1.0000 1.0000 1.0000 0.32 0.9216 1.0000 1.0000 1.0000 1.0000 0.33 0.9317 1.0000 1.0000 1.0000 1.0000 0.34 0.9489 1.0000 1.0000 1.0000 1.0000 0.35 0.9598 1.0000 1.0000 1.0000 1.0000 0.36 0.9693 1.0000 1.0000 1.0000 1.0000 0.37 0.9749 1.0000 1.0000 1.0000 1.0000 0.38 0.9831 1.0000 1.0000 1.0000 1.0000 0.39 0.9875 1.0000 1.0000 1.0000 1.0000 0.40 0.9898 1.0000 1.0000 1.0000 1.0000</p><p>The proportion of times the 95% credible interval excluded 0 was calculated for multiple sample sizes including the number of submissions that were accepted as talks (n = 108), the number of multiauthor submissions with a complete set of variables used in the regressions (n = 370), the number of multiauthor submissions for which the first author was the corresponding author (n = 430), the number of submissions for which the first author was the corresponding author (n = 470), and the number of submissions (n = 530). The proportions are based on 10,000 repetitions of generating a sample of multivariate normal random variables with a given sample size and a given correlation.</p><p>the default values of 1 3 creating a "medium" spread in the beta distribution centered over 0 and extending between -1 and 1. The code for the power analysis is on the OSF site for the paper.</p><p>1 lists the proportion of times (out of 10,000 repetitions) a 95% credible interval excluded 0 for a range of correlations. We calculated these proportions for a range of different sample sizes that reflect the different sample sizes used in the paper including (a) the number of submissions that were accepted as talks (n = 108); (b) the number of multiauthor submissions with a complete set of variables used in the regressions (n = 370); (c) the number of multiauthor submissions for which the first author was the corresponding author (n = 430); (d) the number of submissions for which the first author was the corresponding author (n = 470); and (e) the number of submissions (n = 530). The table shows that for analyses other than those that focused only on the submissions that were given as talks, data generated with a correlation of ρ = .15 had greater than an 80% chance of being identified as credible. For analyses that focused only on the submissions that were given as talks (i.e., when n = 108), data generated with a correlation of r = .27 had an 80% chance of being identified as credible. Convention in psychology has been to treat a correlation of .10 as a weak to small association and values of .30 as moderate associations. Thus, we conclude the field study was adequately powered to detect small to moderate associations with our lowest-powered test.</p><p>The focus of the study was the difference between single-and double-blind. These comparisons were primarily done via interaction terms via multilevel regressions. But, the lowest powered comparison is via a difference in correlations. We also ran these power analyses. To do so, we generated two sets of bivariate normal variables, each with the same given sample size. One pair of variables was generated with a correlation of ρ = .15. The other pair of variables was generated with a range of different correlations starting with ρ = .25 and ranging up to ρ = .55. 1 Then, for each pair of variables, we calculated the posterior distribution over the Pearson correlation and took the difference in the two distributions. <ref type="table" target="#tab_1">Table 2</ref> lists the proportion of times (out of 10,000 repetitions) that the 95% credible interval of the posterior distribution of differences in correlation contained 0 for a given difference in the correlation. The table shows that for the analyses on the more extensive set of submissions (i.e., other than the ones focused on the submissions given as talks), a sample of data with differences in correlations of Deltaρ = 0.20 or larger was identified as a credible difference greater than 80% of the time. For the analyses based on the smaller sample of submissions given only as a talk, the corresponding difference was ∆ρ = 0.35. Again, we conclude that our field study was adequately powered to detect small to moderate differences in associations with our lowest-powered test.</p><p>These are baseline estimates from correlations and differences in correlations and represent the lowestpowered tests. Most of our analyses and conclusions are based on more powerful regressions that increase the power of detecting if a variable was credibly associated with a dependent variable of interest. There were several aspects by which our regressions increased the power. First, we used simultaneous regressions controlling for 13 author and submission characteristics and 5 reviewer characteristics. Second, each submission received at least three single-blind and three double-blind reviews. This property created a within-submission comparison of single-and double-blind review. In our statistical models, we accounted for this via multi-level regressions with submission modeled as a random effect (a random slope). Because each reviewer reviewed approximately 30 submissions, we also could treat the reviewer as a random effect. Similarly, in the outcome data, the models accounted for random effects in the session and other variables. Third, we used vague but informed priors to regularize our regressions and results to help guard against overly sensitive analyses of extreme data. Interaction effects in multiple regressions are essentially differences in correlations, so these statements hold for the interaction effects.</p><p>Altogether, we believe our field study is informative and well-powered for the debate on single-vs. doubleblind review. We explicitly chose to study this question in the field instead of a lab study as the field seems the best test of these different systems of peer review. We also worked to report our results in the most informative manner possible, providing measures of effect sizes with credible intervals for all the results. 0.8433 1.0000 1.0000 1.0000 1.0000 0.37 0.8590 1.0000 1.0000 1.0000 1.0000 0.38 0.8875 1.0000 1.0000 1.0000 1.0000 0.39 0.9031 0.9999 1.0000 1.0000 1.0000 0.40 0.9209 1.0000 1.0000 1.0000 1.0000</p><p>The proportion of times the 95% credible interval excluded 0 was calculated for multiple sample sizes including the number of submissions that were accepted as talks (n = 108), the number of multiauthor submissions with a complete set of variables used in the regressions (n = 370), the number of multiauthor submissions for which the first author was the corresponding author (n = 430), the number of submissions for which the first author was the corresponding author (n = 470), and the number of submissions (n = 530). The proportions are based on 10,000 repetitions. To estimate the power two samples of a given sample size of multivariate normal random variables were generated. One sample was generated with a correlation of ρ = .15 and the other with a range of correlations starting at ρ = .25 up to ρ = .55. Thus, the difference ranged from ∆ = 0.10 to ∆ = 0.40. The specific values for ρ were relatively arbitrary and changes in the values (so long as they stayed roughly between ρ ≈ −0.50 and ρ ≈= 0.50) had little impact on the power of identifying a credible difference.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2">Conference Materials</head><p>The call for conference submission is available at this link http://www.sjdm.org/programs/2018-cfp.html. The program for the conference is available at this link https://sjdm.org/programs/2018-program.pdf. Many people selected multiple race and ethnicity categories. Instead of marginalizing across categories, we report the joint selections. Except for gender and position, the characteristics of the first author are based on the subset of submissions when the corresponding author was the first author.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3">Submission Characteristics</head><p>A summary of the characteristics of the submitting authors is listed in <ref type="table" target="#tab_6">Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4">Materials</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.1">Information Collected at Submission.</head><p>The call for submissions for the 2018 Annual Meeting for the Society for Judgment and Decision Making invited members and non-members to submit a 600-word long abstract to be considered for a spoken presentation. Submissions also included a title, a 100-word short abstract (to be used in the conference program), a listing of the authors, up to 3 keywords, and an indication as to whether the submission should be considered for a poster if it was not selected for a talk. Authors could also request to present a poster, in which case they were only asked to submit a title, a 100-word abstract for the program, and a list of authors. Here, we focus only on the submissions for a spoken presentation. At the time of submission, we also collected the following information from all authors:  Across all assignments, we worked to minimize conflicts of interest by ensuring no submission was assigned to a reviewer who shared a common institution with one of the institutions of the submitting authors. In addition, upon sending reviewers their assigned submissions, they were asked to inspect the submissions and identify any conflict so that it could be reassigned. If a conflict became apparent during the review, then reviewers were instructed to leave the abstract unrated if a conflict became apparent during the review. However, no submission was left unrated. The ratings were then standardized within each reviewer and aggregated across all six ratings, forming an average reviewer rating for each submission. The Conference Chair (XXX) used the average ratings to decide on accepting a submission for presentation. In the case of the 53 submissions that had two sets of reviews from each process, to make a decision, one set of three double-blind and one set of three single-blind reviews were randomly selected to aggregate across.</p><formula xml:id="formula_2">Position</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.3">Collected Variables on Reviewers at Agreement.</head><p>Besides rating each of their assigned submissions on a 1 poor to 9 excellent point scale and entering any comments they might have, reviewers were also asked a series of questions. Upon agreeing to review, they were asked:</p><formula xml:id="formula_3">Institution Current academic institution Department Current academic department Position Current position</formula><p>Area of study of highest degree Primary area of study for highest degree completed or in progress: (If you ave more than one PhD in a JDM-related field, select the area for your first PhD)</p><p>Year of highest degree Graduation year for this degree (enter all 4 digits, i.e, 2008)</p><p>Department and school where they obtained their highest degree</p><p>Reviewing experience How many times they had reviewed for the annual meeting in the past During the review, reviewers were asked to rate each abstract on a nine-point scale ranging from 1 (Poor) to 9 (Excellent). There was also a field to enter any submission comments.</p><p>After their reviews, these questions asked them the following items.  </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.5">Talk Evaluation and Statistics.</head><p>A total of N = 18 faculty and N = 12 pre-and post-doctoral students (henceforth students) were recruited to rate the talks at the conference. We sought to recruit faculty and students who were representative of the society in terms of gender, nationality, and area of expertise <ref type="table" target="#tab_11">(Table 5)</ref>. Travel expenses were covered for the students to attend the conference while faculty volunteered their time. The conference had nine sessions, each with three tracks of four talks. Based on availability, faculty were randomly assigned to one of the three tracks in three of the nine sessions during the conference. Students were randomly assigned to rate one track of talks in either the first half or second half of the conference. In the end, we aimed to have two faculty raters and two student raters at each of the 108 talks. Each faculty member and graduate student rated the talks along the following dimensions:</p><p>2.5.1 Characteristics of Raters. Each faculty member and graduate student rated the talks along the following dimensions:</p><p>Significance Is the topic of the talk significant? Does it concern a scientifically important subject or is it relevant for policy or other applications?</p><p>Methods Are the methods scientifically sound?</p><p>Results Are results presented in enough detail and in an understandable way?</p><p>Conclusion Do the conclusions follow from the results? Are they justified? Are the results generalizable?</p><p>Innovation Is there something innovative about the presented material?</p><p>Uniqueness Is this talk different from other talks typically at SJDM? 2.5.3 Judged Overall Rating.</p><p>For each rater, we standardized the ratings across all dimensions and all talks they rated. Then, for each rater and each talk, we averaged across the ratings to form an overall rating. Then, for each talk, we averaged the student and faculty ratings together, giving them equal weight. Each research assistant tracked the following statistics:</p><p>Attendance Estimated the attendance at the talk 5 minutes into the talk.</p><p>Potential questions Estimated the number of potential questions for each talk, where a count of raised hands indicated potential questions throughout the talk.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Number of questions answered</head><p>The number of questions answered for each talk.</p><p>Duration of talk The length of the talk.</p><p>Duration of Q &amp; A The length of the question and answer period.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.6">Prestige Rating Survey.</head><p>In May 2024, we sought additional measures of institutional prestige. We targeted the original reviewers of the submissions and asked them to complete a survey. Of the N = 113 reviewers, we had contact information for N = 110. In creating the survey, we identified 328 unique institutions that were associated with at least one author in our 2018 dataset. <ref type="bibr">2</ref> We randomly assigned a subset of these 328 institutions to each reviewer such that each reviewer was asked to rate the prestige of approximately one quarter of the 328 institutions. They assigned each institution to 1 of 4 prestige levels.</p><p>1. World renowned for JDM research.</p><p>2. Known for JDM research.</p><p>3. A little known for JDM research.</p><p>4. Not known for JDM research.</p><p>We set the a priori stop rule to continue data collection until we received at least 20 ratings for each institution. In the end, N = 65 reviewers responded to our request and thus we had approximately 16 ratings for each institution. We used the average rating for each institution and one component of our prestige measure. <ref type="table" target="#tab_12">Table 6</ref> lists the characteristics of the respondents. The characteristics indicate our sample of respondents was representative of the original reviewers <ref type="table" target="#tab_6">(Table 3</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.7">Author and Institution Count.</head><p>As an additional component of our institutional prestige measure, we examined how often scholars from each institution presented at the SJDM meetings. Across authors and reviewers, there were 334 unique institutions. For each institution, we tabulated the number of times it appeared in the SJDM Annual Meeting program over 10 years <ref type="bibr">(2008 to 2017)</ref>, affiliated with an author of either a talk or a poster. <ref type="bibr">3</ref> We did the same thing for author names. That is, for each author who submitted an abstract in 2018, we tabulated how often they appeared in the SJDM programs from 2008 to 2017. To do so, we acquired tab-delimited text files of all the paper and poster submissions to the SJDM conferences between 2008 and 2017. We used the Python function fuzz.partial ratio to identify a matching string of characters with a target string of characters. This function has a similarity value that we can adjust to determine the degree of match needed to count as a match. For institutions, we set this value at .95, and for authors, we set this value at .91. We chose these values after extensive tests with a range of values revealed these values ensured we minimized the chance of misses. But, since we minimized misses, we had an increased chance of false alarms. Thus, three researchers inspected each match and confirmed a match. For the institutions, per year, there were between 5 to 10 false alarms. For the author names, per year there were 3 to 5 false alarms. We then tabulated across all the identified matches, counting the number of matches per talk and poster per year. <ref type="figure" target="#fig_0">Figure 2</ref> displays the relationship between institutional citation rates, the number of institutional appearances at the annual SJDM meetings from 2008 to 2017, and the prestige rating. The three different measures were correlated. Thus, we standardized each measure and averaged across the three measures to create a prestige score. For some institutions, we did not have all three measures. We addressed this issue by averaging and ignored missing values. 2.9 Poster Ratings.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.8">Prestige Score</head><p>There were a total of N = posters that were submitted for the student-poster competition during the 2018 conference and judged on a similar set of dimensions as those used to judge the quality of the talks. During the conference, student posters were judged for a student poster competition award. To do so, faculty members are recruited to rate the posters. Initially, 94 members volunteered to complete the ratings. Each rater was assigned 5 to 6 posters. The assignment was random with the constraint that the raters did not share an institution or other apparent conflicts of interest (e.g., faculty mentor) with the poster author. Raters were also instructed to withhold ratings if there was a conflict of interest.</p><p>A few days before the conference, raters received links to the electronic version of each poster. They were instructed to rate the posters either via the electronic file or in person at the conference. They rated the posters on a 7-point scale using the following 5 dimensions.</p><p>Visual presentation and organization Clearly labeled abstract/introduction, methods, results, discussion/conclusions. Visual appeal, appropriate use of figures and tables, clarity of presentation, decent font sizes.</p><p>Methodological quality Are the methods appropriate for the topics, in terms of research design and proper use of statistical analyses?</p><p>Appropriateness of interpretation Abstract appropriately written, results don't over-interpret or misinterpret, conclusions and discussion don't generalize inappropriately. Conclusion addresses purpose of study as described in introduction.</p><p>Significance / Theoretical importance of contribution Does the poster address an important issue? Does the study advance knowledge?</p><p>Originality Is the topic treated in a substantially new way? Does the design elaborate or improve on the standard paradigm? Do the results allow for new interpretations or provide a novel source of evidence?</p><p>In the end, N = 69 raters finished the ratings, resulting in each poster receiving 4 to 5 ratings. A subset of the posters (N = 57) had been originally submitted for talks at the conference and had single-and double-blind abstract evaluation scores. Thus, we took the poster ratings, standardized them across each judge, averaged them across the dimensions to arrive at an overall rating for each poster, and used them to investigate how well the review rating systems predicted these ratings. Due to the similar rating systems in how the posters and talks were judged, we also integrated these ratings with the ratings for the submissions given as a talk, creating a new talk/poster rating.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.10">Preference for Review Process Survey.</head><p>Shortly before the 2019 conference, we surveyed members of the Society for Judgment and Decision Making listserv, asking them to report their preference between single-vs. double-blind review processes and their judged fairness of each review process. We sent the request for participation out on October 25, 2019. We sent a reminder on November 1, 2019, and we stopped data collection on November 7, 2019. There were N = 173 responses to the survey.</p><p>The survey asked the following questions.</p><p>Author characteristics predictions Indicate the extent to which they believed that specific author characteristics (e.g., gender, proportion of male co-authors, institution, etc.) would increase versus decrease the chances a talk would be accepted as a talk at the conference if using single-vs. double-blind review on a 7-point scale ranging from significantly decreases to significant increases.</p><p>Unfair vs. fair to use author characteristics Rate [7-point scale] the extent to which they believed it was very unfair to very fair for reviewers to take into account each of the above author characteristics when judging abstracts.</p><p>Preference for review process Rate preferences for single-versus double-blind review as an author v. author v. conference attendee v. overall (1 = definitely prefer single-blind, 7 = definitely prefer double-blind).</p><p>Fairness of review process Rate each review process according to its fairness (1 = very unfair, 7 = very fair).</p><p>Agreement Rate the degree of agreement between the two review processes.</p><p>Validity Rate which review process would better predict the aspects of judged talk quality (1 = much better predicted by single-blind review, 7 = much better predicted by double-blind review).</p><p>Demographics Demographics were collected.</p><p>Knowledge of study Yes/No you had heard about the current blind-review study being conducted within the society.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.11">Journal Publications.</head><p>Two and six years after the conference, we sought to identify submissions that were published. In total, N = 276 submissions were identified as published in a peer-reviewed journal. Our process for identifying publication status was a follows. Two years after the conference, we searched Google Scholar using as a search term the first author's last name and the title of the submission. That yielded 130 published submissions. Then we contacted via email all of the corresponding authors of the remaining submissions and asked if their submission had been published in a peer-reviewed journal and what the journal was. The initial email was sent in October 2020 and we collected emails up until December 18, 2020. Responses to the email identified an additional N = 54 submissions that had been published. Then in March 2025, we repeated the Google Scholar search and also searched author C.V.s to establish publication status. In total, we identified 276 submissions that were published as of March 13, 2025. We also separately identified the impact factor of each journal via Web of Science and Google Scholar. We used the (logged) impact factor from Web of Science as a metric of impact.</p><p>2.12 Analyses.</p><p>We used Bayesian estimation methods for data analysis. Statistics were conducted using R 3.6.2 (R Core Team, 2019), the rstanarm package <ref type="bibr">(v2.19.3;</ref><ref type="bibr" target="#b66">Goodrich et al., 2020)</ref>, and the BayesFactor package (0.9.12-4.2; <ref type="bibr" target="#b71">Morey &amp; Rouder, 2018)</ref>. We report the posterior predicted mean of the parameter of interest and in brackets its 95% Credible Interval (CI). The CI summarizes the posterior distribution excluding the 2.5% of the distribution at each tail. We use the term credible when the 95% CI excludes 0.For model comparisons, we used leave-one-out cross validation (LOO) to compare models based on the expected log pointwise predictive density for a new dataset (elpd loo ). The difference between models on elpd loo quantifies the difference in predictive accuracy between them. The standard error (SE) captures the uncertainty around each elpd loo . In general, we consider |∆elpd loo | &lt; 1 SE to be weak evidence for a particular model. In all cases, we used the default priors, which were set to be weakly informative providing moderate regularization to the estimates (i.e., priors that are skeptical of extreme parameter values). We inspected MCMC chains for representation and accuracy, and we sought to have all reported parameters based on an effective sample size of 10,000. Posterior distributions do not change based on the number of planned or unplanned tests. Thus, there is no correction for the number of tests as statistics and inferences from them are based on the posterior distribution <ref type="bibr" target="#b65">(Gelman et al., 2012b;</ref><ref type="bibr">?)</ref>.</p><p>3 Modeling the Text of the Long Abstracts</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1">Text Corpus</head><p>The text corpus was the Wiley Blackwell Handbook of Judgment and Decision Making edited by Keren and Wu published in 2015. This two volume handbook has 35 chapters that provides a comprehensive, examination of the field of judgment and decision making. The handbook has authors from across the discipline including psychology, economics, marketing, finance, public policy, sociology, and philosophy. The review covered traditional topics, controversies, new topics, as well as applications. Therefore, the text provides a good representation of the field. We obtained the text from all 35 chapters and prepared it to model by removing • <ref type="table">Table and table captions</ref> In the end, we created a .txt file where each line was a chapter. Then we applied the following pre-processing steps in Matlab. See OSF for further details.</p><p>• Converted all the text to lower-case.</p><p>• Removed hyphens</p><p>• Removed numbers</p><p>• Made a second pass to remove authors using the author index as a reference.</p><p>• Removed punctuation</p><p>• Removed stop words like "a", "and", "to", and "the".</p><p>• Removed words two letters or shorter.</p><p>• Removed words 15 letters or longer.</p><p>• Tokenized the text (via Matlab's 'tokenizedDocument' function.</p><p>• Removed words that occurred 3 or fewer times across the text.</p><p>The end text corpus had 35 chapters with 5020 words. <ref type="figure" target="#fig_8">Figure 3</ref> shows a word cloud of the frequent words and it suggests that the handbook, indeed, contains the relevant words one would expect in a handbook about how people make judgments and decisions. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2">Topics Modeling</head><p>We fit a latent Dirichlet allocation (LDA) topic model to the Wiley Handbook of Judgment and Decision Making text corpus using Gibbs sampling <ref type="bibr" target="#b63">(Blei et al., 2003;</ref>). The LDA model discovers underlying topics in a collection of documents and infers word probabilities in topics. It was fit using a bag-of-n-grams model treating the n-grams as individual words.</p><p>To identify the number of topics that best fit the handbook, we carried out a cross validation holding out 7 of the chapters and fitting a topics model with 1 to 15 topics to the remaining 28 chapters. Then we calculated a perplexity score-the geometric mean of the inverse marginal probability of each word in the held-out set of documents-as a measure of goodness of fit. We repeated this process 10 times using a different partition of chapters each time. Across iterations, the median number of topics that returned a minimum perplexity score was 2.5. Therefore we selected 3 topics for the best fitting model.  <ref type="figure" target="#fig_8">Figure 3</ref>).</p><p>These labels correspond well to the chapters. For instance, for Chapter 2 Topic 1 had the greatest probability. It focused on the theory of how people make decisions under risk, a core topic of judgment and decision making. For Chapter 6 Topic 2 had the greatest probability and it focused on the empirical phenomena of overconfidence in judgment. And for Chapter 22 Topic 3 had the greatest probability and it focused on learning processes during decision making.</p><p>We then used the model to calculate the posterior probability that each long abstract belonged to each of these three topics and assigned each submission the topic with the greatest posterior probability. <ref type="figure" target="#fig_9">Figure 4</ref> shows the distribution of topics across the 530 long abstracts. The code and output for the topic modeling is available on OSF.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3">Sentiment Analysis</head><p>The sentiment analysis assigned a score to each long abstract according to whether it had on average a positive or negative sentiment. The score was based on a sentiment analysis conducted by training a support vector machine classifier on a subset of 6,800 positive and negative words from . Then after validating the classifier on the hold-out set, we predicted the sentiment of the words in the long abstract with the classifier. Note both the positive and negative words and the abstract words were represented by 300 dimensional numerical vectors via a pre-trained word embedding of 1 million English words available in Matlab. <ref type="figure" target="#fig_10">Figure 5</ref> shows the word clouds of the words with the strongest negative and positive sentiment in the abstracts. The sentiment of the abstract was determined by averaging across the sentiment scores of each word in the abstract. The average sentiment is shown in the bottom panel of <ref type="figure" target="#fig_10">Figure 5</ref>. The code and output for the sentiment analysis is available on OSF. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4">Survey of SJDM Members' Preferences</head><p>We survey SJDM member's preferences regarding single-and double-blind review. We asked them to report their preferences from the view point of an author, reviewer, and as an attendee. Details on the methods are in Section 2.10. Here we report the analyses.  <ref type="figure">Figure 6</ref>: A: Society for Judgment and Decision Making members' surveyed preference for single-blind versus double-blind review for selecting submissions for the annual conference from the perspective of different roles (1 = Strong preference for single-blind, 7 = Strong preference for double-blind). B: Judged fairness of the two review processes (1 = Very unfair, 7 = Very fair). Reviewing experience was analyzed as a continuous variable. For the figure, we split the responses into whether respondents had never reviewed (0 years of reviewing), reviewed (&gt; 0 years of reviewing), or did not report their reviewing experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1">Respondent Characteristics</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.1">Regression</head><p>Coefficients for Predictors of Double-vs. Single-blind Preference. Bolded values indicated credible interval excludes 0. Preference and reviewing experience were standardized in the model. Respondent id was a random intercept in the regression model.  <ref type="bibr">[-0.41, -0.07]</ref> Bolded values indicated credible interval excludes 0. Fairness ratings and reviewing experience were standardized in the model. Respondent id was a random intercept in the regression model. <ref type="figure">Figure 6</ref> also shows the distribution of fairness ratings. Double-blind review was rated as more fair (Table 9. Moreover, reviewing experience was also associated with the difference in fairness between singleand double-blind with more experienced reviewers rating seeing less of a difference in fairness <ref type="table" target="#tab_14">(Tables 8).</ref> This pattern raises the question whether differences in fairness perceptions accounts for the relationship between review experience and reviewer preference for double-blind review? When fairness is included in the regression predicting the preference, the relationship between reviewing experience and review-system preference dissipates once fairness perceptions are accounted for (β = −0.09, [−0.23, 0.05]) ( <ref type="table" target="#tab_15">Table 9</ref>). This result suggests that part of the reason for the differences in preference for double-blind and single-blind across levels of reviewing experience is the different perceptions of fairness.  Represented corresponds to Black, Hispanic, and Native American authors who had very low numbers of authors <ref type="table" target="#tab_6">(Table 3)</ref>. Area of Ph.D. and submission topic (from a topic model) are categorical variables and are not in these matrices but were entered into the regressions. <ref type="table">Table ?</ref>? describes each of these characteristics. See also Tables 11-13.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3">Fairness Perceptions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2">Model Comparison</head><p>Our first step was to assess the overall evidence for submission characteristics like the author's identity being used differently between single-and double-blind using a model comparison. We compared a model that had interaction terms between each of the fourteen characteristics and the condition (Single vs Double Review Differential Item Functioning (SvB DIF) Model ) to a model that did not have these interaction terms (Differential Item Functioning (NoDIF) Model)) using leave-one-out cross validation. The difference The comparisons were made with the expected log pointwise predictive density for a new dataset estimated from the leave-one-out cross-validation (elpd loo ) for each model. The difference between two models with this statistic (∆ elpd loo ) quantifies the difference in predictive accuracy between the two and offers a measure of the relative support for either model. There is uncertainty around each elpd loo , and this is captured by the standard error (SE) around each estimate.</p><p>between the SvB DIF (elpd loo = −3700.31; SE(elpd loo ) = 35.40) and the simpler DIF model (elpd loo = −3693.62; SE(elpd loo ) = 35.05) in terms of the expected log-pointwise predictive density was ∆elpd loo = 6.7 favoring the simpler DIF model without the interaction terms, but this difference was within the margin of error of SE = 7.35 indicating very weak evidence against an omnibus differential item or merit evaluation functioning between single and double-blind review.</p><p>Our main analysis entered all fourteen characteristics <ref type="table" target="#tab_0">(Table 1</ref>) simultaneously in a multilevel regression model with the ratings for the single-and double-blind conditions as the outcome variables. Though reviewers were randomly assigned to conditions and submission, we also included the six reviewer characteristics listed in <ref type="table" target="#tab_0">Table 1</ref> as predictors. In the analyses reported in the main paper, the reviewer characteristics were entered alone. We also explored whether there were potential interactions between the review condition and reviewer characteristics. None of the reviewer characteristics showed credible interactions with the review condition <ref type="table" target="#tab_0">(Table 14)</ref>. Moreover, a model comparison between the SvB DIF model and the model, including an interaction between reviewer characteristics and condition as well as potential three-way interactions with author-specific author characteristics, led to a substantially worse fit of the regression model <ref type="table" target="#tab_0">(Table 10)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3">Regression Coefficients With All Characteristics Entered Simultaneously</head><p>As discussed in the text, to assess the degree to which review systems may advantage an individual or group, we entered review type (single vs. double), all fourteen author and submission characteristics, and the interaction between each characteristic and review type simultaneously in a Bayesian hierarchical regression model, with the rating of each submission by each reviewer as the outcome variable. The main regression replaced the coauthor variables with variables for all authors (e.g., the proportion of male authors instead of male coauthors) for all the submissions so as to retain the single author submissions in the analysis. The regression coefficients for this regression are reported in <ref type="table" target="#tab_0">Table 11</ref>. Because our approach to handling single author submissions introduced multicollinearity, we also reran the regression using multi-author submissions. Those coefficients are reported in <ref type="table" target="#tab_0">Table 12</ref>. Regression based on N = 440 submissions. Bolded values indicate credible intervals exclude 0. All coauthor characteristics were represented by the statistics based on all the authors (e.g., proportion of male authors instead of male coauthors) so that singleauthor submissions were included in the analysis. Thus, the regression coefficients for the first author variables represent incremental change for the variables in which there are corresponding coauthor characteristics. Review ratings and numerical predictors were standardized as indicated by the z. This regression is based on N = 413 submissions. As discussed in the text, the main analysis sought to include all submissions and therefore used all the authors when entering statistics for the co-authors. But, this introduces multicollinearity. Thus, we reran the models with multi-author submissions only. Bolded values indicated credible interval excludes 0. Review ratings and numerical predictors were standardized. The z indicates when the variables were standardized. Review ratings and numerical predictors were standardized. The characteristics were entered simultaneously for both regression models.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.4">Regression Coefficients with All Variables Entered Simultaneously Predicting Single or Double-Blind</head><p>To better understand our results, particularly the interaction terms with review conditions, we also regressed single-blind review ratings onto author and submission characteristic. We did the same for double-blind review ratings. These regressions are presented side-by-side in <ref type="table" target="#tab_0">Table 13</ref>.  Bolded values indicated credible interval excludes 0. Review ratings and numerical predictors were standardized. The interaction term was run entering the variable predicting both single-and double-blind ratings together with condition dummy coded (0: singleblind; 1: double-blind). The N indicates the number of submissions used in each regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6">Comparing Single-vs. Double-blind in the Top 108</head><p>The comparison between single-and double-blind review revealed there were three author characteristics that had a differential impact on single-and double-blind review: first author gender, whether the first author identified as Asian or not, and the seniority of the coauthors. We were curious how these effects would be realized if the top 108 submissions were identified by single-blind or double-blind reviews. In terms of the gender difference, if we look at the top 108 as specified by the single-blind review ratings and do the same for double-blind review, then double-blind review has less of a gender difference than single-blind. In the top 108 submission according to single-blind review there were 35 submissions (32%) with female first authors while according to double-blind review there were 39 submissions (36%). Note across all 530 submissions there were 246 female first authors (46%). Thus, for both review systems there would be a gender difference with less representation of women in the hypothetical conference, but if anything the gender difference would be slightly stronger for single-blind review. This difference reinforces the fact that the difference between single-and double-blind in terms of gender is subtle and should be interpreted with caution.</p><p>In terms of race, if the top 108 submissions were identified by the single-blind review ratings the number of Asian first authors would be N = 19 (18%). In contrast, if the top 108 were identified by double-blind review ratings then the number of Asian first authors would be N = 29 (26%). This difference illustrates an important aspect of double-blind review that it can help address potential inequities that arise with single-blind review. We can do the same analysis and ask how the representation of senior coauthorship would change if the selection was done with single-blind review or double-blind review. If the top 108 submissions were identified by the single-blind review ratings the mean coauthor rank would be 8.3 (SD = 1.7) (i.e., between an Associate and a Full Professor). In contrast, if the top 108 were identified by double-blind review then the mean coauthor rank would be 8.0 (SD = 1.9) (i.e., an Associate Professor). Across all 530 submissions the mean coauthor rank excluding the first author was 7.9 (SD = 1.9) (i.e., just below Associate Professor). Thus, from the perspective of the conference threshold, selection of talks by single-blind review would have advanced submissions with more senior coauthors, but not in double-blind.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7">Predictive Validity of Review Ratings and Author and Submission Characteristics</head><p>This section reports supplemental results for the outcome variables we collected as well as supporting analyses for evaluating the predictive validity of review ratings and author and submission characteristics.  Intercorrelations between talk rating and talk/poster rating and published and journal impact factor are not informative and are thus excluded. Journal impact factor was log-transformed before computing the correlation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.1">Summary of Talk Outcomes Across sessions</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.2">Correlations Between Outcomes</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.3">Regression of Outcomes onto Single-and Double-blind Review Ratings</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.4">Regression of Outcomes Onto Author and Submission Characteristics</head><p>We collected several relevant outcomes including an overall rating of those submissions that were presented as a talk, the attendance at talks, number of questions asked, ratings of submissions that were presented to posters and rated in the student competition, if the submission was published, and the impact factor of the journal the submission was ultimately published in. For each outcome, we regressed the outcome variable on the the author and submission characteristics simultaneously. This regression evaluated how well the characteristics predict the outcome. We report the regressions using all the submissions with standardized outcome values <ref type="table" target="#tab_0">(Table 18)</ref>, the same regression with the nonstandardized outcome variable (when relevant) <ref type="table" target="#tab_0">(Table 21)</ref>, and the corresponding regressions for multi-author submissions to address multicollinearity <ref type="table" target="#tab_0">(Tables 21 and 21</ref>). Bolded values indicated credible intervals exclude 0. As with the regressions comparing single-vs. double-blind reviews, all coauthor characteristic characteristics were represented by the statistics based on all the authors (e.g., the proportion of male authors instead of male coauthors) so that single-author submissions were included in the analysis. Thus, the regression coefficients for the first author variables represent incremental change for the variables with corresponding coauthor characteristics. The z indicates when the variables were standardized. When regressing conference outcomes (talk rating, attendance, questions, and talk/poster rating) conference session was entered as a covariate in the model. When regressing publication outcomes, whether the submission was presented at the conference or not was entered as a covariate. <ref type="table" target="#tab_1">Table 20</ref> provides the regression coefficients when subsetting the data on multiple author submissions.  Bolded values indicated credible interval excludes 0. The z indicates when the variables were standardized. The data were subsetted only to include multi-author submissions. When regressing conference outcomes (talk rating, attendance, questions, and talk/poster rating) conference session was entered as a covariate in the model. When regressing publication outcomes whether the submission was presented at the conference or not was entered as a covariate. </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 2 .</head><label>2</label><figDesc>Correlation between author and submission characteristics, review ratings, and relevant outcomes. The central value is the mean posterior estimate. The values in the upper and lower right-hand corners are the estimates of the upper and lower bounds of the 95% credible interval. Starred values indicate the credible interval excludes 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Full Professors) (β = −0.493, [−0.962, −0.025]), largely because Ph.D. students received higher ratings than Full Professors under single-blind review (β = 0.615 [0.149, 1.074]) but showed a nearzero difference under double-blind review (β = 0.046 [−0.429, 0.525]). A similar pattern emerged for research scientists (vs. Full Professors) (β = −0.578, [−1.094, −0.060]). This difference arises because in single-blind review, research scientists received a higher rating than Full Professors (β = 0.669[0.156, 1.074]) as compared to a near-zero non-credible difference in double-blind review (β = 0.062 [−0.465, 0.586]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>ReferencesAigner,D. J., &amp; Cain, G. G. (1977). Statistical theories of discrimination in labor markets.ILRReview, 30  (2), 175-187. doi: 10.1177/001979397703000204Allen-Ramdial, S.-A. A., &amp; Campbell, A. G. (2014). Reimagining the pipeline: Advancing stem diversity, persistence, and success. BioScience, 64(7), 612-618. doi: 10.1093/biosci/ biu076 American Educational Research Association, . N. C. o. M. i. E., American Psycho-logical Association. (1999). Standards for educational and psychological testing. American Educational Research Association. Arkes, H. R., Shaffer, V. A., &amp; Dawes, R. M. (2006). Comparing holistic and disaggregated ratings in the evaluation of scientific presentations. Journal of Behavioral Decision Making, 19 (5), 429-439. Arrow, K. J. (1973). The theory of discrimination. In O. Ashenfelter &amp; A. Rees (Eds.), Discrimination in labor markets (pp. 3-33). Princeton University Press. Åslund, O., &amp; Skans, O. N. (2012). Do anonymous job application procedures level the playing field? ILR Review, 65 (1), 82-107. doi: 10.1177/001979391206500105 Becker, G. S. (1957). The economics of discrimination. University of Chicago press. Behaghel, L., Crépon, B., &amp; Le Barbanchon, T. (2015). Unintended effects of anonymous resumes. American Economic Journal: Applied Economics, 7 (3), 1-27. doi: 10.1257/ app.20140185 Bertrand, M., &amp; Duflo, E. (2017). Field experiments on discrimination. In A. V. Banerjee &amp; E. Duflo (Eds.), Handbook of economic field experiments (Vol. 1, pp. 309-393). Elsevier. doi: 10.1016/bs.hefe.2016.08.004 Biernat, M., Manis, M., &amp; Nelson, T. E. (1991). Stereotypes and standards of judgment. Journal of Personality and Social Psychology, 60 (4), 485. doi: 10.1037/0022-3514.60.4 .485 Blank, R. M. (1991). The effects of double-blind versus single-blind reviewing: Experimental evidence from the american economic review. The American Economic Review, 1041-1067. Blei, D. M., Ng, A. Y., &amp; Jordan, M. I. (2003). Latent dirichlet allocation. The Journal of Machine Learning Research, 3 , 993-1022. Bohren, J. A., Imas, A., &amp; Rosenberg, M. (2019). The dynamics of discrimination: Theory and evidence. American Economic Review, 109 (10), 3395-3436. doi: 10.1257/ aer.20171829 Bordalo, P., Coffman, K., Gennaioli, N., &amp; Shleifer, A. (2016). Stereotypes. The Quarterly Journal of Economics, 131 (4), 1753-1794. doi: 10.1093/qje/qjw029</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>1.5 Deviation 5 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.6 Deviation 6 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.7 Deviation 7 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.8 Deviation 8 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>2</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 1 :</head><label>1</label><figDesc>Intercorrelations between reviewer characteristics. Values in the center of each cell are posterior estimates of the Pearson correlations, and values in the upper and lower right-hand corner are the corresponding credible intervals. Starred values indicate credible interval excludes 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 2 :</head><label>2</label><figDesc>Scatterplot matrix of the measures of institutional prestige. Prestige score is the omnibus measure calculated as the mean of the three other standardized measures.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>•</head><label></label><figDesc>Front and back matter • Titles • Author names, and cited authors • Page numbers • Equations, numbers, and mathematical notation • Figure and figure caption</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>Figure 3 :</head><label>3</label><figDesc>Topic modeling of the 2015 Wiley Blackwell Handbook of Judgment and Decision Making. The top plot is a word cloud of the most frequent words in the handbook. The middle plots show the most frequent words associated with the three topics from the LDA topic model. The bottom plot shows the distribution of topics across the 35 chapters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 4 :</head><label>4</label><figDesc>Figure 3shows the word clouds of the most frequent words associated with each topic and the topic mixtures of the different chapters. Roughly the three topics were1. Theories of judgment and decision making 2. Empirical phenomena of judgment and decision making 3. Psychological processes of judgment and decision making Topic distribution across the 530 long abstracts. The topic model came from the best fitting LDA topic model of the 2015 Wiley Blackwell Handbook of Judgment and Decision Making (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_10"><head>Figure 5 :</head><label>5</label><figDesc>Sentiment analysis of the long abstracts. The word clouds show the words with the strongest negative and positive sentiments in the abstracts. The bottom plot is the average sentiment of each of the 530 abstracts.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_11"><head>Figure 7 :</head><label>7</label><figDesc>Correlations between author and text characteristics and single-vs. double-blind review ratings. The central value is the mean posterior estimate. The values in the upper and lower right-hand corners are the estimates of the upper and lower bounds of the 95% credible interval. Starred values indicate a credible interval that excludes 0. Academic position of the first author was treated as a numerical variable in these correlations but as a categorical variable in the regressions. Correlations for Asian, White, Other, Under Represented, and No Answer were calculated by comparing each group to all others. Under</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_12"><head>Figure 8 :</head><label>8</label><figDesc>Correlations between outcome data. Note: The central value is the mean posterior estimate. The values in the upper and lower right-hand corners are the estimates of the upper and lower bounds of the 95% credible interval. Starred values indicate the credible interval excludes 0.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Predictors used in comparing single-vs. double-blind reviews.   </figDesc><table><row><cell></cell><cell cols="2">Position of the first author</cell><cell>Position of the first author (student, undergraduate student, master's student, Ph.D. stu-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>dent, Post-doc, research scientist, practitioner, assistant professor, associate professor, full</cell></row><row><cell></cell><cell></cell><cell></cell><cell>professor).</cell></row><row><cell>Coauthors</cell><cell cols="2">Proportion of coauthors who were</cell><cell>Proportion of coauthors excluding first author who were male.</cell></row><row><cell></cell><cell>men*</cell><cell></cell></row><row><cell></cell><cell cols="2">Prestige score of coauthors' insti-</cell><cell>See prestige score of first author's institutions, calculated for co-author(s) excluding the</cell></row><row><cell></cell><cell>tutions*</cell><cell></cell><cell>focal author.</cell></row><row><cell></cell><cell cols="2">Average number of coauthor ap-</cell><cell>See author appearances in SJDM program, calculated for co-author(s) excluding the focal</cell></row><row><cell></cell><cell cols="2">pearances in SJDM program*</cell><cell>author.</cell></row><row><cell></cell><cell>Ave.</cell><cell>position rank of coau-</cell><cell>Average position rank of coauthor(s) excluding focal author where there are 10 positions</cell></row><row><cell></cell><cell>thor(s)*</cell><cell></cell><cell>(see Position of first author).</cell></row><row><cell>Text</cell><cell>Topic</cell><cell></cell><cell>Topic was calculated from a topic model of the 35 chapter Blackwell-Wiley Handbook of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>Judgment and Decision Making Keren &amp; Wu (2015). Three core topics emerged from the</cell></row><row><cell></cell><cell></cell><cell></cell><cell>handbook: theories of judgment and decision making, empirical phenomena of judgment</cell></row><row><cell></cell><cell></cell><cell></cell><cell>and decision making, and psychology of judgment and decision making.</cell></row><row><cell></cell><cell cols="2">Sentiment</cell><cell>Sentiment score was estimated from a sentiment classifier where sentiment ranged from -1</cell></row><row><cell></cell><cell></cell><cell></cell><cell>(negative) to 1 (positive).</cell></row><row><cell>Reviewer</cell><cell cols="2">Reviewer gender</cell><cell>Binary variable indicating whether reviewer was female (0) or male (1).</cell></row><row><cell></cell><cell cols="2">Reviewer years since Ph.D.</cell><cell>Years since 2018 that reviewer obtained Ph.D.</cell></row><row><cell></cell><cell cols="2">Prestige score of reviewer's insti-</cell><cell>The average number of citations for top papers from Psychology, Economics and Business,</cell></row><row><cell></cell><cell>tutions</cell><cell></cell><cell>and Social Science departments at the institution of the coauthors. See ave. number of</cell></row><row><cell></cell><cell></cell><cell></cell><cell>citations JDM-relevant departments at first author's institutions.</cell></row><row><cell></cell><cell cols="2">Ph.D. area of the reviewer</cell><cell>Ph.D. area of the reviewer (Economics, Management, Marketing, Other, Psychology).</cell></row><row><cell></cell><cell cols="2">Position of the reviewer</cell><cell>Position of the reviewer (research scientist, practitioner, assistant professor, associate pro-</cell></row><row><cell></cell><cell></cell><cell></cell><cell>fessor, full professor).</cell></row><row><cell></cell><cell cols="2">Reviewer experience past 7 years</cell><cell>Number of times reviewed for the SJDM Annual Meeting in the past 7 years.</cell></row><row><cell cols="4">* In the regressions, this statistic was sometimes expanded to include all authors to not exclude single-author submissions in the anal-</cell></row><row><cell cols="2">ysis. See Footnote 6.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc>Coefficients from regressing submission outcomes onto single-and double-blind ratings.</figDesc><table><row><cell></cell><cell>N</cell><cell>Single (Alone)</cell><cell>Double (Alone)</cell><cell>Rating x Condition</cell></row><row><cell>Talk Rating</cell><cell>107</cell><cell>0.05 [-0.08, 0.18]</cell><cell>-0.02 [-0.14, 0.10]</cell><cell>-0.07 [-0.31, 0.17]</cell></row><row><cell>Attendance</cell><cell>107</cell><cell>-0.11 [-0.42, 0.21]</cell><cell>-0.11 [-0.39, 0.17]</cell><cell>-0.04 [-0.61, 0.52]</cell></row><row><cell>Num. Questions</cell><cell>107</cell><cell>-0.01 [-0.36, 0.34]</cell><cell>0.16 [-0.15, 0.47]</cell><cell>0.11 [-0.53, 0.75]</cell></row><row><cell>Poster Rating</cell><cell>57</cell><cell>0.22 [0.10,0.34]</cell><cell>0.22 [0.09, 0.35]</cell><cell>0.01 [-0.24, 0.26]</cell></row><row><cell>Talk/Poster Rating</cell><cell>164</cell><cell>0.35 [0.14, 0.56]</cell><cell>0.23 [0.01, 0.43]</cell><cell>-0.18 [-0.75, 0.41]</cell></row><row><cell>Published</cell><cell>530</cell><cell>0.26 [0.05, 0.47]</cell><cell>0.42 [0.20, 0.63]</cell><cell>0.26 [-1.62, 2.18]</cell></row><row><cell>Impact Factor</cell><cell>274</cell><cell>0.13 [-0.02, 0.28 ]</cell><cell>0.14 [-0.02 0.29]</cell><cell>0.02 [-0.23, 0.27]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Pleskac 1 , Ellie Kyung 2 , Gretchen Chapman 3 , and Oleg Urminsky 4</figDesc><table><row><cell>1 Indiana University</cell></row><row><cell>2 Babson College</cell></row><row><cell>3 Carnegie Mellon University</cell></row><row><cell>4 University of Chicago</cell></row><row><cell>March 21, 2025</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>Power Analyses . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 4 2.2 Conference Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2.3 Submission Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.4 Materials . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.4.1 Information Collected at Submission. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.4.2 Conflicts of Interest and Selection Process. . . . . . . . . . . . . . . . . . . . . . . . . 9 2.4.3 Collected Variables on Reviewers at Agreement. . . . . . . . . . . . . . . . . . . . . . 2.4.4 Collected Variables from Reviewers During and After Completing Reviews. . . . . . . 10 2.4.5 Intercorrelations Between Reviewer Characteristics. . . . . . . . . . . . . . . . . . . . 10 2.5 Talk Evaluation and Statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5.1 Characteristics of Raters. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.5.2 Rated Dimensions. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.5.3 Judged Overall Rating. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11 2.5.4 Collected Talk Statistics. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.6 Prestige Rating Survey. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 12 2.7 Author and Institution Count. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 13 2.8 Prestige Score . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 2.9 Poster Ratings. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14 2.10 Preference for Review Process Survey. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.11 Journal Publications. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 15 2.12 Analyses. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 3 Modeling the Text of the Long Abstracts 16 3.1 Text Corpus . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16 3.2 Topics Modeling . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 17 3.3 Sentiment Analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 Respondent Characteristics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 20 4.2 Preference Ratings . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 22 4.2.1 Regression Coefficients for Predictors of Double-vs. Single-blind Preference. . . . . . 22 4.3 Fairness Perceptions . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5 Differential Use Between Single-and Double-blind Review 23 5.1 Zero-order Correlations . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 23 5.2 Model Comparison . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 24 5.3 Regression Coefficients With All Characteristics Entered Simultaneously . . . . . . . . . . . . 25 5.4 Regression Coefficients with All Variables Entered Simultaneously Predicting Single or Double-Blind . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 28 5.5 Regression Coefficients With Each Variable Entered Alone . . . . . . . . . . . . . . . . . . . . 30 6 Comparing Single-vs. Double-blind in the Top 108 31 7 Predictive Validity of Review Ratings and Author and Submission Characteristics 33 7.1 Summary of Talk Outcomes Across sessions . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 7.2 Correlations Between Outcomes . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 33 7.3 Regression of Outcomes onto Single-and Double-blind Review Ratings . . . . . . . . . . . . . 34 7.4 Regression of Outcomes Onto Author and Submission Characteristics . . . . . . . . . . . . . 35</figDesc><table><row><cell>Methods 2.1 4 Survey of SJDM Members' Preferences 4.1</cell><cell>4 19</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 1 :</head><label>1</label><figDesc>Proportion of times a 95% credible interval for the posterior distribution over the Pearson-r correlation ρ excluded 0 for a sample of multivariate-normal data generated with a correlation.</figDesc><table><row><cell></cell><cell></cell><cell cols="3">Prop. Excludes 0</cell><cell></cell></row><row><cell cols="6">Correlation n = 108 n = 370 n = 430 n = 456 n = 530</cell></row><row><cell>0.10</cell><cell>0.1676</cell><cell>0.4878</cell><cell>0.5425</cell><cell>0.5667</cell><cell>0.6321</cell></row><row><cell>0.11</cell><cell>0.1829</cell><cell>0.5530</cell><cell>0.6237</cell><cell>0.6512</cell><cell>0.7169</cell></row><row><cell>0.12</cell><cell>0.2213</cell><cell>0.6322</cell><cell>0.6996</cell><cell>0.7279</cell><cell>0.7858</cell></row><row><cell>0.13</cell><cell>0.2479</cell><cell>0.7072</cell><cell>0.7671</cell><cell>0.7893</cell><cell>0.8570</cell></row><row><cell>0.14</cell><cell>0.2885</cell><cell>0.7670</cell><cell>0.8310</cell><cell>0.8463</cell><cell>0.9012</cell></row><row><cell>0.15</cell><cell>0.3185</cell><cell>0.8159</cell><cell>0.8814</cell><cell>0.8943</cell><cell>0.9390</cell></row><row><cell>0.16</cell><cell>0.3737</cell><cell>0.8720</cell><cell>0.9123</cell><cell>0.9258</cell><cell>0.9544</cell></row><row><cell>0.17</cell><cell>0.3997</cell><cell>0.9091</cell><cell>0.9441</cell><cell>0.9536</cell><cell>0.9749</cell></row><row><cell>0.18</cell><cell>0.4531</cell><cell>0.9410</cell><cell>0.9634</cell><cell>0.9693</cell><cell>0.9877</cell></row><row><cell>0.19</cell><cell>0.4849</cell><cell>0.9558</cell><cell>0.9800</cell><cell>0.9853</cell><cell>0.9933</cell></row><row><cell>0.20</cell><cell>0.5402</cell><cell>0.9708</cell><cell>0.9872</cell><cell>0.9897</cell><cell>0.9962</cell></row><row><cell>0.21</cell><cell>0.5727</cell><cell>0.9849</cell><cell>0.9923</cell><cell>0.9948</cell><cell>0.9985</cell></row><row><cell>0.22</cell><cell>0.6152</cell><cell>0.9886</cell><cell>0.9970</cell><cell>0.9972</cell><cell>0.9991</cell></row><row><cell>0.23</cell><cell>0.6575</cell><cell>0.9937</cell><cell>0.9982</cell><cell>0.9984</cell><cell>0.9970</cell></row><row><cell>0.24</cell><cell>0.6996</cell><cell>0.9970</cell><cell>0.9989</cell><cell>0.9988</cell><cell>0.9970</cell></row><row><cell>0.25</cell><cell>0.7375</cell><cell>0.9975</cell><cell>0.9996</cell><cell>0.9996</cell><cell>1.0000</cell></row><row><cell>0.26</cell><cell>0.7704</cell><cell>0.9993</cell><cell>0.9999</cell><cell>0.9997</cell><cell>1.0000</cell></row><row><cell>0.27</cell><cell>0.8019</cell><cell>0.9997</cell><cell>1.0000</cell><cell>1.0000</cell><cell>1.0000</cell></row><row><cell>0.28</cell><cell>0.8306</cell><cell>1.0000</cell><cell>1.0000</cell><cell>1.0000</cell><cell>1.0000</cell></row><row><cell>0.29</cell><cell>0.8596</cell><cell>1.0000</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 2 :</head><label>2</label><figDesc>Proportion of times a 95% credible interval for the posterior distribution over the difference in two Pearson-r correlations ρ excluded 0 for a sample of multivariate-normal data generated with a correlation.</figDesc><table><row><cell></cell><cell cols="5">Prop. 95% Credible Interval Excludes 0</cell></row><row><cell cols="6">Difference in Correlations n = 108 n = 370 n = 430 n = 456 n = 530</cell></row><row><cell>0.10</cell><cell>0.1095</cell><cell>0.2944</cell><cell>0.3291</cell><cell>0.3440</cell><cell>0.3892</cell></row><row><cell>0.11</cell><cell>0.1251</cell><cell>0.3448</cell><cell>0.3861</cell><cell>0.4136</cell><cell>0.4612</cell></row><row><cell>0.12</cell><cell>0.1491</cell><cell>0.3925</cell><cell>0.4403</cell><cell>0.4717</cell><cell>0.5249</cell></row><row><cell>0.13</cell><cell>0.1591</cell><cell>0.4529</cell><cell>0.5139</cell><cell>0.5422</cell><cell>0.5883</cell></row><row><cell>0.14</cell><cell>0.1828</cell><cell>0.5138</cell><cell>0.5735</cell><cell>0.6036</cell><cell>0.6685</cell></row><row><cell>0.15</cell><cell>0.1937</cell><cell>0.5682</cell><cell>0.6472</cell><cell>0.6642</cell><cell>0.7345</cell></row><row><cell>0.16</cell><cell>0.2186</cell><cell>0.6172</cell><cell>0.6963</cell><cell>0.7289</cell><cell>0.7891</cell></row><row><cell>0.17</cell><cell>0.2445</cell><cell>0.6838</cell><cell>0.7562</cell><cell>0.7740</cell><cell>0.8313</cell></row><row><cell>0.18</cell><cell>0.2720</cell><cell>0.7364</cell><cell>0.8038</cell><cell>0.8192</cell><cell>0.8708</cell></row><row><cell>0.19</cell><cell>0.2988</cell><cell>0.7854</cell><cell>0.8393</cell><cell>0.8661</cell><cell>0.9074</cell></row><row><cell>0.20</cell><cell>0.3263</cell><cell>0.8264</cell><cell>0.8830</cell><cell>0.8985</cell><cell>0.9363</cell></row><row><cell>0.21</cell><cell>0.3699</cell><cell>0.8675</cell><cell>0.9051</cell><cell>0.9267</cell><cell>0.9545</cell></row><row><cell>0.22</cell><cell>0.3895</cell><cell>0.8935</cell><cell>0.9335</cell><cell>0.9482</cell><cell>0.9726</cell></row><row><cell>0.23</cell><cell>0.4230</cell><cell>0.9230</cell><cell>0.9498</cell><cell>0.9637</cell><cell>0.9794</cell></row><row><cell>0.24</cell><cell>0.4539</cell><cell>0.9426</cell><cell>0.9708</cell><cell>0.9752</cell><cell>0.9891</cell></row><row><cell>0.25</cell><cell>0.4901</cell><cell>0.9577</cell><cell>0.9764</cell><cell>0.9828</cell><cell>0.9915</cell></row><row><cell>0.26</cell><cell>0.5238</cell><cell>0.9730</cell><cell>0.9865</cell><cell>0.9885</cell><cell>0.9972</cell></row><row><cell>0.27</cell><cell>0.5689</cell><cell>0.9785</cell><cell>0.9899</cell><cell>0.9948</cell><cell>0.9979</cell></row><row><cell>0.28</cell><cell>0.5981</cell><cell>0.9840</cell><cell>0.9954</cell><cell>0.9959</cell><cell>0.9995</cell></row><row><cell>0.29</cell><cell>0.6317</cell><cell>0.9916</cell><cell>0.9973</cell><cell>0.9983</cell><cell>0.9992</cell></row><row><cell>0.30</cell><cell>0.6690</cell><cell>0.9946</cell><cell>0.9984</cell><cell>0.9990</cell><cell>0.9999</cell></row><row><cell>0.31</cell><cell>0.6982</cell><cell>0.9965</cell><cell>0.9992</cell><cell>0.9994</cell><cell>0.9999</cell></row><row><cell>0.32</cell><cell>0.7269</cell><cell>0.9968</cell><cell>0.9994</cell><cell>0.9999</cell><cell>0.9999</cell></row><row><cell>0.33</cell><cell>0.7582</cell><cell>0.9989</cell><cell>0.9998</cell><cell>1.0000</cell><cell>1.0000</cell></row><row><cell>0.34</cell><cell>0.7857</cell><cell>0.9992</cell><cell>0.9999</cell><cell>1.0000</cell><cell>1.0000</cell></row><row><cell>0.35</cell><cell>0.8139</cell><cell>0.9997</cell><cell>1.0000</cell><cell>1.0000</cell><cell>1.0000</cell></row><row><cell>0.36</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_6"><head>Table 3 :</head><label>3</label><figDesc>Characteristics of authors and reviewers.</figDesc><table><row><cell>First Author</cell><cell>coauthors</cell><cell>Reviewers</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_7"><head></head><label></label><figDesc>Primary area of study for highest degree completed or in progress Economics; Marketing; Management; Psychology (Cognitive); Psychology (Social); Psychology (Other); Statistics; Other (Please specify); Prefer not to answer Department and institution where the degree was obtained Text Answer Graduation year for this degree Four digit year</figDesc><table><row><cell>Race/ethnic group Arab; Asian; Black, African, or African American; Hispanic or Latino origin; Native</cell></row><row><cell>American or Alaska Native; Native Hawaiian or Other Pacific Islander; Caucasian, White, or European;</cell></row><row><cell>Other (please specify); Prefer not to answer</cell></row><row><cell>Nationality List of countries</cell></row><row><cell>Undergraduate student; Masters student; PhD student; Post doctoral researcher; Research scien-</cell></row><row><cell>tist; Lecturer; Assistant Professor; Associate Professor; Full Professor; Practitioner; Other; Prefer not</cell></row><row><cell>to answer</cell></row><row><cell>Department Text answer</cell></row><row><cell>Institution Text Answer</cell></row></table><note>Gender Female; Male; Other (please specify); Prefer not to answer The submitting or corresponding author was also asked to report the following information Highest degree obtained or in progress Bachelors; Masters; Ph.D.; MD; MPH; Other; Prefer not to answer</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_8"><head>Table 4 :</head><label>4</label><figDesc>Distribution of the number of authors.</figDesc><table><row><cell cols="2">Number of Authors Frequency</cell></row><row><cell>1</cell><cell>26</cell></row><row><cell>2</cell><cell>218</cell></row><row><cell>3</cell><cell>176</cell></row><row><cell>4</cell><cell>78</cell></row><row><cell>5</cell><cell>26</cell></row><row><cell>6</cell><cell>6</cell></row><row><cell>2.4.2 Conflicts of Interest and Selection Process.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_9"><head></head><label></label><figDesc>Gender Female; Male; Other (please specify); Prefer not to answer Nationality Dropdown list of countries Race Arab; Asian; Black, African, or African American; Hispanic or Latino origin; Native American or Alaska Native; Native Hawaiian or Other Pacific Islander; Caucasian, White or European; Other (please specify); Prefer not to answer 2.4.4 Collected Variables from Reviewers During and After Completing Reviews.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_11"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell></cell><cell cols="3">: Distribution of rater characteristics.</cell></row><row><cell></cell><cell></cell><cell>Pre-and Post-</cell><cell></cell></row><row><cell></cell><cell></cell><cell>doctoral Students</cell><cell>Faculty</cell><cell>Total</cell></row><row><cell>Gender</cell><cell>Female</cell><cell>7 (58%)</cell><cell cols="2">7 (39%) 14 (47%)</cell></row><row><cell></cell><cell>Male</cell><cell>5 (42%)</cell><cell cols="2">11 (61%) 16 (53%)</cell></row><row><cell>Ethnicity</cell><cell>White</cell><cell>9 (75%)</cell><cell cols="2">15 (83%) 24 (80%)</cell></row><row><cell></cell><cell>Not White</cell><cell>2 (17%)</cell><cell>2 (11%)</cell><cell>4 (13%)</cell></row><row><cell></cell><cell>No Response</cell><cell>1 (8%)</cell><cell>1 (6%)</cell><cell>2 (7%)</cell></row><row><cell>Country of Home</cell><cell></cell><cell></cell><cell></cell></row><row><cell>Institution</cell><cell></cell><cell></cell><cell></cell></row><row><cell>(Nationality)</cell><cell>US</cell><cell>7 (58%)</cell><cell cols="2">14 (78%) 21 (70%)</cell></row><row><cell></cell><cell>International</cell><cell>4 (33%)</cell><cell>3 (17%)</cell><cell>7 (23%)</cell></row><row><cell></cell><cell>No Response</cell><cell>1 (8%)</cell><cell>1 (5%)</cell><cell>2 (7%)</cell></row><row><cell>Area of Specialty</cell><cell>Psychology</cell><cell>2 (17%)</cell><cell cols="2">12 (67%) 14 (47%)</cell></row><row><cell></cell><cell>Marketing</cell><cell>5 (42%)</cell><cell>1 (5.5%)</cell><cell>6 (20%)</cell></row><row><cell></cell><cell>Economics</cell><cell>1 (8%)</cell><cell>1 (5.5%)</cell><cell>2 (7%)</cell></row><row><cell></cell><cell>Other</cell><cell>4 (33%)</cell><cell>4 (22%)</cell><cell>8 (26%)</cell></row><row><cell>2.5.2 Rated Dimensions.</cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_12"><head>Table 6 :</head><label>6</label><figDesc>Reviewer characteristics who rated the prestige of institutions.</figDesc><table><row><cell>Gender</cell><cell></cell></row><row><cell>Men</cell><cell>35</cell></row><row><cell>Women</cell><cell>27</cell></row><row><cell>Prefer not to answer</cell><cell>2</cell></row><row><cell>Mean Age</cell><cell>44.6 (SD = 8.3, Range 31 to 67; N = 56)</cell></row><row><cell>Race</cell><cell></cell></row><row><cell>Asian or Asian American</cell><cell>13</cell></row><row><cell>Black, African, or African American</cell><cell>2</cell></row><row><cell>White or European</cell><cell>48</cell></row><row><cell>prefer not to answer</cell><cell>4</cell></row><row><cell>Department</cell><cell></cell></row><row><cell>Cognitive psychology</cell><cell>10</cell></row><row><cell>Social psychology</cell><cell>6</cell></row><row><cell>Other psychology</cell><cell>1</cell></row><row><cell>Marketing</cell><cell>27</cell></row><row><cell>Organizational behavior</cell><cell>4</cell></row><row><cell>Economics</cell><cell>1</cell></row><row><cell>Policy</cell><cell>1</cell></row><row><cell>Decision Sciences</cell><cell>14</cell></row><row><cell>prefer not to answer</cell><cell>1</cell></row><row><cell>Position Rank</cell><cell></cell></row><row><cell>Assistant Professor</cell><cell>12</cell></row><row><cell>Associate Professor</cell><cell>22</cell></row><row><cell>Full Professor</cell><cell>29</cell></row><row><cell>Clinical Professor / Professor of Practice</cell><cell>1</cell></row><row><cell>prefer to self describe</cell><cell>1</cell></row><row><cell>Continent</cell><cell></cell></row><row><cell>Asia</cell><cell>7</cell></row><row><cell>Europe</cell><cell>8</cell></row><row><cell>North America</cell><cell>50</cell></row><row><cell>2.5.4 Collected Talk Statistics.</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_13"><head>Table 7 :</head><label>7</label><figDesc>Characteristics of the respondents to the survey of the Society for Judgment and Decision Making on single-vs. double-blind review.</figDesc><table><row><cell></cell><cell>Group</cell><cell>Count</cell></row><row><cell>Gender</cell><cell>Female</cell><cell>73 (42%)</cell></row><row><cell></cell><cell>Male</cell><cell>85 (49%)</cell></row><row><cell></cell><cell>Other</cell><cell>1 (1%)</cell></row><row><cell></cell><cell>No Response</cell><cell>14 (8%)</cell></row><row><cell>Area of Ph.D.</cell><cell>Cognitive Psychology</cell><cell>36 (21%)</cell></row><row><cell></cell><cell>Social Psychology</cell><cell>26 (15%)</cell></row><row><cell></cell><cell>Other Psychology</cell><cell>10 (6%)</cell></row><row><cell></cell><cell>Marketing</cell><cell>31 (18%)</cell></row><row><cell></cell><cell>Organizational Behavior</cell><cell>9 (5%)</cell></row><row><cell></cell><cell>Management</cell><cell>6 (3%)</cell></row><row><cell></cell><cell>Economics</cell><cell>1 (1%)</cell></row><row><cell></cell><cell>Accounting</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Finance</cell><cell>1 (1%)</cell></row><row><cell></cell><cell>Public Policy</cell><cell>2 (1%)</cell></row><row><cell></cell><cell>Law</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Medicine</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Decision Science</cell><cell>24 (14%)</cell></row><row><cell></cell><cell>Other</cell><cell>10 (6%)</cell></row><row><cell></cell><cell>No Response</cell><cell>17 (10%)</cell></row><row><cell>Department Area</cell><cell>Cognitive Psychology</cell><cell>21 (12%)</cell></row><row><cell></cell><cell>Social Psychology</cell><cell>11 (6%)</cell></row><row><cell></cell><cell>Other Psychology</cell><cell>8 (5%)</cell></row><row><cell></cell><cell>Marketing</cell><cell>48 (28%)</cell></row><row><cell></cell><cell>Organizational Behavior</cell><cell>11 (6%)</cell></row><row><cell></cell><cell>Management</cell><cell>13 (8%)</cell></row><row><cell></cell><cell>Economics</cell><cell>3 (2%)</cell></row><row><cell></cell><cell>Accounting</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Finance</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Public policy</cell><cell>4 (2%)</cell></row><row><cell></cell><cell>Law</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>Medicine</cell><cell>2 (1%)</cell></row><row><cell></cell><cell>Decision Science</cell><cell>15 (9%)</cell></row><row><cell></cell><cell>Other</cell><cell>19 (11%)</cell></row><row><cell></cell><cell>No Response</cell><cell>18 (10%)</cell></row><row><cell>Position</cell><cell>Undergraduate</cell><cell>1 (1%)</cell></row><row><cell></cell><cell>Masters student / graduate</cell><cell>0 (0%)</cell></row><row><cell></cell><cell>PhD student / graduate</cell><cell>35 (20%)</cell></row><row><cell></cell><cell>Postdoctoral Researcher</cell><cell>18 (10%)</cell></row><row><cell></cell><cell>Research Scientist</cell><cell>4 (2%)</cell></row><row><cell></cell><cell>Assistant Professor</cell><cell>49 (28%)</cell></row><row><cell></cell><cell>Associate Professor</cell><cell>24 (14%)</cell></row><row><cell></cell><cell>Full Professor</cell><cell>25 (14%)</cell></row><row><cell></cell><cell>Other</cell><cell>3 (2%)</cell></row><row><cell></cell><cell>No Response</cell><cell>14 (8%)</cell></row><row><cell>Member of SJDM</cell><cell>Yes</cell><cell>154 (89%)</cell></row><row><cell></cell><cell>No</cell><cell>8 (5%)</cell></row><row><cell></cell><cell>No Response</cell><cell>11 (6%)</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_14"><head>Table 8 :</head><label>8</label><figDesc>Coefficients from regressing perspective, reviewing experience, and fairness on double-blind vs.</figDesc><table><row><cell>single-blind preference.</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell cols="2">w/o Fairness</cell><cell></cell><cell>w Fairness</cell></row><row><cell></cell><cell>M</cell><cell>95% CI</cell><cell>M</cell><cell>95% CI</cell></row><row><cell>Intercept</cell><cell>0.139</cell><cell>[-0.025, 0.298]</cell><cell>0.125</cell><cell>[-0.011, 0.261]</cell></row><row><cell cols="2">Reviewer vs. Author -0.112</cell><cell>[-0.24, 0.012]</cell><cell>-0.113</cell><cell>[-0.242, 0.017]</cell></row><row><cell cols="2">Attendee vs Author -0.225</cell><cell>[-0.353, -0.1]</cell><cell cols="2">-0.229 [-0.36, -0.098]</cell></row><row><cell cols="4">Reviewing Experience (z) -0.206 [-0.364, -0.049] -0.091</cell><cell>[-0.231, 0.047]</cell></row><row><cell cols="2">Reviewer vs. Author x Reviewing Experience -0.042</cell><cell>[-0.17, 0.082]</cell><cell>-0.043</cell><cell>[-0.165, 0.084]</cell></row><row><cell cols="2">Attendee vs. Author x Reviewing Experience -0.008</cell><cell>[-0.135, 0.119]</cell><cell>-0.008</cell><cell>[-0.135, 0.117]</cell></row><row><cell>Fairness of Double-vs. Single-Blind (z)</cell><cell>-</cell><cell>-</cell><cell cols="2">0.538 [0.422, 0.652]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_15"><head>Table 9 :</head><label>9</label><figDesc>Coefficients from regressing perspective and reviewing experience onto fairness.</figDesc><table><row><cell>M</cell><cell>95% CI</cell></row><row><cell>Double (1) or Single (0) 1.31</cell><cell>[1.14, 1.48]</cell></row><row><cell>Reviewing Experience (z) 0.20</cell><cell>[0.08, 0.32]</cell></row><row><cell>Double or Single x Reviewer Experience (z) -0.24</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_17"><head>Table 10 :</head><label>10</label><figDesc>Model comparison between models with interactions between reviewer characteristics and review condition.</figDesc><table><row><cell>∆elpd se(∆elpd)</cell><cell>elpd loo</cell><cell>se(elpd loo )</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_18"><head>Table 11 :</head><label>11</label><figDesc>Coefficients when regressing single-and double-blind ratings onto author and submission characteristics simultaneously.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Coefficient</cell><cell>Interaction Coefficient</cell></row><row><cell></cell><cell>Intercept</cell><cell>-0.604 [-1.037, -0.165]</cell><cell></cell></row><row><cell></cell><cell>Condition: Single (0) or Double (1)</cell><cell>0.216 [-0.2, 0.627]</cell><cell></cell></row><row><cell>First Author</cell><cell>Male vs Female</cell><cell>0.172 [-0.008, 0.352]</cell><cell>0.225 [0.043, 0.408]</cell></row><row><cell></cell><cell>No Answer vs Female</cell><cell>-0.413 [-1.124, 0.3]</cell><cell>-0.24 [-0.963, 0.489]</cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.04 [-0.161, 0.081]</cell><cell>-0.029 [-0.147, 0.089]</cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.066 [-0.072, 0.203]</cell><cell>-0.023 [-0.162, 0.117]</cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.067 [-0.228, 0.095]</cell><cell>0.166 [0.005, 0.328]</cell></row><row><cell></cell><cell>Black vs White</cell><cell>-0.099 [-1.051, 0.859]</cell><cell>-0.34 [-1.308, 0.634]</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>0.072 [-0.337, 0.48]</cell><cell>-0.076 [-0.49, 0.337]</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell>0.345 [-0.985, 1.672]</cell><cell>-0.131 [-1.487, 1.227]</cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.375 [-0.064, 0.812]</cell><cell>-0.141 [-0.59, 0.311]</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>0.081 [-0.148, 0.313]</cell><cell>-0.046 [-0.279, 0.186]</cell></row><row><cell></cell><cell>SJDM Appearances</cell><cell>0.104 [0.009, 0.198]</cell><cell>0.012 [-0.083, 0.106]</cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.169 [0.044, 0.295]</cell><cell>-0.055 [-0.182, 0.073]</cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.169 [0.044, 0.295]</cell><cell>-0.055 [-0.182, 0.073]</cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.042 [-0.089, 0.173]</cell><cell>-0.032 [-0.164, 0.1]</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.137 [-0.149, 0.422]</cell><cell>0.083 [-0.208, 0.372]</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.081 [-0.146, 0.308]</cell><cell>0.078 [-0.149, 0.308]</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell>0.888 [-0.533, 2.319]</cell><cell>-1.291 [-2.769, 0.167]</cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>0.336 [-0.31, 0.98]</cell><cell>-0.298 [-0.939, 0.34]</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>0.539 [0.07, 1.008]</cell><cell>-0.493 [-0.962, -0.025]</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>0.522 [0.072, 0.969]</cell><cell>-0.34 [-0.788, 0.11]</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>0.631 [0.126, 1.139]</cell><cell>-0.578 [-1.094, -0.06]</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>0.209 [-0.427, 0.847]</cell><cell>-0.212 [-0.842, 0.409]</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>0.519 [0.127, 0.908]</cell><cell>-0.316 [-0.703, 0.078]</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.336 [-0.034, 0.707]</cell><cell>-0.196 [-0.571, 0.176]</cell></row><row><cell>Coauthors</cell><cell>Proportion Male Authors</cell><cell>-0.04 [-0.131, 0.052]</cell><cell>-0.107 [-0.2, -0.016]</cell></row><row><cell></cell><cell>Ave. SJDM Appearances</cell><cell>0.11 [0.028, 0.192]</cell><cell>-0.01 [-0.094, 0.074]</cell></row><row><cell></cell><cell>Ave. Prestige Score</cell><cell>0.042 [-0.089, 0.173]</cell><cell>-0.032 [-0.164, 0.1]</cell></row><row><cell></cell><cell>Ave. Seniority</cell><cell>0.146 [0.067, 0.226]</cell><cell>-0.088 [-0.168, -0.007]</cell></row><row><cell>Submission</cell><cell>Empirical Studies vs Traditional</cell><cell>-0.034 [-0.186, 0.118]</cell><cell>0.019 [-0.131, 0.17]</cell></row><row><cell></cell><cell>Psychology of JDM vs Traditional</cell><cell>0.01 [-0.191, 0.207]</cell><cell>-0.009 [-0.208, 0.193]</cell></row><row><cell></cell><cell>Sentiment</cell><cell>-0.05 [-0.117, 0.016]</cell><cell>0.046 [-0.021, 0.112]</cell></row><row><cell>Reviewer</cell><cell>Male vs Female</cell><cell>-0.028 [-0.102, 0.045]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.013 [-0.07, 0.043]</cell><cell></cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.023 [-0.015, 0.061]</cell><cell></cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.035 [-0.084, 0.154]</cell><cell></cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.018 [-0.095, 0.128]</cell><cell></cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>-0.002 [-0.097, 0.092]</cell><cell></cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>-0.011 [-0.157, 0.134]</cell><cell></cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>-0.084 [-0.266, 0.102]</cell><cell></cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>-0.079 [-0.452, 0.295]</cell><cell></cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>-0.013 [-0.151, 0.125]</cell><cell></cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.006 [-0.109, 0.121]</cell><cell></cell></row><row><cell></cell><cell>Reviewer No. Times Review Past 7 Years</cell><cell>-0.018 [-0.057, 0.019]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_19"><head>Table 12 :</head><label>12</label><figDesc>Coefficients when regressing single-or double-blind review ratings onto author and submission characteristics simultaneously for multiauthor submissions.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Coefficient</cell><cell>Interaction Coefficient</cell></row><row><cell></cell><cell>Intercept</cell><cell>-0.459 [-0.882, -0.04]</cell><cell></cell></row><row><cell></cell><cell>Condition: Single (0) or Double (1)</cell><cell>0.146 [-0.262, 0.552]</cell><cell></cell></row><row><cell>First Author</cell><cell>Male vs Female</cell><cell>0.141 [0.006, 0.275]</cell><cell>0.102 [-0.035, 0.238]</cell></row><row><cell></cell><cell>No Answer vs Female</cell><cell>-0.075 [-1.05, 0.901]</cell><cell>0.461 [-0.538, 1.457]</cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.024 [-0.157, 0.11]</cell><cell>-0.046 [-0.176, 0.083]</cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.092 [-0.05, 0.232]</cell><cell>-0.045 [-0.191, 0.1]</cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.077 [-0.243, 0.086]</cell><cell>0.181 [0.013, 0.349]</cell></row><row><cell></cell><cell>Black vs White</cell><cell>-0.09 [-1.03, 0.848]</cell><cell>-0.331 [-1.317, 0.654]</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>0.069 [-0.334, 0.47]</cell><cell>-0.108 [-0.521, 0.308]</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell>0.317 [-1.003, 1.637]</cell><cell>-0.119 [-1.482, 1.238]</cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.453 [-0.006, 0.906]</cell><cell>-0.13 [-0.597, 0.338]</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>0.081 [-0.151, 0.312]</cell><cell>-0.038 [-0.269, 0.196]</cell></row><row><cell></cell><cell>SJDM Apperances</cell><cell>0.137 [0.049, 0.224]</cell><cell>0.02 [-0.069, 0.11]</cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.175 [0.081, 0.27]</cell><cell>-0.06 [-0.157, 0.036]</cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.186 [-0.114, 0.49]</cell><cell>0.087 [-0.219, 0.394]</cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.137 [-0.095, 0.367]</cell><cell>0.056 [-0.183, 0.299]</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.122 [-0.064, 0.307]</cell><cell>0.002 [-0.187, 0.189]</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.134 [-0.104, 0.372]</cell><cell>-0.073 [-0.314, 0.168]</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell>0.413 [-0.987, 1.813]</cell><cell>-1.04 [-2.488, 0.395]</cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>0.049 [-0.579, 0.676]</cell><cell>-0.117 [-0.747, 0.51]</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>0.312 [-0.136, 0.766]</cell><cell>-0.317 [-0.768, 0.137]</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>0.316 [-0.121, 0.753]</cell><cell>-0.22 [-0.659, 0.219]</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>0.455 [-0.044, 0.959]</cell><cell>-0.462 [-0.973, 0.046]</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>0.179 [-0.506, 0.866]</cell><cell>-0.141 [-0.81, 0.526]</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>0.437 [0.044, 0.829]</cell><cell>-0.264 [-0.657, 0.132]</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.339 [-0.039, 0.713]</cell><cell>-0.217 [-0.595, 0.163]</cell></row><row><cell>Coauthors</cell><cell>Proportion Male Coauthors</cell><cell>-0.009 [-0.078, 0.061]</cell><cell>-0.072 [-0.142, -0.002]</cell></row><row><cell></cell><cell>Ave. SJDM Coauthor Appearances</cell><cell>0.109 [0.033, 0.186]</cell><cell>-0.016 [-0.093, 0.062]</cell></row><row><cell></cell><cell>Ave. Coauthor Prestige Score</cell><cell>0.027 [-0.067, 0.123]</cell><cell>-0.027 [-0.122, 0.069]</cell></row><row><cell></cell><cell>Ave. Coauthor Seniority</cell><cell>0.117 [0.042, 0.193]</cell><cell>-0.104 [-0.179, -0.028]</cell></row><row><cell>Submission</cell><cell>Empirical Studies vs Traditional</cell><cell>-0.031 [-0.189, 0.126]</cell><cell>0.07 [-0.087, 0.228]</cell></row><row><cell></cell><cell>Psychology of JDM vs Traditional</cell><cell>0.007 [-0.199, 0.213]</cell><cell>0.064 [-0.144, 0.273]</cell></row><row><cell></cell><cell>Sentiment</cell><cell>-0.044 [-0.112, 0.024]</cell><cell>0.028 [-0.041, 0.098]</cell></row><row><cell>Reviewer</cell><cell>Male vs Female</cell><cell>-0.028 [-0.105, 0.049]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.019 [-0.076, 0.04]</cell><cell></cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.025 [-0.014, 0.064]</cell><cell></cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.032 [-0.09, 0.154]</cell><cell></cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.016 [-0.099, 0.13]</cell><cell></cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>-0.004 [-0.102, 0.094]</cell><cell></cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.001 [-0.151, 0.153]</cell><cell></cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>-0.087 [-0.281, 0.105]</cell><cell></cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>-0.072 [-0.461, 0.321]</cell><cell></cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>-0.012 [-0.152, 0.13]</cell><cell></cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.001 [-0.117, 0.12]</cell><cell></cell></row><row><cell></cell><cell>Reviewer No. Times Review Past 7 Years</cell><cell>-0.018 [-0.057, 0.021]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_20"><head>Table 13 :</head><label>13</label><figDesc>Coefficients when regressing single-or double-blind review ratings onto author and submission characteristics simultaneously.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Single (N = 440)</cell><cell>Double (N = 440)</cell></row><row><cell></cell><cell>Intercept</cell><cell>-0.754 [-1.202, -0.303]</cell><cell>-0.289 [-0.745, 0.172]</cell></row><row><cell>First Author</cell><cell>Male vs Female</cell><cell>0.179 [-0.001, 0.361]</cell><cell>0.383 [0.197, 0.567]</cell></row><row><cell></cell><cell>No Answer vs Female</cell><cell>-0.43 [-1.151, 0.277]</cell><cell>-0.637 [-1.359, 0.095]</cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.022 [-0.142, 0.098]</cell><cell>-0.064 [-0.186, 0.058]</cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.063 [-0.075, 0.202]</cell><cell>0.045 [-0.097, 0.186]</cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.07 [-0.234, 0.09]</cell><cell>0.101 [-0.068, 0.268]</cell></row><row><cell></cell><cell>Black vs White</cell><cell>-0.113 [-1.067, 0.843]</cell><cell>-0.449 [-1.421, 0.521]</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>0.075 [-0.329, 0.481]</cell><cell>0.016 [-0.397, 0.424]</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell>0.353 [-0.972, 1.685]</cell><cell>0.228 [-1.123, 1.573]</cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.367 [-0.074, 0.808]</cell><cell>0.243 [-0.194, 0.683]</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>0.078 [-0.158, 0.308]</cell><cell>0.046 [-0.193, 0.283]</cell></row><row><cell></cell><cell>SJDM Apperances</cell><cell>0.11 [0.016, 0.204]</cell><cell>0.113 [0.016, 0.211]</cell></row><row><cell></cell><cell>Institutional Prestige</cell><cell>0.166 [0.038, 0.291]</cell><cell>0.116 [-0.012, 0.246]</cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.135 [-0.152, 0.418]</cell><cell>0.218 [-0.071, 0.509]</cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.076 [-0.154, 0.304]</cell><cell>0.163 [-0.069, 0.394]</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.137 [-0.045, 0.32]</cell><cell>0.112 [-0.076, 0.298]</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.084 [-0.148, 0.315]</cell><cell>0.028 [-0.202, 0.262]</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell>0.947 [-0.483, 2.374]</cell><cell>-0.418 [-1.878, 1.028]</cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>0.384 [-0.251, 1.025]</cell><cell>0.053 [-0.601, 0.718]</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>0.615 [0.149, 1.074]</cell><cell>0.046 [-0.429, 0.525]</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>0.581 [0.137, 1.024]</cell><cell>0.19 [-0.267, 0.649]</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>0.669 [0.156, 1.177]</cell><cell>0.062 [-0.465, 0.586]</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>0.257 [-0.377, 0.893]</cell><cell>-0.005 [-0.648, 0.638]</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>0.575 [0.187, 0.958]</cell><cell>0.205 [-0.189, 0.6]</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.361 [-0.007, 0.734]</cell><cell>0.15 [-0.23, 0.532]</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_21"><head>Table 15 :</head><label>15</label><figDesc>Coefficients when single and double-blind review ratings together onto submission characteristic, the review condition, and the interaction as an individual set without any other characteristic.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Coefficient</cell><cell>Interaction Coefficient</cell><cell>N</cell></row><row><cell>First Author</cell><cell>Male vs Female</cell><cell>0.094 [-0.036, 0.225]</cell><cell>0.081 [-0.040 0.204]</cell><cell></cell></row><row><cell></cell><cell>No Answer vs Female</cell><cell>-0.361 [-0.966, 0.261]</cell><cell>-0.131 [-0.677 0.429]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.103 [-0.172, -0.034]</cell><cell>0.073 [0.012, 0.136]</cell><cell></cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.173 [0.042, 0.305 ]</cell><cell>-0.024 [-0.145, 0.096]</cell><cell></cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.031 [-0.192, 0.125]</cell><cell>0.116 [-0.031, 0.264]</cell><cell></cell></row><row><cell></cell><cell>Black vs White</cell><cell>0.172 [-0.828, 1.187]</cell><cell>-0.318 [-1.268, 0.623]</cell><cell>"</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>0.320 [-0.104, 0.742]</cell><cell>-0.089 [-0.487, 0.316]</cell><cell>"</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell>0.101 [-1.332, 1.525]</cell><cell>-0.079 [-1.388, 1.260]</cell><cell>"</cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.244 [-0.223, 0.704]</cell><cell>-0.100[-0.535, 0.341]</cell><cell>"</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>-0.010 [-0.234, 0.211]</cell><cell>-0.062 [-0.272, 0.143 ]</cell><cell>"</cell></row><row><cell></cell><cell>SJDM Appearances</cell><cell>0.119 [0.047, 0.190]</cell><cell>0.043 [-0.025, 0.111]</cell><cell></cell></row><row><cell></cell><cell>Institutional Prestige</cell><cell>0.266 [0.198, 0.336]</cell><cell>-0.083 [-0.148, -0.018]</cell><cell></cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.111 [-0.157, 0.375]</cell><cell>0.033 [-0.215, 0.279]</cell><cell></cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.243 [0.023, 0.462]</cell><cell>-0.032 [-0.149, 0.267]</cell><cell>"</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.221 [0.060, 0.384]</cell><cell>0.083 [-0.188, 0.121]</cell><cell>"</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.353 [0.140, 0.566]</cell><cell>0.078 [-0.341, 0.060]</cell><cell>"</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell>0.247 [-1.160, 1.680]</cell><cell>-0.688 [-2.103, 0.680]</cell><cell></cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>-0.184 [-0.728, 0.349]</cell><cell>-0.017 [-0.508, 0.479]</cell><cell>"</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>0.337[0.081, 0.597]</cell><cell>-0.338 [-0.573, -0.105]</cell><cell>"</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>0.271 [-0.022, 0.576]</cell><cell>-0.211 [-0.484, 0.058]</cell><cell>"</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>0.354 [-0.065, 0.777]</cell><cell>-0.451[-0.835, -0.071]</cell><cell>"</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>-0.036 [-0.625, 0.575]</cell><cell>-0.151 [-0.684, 0.375 ]</cell><cell>"</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>0.373 [0.106, 0.650]</cell><cell>-0.209 [-0.454, 0.034]</cell><cell>"</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.059[-0.263, 0.389]</cell><cell>-0.102 [-0.403, 0.191]</cell><cell>"</cell></row><row><cell>Authors</cell><cell>Proportion Male Coauthors</cell><cell>0.042 [-0.025, 0.108 ]</cell><cell>-0.075 [-0.139, -0.012]</cell><cell></cell></row><row><cell></cell><cell>Proportion Male Authors</cell><cell>-0.04 [-0.131, 0.052]</cell><cell>-0.107 [-0.2, -0.016]</cell><cell></cell></row><row><cell></cell><cell>Ave. Co-author SJDM Appearances</cell><cell>0.202 [0.136, 0.267]</cell><cell>-0.084 [-0.146, -0.022]</cell><cell></cell></row><row><cell></cell><cell>Ave. SJDM Appearances</cell><cell>0.236 [0.172, 0.300]</cell><cell>-0.065 [-0.127, -0.004]</cell><cell></cell></row><row><cell></cell><cell>Ave. Co-author Institutional Prestige</cell><cell>0.237 [0.174, 0.302]</cell><cell>-0.082 [-0.145, -0.020]</cell><cell></cell></row><row><cell></cell><cell>Ave. Institutional Prestige</cell><cell>0.272 [0.210, 0.337]</cell><cell>-0.089 [-0.149, -0.028]</cell><cell></cell></row><row><cell></cell><cell>Ave. Co-author Seniority</cell><cell>0.152 [0.084, 0.220]</cell><cell>-0.141 [-0.205, -0.078]</cell><cell></cell></row><row><cell></cell><cell>Ave. Author Seniority</cell><cell>0.110 [0.047, 0.174]</cell><cell>-0.047 [-0.106, 0.013]</cell><cell></cell></row><row><cell>Submission</cell><cell>Empirical Studies vs Traditional</cell><cell>0.020 [-0.137 0.173]</cell><cell>0.031 [-0.110, 0.174]</cell><cell></cell></row><row><cell></cell><cell>Psychology of JDM vs Traditional</cell><cell>-0.116 [-0.313, 0.084]</cell><cell>0.033 [-0.152, 0.217]</cell><cell></cell></row><row><cell></cell><cell>Sentiment</cell><cell>-0.010 [-0.074, 0.055]</cell><cell>0.026 [-0.035, 0.087]</cell><cell></cell></row><row><cell>Reviewer</cell><cell>Male vs Female</cell><cell>-0.024 [-0.116, 0.070]</cell><cell>0.035 [-0.095, 0.164]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>-0.001 [-0.008, 0.007]</cell><cell>0.003 [-0.013, 0.007]</cell><cell></cell></row><row><cell></cell><cell>Institutional Prestige</cell><cell>0.015 [-0.033, 0.062]</cell><cell>0.009 [-0.056, 0.076]</cell><cell></cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.074 [-0.084, 0.154]</cell><cell>-0.061 [-0.275, 0.159]</cell><cell></cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.015 [-0.095, 0.128]</cell><cell>0.054 [-0.159, 0.159]</cell><cell>"</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.001 [-0.097, 0.092]</cell><cell>-0.019 [-0.193, 0.145]</cell><cell>"</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>-0.003 [-0.157, 0.134]</cell><cell>-</cell><cell>"</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>-0.084 [-0.266, 0.102]</cell><cell>-0.078 [-0.400, 0.247]</cell><cell></cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>-0.079 [-0.452, 0.295]</cell><cell>-</cell><cell>"</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>-0.013 [-0.151, 0.125]</cell><cell>-0.069 [-0.238, 0.093]</cell><cell>"</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.006 [-0.109, 0.121]</cell><cell>-0.111 [-0.302, 0.079]</cell><cell>"</cell></row><row><cell></cell><cell>Reviewer No. Times Review Past 7 Years</cell><cell>-0.009 [-0.039, 0.020]</cell><cell>-0.013 [-0.025, 0.050]</cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_22"><head>Table 16 :</head><label>16</label><figDesc>Mean (M)  and standard deviation (SD) of talk ratings, attendance, and total potential questions</figDesc><table><row><cell></cell><cell cols="6">Overall Rating (Std.) Attendance Potential Questions</cell></row><row><cell>Session</cell><cell>M</cell><cell>SD</cell><cell>M</cell><cell>SD</cell><cell>M</cell><cell>SD</cell></row><row><cell cols="2">1 -0.13</cell><cell>0.45</cell><cell cols="3">99.2 23.8 3.3</cell><cell>1.5</cell></row><row><cell cols="2">2 -0.04</cell><cell>0.31</cell><cell cols="3">117.3 21.4 3.3</cell><cell>2.0</cell></row><row><cell cols="2">3 0.09</cell><cell>0.40</cell><cell cols="3">102.8 30.3 2.5</cell><cell>1.6</cell></row><row><cell cols="2">4 0.07</cell><cell>0.39</cell><cell cols="3">89.5 20.9 2.0</cell><cell>1.1</cell></row><row><cell cols="2">5 0.20</cell><cell>0.40</cell><cell cols="3">100.6 37.6 3.4</cell><cell>1.3</cell></row><row><cell cols="2">6 -0.08</cell><cell>0.29</cell><cell cols="3">106.7 43.0 2.5</cell><cell>1.9</cell></row><row><cell cols="2">7 0.14</cell><cell>0.43</cell><cell cols="3">102.4 44.7 3.1</cell><cell>1.8</cell></row><row><cell cols="2">8 0.05</cell><cell>0.39</cell><cell cols="3">62.6 28.8 2.8</cell><cell>1.3</cell></row><row><cell cols="2">9 0.19</cell><cell>0.27</cell><cell cols="3">65.1 17.1 1.9</cell><cell>1.8</cell></row><row><cell cols="7">Talk ratings were standardized within each talk evaluator.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_23"><head>Table 17 :</head><label>17</label><figDesc>Coefficients from regressing conference outcomes onto single-and double-blind review ratings simultaneously.</figDesc><table><row><cell></cell><cell></cell><cell>Single</cell><cell></cell><cell>Double</cell></row><row><cell>N</cell><cell>M</cell><cell>95% CI</cell><cell>M</cell><cell>95% CI</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_24"><head>Table 18 :</head><label>18</label><figDesc>Coefficients from regressing standardized conference outcomes onto submission characteristics.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Attendance (z) (N = 84)</cell><cell>Overall (z) (N = 84)</cell><cell>Questions (z) (N = 84)</cell><cell>Poster Rating (z) (N = 44)</cell><cell>Talk/Poster Rating (z) (N = 127)</cell><cell>Publication (N = 440)</cell><cell>Imp</cell></row><row><cell></cell><cell>Intercept</cell><cell>-1.067, [-2.628, 0.52]</cell><cell>-0.405, [-1.162, 0.337]</cell><cell>0.768, [-1.135, 2.71]</cell><cell>-1.366, [-2.935, 0.248]</cell><cell>-1.566, [-3.28, 0.147]</cell><cell>0.694, [-0.675, 2.054]</cell><cell>0.2</cell></row><row><cell></cell><cell>Male vs Female</cell><cell>-0.255, [-0.859, 0.349]</cell><cell>0.138, [-0.151, 0.431]</cell><cell>-0.123, [-0.875, 0.637]</cell><cell>0.532, [-0.01, 1.081]</cell><cell>0.443, [-0.079, 0.984]</cell><cell>0.235, [-0.359, 0.827]</cell><cell>-0.1</cell></row><row><cell>First Author</cell><cell>No Answer vs Female</cell><cell>2.168, [-0.058, 4.455]</cell><cell>1.528, [0.447, 2.62]</cell><cell>2.61, [-0.365, 5.6]</cell><cell></cell><cell>2.668, [0.146, 5.243]</cell><cell>-22.123, [-60.462, -2.373]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>0.682, [0.103, 1.258]</cell><cell>-0.041, [-0.313, 0.235]</cell><cell>-0.208, [-0.919, 0.505]</cell><cell>0.154, [-1.085, 1.418]</cell><cell>-0.035, [-0.663, 0.609]</cell><cell>-0.249, [-0.645, 0.148]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.536, [0.069, 1.007]</cell><cell>0.035, [-0.195, 0.269]</cell><cell>-0.099, [-0.719, 0.525]</cell><cell>0.355, [-0.108, 0.819]</cell><cell>0.082, [-0.344, 0.503]</cell><cell>0.124, [-0.332, 0.574]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.444, [-1.024, 0.143]</cell><cell>0.139, [-0.148, 0.421]</cell><cell>-0.256, [-1.012, 0.5]</cell><cell>0.196, [-0.194, 0.591]</cell><cell>0.273, [-0.214, 0.758]</cell><cell>-0.211, [-0.751, 0.319]</cell><cell>0.</cell></row><row><cell></cell><cell>Black vs White</cell><cell>0.511, [-0.446, 1.466]</cell><cell>0.283, [-0.187, 0.753]</cell><cell>1.224, [-0.004, 2.434]</cell><cell></cell><cell></cell><cell>-0.611, [-4.359, 3.074]</cell><cell>-1.2</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>1.01, [-0.825, 2.903]</cell><cell>0.311, [-0.575, 1.198]</cell><cell>-0.106, [-2.435, 2.238]</cell><cell></cell><cell>0.727, [-0.379, 1.846]</cell><cell>1.25, [-0.183, 2.892]</cell><cell>0.3</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.561, [-1.627, 2.735]</cell><cell>-42.501, [-118.378, -1.844]</cell><cell></cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.237, [-0.906, 1.376]</cell><cell>0.064, [-0.5, 0.616]</cell><cell>-0.631, [-2.109, 0.849]</cell><cell></cell><cell>0.21, [-1.071, 1.501]</cell><cell>0.683, [-0.795, 2.243]</cell><cell>0.0</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>-0.273, [-1.16, 0.62]</cell><cell>-0.156, [-0.588, 0.281]</cell><cell>-0.619, [-1.747, 0.536]</cell><cell>0.972, [-0.19, 2.143]</cell><cell>0.179, [-0.704, 1.065]</cell><cell>-0.358, [-1.137, 0.411]</cell><cell>-0.0</cell></row><row><cell></cell><cell>SJDM Apperances</cell><cell>0.144, [-0.106, 0.4]</cell><cell>0.069, [-0.054, 0.193]</cell><cell>-0.051, [-0.37, 0.278]</cell><cell>-0.007, [-0.585, 0.585]</cell><cell>0.138, [-0.131, 0.397]</cell><cell>-0.18, [-0.462, 0.101]</cell><cell>0.0</cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.179, [-0.176, 0.532]</cell><cell>0.152, [-0.019, 0.32]</cell><cell>0.257, [-0.199, 0.705]</cell><cell>0.273, [-0.212, 0.755]</cell><cell>0.423, [0.043, 0.798]</cell><cell>0.24, [-0.153, 0.635]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.06, [-0.945, 1.044]</cell><cell>0.453, [-0.027, 0.932]</cell><cell>0.232, [-1.038, 1.48]</cell><cell>-0.228, [-1.657, 1.206]</cell><cell>0.875, [-0.136, 1.877]</cell><cell>-0.282, [-1.234, 0.685]</cell><cell>0.1</cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.277, [-0.446, 0.996]</cell><cell>-0.01, [-0.365, 0.341]</cell><cell>-0.397, [-1.286, 0.522]</cell><cell>-0.459, [-1.04, 0.128]</cell><cell>-0.413, [-1.075, 0.241]</cell><cell>-0.359, [-1.077, 0.383]</cell><cell>0.4</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.036, [-0.538, 0.609]</cell><cell>0.048, [-0.235, 0.328]</cell><cell>0.53, [-0.207, 1.272]</cell><cell>0.198, [-0.28, 0.675]</cell><cell>0.175, [-0.356, 0.704]</cell><cell>-0.838, [-1.435, -0.245]</cell><cell>0.3</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.234, [-0.415, 0.882]</cell><cell>-0.001, [-0.32, 0.318]</cell><cell>0.424, [-0.439, 1.288]</cell><cell>0.131, [-0.582, 0.837]</cell><cell>-0.04, [-0.728, 0.651]</cell><cell>-0.651, [-1.427, 0.108]</cell><cell>0.</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-1.831, [-4.904, 1.181]</cell><cell>-41.366, [-118.333, -0.478]</cell><cell></cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>1.138, [-1.011, 3.271]</cell><cell>-0.048, [-1.059, 0.961]</cell><cell>-0.52, [-3.156, 2.164]</cell><cell>0.881, [-0.488, 2.215]</cell><cell>-0.747, [-2.873, 1.355]</cell><cell>-1.884, [-4.385, 0.389]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>0.235, [-1.65, 2.117]</cell><cell>-0.086, [-0.973, 0.826]</cell><cell>-0.947, [-3.271, 1.366]</cell><cell>1.134, [-0.308, 2.543]</cell><cell>0.123, [-1.852, 2.079]</cell><cell>-0.39, [-1.92, 1.143]</cell><cell>-0.4</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>0.874, [-0.875, 2.615]</cell><cell>-0.007, [-0.831, 0.828]</cell><cell>-0.837, [-3.032, 1.368]</cell><cell></cell><cell>0.343, [-1.526, 2.206]</cell><cell>-0.104, [-1.604, 1.356]</cell><cell>-0.4</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>0.357, [-1.31, 2.009]</cell><cell>0.432, [-0.359, 1.234]</cell><cell>-0.969, [-3.03, 1.103]</cell><cell></cell><cell>0.907, [-0.998, 2.842]</cell><cell>-1.613, [-3.445, 0.102]</cell><cell>-0.8</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>1.357, [-1.037, 3.744]</cell><cell>0.152, [-0.982, 1.294]</cell><cell>0.691, [-2.356, 3.707]</cell><cell></cell><cell>0.573, [-2.113, 3.287]</cell><cell>-1.294, [-3.852, 1.055]</cell><cell>0.0</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>1.114, [-0.352, 2.59]</cell><cell>0.079, [-0.607, 0.776]</cell><cell>-0.624, [-2.415, 1.158]</cell><cell>-0.625, [-3.295, 2.138]</cell><cell>0.502, [-1.054, 2.062]</cell><cell>0.034, [-1.249, 1.295]</cell><cell>-0.1</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>-0.183, [-1.454, 1.087]</cell><cell>-0.268, [-0.862, 0.336]</cell><cell>-1.071, [-2.678, 0.538]</cell><cell></cell><cell>-0.474, [-1.903, 0.97]</cell><cell>-0.556, [-1.756, 0.611]</cell><cell>-0.4</cell></row><row><cell>Authors</cell><cell>Proportion Male Authors</cell><cell>0.013, [-0.304, 0.33]</cell><cell>-0.041, [-0.193, 0.113]</cell><cell>0.349, [-0.057, 0.768]</cell><cell>-0.335, [-0.596, -0.073]</cell><cell>-0.243, [-0.517, 0.028]</cell><cell>0.07, [-0.231, 0.368]</cell><cell>0.1</cell></row><row><cell></cell><cell>Ave. SJDM Appearances</cell><cell>0.135, [-0.132, 0.406]</cell><cell>-0.001, [-0.133, 0.128]</cell><cell>-0.164, [-0.507, 0.171]</cell><cell>0.078, [-0.135, 0.291]</cell><cell>0.097, [-0.138, 0.329]</cell><cell>0.072, [-0.198, 0.344]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Ave. Prestige Score</cell><cell>0.065, [-0.351, 0.482]</cell><cell>-0.042, [-0.243, 0.16]</cell><cell>0.036, [-0.494, 0.559]</cell><cell>-0.353, [-0.882, 0.183]</cell><cell>-0.228, [-0.661, 0.199]</cell><cell>-0.279, [-0.714, 0.157]</cell><cell>0.3</cell></row><row><cell></cell><cell>Ave. Seniority</cell><cell>-0.417, [-0.768, -0.075]</cell><cell>0.056, [-0.107, 0.222]</cell><cell>-0.14, [-0.571, 0.293]</cell><cell>0.293, [0.024, 0.563]</cell><cell>0.147, [-0.144, 0.438]</cell><cell>0.278, [0.017, 0.551]</cell><cell>-0.0</cell></row><row><cell>Submission</cell><cell>Empirical Studies vs Traditional</cell><cell>0.091, [-0.47, 0.654]</cell><cell>0.094, [-0.177, 0.368]</cell><cell>0.439, [-0.32, 1.186]</cell><cell>0.142, [-0.192, 0.473]</cell><cell>0.311, [-0.146, 0.766]</cell><cell>-0.085, [-0.596, 0.418]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Psychology of JDM vs Traditional</cell><cell>0.481, [-0.232, 1.204]</cell><cell>0.036, [-0.317, 0.391]</cell><cell>-0.188, [-1.132, 0.733]</cell><cell>0.119, [-0.403, 0.634]</cell><cell>0.303, [-0.329, 0.93]</cell><cell>-0.665, [-1.325, -0.008]</cell><cell>-0.0</cell></row><row><cell></cell><cell>Sentiment</cell><cell>-0.018, [-0.256, 0.217]</cell><cell>-0.055, [-0.172, 0.058]</cell><cell>0.097, [-0.2, 0.387]</cell><cell>-0.084, [-0.273, 0.104]</cell><cell>-0.109, [-0.318, 0.1]</cell><cell>-0.066, [-0.289, 0.156]</cell><cell>0.0</cell></row><row><cell>Session</cell><cell>Session2</cell><cell>1.052, [0.201, 1.907]</cell><cell>0.038, [-0.381, 0.452]</cell><cell>-0.16, [-1.24, 0.926]</cell><cell></cell><cell>0.113, [-0.886, 1.114]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session3</cell><cell>0.189, [-0.721, 1.089]</cell><cell>-0.078, [-0.522, 0.357]</cell><cell>-0.511, [-1.67, 0.644]</cell><cell></cell><cell>-0.084, [-1.128, 0.955]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session4</cell><cell>0.411, [-0.379, 1.206]</cell><cell>0.258, [-0.124, 0.641]</cell><cell>-0.518, [-1.506, 0.458]</cell><cell></cell><cell>0.585, [-0.327, 1.492]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session5</cell><cell>0.175, [-0.611, 1]</cell><cell>0.213, [-0.175, 0.6]</cell><cell>0.03, [-1.044, 1.128]</cell><cell></cell><cell>0.676, [-0.279, 1.621]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session6</cell><cell>0.637, [-0.226, 1.483]</cell><cell>0.073, [-0.329, 0.489]</cell><cell>-0.524, [-1.606, 0.556]</cell><cell></cell><cell>0.277, [-0.695, 1.265]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session7</cell><cell>-0.224, [-1.074, 0.623]</cell><cell>0.019, [-0.395, 0.433]</cell><cell>-0.386, [-1.453, 0.679]</cell><cell></cell><cell>0.306, [-0.734, 1.373]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session8</cell><cell>-0.872, [-1.727, -0.025]</cell><cell>0.263, [-0.139, 0.667]</cell><cell>-0.28, [-1.337, 0.763]</cell><cell></cell><cell>0.665, [-0.315, 1.65]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session9</cell><cell>-0.474, [-1.303, 0.353]</cell><cell>0.274, [-0.136, 0.673]</cell><cell>-0.918, [-1.98, 0.157]</cell><cell></cell><cell>0.798, [-0.139, 1.722]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Poster Session</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.041, [0.252, 1.841]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Presentation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.291, [-0.273, 0.863]</cell><cell>0.0</cell></row><row><cell>Noise</cell><cell>sigma</cell><cell>0.779, [0.638, 0.96]</cell><cell>0.376, [0.307, 0.464]</cell><cell>0.978, [0.796, 1.214]</cell><cell>0.434, [0.326, 0.589]</cell><cell>0.957, [0.828, 1.111]</cell><cell></cell><cell>0.9</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_25"><head>Table 19 :</head><label>19</label><figDesc>Coefficients from regressing nonstandardized conference outcomes onto single-and double-blind review ratings simultaneously.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Attendance</cell><cell>Questions</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_26"><head>Table 20 :</head><label>20</label><figDesc>Coefficients from regressing standardized conference outcomes onto submission characteristics for multiple author papers.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Attendance (z) (N = 83)</cell><cell>Overall (z) (N = 83)</cell><cell>Questions (z) (N = 83)</cell><cell>Poster Rating (z) (N = 42)</cell><cell>Talk/Poster Rating (z) N = 127)</cell><cell>Publication (N = 413)</cell><cell>Im</cell></row><row><cell></cell><cell>Intercept</cell><cell>-1.84, [-3.266, -0.423]</cell><cell>-0.348, [-1.065, 0.375]</cell><cell>0.476, [-1.368, 2.353]</cell><cell>-1.735, [-3.266, -0.165]</cell><cell>-1.276, [-2.931, 0.398]</cell><cell>1.193, [-0.175, 2.566]</cell><cell>0.0</cell></row><row><cell></cell><cell>Male vs Female</cell><cell>-0.281, [-0.726, 0.159]</cell><cell>0.067, [-0.156, 0.289]</cell><cell>0.273, [-0.312, 0.848]</cell><cell>0.175, [-0.187, 0.535]</cell><cell>0.113, [-0.295, 0.517]</cell><cell>0.302, [-0.144, 0.753]</cell><cell>-0.</cell></row><row><cell>First Author</cell><cell>No Answer vs Female</cell><cell>1.626, [-0.641, 3.89]</cell><cell>1.466, [0.302, 2.62]</cell><cell>2.6, [-0.398, 5.639]</cell><cell></cell><cell>3.07, [0.528, 5.585]</cell><cell>-29.19, [-78.699, -2.24]</cell><cell></cell></row><row><cell></cell><cell>Years Since Ph.D.</cell><cell>0.684, [0.127, 1.221]</cell><cell>-0.062, [-0.335, 0.213]</cell><cell>-0.177, [-0.888, 0.539]</cell><cell>-0.071, [-1.293, 1.166]</cell><cell>-0.106, [-0.738, 0.515]</cell><cell>-0.437, [-0.917, 0.015]</cell><cell>-0.</cell></row><row><cell></cell><cell>Domestic (0) or International (1)</cell><cell>0.498, [0.033, 0.965]</cell><cell>0.028, [-0.21, 0.266]</cell><cell>-0.091, [-0.707, 0.53]</cell><cell>0.266, [-0.159, 0.696]</cell><cell>0.172, [-0.25, 0.59]</cell><cell>0.056, [-0.43, 0.538]</cell><cell>0.0</cell></row><row><cell></cell><cell>Asian vs. White</cell><cell>-0.381, [-0.958, 0.198]</cell><cell>0.171, [-0.121, 0.464]</cell><cell>-0.278, [-1.046, 0.465]</cell><cell>0.3, [-0.088, 0.693]</cell><cell>0.408, [-0.078, 0.9]</cell><cell>-0.218, [-0.776, 0.335]</cell><cell>-0.</cell></row><row><cell></cell><cell>Black vs White</cell><cell>0.503, [-0.41, 1.418]</cell><cell>0.228, [-0.237, 0.696]</cell><cell>1.372, [0.177, 2.598]</cell><cell></cell><cell></cell><cell>-0.666, [-4.51, 3.188]</cell><cell>-1.</cell></row><row><cell></cell><cell>Hispanic or Latino vs. White</cell><cell>0.982, [-0.803, 2.772]</cell><cell>0.205, [-0.693, 1.105]</cell><cell>-0.035, [-2.388, 2.297]</cell><cell></cell><cell>0.607, [-0.5, 1.713]</cell><cell>1.177, [-0.307, 2.824]</cell><cell>0.2</cell></row><row><cell></cell><cell>Native American vs. White</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.354, [-1.733, 2.497]</cell><cell>-40.062, [-112.352, -2.228]</cell><cell></cell></row><row><cell></cell><cell>Other vs. White</cell><cell>0.137, [-0.975, 1.257]</cell><cell>0.031, [-0.529, 0.599]</cell><cell>-0.662, [-2.137, 0.806]</cell><cell></cell><cell>0.259, [-1.025, 1.526]</cell><cell>0.847, [-0.671, 2.544]</cell><cell>0.0</cell></row><row><cell></cell><cell>No Answer vs. White</cell><cell>-0.217, [-1.104, 0.663]</cell><cell>-0.119, [-0.573, 0.322]</cell><cell>-0.686, [-1.841, 0.475]</cell><cell>-0.039, [-1.397, 1.294]</cell><cell>0.09, [-0.765, 0.948]</cell><cell>-0.312, [-1.09, 0.461]</cell><cell>-0.</cell></row><row><cell></cell><cell>SJDM Apperances</cell><cell>0.246, [0.02, 0.474]</cell><cell>0.089, [-0.026, 0.201]</cell><cell>-0.121, [-0.415, 0.172]</cell><cell>-0.312, [-0.863, 0.241]</cell><cell>0.173, [-0.075, 0.415]</cell><cell>-0.151, [-0.424, 0.125]</cell><cell>0.0</cell></row><row><cell></cell><cell>Prestige Score</cell><cell>0.156, [-0.13, 0.439]</cell><cell>0.096, [-0.046, 0.238]</cell><cell>0.291, [-0.077, 0.66]</cell><cell>0.44, [0.016, 0.854]</cell><cell>0.326, [0.05, 0.601]</cell><cell>0.093, [-0.209, 0.399]</cell><cell>0.0</cell></row><row><cell></cell><cell>Economics Ph.D. vs Psychology</cell><cell>0.099, [-0.892, 1.08]</cell><cell>0.488, [0.001, 0.982]</cell><cell>0.198, [-1.082, 1.47]</cell><cell>-0.79, [-2.383, 0.75]</cell><cell>0.767, [-0.226, 1.751]</cell><cell>-0.465, [-1.473, 0.564]</cell><cell>0.2</cell></row><row><cell></cell><cell>Management Ph.D. vs Psychology</cell><cell>0.261, [-0.464, 0.961]</cell><cell>-0.014, [-0.369, 0.335]</cell><cell>-0.368, [-1.279, 0.562]</cell><cell>-0.627, [-1.209, -0.04]</cell><cell>-0.399, [-1.036, 0.226]</cell><cell>-0.434, [-1.208, 0.309]</cell><cell>0.5</cell></row><row><cell></cell><cell>Marketing Ph.D. vs Psychology</cell><cell>0.04, [-0.525, 0.617]</cell><cell>0.045, [-0.237, 0.33]</cell><cell>0.492, [-0.248, 1.223]</cell><cell>0.055, [-0.43, 0.535]</cell><cell>0.128, [-0.379, 0.636]</cell><cell>-0.955, [-1.594, -0.337]</cell><cell>0.4</cell></row><row><cell></cell><cell>Other Ph.D. vs Psychology</cell><cell>0.294, [-0.356, 0.938]</cell><cell>0.051, [-0.274, 0.366]</cell><cell>0.44, [-0.421, 1.313]</cell><cell>-0.194, [-0.921, 0.53]</cell><cell>0.002, [-0.689, 0.679]</cell><cell>-0.658, [-1.451, 0.119]</cell><cell>0.</cell></row><row><cell></cell><cell>Undergraduate vs. Full</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>-2.754, [-5.625, 0.068]</cell><cell>-40.474, [-114.193, -1.326]</cell><cell></cell></row><row><cell></cell><cell>Masters vs. Full</cell><cell>2.137, [0.183, 4.085]</cell><cell>-0.109, [-1.075, 0.864]</cell><cell>-0.244, [-2.743, 2.309]</cell><cell>0.963, [-0.352, 2.229]</cell><cell>-1.247, [-3.269, 0.724]</cell><cell>-2.68, [-5.19, -0.454]</cell><cell>0.1</cell></row><row><cell></cell><cell>Ph.D. vs. Full</cell><cell>1.311, [-0.333, 2.956]</cell><cell>-0.127, [-0.942, 0.688]</cell><cell>-0.684, [-2.842, 1.453]</cell><cell>1.218, [-0.168, 2.563]</cell><cell>-0.304, [-2.228, 1.558]</cell><cell>-1.098, [-2.645, 0.401]</cell><cell>-0.</cell></row><row><cell></cell><cell>Post Doc vs. Full</cell><cell>1.921, [0.273, 3.52]</cell><cell>-0.017, [-0.823, 0.776]</cell><cell>-0.681, [-2.792, 1.41]</cell><cell></cell><cell>0.004, [-1.87, 1.833]</cell><cell>-0.753, [-2.218, 0.701]</cell><cell>-0.</cell></row><row><cell></cell><cell>Research Scientist vs. Full</cell><cell>1.164, [-0.422, 2.743]</cell><cell>0.43, [-0.371, 1.228]</cell><cell>-0.896, [-2.952, 1.181]</cell><cell></cell><cell>0.9, [-1.016, 2.764]</cell><cell>-2.119, [-3.938, -0.418]</cell><cell>-0.</cell></row><row><cell></cell><cell>Practitioner vs. Full</cell><cell>2.154, [-0.185, 4.491]</cell><cell>0.213, [-0.945, 1.377]</cell><cell>0.74, [-2.265, 3.761]</cell><cell></cell><cell>0.329, [-2.337, 2.972]</cell><cell>-1.526, [-4.144, 1.005]</cell><cell>0.1</cell></row><row><cell></cell><cell>Assistant vs. Full</cell><cell>1.645, [0.276, 3.017]</cell><cell>0.083, [-0.61, 0.776]</cell><cell>-0.599, [-2.454, 1.21]</cell><cell>1.349, [-0.967, 3.71]</cell><cell>0.441, [-1.137, 2.017]</cell><cell>-0.075, [-1.375, 1.219]</cell><cell>-0.</cell></row><row><cell></cell><cell>Associate vs. Full</cell><cell>0.203, [-1.038, 1.421]</cell><cell>-0.238, [-0.843, 0.373]</cell><cell>-1.052, [-2.638, 0.558]</cell><cell></cell><cell>-0.616, [-2.059, 0.819]</cell><cell>-0.68, [-1.916, 0.52]</cell><cell>-0.</cell></row><row><cell>Authors</cell><cell>Proportion Male Coauthors</cell><cell>-0.076, [-0.313, 0.163]</cell><cell>-0.028, [-0.146, 0.09]</cell><cell>0.284, [-0.02, 0.589]</cell><cell>-0.234, [-0.416, -0.046]</cell><cell>-0.18, [-0.391, 0.028]</cell><cell>0.057, [-0.179, 0.289]</cell><cell>0</cell></row><row><cell></cell><cell>Ave. SJDM Coauthor Appearances</cell><cell>0.119, [-0.128, 0.363]</cell><cell>-0.003, [-0.125, 0.117]</cell><cell>-0.182, [-0.51, 0.135]</cell><cell>0.154, [-0.035, 0.339]</cell><cell>0.096, [-0.116, 0.312]</cell><cell>0.078, [-0.178, 0.34]</cell><cell>-0.</cell></row><row><cell></cell><cell>Ave. Coauthor Prestige Score</cell><cell>-0.004, [-0.298, 0.291]</cell><cell>-0.027, [-0.172, 0.118]</cell><cell>0.01, [-0.369, 0.393]</cell><cell>-0.419, [-0.847, 0.012]</cell><cell>-0.144, [-0.45, 0.161]</cell><cell>-0.192, [-0.508, 0.121]</cell><cell>0.2</cell></row><row><cell></cell><cell>Ave. Coauthor Seniority</cell><cell>-0.359, [-0.616, -0.102]</cell><cell>0.01, [-0.117, 0.139]</cell><cell>-0.06, [-0.401, 0.274]</cell><cell>0.029, [-0.22, 0.271]</cell><cell>-0.049, [-0.292, 0.194]</cell><cell>0.146, [-0.094, 0.387]</cell><cell>-0.</cell></row><row><cell>Submission</cell><cell>Empirical Studies vs Traditional</cell><cell>-0.01, [-0.576, 0.555]</cell><cell>0.054, [-0.227, 0.339]</cell><cell>0.397, [-0.331, 1.142]</cell><cell>0.282, [-0.064, 0.63]</cell><cell>0.315, [-0.151, 0.786]</cell><cell>-0.126, [-0.652, 0.405]</cell><cell>0.0</cell></row><row><cell></cell><cell>Psychology of JDM vs Traditional</cell><cell>0.319, [-0.41, 1.034]</cell><cell>0.005, [-0.351, 0.354]</cell><cell>-0.29, [-1.206, 0.63]</cell><cell>0.073, [-0.444, 0.589]</cell><cell>0.25, [-0.397, 0.893]</cell><cell>-0.616, [-1.295, 0.061]</cell><cell>-0.</cell></row><row><cell></cell><cell>Sentiment</cell><cell>0.015, [-0.215, 0.248]</cell><cell>-0.058, [-0.175, 0.057]</cell><cell>0.088, [-0.211, 0.388]</cell><cell>-0.033, [-0.206, 0.137]</cell><cell>-0.108, [-0.316, 0.1]</cell><cell>-0.097, [-0.332, 0.133]</cell><cell>0.0</cell></row><row><cell>Session</cell><cell>Session2</cell><cell>1.206, [0.369, 2.053]</cell><cell>0.109, [-0.322, 0.528]</cell><cell>-0.206, [-1.278, 0.876]</cell><cell></cell><cell>0.308, [-0.698, 1.291]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session3</cell><cell>0.463, [-0.452, 1.365]</cell><cell>-0.024, [-0.481, 0.438]</cell><cell>-0.518, [-1.711, 0.677]</cell><cell></cell><cell>0.01, [-1.037, 1.057]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session4</cell><cell>0.443, [-0.316, 1.214]</cell><cell>0.268, [-0.114, 0.654]</cell><cell>-0.539, [-1.544, 0.456]</cell><cell></cell><cell>0.722, [-0.203, 1.647]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session5</cell><cell>0.498, [-0.321, 1.324]</cell><cell>0.298, [-0.118, 0.712]</cell><cell>-0.028, [-1.116, 1.062]</cell><cell></cell><cell>0.856, [-0.131, 1.83]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session6</cell><cell>0.85, [0.015, 1.679]</cell><cell>0.128, [-0.29, 0.542]</cell><cell>-0.545, [-1.647, 0.545]</cell><cell></cell><cell>0.478, [-0.521, 1.468]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session7</cell><cell>-0.133, [-0.956, 0.696]</cell><cell>0.046, [-0.374, 0.468]</cell><cell>-0.434, [-1.508, 0.659]</cell><cell></cell><cell>0.25, [-0.778, 1.278]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session8</cell><cell>-0.698, [-1.506, 0.106]</cell><cell>0.284, [-0.122, 0.689]</cell><cell>-0.288, [-1.334, 0.768]</cell><cell></cell><cell>0.791, [-0.194, 1.782]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Session9</cell><cell>-0.344, [-1.149, 0.474]</cell><cell>0.318, [-0.092, 0.729]</cell><cell>-0.946, [-1.994, 0.116]</cell><cell></cell><cell>0.985, [0.058, 1.907]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Poster Session</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>1.258, [0.431, 2.065]</cell><cell></cell><cell></cell></row><row><cell></cell><cell>Presentation</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell>0.322, [-0.229, 0.898]</cell><cell>-0.</cell></row><row><cell>Noise</cell><cell>sigma</cell><cell>0.752, [0.617, 0.928]</cell><cell>0.376, [0.307, 0.464]</cell><cell>0.978, [0.799, 1.211]</cell><cell>0.411, [0.306, 0.565]</cell><cell>0.932, [0.801, 1.091]</cell><cell></cell><cell>0.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_27"><head>Table 21 :</head><label>21</label><figDesc>Coefficients from regressing nonstandardized conference outcomes onto single-and double-blind review ratings simultaneously.</figDesc><table><row><cell>Category</cell><cell>Variable</cell><cell>Attendance</cell><cell>Questions</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">We adopt the term fairness from psychological and educational testing that denotes the extent to which an assessment does not systematically disadvantage or advantage any individual or group and instead any observed differences are relevant to the test construct (American Educational Research Association, 1999;<ref type="bibr" target="#b4">Camilli, 2006)</ref> 2 The construct of equity can have a broader scope, including whether people from different backgrounds may face different barriers, obstacles, and opportunities. Here, we focus on the narrower question of peerreview equity, focusing on whether or not a particular group is advantaged or disadvantaged due to the disclosure of author characteristics during the review process.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">The survey responses only reflect the views of the society members to the degree that participation rates were uncorrelated with views about blind review.4 The preference for double-blind review was strongest when respondents took the perspective of an author vs. a conference attendee (β = −0.23, [−0.36, −0.10]), and only slightly stronger as an author vs. a reviewer (β = −0.11, [−0.24, 0.02]) (SMTable 8). Less experienced reviewers also had a stronger preference for double-blind review (β = −0.21,[-0.36, -0.05]).</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">We tested whether the effects of review type differed by reviewer characteristics. None showed credible interactions with the review condition (SMTable 10). Including these interactions and potential threeway interactions with author characteristics worsened model prediction according to leave-one-out crossvalidation (SMTable 10).6 One might speculate that reviewers are more sensitive to the maximum value across authors as opposed to the average. We have rerun all the main analyses, replacing the average author statistic with the maximum, including prestige, author appearances, and rank. We reach the same conclusions with the exception that there is not a credible difference between Ph.D. students and Full Professors, but the effect is in the same direction. This analysis is available at the OSF site for the paper.7 Recall that the first author was also the corresponding author for 456 of the 530 submissions, which are the submissions we were able to collect a full set of author characteristics like race and area of Ph.D. The remaining 456 − 440 = 16 submissions that were excluded had one or more missing responses to the author characteristics.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">This variable may be influenced by a suppression effect stemming from its positive correlation with coauthor seniority. When entered alone, the proportion of male authors shows a weak positive relationship (SMTable 14), but after accounting for average seniority, these positive effects become weakly negative. This suppression effect is not present when we look at only multiauthor submissions.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="9">Talk quality, as judged on-site by experts, was credibly associated with attendance (β = 0.188, [0.015, 0.363]), implying that a one SD increase in quality corresponded to 6.5 [0.3, 12.6] more attendees (mean attendance was 93.9 (SD = 34.9)). Such a relationship suggests there is some signal in the use of on-site ratings of the quality of the talks as an outcome measure. However, there is a directionality problem in that the ratings could have been influenced by the attendance.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="10">There is no credible relationship with the number of authors. The correlation between first-author gender (male vs. female) and the number of authors is r = 0.02[−0.07, 0.11]. Similarly, the correlation between the proportion of male coauthors and the number of authors is r = 0.01 [−0.08, 0.10].</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">These values were relatively arbitrary, and adjusting these values within the range of intermediate correlations (−.5 ≥ ρ ≤ .5) did not impact the estimates as the power analysis was based on the difference in correlations.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="2">When we include reviewers, there are 334 institutions. As we include the reviewer's institutional prestige in the regressions, it was an error not to include these six institutions. We addressed this issue by averaging the three different prestige measures to form a prestige score so that every institution for authors and reviewers was assigned a prestige score. See 2.8.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">When we solicited prestige ratings, we identified 328 institutions. This difference is because we included reviewers' institutions in the count.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Authors</head><p>Proportion Male Authors -0.045 <ref type="bibr">[-0.137</ref> Bolded values indicated credible interval excludes 0. All co-author characteristic characteristics were represented by the statistics based on all the authors (e.g., proportion of male authors instead of male coauthors) so that single-author submissions were included in the analysis. Thus, the regression coefficients for the first author variables represent incremental change for the variables in which there are corresponding coauthor characteristics. Review ratings and numerical predictors were standardized. The z indicates when the variables were standardized. Review ratings and numerical predictors were standardized. The characteristics were entered simultaneously for both regression models. The N indicates the number of submissions used in each regression.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.5">Regression Coefficients With Each Variable Entered Alone</head><p>The zero-order correlations shown in Figures 8 and 7 do not control for submission and reviewer variability. Thus, for each author and submission characteristic, we conducted a regression, entering each characteristic alone and predicting either a single-or double-blind review rating. The coefficients for these regressions are reported in <ref type="table">Table 14</ref>. We also sought to understand if there was a difference between single-and doubleblind review ratings for each characteristic alone (without accounting for each characteristic). Thus, we ran separate regressions for each characteristic, regressing the review rating onto the characteristic, review condition, and interaction. The coefficients for those regressions are reported in <ref type="table">Table 15</ref>  Bolded values indicated credible interval excludes 0. Starred variables () indicate a credible interaction between the variable and the condition in <ref type="table">Table 13</ref>. Review ratings and numerical predictors were standardized. The coefficients in the single-and double-blind were entered alone. The N indicates the number of submissions used in each regression.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A reliability-generalization study of journal peer reviews: A multilevel meta-analysis of inter-rater reliability and its determinants</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bornmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Mutz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-D</forename><surname>Daniel</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0014331</idno>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Perceiving pervasive discrimination among african americans: Implications for group identification and wellbeing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">R</forename><surname>Branscombe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Schmitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Harvey</surname></persName>
		</author>
		<idno>doi: 10.1037/ 0022-3514.77.1.135</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="135" to="149" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">From description to explanation: An empirical exploration of the african-american pipeline problem in stem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">A</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Henderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Donovan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sullivan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Patterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Waggstaff</surname></persName>
		</author>
		<idno type="DOI">10.1002/tea.21249</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Research in Science Teaching</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="146" to="177" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Double-blind review favours increased representation of female authors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Budden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Tregenza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">W</forename><surname>Aarssen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Koricheva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Leimu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Lortie</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tree.2007.07.008</idno>
	</analytic>
	<monogr>
		<title level="j">Trends in Ecology &amp; Evolution</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="4" to="6" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Test fairness. Educational measurement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Camilli</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="221" to="256" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Women in academic science: A changing landscape</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Ceci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Ginther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<idno type="DOI">10.1177/1529100614541236</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science in the Public Interest</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="75" to="141" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Applicant attraction to organizations and job choice: a meta-analytic review of the correlates of recruiting outcomes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">S</forename><surname>Chapman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Uggerslev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Carroll</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">A</forename><surname>Piasentin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Jones</surname></persName>
		</author>
		<idno type="DOI">10.1037/0021-9010.90.5.928</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of applied psychology</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="928" to="944" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Masculine defaults: Identifying and mitigating hidden cultural biases</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Cheryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Markus</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000209</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1022" to="1052" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title level="m" type="main">Inconsistency in conference peer review: Revisiting the 2014 neurips experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cortes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Lawerence</surname></persName>
		</author>
		<idno type="DOI">10.48550/arXiv.2109.09774</idno>
		<ptr target="https://doi.org/10.48550/arXiv.2109.09774" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">The cases for and against double-blind reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Montgomerie</surname></persName>
		</author>
		<idno type="DOI">10.7717/peerj.6702</idno>
	</analytic>
	<monogr>
		<title level="j">PeerJ</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">6702</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The gatekeepers of science: Some factors affecting the selection of articles for scientific journals</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Crane</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Sociologist</title>
		<imprint>
			<biblScope unit="page" from="195" to="201" />
			<date type="published" when="1967" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Clinical versus actuarial judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Faust</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Meehl</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.2648573</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="issue">4899</biblScope>
			<biblScope unit="page" from="1668" to="1674" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">The role of conferences on the pathway to academic impact evidence from a natural experiment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">L L</forename><surname>De Leon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Mcquillin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Human Resources</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="164" to="193" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Research funding: The case for a modified lottery</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Casadevall</surname></persName>
		</author>
		<idno type="DOI">10.1128/mBio.00422-16</idno>
		<imprint>
			<date type="published" when="2016" />
			<publisher>American Society for Microbiology</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Theories of statistical discrimination and affirmative action: A survey</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Moro</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="133" to="200" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">But the reviewers are making different criticisms of my paper! diversity and uniqueness in reviewer comments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Fiske</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fogg</surname></persName>
		</author>
		<idno type="DOI">10.1037/10109-048</idno>
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="page" from="591" to="598" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A categorical model of cognition and biased decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Fryer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">O</forename><surname>Jackson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Theoretical Economics</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Why we (usually) don&apos;t have to worry about multiple comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yajima</surname></persName>
		</author>
		<idno type="DOI">10.1080/19345747.2011.618213</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Research on Educational Effectiveness</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="211" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Biomedical science ph. d. career interest patterns by race/ethnicity and gender</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">D</forename><surname>Gibbs</surname><genName>Jr</genName></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Mcgready</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Bennett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffin</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pone.0114736</idno>
	</analytic>
	<monogr>
		<title level="j">PloS one</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">12</biblScope>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Race, ethnicity, and nih research awards</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">K</forename><surname>Ginther</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">T</forename><surname>Schaffer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Schnell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Masimore</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Haak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kington</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.1196783</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">333</biblScope>
			<biblScope unit="issue">6045</biblScope>
			<biblScope unit="page" from="1015" to="1019" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Orchestrating impartiality: The impact of&quot; blind&quot; auditions on female musicians</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Goldin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rouse</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Review</title>
		<imprint>
			<biblScope unit="volume">90</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="715" to="741" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Conference presentations and academic publishing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Gorodnichenko</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Talavera</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.econmod.2020.12.017</idno>
	</analytic>
	<monogr>
		<title level="j">Economic Modelling</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="228" to="254" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">No substitute for the real thing: The importance of in-context field experiments in fundraising</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Goswami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Urminsky</surname></persName>
		</author>
		<idno type="DOI">10.1287/mksc.2020.1252</idno>
	</analytic>
	<monogr>
		<title level="j">Marketing Science</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1052" to="1070" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0307752101</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Does double-blind review favor female authors?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Hammerschmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Reinhardt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rolff</surname></persName>
		</author>
		<idno>doi: 1540 -9295</idno>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Ecology and the Environment</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page">6</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
	<note>354a:DDRFFA]2.0.CO;2</note>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Pleskac</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pachur</surname></persName>
		</author>
		<title level="m">&amp; the Center for Adaptive Rationality. (2019). Taming uncertainty</title>
		<meeting><address><addrLine>Cambridge, MA</addrLine></address></meeting>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Mining opinion features in customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Aaai</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="755" to="760" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">Science as a process: An evolutionary account of the social and conceptual development of science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Hull</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1988" />
			<publisher>University of Chicago Press</publisher>
			<pubPlace>Chicago, IL</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Racial discrimination and white-collar workers in britain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Jowell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Prescott-Clarke</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Race</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="397" to="417" />
			<date type="published" when="1970" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Definition and assessment of accuracy in social stereotypes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Judd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Park</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.100.1.109</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">100</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="109" to="128" />
			<date type="published" when="1993" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">Stereotype accuracy: One of the largest and most replicable effects in all of social psychology. Handbook of Prejudice, Stereotyping, and Discrimination</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Jussim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Crawford</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Anglin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Chambers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Stevens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cohen</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="31" to="63" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Noise: A flaw in human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sibony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2021" />
			<pubPlace>Little Brown</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">The Wiley-Blackwell handbook of judgment and decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>John Wiley &amp; Sons, Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Is blinded review enough? how gendered outcomes arise even under anonymous evaluation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kolev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Fuentes-Medel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Murray</surname></persName>
		</author>
		<ptr target="https://www.nber.org/papers/w25759" />
	</analytic>
	<monogr>
		<title level="j">National Bureau of Economic Research</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note type="report_type">Tech. Rep.</note>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Understanding procedural justice and its impact on business organizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Konovsky</surname></persName>
		</author>
		<idno type="DOI">10.1177/014920630002600306</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Management</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="489" to="511" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Anonymous job applications in europe</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Krause</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Rinne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">F</forename><surname>Zimmermann</surname></persName>
		</author>
		<idno type="DOI">10.1186/2193-9012-1-5</idno>
	</analytic>
	<monogr>
		<title level="j">IZA Journal of European Labor Studies</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">The bayesian new statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Liddell</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-016-1221-4</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="206" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">Nips experiment analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lawrence</surname></persName>
		</author>
		<ptr target="https://inverseprobability.com/2015/01/16/blogs-on-the-nips-experiment" />
		<imprint>
			<date type="published" when="2015-01-16" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<monogr>
		<title level="m" type="main">Blinding to remove biases in science and society</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Maccoun</surname></persName>
		</author>
		<editor>R. Hertwig &amp; C. Engel</editor>
		<imprint>
			<date type="published" when="2020" />
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
	<note>Deliberate ignorance: Choosing not to know</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Corrections for attenuation and range restriction on the predictor</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mendoza</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mumford</surname></persName>
		</author>
		<idno type="DOI">10.3102/10769986012003282</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Statistics</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="282" to="293" />
			<date type="published" when="1987" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">The matthew effect in science: The reward and communication systems of science are considered</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">K</forename><surname>Merton</surname></persName>
		</author>
		<idno type="DOI">10.1126/science.159.3810.56</idno>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">159</biblScope>
			<biblScope unit="issue">3810</biblScope>
			<biblScope unit="page" from="56" to="63" />
			<date type="published" when="1968" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Temporal distance and discrimination: An audit study in academia</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">L</forename><surname>Milkman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Akinola</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Chugh</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="710" to="717" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Single-blind vs doubleblind peer review in the setting of author prestige</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Okike</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">T</forename><surname>Hug</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Kocher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Leopold</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2016.11014</idno>
	</analytic>
	<monogr>
		<title level="j">Jama</title>
		<imprint>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1315" to="1316" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">The statistical theory of racism and sexism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Phelps</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Economic Review</title>
		<imprint>
			<biblScope unit="volume">62</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="659" to="661" />
			<date type="published" when="1972" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Low agreement among reviewers evaluating the same nih grant applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Pier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Brauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Filut</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kaatz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Raclaw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Nathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">.</forename><forename type="middle">.</forename><surname>Carnes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences</title>
		<meeting>the National Academy of Sciences</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="2952" to="2957" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Achieving more with less: Intuitive correction in selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Rabinovitch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Bereby-Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<idno>doi: 10.1177/ 0956797620903717</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="437" to="448" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title level="m" type="main">Blinding as a solution to bias: Strengthening biomedical science, forensic science, and law</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">T</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Kesselheim</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Academic Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Applicants&apos; perceptions of selection procedures and decisions: A critical review and agenda for the future</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Ryan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Ployhart</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Management</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="565" to="606" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<monogr>
		<title level="m" type="main">Judging merit</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Thorngate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Dawes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Foddy</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2010" />
			<publisher>Psychology Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Reviewer bias in single-versus doubleblind peer review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Heavlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="12708" to="12713" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Practical bayesian model evaluation using leave-one-out cross-validation and waic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-016-9696-4</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Practical bayesian model evaluation using leave-one-out cross-validation and waic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-016-9696-4</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title level="m" type="main">Journal review and gender equality: a critical comment on budden et al. Trends in Ecology and Evolution</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Whittaker</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.tree.2008.03.003</idno>
		<imprint>
			<date type="published" when="2008" />
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="478" to="479" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">National hiring experiments reveal 2: 1 faculty preference for women on stem tenure track</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Ceci</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1418878112</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="5360" to="5365" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Asian vs. White -15</title>
		<idno>16.1, 35.6] -0.7</idno>
	</analytic>
	<monogr>
		<title level="m">First Author No Answer vs Female</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
		</imprint>
	</monogr>
	<note>30.4, 12.4] -0.2, [-1.5, 1.1. 0.5, 5.3] 0, [-0.2, 0.1] Domestic (0) or International (1) 18.8, [2.1, 35.3] -0.2, [-1.2, 0.9. 35.7, 5] -0.4, [-1.7, 0.8] Black vs White 17.5, [-15.3, 50.3] 2, [0, 4] Hispanic or Latino vs. White 34.8, [-29.3, 98.9. American vs. White --Other vs. White 8.1, [-32.3, 48.7] -1, [-3.4, 1.4] No Answer vs. White -9.6, [-41.2, 22.3] -1, [-2.9, 0.9] SJDM Apperances 1.6, [-1.2, 4.3] 0, [-0.2, 0.1] Prestige Score 4.2, [-4.2, 12.5] 0.3, [-0.2, 0.8] Economics Ph.D. vs Psychology 2.2, [-32.6, 36.6] 0.4, [-1.7, 2.5. 2.1, 0.9] Marketing Ph.D. vs Psychology 1.4, [-18.4, 21.6] 0.9, [-0.3, 2.1</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Post Doc vs. Full 30</title>
		<idno>14.4, 30.8] 0.7</idno>
	</analytic>
	<monogr>
		<title level="m">Undergraduate vs. Full --Masters vs. Full 39</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
		</imprint>
	</monogr>
	<note>33.2, 114.3] -0.9. 5.2, 3.6] Ph.D. vs. Full 8.3, [-55.5, 73.4] -1.6, [-5.4, 2.4. 30.3, 91.2] -1.4, [-5, 2.3. 43.7, 70.3] -1.6, [-4.9, 1.8] Practitioner vs. Full 47.4, [-36.1, 130.3] 1.2, [-3.7, 6.2] Assistant vs. Full 38.8, [-11.8, 90.4] -1, [-4, 2] Associate vs. Full -6.2, [-48.7, 37.6] -1.8, [-4.4, 0.9] Authors Proportion Male Authors 1.4, [-31.8, 34.4] 1.7, [-0.3, 3.7</note>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>SJDM Appearances 4.2, [-21.4, 29] 0.1, [-1.4, 1.6</note>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">Prestige Score 2</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note>2.9, 8.7] -0.2, [-0.5, 0.2</note>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
		<idno>24.7, 37.7</idno>
	</analytic>
	<monogr>
		<title level="m">Submission Empirical Studies vs Traditional 3</title>
		<imprint>
			<date type="published" when="2009-07-07" />
			<biblScope unit="volume">2</biblScope>
		</imprint>
	</monogr>
	<note>Seniority -11.8, [-21.5, -2] -0.2, [-0.8, 0.4. 0.5, 1.9. 8.1, 41.6] -0.3, [-1.9, 1.2] Sentiment -2.1, [-29.8, 26.3] 0.5, [-1.1, 2.2] Session Session2 36.9. 6.2, 67.1] -0.3, [-2.1, 1.5] Session3 6.. 2.7, 1] Session4 14.3, [-13.3, 41.5] -0.9. 2.5, 0.8] Session5 6.1, [-21.7, 34.1] 0, [-1.7, 1.8] Session6 22.2, [-7.6, 52.1] -0.9. 2.6, 0.9. 37.9, 21.9. 2.4, 1.1] Session8 -30.4, [-59.3, -1.2] -0.5, [-2.2, 1.2] Session9 -16.6, [-45.7, 13.1] -1.5, [-3.2, 0.2] Poster Session --Presentation --Noise sigma 27.1, [22.2, 33.5] 1.6, [1.3, 2</note>
</biblStruct>

<biblStruct xml:id="b59">
	<analytic>
		<title level="a" type="main">2] Undergraduate vs. Full --Masters vs. Full 73</title>
		<idno>136.8] 4.4</idno>
	</analytic>
	<monogr>
		<title level="m">Bolded values indicated credible interval excludes 0. All regressions included a dummy variable indicating whether the submission was presented at the conference or not. The z indicates when the variables were standardized</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note type="report_type">White --Other vs. White 4</note>
	<note>Hispanic or Latino vs. 5, 141.9] -0.4, [-4.5, 3.8] Ph.D. vs. Full 45.4, [-13.1, 102.5] -1.1, [-4.7, 2.4] Post Doc vs. Full 66.6, [9.5, 122.6] -1.1, [-4.6, 2.3] Research Scientist vs. Full 40.1, [-16.3, 95.6] -1.4, [-4.8, 2] Practitioner vs. Full 74.8, [-7.9, 156] 1.2, [-3.8, 6.2] Assistant vs. Full 56.9. 7.4, 105.9. 4, 2] Associate vs. Full 6.8, [-36.4, 50.5] -1.7, [-4.4, 1] Coauthors Proportion Male Coauthors -6.6, [-26.7, 13.8] 1.2, [-0.1, 2.4</note>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">SJDM Coauthor Appearances</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">3</biblScope>
		</imprint>
	</monogr>
	<note>2.4, 7.1] -0.2, [-0.5, 0.1</note>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Coauthor Prestige Score -0</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
		<imprint>
			<biblScope unit="volume">3</biblScope>
		</imprint>
	</monogr>
	<note>20.5, 19.6] 0.1, [-1.2, 1.3</note>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Coauthor Seniority -6</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ave</forename></persName>
		</author>
		<idno>11.8, -1.9] -0.1, [-0.4, 0.2] Submission Empirical Studies vs Traditional -0.3</idno>
	</analytic>
	<monogr>
		<title level="j">Psychology of JDM vs Traditional</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
		</imprint>
	</monogr>
	<note>20.1, 19.6] 0.6, [-0.6, 1.9. 13.3, 36.2] -0.5, [-2, 1.1] Sentiment 1.6, [-25.4, 28.5] 0.5, [-1.2, 2.1] Session Session2 41.8, [12.3, 71.4] -0.3, [-2.1, 1.5] Session3 16.2, [-15.8, 47.8] -0.8, [-2.8, 1.1] Session4 15.4, [-11.6, 42.5] -0.9. 2.5, 0.8] Session5 17.3, [-11.5, 46.6] 0, [-1.8, 1.8] Session6 29.6, [-0.2, 59] -0.9. 2.7, 0.9] Session7 -4.5, [-32.9, 25.2] -0.7, [-2.5, 1.1] Session8 -24.4, [-53.4, 4.4] -0.5, [-2.2, 1.3] Session9 -11. 41.1, 17.3] -1.5, [-3.3, 0.2] Poster Session --Presentation --Noise sigma 26.2, [21.4, 32.6] 1.6, [1.3, 2</note>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Latent dirichlet allocation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Blei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The Journal of Machine Learning Research</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="993" to="1022" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Why we (usually) don&apos;t have to worry about multiple comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yajima</surname></persName>
		</author>
		<idno type="DOI">10.1080/19345747.2011.618213</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Research on Educational Effectiveness</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="211" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Why we (usually) don&apos;t have to worry about multiple comparisons</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Yajima</surname></persName>
		</author>
		<idno type="DOI">10.1080/19345747.2011.618213</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Research on Educational Effectiveness</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="189" to="211" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">rstanarm: Bayesian applied regression modeling via Stan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Goodrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Ali</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Brilleman</surname></persName>
		</author>
		<ptr target="https://mc-stan.org/rstanarm" />
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
	<note>R package version 2.21.1)</note>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Finding scientific topics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.0307752101</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">101</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="5228" to="5235" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
	<note>suppl</note>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Mining opinion features in customer reviews</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Liu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">In Aaai</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="page" from="755" to="760" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title level="m" type="main">The Wiley-Blackwell handbook of judgment and decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Keren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Wu</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2015" />
			<publisher>John Wiley &amp; Sons, Ltd</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The bayesian new statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Kruschke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Liddell</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13423-016-1221-4</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="178" to="206" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<monogr>
		<title level="m" type="main">Bayesfactor: Computation of Bayes factors for common designs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Morey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Rouder</surname></persName>
		</author>
		<ptr target="https://CRAN.R-project.org/package=BayesFactor" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
	<note>Computer software manual. R package version 0.9.12-4.2)</note>
</biblStruct>

<biblStruct xml:id="b72">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
	<note>Computer software manual</note>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Austria</forename><surname>Vienna</surname></persName>
		</author>
		<ptr target="https://www.R-project.org/" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Reviewer bias in single-versus double-blind peer review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tomkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Heavlin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="issue">48</biblScope>
			<biblScope unit="page" from="12708" to="12713" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Practical bayesian model evaluation using leave-one-out cross-validation and waic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Vehtari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gabry</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11222-016-9696-4</idno>
	</analytic>
	<monogr>
		<title level="j">Statistics and Computing</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="1413" to="1432" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
