<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Credences and Trustworthiness: A Calibrationist Account</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">John</forename><surname>Wilcox</surname></persName>
							<email>john.wilcox@columbia.edu</email>
							<affiliation key="aff0">
								<orgName type="department" key="dep1">Department of Psychology</orgName>
								<orgName type="department" key="dep2">Department of Philosophy</orgName>
								<orgName type="institution">Columbia University New York</orgName>
								<address>
									<region>New York</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">Stanford University Stanford</orgName>
								<address>
									<region>California</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Credences and Trustworthiness: A Calibrationist Account</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:08+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Probability</term>
					<term>calibration</term>
					<term>trustworthiness</term>
					<term>calibrationism</term>
					<term>track records</term>
					<term>Bayesianism</term>
				</keywords>
			</textClass>
			<abstract>
				<p>All of us make judgments of probability, and we rely on them for our decision-making. This paper argues that such judgments are trustworthy only to the extent that one has good reasons to think that they are produced by maximally inclusive, well calibrated cognitive processes. A cognitive process is maximally inclusive when it takes into account all the evidence which one regards as relevant, and it is well calibrated when anything it would assign, say, an 80% probability to would be true 80% of the time. We further have good reasons to think these judgments are trustworthy when, inter alia, they are produced by processes that have good track records of calibration. Call this inclusive calibrationism-or just &quot;calibrationism&quot; for short. In arguing for calibrationism, I also appeal to various empirical results, including research into probabilistic reasoning funded by the US intelligence community. Together, these ideas and results have implications for some important philosophical problems: the problem of the priors, the problem of unique events and the use of intuition in probabilistic reasoning. These theses and results also imply that our judgments are often less trustworthy than we might hope in potentially many domains, including law, medicine and othersbarring good track records, that is.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">The Practical Problem of Probabilistic Inference</head><p>We all have to make judgments of probability. Many of our important life decisions depend on them. But when should we regard such judgments as trustworthy from our inside perspective? <ref type="bibr">1</ref> This paper explores this problem, but it is explicitly about the "inside perspective"-that is, the internalistic perspective of the agent who is aiming to determine whether to trust their own judgments or those of others. It does not explore whether credences are trustworthy from some externalistic God's eye-view. Consequently, the paper aims to specify which cognitively accessible factors should determine whether we should trust a judgment of probability. A factor is "cognitively accessible" as such when we can always know about that factor merely upon reflection-like how one can know whether they are in pain merely upon reflection. 2 This contrasts to, say, how one cannot determine their bank balance merely upon reflection, since they would need some other means-like an electronic device.</p><p>So why focus on a problem explicitly about the inside internalistic perspective? My answer: because this paper aims to give guidance that is practically helpful.</p><p>To see how this internalistic framing is helpful, consider an analogy. Suppose you are stranded in the Amazon with no reception. You are trying to determine whether to trust a potentially dangerous bridge. One suggestion is, "Trust the bridge if and only if it is produced by a reliable engineering company". But suppose these factors are "externalist" and inaccessible to you: who built the bridge or whether it is a reliable company are factors you could not even get good direct evidence for or against. Consequently, the suggestion may be plausible in some sense, but it is also unhelpful because you cannot determine whether the factor applies, whether to trust the bridge and whether to use it or not. An alternative suggestion is, "Trust the bridge if and only if you have good evidence that it is safe". We could suppose this suggestion is more helpful because it is internalist: you can determine whether the factor applies-whether you have good evidence of its safety-and then decide whether to trust and use the bridge. It is also helpful because it can direct you to searching for evidence about its safety, such as testing the bridge with a suitably heavy object. But in this case, we can suppose you realize that you do not have-nor can you get-good evidence about whether the bridge is safe. So you do not trust the bridge, and you decide not to use it. Problem solved.</p><p>Similarly, because this paper aims to provide practically helpful guidance, it focuses on the problem of when judgments of probability are worthy of trust, but specifically from our inside perspective. We can call this the practical problem of probabilistic inference. Here, we will follow the Bayesian tradition of thinking of judgments of probability in terms of credences-that is, degrees of belief, like your degree of belief that the sun will rise tomorrow or your degree of belief that some medication is safe.</p><p>While externalist accounts of justification, rationality and reliability might be plausible and somewhat helpful, they have not solved the practical problem of probabilistic inference, often because they instead aim to address other worthwhile problems in epistemology (I will defend this claim further in subsection 6.11). For example, a good externalist solution to some problems might be this suggestion: "A credence is justified if and only if it is produced by a reliable cognitive process". But if the relevant "reliability" is cognitively inaccessible, then one often cannot straight-forwardly use the suggestion to determine whether to trust their credences, because they will not know whether the factor applies-similarly to the bridge analogy. The suggestion then does not solve the practical problem of specifying cognitively accessible conditions for trustworthiness, even if it solves other problems.</p><p>Consequently, I present another solution, and I use the term "trustworthiness" instead of, say, "justification" to signify that I am addressing a different problem for which-by stipulative definition-the answer is an internalist solution. Furthermore, this internalistic framing will be essential for addressing multiple objections later on (though I will also add an externalist-styled caveat).</p><p>This paper then has the following structure. In the second section, I outline the central solution to the problem: a credence is trustworthy to the extent that one has good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process. Roughly speaking, a cognitive process would be inclusive and calibrated as such if, for example, it took into account all the evidence which one regards as relevant and if anything it would assign, say, an 80% credence to would be true 80% of the time. In the third section, I argue for this thesis, and in the next, I provide complementary theses about when we have good reasons to think credences are produced by a process of the relevant sort. I call these theses the inclusive calibrationist solution to the practical problem of probabilistic inference-or calibrationism for short. I then examine some implications for some important philosophical problems: namely, the problem of the priors, the problem of unique events and the use of intuition in probabilistic reasoning. I also consider a range of issues and objections in the final section, although I candidly acknowledge that other objections necessarily remain undiscussed for lack of space.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">The Trustworthiness/Inclusive Calibration Thesis</head><p>In exploring the practical problem, I will argue for the following thesis:</p><p>(TIC) Trustworthiness/Inclusive Calibration thesis: A credence is trustworthy to the extent that one has good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process.</p><p>The TIC thesis is a normative thesis; it articulates a standard for when people ought to trust credences, but it is not necessarily a thesis which people conform to.</p><p>Let us clarify four aspects of TIC:</p><p>1) its internalist nature, 2) the notion of a cognitive process, 3) the notion of a maximally inclusive cognitive process and 4) the notion of a well calibrated cognitive process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">The Internalist Nature of the Thesis</head><p>TIC is internalist in a specific sense. Since the practical problem concerns the inside perspective, we are considering whether a credence is trustworthy from our perspective, and-in a sense-the only things that can influence whether such credences are trustworthy as such are themselves things we can know about. Consequently, the thesis is that a credence is trustworthy to the extent that we have good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process. And of course, the credence in question may be either our own or someone else's. Perhaps we want to figure out whether to trust the credence of an expert, for instance. The thesis implies that the same consideration underpins trustworthiness: namely, the extent to which we have good reasons to think that that a given credence is produced by a maximally inclusive, well calibrated cognitive process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">A Cognitive Process</head><p>What, then, is a cognitive process? Here, I understand a cognitive process as synonymous with what some call a "psychological mechanism" <ref type="bibr" target="#b14">(Goldman, 1979;</ref><ref type="bibr">Tang, 2016)</ref>. To modify an example from Tang (2016a), suppose your biology teacher with a doctorate tells you that Darwin was born in 1809. You then form a credence of .98 that Darwin was born in 1809. Here, you then have a cognitive process that inputted the biology teacher's testimony and then outputted a credence about the history of biology. Cognitive processes also include other inferential processes, like Bayesian updating and-more generally-abductive or inductive reasoning. (Of course, the specification of such processes confronts the so-called "generality problem", but I will delay a discussion of this until the objections section of this paper.)</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.3.">A Maximally-Inclusive Process</head><p>TIC relates trustworthiness to a particular kind of cognitive process-namely, those that are, inter alia, maximally inclusive. A credence-forming process is maximally inclusive just in case the process takes into account all the agent's evidence which she regards as relevant to the proposition which the credence is about. <ref type="bibr">3</ref> Here, an agent regards some evidence e as relevant to some proposition h when they think that the evidence e affects the probability for the proposition h such that there is a probabilistic dependence where (ℎ) ≠ (ℎ| ) (and we might interpret (. ) as their credences-or their ideally rational credences). For example, suppose I get a new haircut, and two friends give me feedback: Mitchell says it looks good, and Sarah says it looks silly. It hurts to hear Sarah's opinion, and so I ignore it when forming my credence that my haircut looks good-even though, deep down, I know it is relevant evidence I am ignoring. And it is relevant evidence in the sense that the probability (or my credence) that my hair cut looks good would be affected if I updated on that evidence and properly took it into account. In that case, the process that produces my credence is not maximally inclusive: it excludes some of the evidence which the agent regards as relevant to the proposition which the credence is about. TIC then claims that one should think this credence about my haircut is less trustworthy than a credence which is produced by a more inclusive process.</p><p>More generally, then, if an agent was aware of two equally well calibrated processes by which to possibly arrive at a credence, but they had reason to think one process was less inclusive than the other, then the less inclusive process would be less trustworthy. This also implies that when, say, Susan estimates the trustworthiness of Jeff's credences, Susan would think Jeff has a maximally inclusive credence-forming process just in case Jeff takes into account all the evidence which Susan regards as relevant. (And of course, someone might incorrectly deem some evidence as relevant, so calibration will be introduced later as another constraint on trustworthiness too.)</p><p>Furthermore, if some evidence is relevant in one non-maximal process, then that evidence will normally also be relevant in a maximally inclusive process (unless the maximally inclusive process considers other relevant evidence ′ which negates the relevance of this evidence ).</p><p>So TIC claims that trustworthiness is partly a matter of inclusivity, defined as such. However, TIC does not claim that a credence is trustworthy only if it is maximally inclusive. This would imply that a credence is untrustworthy if it excludes even a little bit of evidence. But this is too strong a requirement. Perhaps I need to form a quick judgment as to whether a suspicious figure will mug me if I walk by them. To estimate how dangerous the suspicious figure is, I may only recall some instances of similarly suspicious individuals and their behavior. But because of the circumstances, I will not be able to think thoroughly about every potentially relevant experience I have ever had. Regardless, we may have the intuition that I could form a trustworthy credence in this way, even if the cognitive process is not maximally inclusive.</p><p>TIC would merely say that the credence is less trustworthy than it would have been if the process was maximally inclusive-but this does not necessarily mean that it is completely untrustworthy. Hence, the thesis permits that credences can have differing levels of trustworthiness, and it specifies the factors which determine this trustworthiness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.4.">A Well Calibrated Process</head><p>A second which determines trustworthiness is calibration. For the purposes of this paper, we can talk about calibration as a property of two things. One is a set of credences. Suppose we have a set of credences, each of confidence level n percent for a set of propositions. Then, the set of credences is well calibrated just in case n percent of the propositions are true. <ref type="bibr">4</ref> For instance, if the agent is 60% confident in each proposition in a set of propositions, then their credences for those propositions are well calibrated just in case 60% of those propositions are true. The second thing that may be well calibrated is the process that produces credences. So what does it mean for such a process to be well calibrated? A process is calibrated to the extent that it bears some particular relation to a set of credences (a relation to be explicated). However, the question arises as to which set of credences are relevant.</p><p>There are two possible answers here. One answer appeals to an agent's hypothetical credences. According to this answer, a process is well calibrated to the extent that it would produce well calibrated credences in particular circumstances that might not be actual. The other answer appeals to their actual credences. According to this answer, a process is well calibrated to the extent that it actually does produce well calibrated credences.</p><p>Which notion of calibration is relevant to trustworthiness: hypothetical or actual? I think the answer is both, but each notion is relevant in different ways: one ontological and the other epistemic. To illustrate these ways, consider an analogy: suppose we want to know whether a coin is a fair coin, and we toss it a finite number of times to figure this out. Arguably, what we really want to know is something which concerns a hypothetical question: how would it behave if we were to toss it a large number of times in otherwise normal circumstances? Ultimately, then, the ontological question of whether the coin is fair concerns its hypothetical behavior.</p><p>But to estimate that hypothetical behavior, we look to its actual behavior and consider an epistemic question: given how the coin has actually behaved, what can we infer about how it would hypothetically behave? After all, the actual behavior of the coin does not fully answer the question of whether it is fair: a coin may land heads 10 out of 10 times, and it may ontologically be fair even if its actual behavior is epistemically misleading and highly improbable.</p><p>I suggest we think about credence-forming processes analogously. When we consider whether a credenceforming process is well calibrated (and has trustworthy outputs), what we want to know is the ontological fact about whether that process would produce well calibrated credences in normal circumstances. If we consider whether to trust your credence about Darwin's birth, perhaps we would like to know whether biology teachers would be correct 98% of the time when they assert propositions about the history of biology in normal circumstances. Then, we may use facts about actual calibration-about the observed calibration-for an epistemic function: to estimate the hypothetical calibration of a process. <ref type="bibr">5</ref> Of course, the question arises as to what these "normal circumstances" are. Specifying such circumstances is indeed a problem, and it is one which other accounts of calibration struggle with, such as Dunn's (2015). 6 But it is not a problem that needs a specific answer. Nor should the lack of such an answer cast doubt on the intelligibility or existence of hypothetical calibration. In that sense, we might say it is a problem that is unproblematic. There are two reasons it is unproblematic as such-one general and the other more specific. The more general reason is that we often justifiably have beliefs about hypothetical behavior in "normal circumstances", even though we cannot specify exhaustively and precisely what those normal conditions are. For example, many would believe a coin is fair just in case it would land heads half the time in normal circumstances. But this is true even if we cannot specify precisely what those conditions are. We might be able to specify some aspects of the conditions, like not placing a magnetic strip on one side of the coin and tossing it on a metal surface. 7 But we will not be able to specify the precise features of exactly how it is tossed, the exact wind conditions and the like.</p><p>Similarly, it might not be feasible to specify what the normal circumstances would be for a process to produce well calibrated credences about such topics as the assertions of a biology teacher. Of course, it would be interesting and philosophically valuable to specify such conditions. But the point is that we do not need to specify these conditions in order for the notion of hypothetical calibration to be intelligible.</p><p>The second reason that the problem is unproblematic is that, as I shall argue later, we have good evidence for hypothetical calibration despite our inability to specify the normal circumstances.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">The Argument for Trustworthiness/Inclusive Calibration</head><p>We have now specified the main ingredients involved in TIC-the thesis that a credence is trustworthy to the extent that one has good reasons to think it is produced by a maximally inclusive, well calibrated cognitive process. In this section, I will argue for TIC in two steps. First, I shall give some reason to think that the property of hypothetical calibration (or miscalibration) exists in the world. Second, I will argue for the connection between the trustworthiness of credences on the one hand and the inclusivity and calibration of the processes that produce them on the other.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">The Existence of Hypothetical Calibration</head><p>TIC ultimately claims that our credences are trustworthy to the extent that, among other things, they are produced by well calibrated processes-or more accurately, to the extent we have good reasons to think as such. Furthermore, such processes are well calibrated in the sense that they concern hypothetical circumstances-how things would be in particular circumstances that might not be actual. One immediate objection is that such a notion of hypothetical calibration is fanciful: no such property exists in the world, and so we cannot construe trustworthiness in terms of it. Of course, even if we have no good reason to think it does not exist, we might still worry that we have no good reason to think it does exist either.</p><p>To the contrary, however, I think there is good evidence to support the existence of hypothetical calibration. This evidence comes from observed calibration in what is known as the "Aggregative Contingent Estimation" (ACE) program. The ACE program was launched by the US intelligence community in 2011. It sought to "dramatically enhance the accuracy, precision, and timeliness of intelligence forecasts for a broad range of event types"(Aggregative Contingent Estimation, n.d.). Ultimately, it aimed to increase the accuracy of probabilistic predictions (i.e. "intelligence forecasts") about future events. To do this, one university-based research team within the program, The Good Judgment Project, recruited thousands of forecasters around the world to make predictions about future events. Forecasters would make predictions about geopolitical questions. Examples of such questions included, "Will Bashar al-Assad remain President of Syria through January 31, 2012?", or, "Who will win the January 2012 Taiwan Presidential election?" The accuracy of participants was tracked over time. In doing so, the researchers hoped to determine what made participants good at predicting future events.</p><p>The program is relevant here, however, because one can measure and predict the observed calibration of its forecasters. The calibration of forecasters can be depicted with calibration graphs. 8 For example, below we have a calibration graph for one forecaster-user 5265-who made 1,423 predictions in the first year of the program. 9 Each prediction assigns a decimal value to a proposition; for example, if the forecaster thought there was a 50% chance that a particular individual would win an election, they would assign a value of .5 to that proposition. In the graph below, these predictions have been grouped or "binned" into 11 categories: 1) 0 to .0499, 2) .05 to .1499, 3) .15 to .2499, … 10) .85 to .9499, and 11) .95 to 1. The x-axis of the graph denotes the middle value of the bin. For example, the second dot from the left side represents a middle value of .1 for the bin .05 to .1499. The y-axis of the grid denotes the proportion of true propositions for the predictions in a given bin. For example, if we consider the predictions in the second bin that has .1 as its middle value, then we can see that approximately 11% of the propositions in that bin turned out to be true. The red line indicates what it would look like if the forecaster was perfectly calibrated.  So this graph depicts an individual's calibration and, as we can see, they are very well calibrated: anything they attached a probability of n percent to was true approximately n percent of the time.</p><p>Of course, these things also include unique events. They might assign a probability of about 80% to various propositions such as, for instance, whether Libyan forces would regain control of Bani Walid before February 6 th 2012, or whether Bashar Al-Assad would remain president through January 31, 2012. The point is that even if they attached a probability of approximately 80% to each unique event in a set of propositions, this individual was well calibrated in the sense that approximately 83% of those events happened.</p><p>The significance of this data is that it can be used to provide an argument for the existence of hypothetical calibration. Suppose that we are now living in 2012 at the end of the first year of this program, and we observe the individual's calibration graph above. Then, arguably, we could use this observed calibration to infer something about their hypothetical calibration. In particular, we would expect the individual to be similarly well calibrated in the future-that is, in the hypothetical future circumstances which (we suppose) have not been actualized. Furthermore, we would expect this provided that the circumstances are normal. We might not be able to specify exactly what all of these "normal" circumstances are, but we can say something about what they involve: the individual would be making predictions about political topics, the individual would not be suffering from a severe brain injury, and the like. Now if hypothetical calibration exists and is a property we can make judgments about, then we would expect that that individual will continue to be well calibrated when those hypothetical circumstances are actualized and when the individual continues to make predictions.</p><p>And this is precisely what we observe in the following calibration graph for the second year of the program:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>User 5265's calibration graph for year 2 Here, we can see that the individual is similarly well calibrated in the second year of the program, perhaps even more so. (And this makes sense; individuals generally improved their prediction capabilities throughout the program.) This is not a unique phenomenon; as I discuss elsewhere, the data shows that past calibration is a good indicator of future calibration <ref type="bibr">(Wilcox, Work in progress)</ref>. What's more, other psychologists have also reported that track records of past accuracy are good predictors of future accuracy <ref type="bibr" target="#b19">(Himmelstein et al., 2021)</ref>.</p><p>The moral of the story, then, is this: hypothetical calibration is a reasonable property to postulate since it can explain why we can successfully predict future calibration. And this is true even if it is difficult to fully specify the "normal" circumstances in which individuals make predictions. This, then, is the second and more specific reason that the problem of specifying normal circumstances is, in a sense, unproblematic.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">The TIC Connection</head><p>So far, I have argued that we should postulate the existence of hypothetical calibration. Ultimately, however, we are interested in TIC:</p><p>(TIC) Trustworthiness/Inclusive Calibration thesis: A credence is trustworthy to the extent that one has good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process.</p><p>This claim says that one graded notion co-varies with another graded notion: the more we have reason to think a credence is formed by a maximally inclusive and well calibrated process, the more trustworthy the credence is, and vice versa. We can argue for this claim by handling it as a biconditional of the form if and only if ( is true if q is true, and vice versa). That is, I will argue that:</p><p>(1) if one lacks good reasons to think that a credence is produced by a maximally inclusive, well calibrated cognitive process, then it is not trustworthy. (2) if one has good reasons to think that a credence is produced by a maximally inclusive, well calibrated cognitive process, then it is trustworthy.</p><p>Let us consider the arguments for (1) and (2). The argument for (2) is straightforward. Suppose that you have a credence of n percent in a proposition, and that you have good reasons to think that the process which produced it is maximally inclusive and well calibrated. Then, by definition, you have good reasons to think that it takes into account all the evidence you regard as relevant and that whatever proposition it assigns n percent to will hypothetically be true n percent of the time (in normal circumstances). Intuitively, but surely, this credence should be trustworthy from your perspective. If so, then (2) is intuitively plausible.</p><p>However, the argument for (1) is more complicated. Suppose you lack good reasons to think that a credence is anywhere near produced by a maximally inclusive, well calibrated cognitive process. This is consistent with two possibilities. One is that you have reasons to think it is either ignoring some evidence or miscalibrated-or both. With this possibility, it is clear how such a credence is (at least somewhat) untrustworthy.</p><p>The second possibility is that you lack reasons either way: that is, you lack reasons to think the process is ignoring some evidence or ill calibrated, and you also lack reasons to think it is maximally inclusive and well calibrated. In this case, you simply have no idea-either about how inclusive the process is or how calibrated it is, or both.</p><p>In this case, it also seems that the credence is untrustworthy-or so I claim. To see this, let us reason by cases: for all you know, either it is possible that the process is exclusive or it is possible that it is ill calibrated-or both.</p><p>On the one hand, if it is possibly exclusive, then-by definition-the process possibly neglects evidence which you think is relevant to the proposition in question. By the earlier definition, such relevant evidence e would change your credence were you to take it into account, so (ℎ) ≠ (ℎ| ). In this case, the credence is not worthy of your trust since it possibly neglects evidence which you think would affect your credence if you were to take it into account. 10 It would be much better to form a credence using a more inclusive process. I take this as prima facie plausible, but I will also defend it further in the objections section.</p><p>On the other hand, if the process is possibly miscalibrated (that is, hypothetically miscalibrated in normal circumstances), then it is also untrustworthy. Perhaps, for example, if it assigns a probability of, say, 70% to some propositions, those propositions may be true only 40% of the time. If it is possible to be so miscalibrated, then it is also not entirely worthy of your trust. Of course, it is also possible that the process is inclusive and well calibrated, but the point is that for you it is not worthy of your trust from your inside perspective until you have good reasons to think it is inclusive and calibrated as such.</p><p>What's more, it is even less worthy of your trust given the large body of evidence that humans are frequently overconfident. "Overconfidence" here is a technical term. If you assign a probability of 80% to each proposition in a set of propositions, but only 60% of those propositions are true, then you are overconfident-and by 20% in this case. In this way, overconfidence in general is when our probabilities for a set of propositions exceed the proportion of those propositions that are true. 11 Numerous studies have reported that humans are often overconfident in this and similar ways <ref type="bibr" target="#b1">(Barnsley et al., 2004;</ref><ref type="bibr" target="#b2">Berner &amp; Graber, 2008;</ref><ref type="bibr" target="#b5">Callender et al., 2016;</ref><ref type="bibr" target="#b10">Ehrlinger et al., 2008;</ref><ref type="bibr" target="#b18">Hall et al., 2016;</ref><ref type="bibr" target="#b21">Kruger &amp; Dunning, 1999;</ref><ref type="bibr" target="#b24">Lechuga &amp; Wiebe, 2011;</ref><ref type="bibr" target="#b26">Lundeberg et al., 2000;</ref><ref type="bibr" target="#b30">Meyer et al., 2013;</ref><ref type="bibr" target="#b31">Perel et al., 2016;</ref><ref type="bibr" target="#b34">Podbregar et al., 2001;</ref><ref type="bibr" target="#b41">Tetlock, 2005;</ref><ref type="bibr" target="#b42">Whitcomb et al., 1995;</ref><ref type="bibr" target="#b47">Wright et al., 1978;</ref><ref type="bibr" target="#b52">Yates et al., 1989</ref><ref type="bibr" target="#b49">Yates et al., , 1996</ref><ref type="bibr" target="#b48">Yates et al., , 1997</ref><ref type="bibr" target="#b50">Yates et al., , 1998</ref><ref type="bibr" target="#b51">Yates et al., , 2002</ref>. For example, one study found that one group of students collectively assigned a probability of 95% or more to a set of propositions, but only 73% of those propositions were correct <ref type="bibr" target="#b24">(Lechuga &amp; Wiebe, 2011)</ref>. Another study found that a group of "political experts" were certain-with a probability of 100%-that particular events would not happen in the long-term. But it turns out 19% of those things actually did happen <ref type="bibr" target="#b41">(Tetlock, 2005)</ref>. According to that study, having a PhD or many years of professional experience did not substantially improve calibration either. On a similar theme, another study found that one group of 118 doctors were similarly confident in their diagnoses about the cases where they were likely to be wrong as they were for their diagnoses in cases where they were likely to be right <ref type="bibr" target="#b30">(Meyer et al., 2013)</ref>. In general, then, miscalibration currently appears to be pervasivealthough there are also some notable exceptions <ref type="bibr" target="#b27">(Mandel &amp; Barnes, 2014</ref><ref type="bibr" target="#b33">, 2018</ref><ref type="bibr" target="#b29">Mandel &amp; Irwin, 2021)</ref>. In that case, there is a real threat that we may be miscalibrated unless we have good reasons to think otherwise. Consequently, a lack of such reasons should then reduce the trust which we have in our credences. I take it that the above argumentation sufficiently supports the thesis that a credence is trustworthy to the extent that one has good reasons to think it is produced by a maximally inclusive, well calibrated process.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Trustworthiness, Introspection and Record-Keeping</head><p>Suppose we know that a credence is trustworthy to the extent that some particular conditions are met. Unfortunately that will not help us unless we know what it takes for those conditions to be met. More specifically, the question is this: when do we have good reasons to think that a credence is produced by a maximally inclusive, well calibrated process? Without an answer, we have no practically helpful solution to the practical problem of probabilistic inference.</p><p>For that reason, I want to offer one answer, but this answer is only for certain contexts-namely, ordinary inductive contexts where one is trying to determine the trustworthiness of their own credences. 12 Given this caveat, that answer is the following thesis:</p><p>10 Of course, you might think that it is worthy of your trust since some think of "trust" as an attitude one takes in the absence of information. However, as mentioned in section 1, this is not the way I use the term "trust". The term is used without connotations of externalism or lacking information about whether that thing is worthy of trust. 11 More technically, overconfidence typically refers to when one is overconfident in a set of "answers" that they give to a set of questions: it is when one provides some answers to some questions and then rates the probability that each answer is correct. Otherwise, if no proposition is designated as the "answer", overconfidence and underconfidence are essentially the same thing: overconfidence in a set of propositions is simply underconfidence in the set of negations for those propositions. The terms overconfidence and underconfidence would then lack any interestingly distinct meaning. In any case, the evidence of overconfidence cited in this paper typically concerns contexts where one clearly designates an "answer" to a question. <ref type="bibr">12</ref> These contexts concern when one is trying to determine the trustworthiness of their own credences-but not the credences of others. It is also an answer for when one is trying to determine the trustworthiness of credences about (ITR) Introspection/Track-Record thesis: One has good reason to think that their credence is produced by a maximally inclusive, well calibrated process just in case:</p><p>A) their honest and thorough introspection indicates that the relevant process is maximally inclusive AND B) they know that the process is of a kind which has good observed calibration-that is, a good track record of past calibration</p><p>The ITR thesis implies one has good reason to think their cognitive process is maximally inclusive to the extent that their honest and thorough introspection suggests this is the case. By "introspection", I mean the process of searching one's memory for evidence and of forming judgments about that process. Such introspection is "thorough" when it searches for all available evidence, and it is "honest" when it impartially searches for evidence-not just the evidence that favors one's preferred conclusion. Of course, our introspection may be fallible: we might forget some of our evidence, and this may be undetected by introspection. For that reason, so too may our reasons be fallible: we can have good reasons to think that our cognitive processes are inclusive, even if it turns out that it is not as such despite having those good reasons.</p><p>Regarding track records, the thesis also implies that one can think a cognitive process is well calibrated just in case the process is of a kind which has a good track record of calibration. Of course, this track record might be one that we have observed ourselves or that others have observed. For example, perhaps we know that our inferential processes about a particular topic have been well calibrated in the past, and so we have good reason to think they will be well calibrated in the future too. Or instead, perhaps we are using a process which we might know has been well calibrated-not from our experience, but rather from studies conducted by others.</p><p>That clarifies the content of the thesis. What is the argumentation for it? Well, fairly simple. How else can we assess the inclusivity of our cognitive processes aside from honest and thorough inspection? Furthermore, how else can we assess the calibration of our inductive processes aside from them being of a kind that has a particular track record of calibration?</p><p>All the alternative candidates seem implausible. <ref type="bibr">13</ref> For example, we lack the brain scanning technology to determine, for instance, whether a process is maximally inclusive. However, we can introspect to assess our inclusivity, and we are often successful at this, even though introspection is fallible. Furthermore, we might try to assess the calibration of our cognitive processes by determining whether they have some particular feature, such as, say, being a process about a topic which we have a PhD on. But we cannot trust that such a feature bestows calibration unless we know the feature is of a kind that has a good track record of past calibration. (And in this case, <ref type="bibr" target="#b41">Tetlock's (2005)</ref> study found that having a PhD in, say, political topics was not significantly correlated with superior calibration when forecasting about political topics. The Forecasting Collaborative (2023) found that holding a PhD had no statistically significant influence on forecasting accuracy about social scientific topics too.) Furthermore, it is quite clear that individuals can in principle assess the trustworthiness of their credences in these ways. In fact, that is precisely what the best forecasters in the ACE program could have done: they are excellent reasoners, and they have good reasons to think this based on their introspection and track records.</p><p>inductive questions-but not the questions that can be addressed purely by deductive processes of reasoning, such as some in mathematics. It is also about "ordinary inductive" contexts as opposed to ones in which one is forming credences about epistemologically foundational questions, such as whether an external world exists or whether one's memory is at all reliable. That said, I expect that there may very well be future refinements to this paper's calibrationism as the range of its application and validity becomes clearer. For example, there may be inductive processes which are calibrated no matter how the world is (such as reasoning per the principle of indifference in some domains), and the track-record thesis may not apply to such "world-invariant" inductive processes. <ref type="bibr">13</ref> Technically, we could imagine counter-examples to this claim. Imagine, say, that we develop brain scanning technology that can tell you whether a cognitive process is ignoring any evidence. The technology might then give you good reasons to think a process is maximally inclusive, even if there is no honest introspection on your part. However, this counter-example and (I suspect) others like it only involve non-actual possibilities or, at the very least, possibilities that are very unlikely to be actual any time soon.</p><p>As such, they are not relevant to the practical problem of probabilistic inference. For instance, in providing philosophical guidance to the ordinary person, I doubt they would find it useful to consider the logical possibility of brain scans that are currently technologically impossible.</p><p>What, then, about the credences of others? Can we say anything about how we could determine the trustworthiness of the opinions of others? I think track records are, at the very least, a necessary condition for the trustworthiness of credences from others, at least in ordinary inductive contexts. Ultimately, the arguments in this paper also support the following thesis: one has good reason to think that someone else's credence is produced by a well calibrated process only if they know that the process is of a kind which has good observed calibration-that is, a good track record of past calibration. So, to take stock, I have argued that a credence is trustworthy just in case we have good reasons to think it is produced by a maximally inclusive and well calibrated process. When it comes to the trustworthiness of our own credences, we have such reasons when two conditions are met. First, our honest and thorough introspection indicates that the relevant process is maximally inclusive. Second, we know that the process is of a kind which has good observed calibration. This second requirement, then, explicitly specifies the epistemic role of observed calibration in estimating hypothetical calibration-a topic alluded to in section 2. I also suggested that observed calibration is similarly necessary for trust in the credences produced by the cognitive processes of others.</p><p>For ease of reference, I call the conjunction of the Trustworthiness/Inclusive Calibration thesis and the theses in this section the inclusive calibrationist account of trustworthiness-or just calibrationism for short.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">Implications</head><p>One striking implication of calibrationism is that our credences may very well be less trustworthy than we might think or hope. This is especially true since we often lack good reasons to think that the credences from ourselves or others are well calibrated in the relevant senses and, furthermore, various results in empirical psychology paint a bleak picture of judgmental accuracy. I welcome this implication as a discomforting-yet important-insight about human psychology, one that (barring good track records) discredits unquestioning trust in the operations of our legal systems, of our medical systems and of other societal structures that rely on human judgment from juries, doctors or others. That said, there is good empirical evidence to discredit unquestioning trust in these structures in any case, evidence which cannot be thoroughly discussed here but which includes the evidence of miscalibration discussed earlier and other studies reviewed in <ref type="bibr" target="#b44">Wilcox (2022)</ref>. But I highlight this pessimistic implication of calibrationism because, not only do I think it is epistemically justified, but I also think it can direct our attention to further measuring and improving calibration and judgment accuracy more generally. This improvement itself could potentially reduce the number of inaccurate misdiagnoses, false criminal convictions and other expressions of inaccuracy that researchers have estimated can cumulatively kill thousands every year <ref type="bibr" target="#b16">(Gross et al., 2014;</ref><ref type="bibr" target="#b23">Leape et al., 2002;</ref><ref type="bibr" target="#b44">Wilcox, 2022;</ref><ref type="bibr" target="#b46">Winters et al., 2012</ref>).</p><p>Yet others may see this pessimistic implication as an objection to the account in this paper, and I shall discuss such an objection in the next section.</p><p>In any case, aside from this, these ideas and results in this paper arguably also have further implications for several important topics in philosophy. I will discuss each of these in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Problem of the Unique Events</head><p>It is controversial as to whether probabilities can be assigned to "unique" events. <ref type="bibr" target="#b17">Hajek (2019)</ref> lists some examples of putatively unique events: "the 2020 presidential election, the final game of the 2019 NBA play-offs, the Civil War, Kennedy's assassination, certain events in the very early history of the universe". As he notes, such events pose a problem for frequentist interpretations of probability: how, for example, does it make sense to talk of the probability of Kennedy's assassination qua the frequency of Kennedy assassinations in some actual or hypothetical series of events? The challenge, then, is to provide an intelligible account of how probabilities could attach to unique events.</p><p>The above ideas and results may provide an answer here. In particular, we can say that the probability of a unique event given some particular body of evidence is the credence that a well calibrated agent would have in that event given that body of evidence. Or perhaps there may be many such credences and consequently many such probabilities: perhaps different well-calibrated agents would have different probabilities for the same unique event given different (or even the same) bodies of evidence. In any case, the point is that sensible probabilities can attach to unique events, not necessarily that any attaching probability itself needs to be unique.</p><p>The advantage of this account is that it appeals to a notion of probability that is not only conceivable-it is actual. More specifically, the insights from the ACE program demonstrate that particular individuals can have credences about unique events, and that these credences are well calibrated. For example, consider the individual depicted in the two calibration graphs above. There, they made a total of 7,623 probabilistic forecasts over two years about geopolitical topics, such as the outcomes of wars, elections and the like. They were near perfectly well calibrated, as depicted by the proximity of their forecasts to the red line denoting perfect calibration. Now suppose this individual assigned a probability to a unique event prior to its occurrence or non-occurrence: say, the individual assigned an 86% probability to the Libyan government regaining control of Bani Walid by February 6 th , 2012. Then, arguably, this probability estimate is an intelligible candidate for what it could mean for a probability to attach to a unique event: the probability of a unique event given some particular body of evidence is the credence that a well calibrated agent would have in that event given that body of evidence. Furthermore, in our example, this event is one which this well calibrated individual actually made forecasts about, and their track record of calibration depicted in the graphs is the kind of track record that organizations, like Good Judgment Inc., actually use to determine which probability forecasts they should trust. Of course, these kinds of examples presuppose that there is a reference class of probability estimates that can provide a basis for estimating trustworthiness. Such a reference class may not always be possible, and there may be difficulties in determining what the relevant reference class is (see the objection about the "Generality Problem" in section 6). But in the case of this individual, they do have a track record of the sort that people and organizations can and do use to estimate the trustworthiness of forecasts.</p><p>This account could then solve the problem of what it could intelligibly mean for a probability to attach to a unique event. 14</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Intuition and the Problem of the Priors</head><p>Another problem is the problem of the priors. This refers to the question of whether there are any objectively correct constraints on the "prior probabilities" that are assigned to propositions <ref type="bibr" target="#b40">(Talbott, 2016)</ref>, Unfortunately, there is an ambiguity in the term "prior probability". Some use the term "prior probability" to refer to a probability prior to receiving any empirical evidence. This is the kind of probability that David Lewis is said to have attributed to a "superbaby", an agent with credences and no relevant evidence whatsoever <ref type="bibr" target="#b32">(Pettigrew, 2014)</ref>. Call this an absolute prior. Others use the term "prior probability" to refer to the receipt of evidence prior to receiving some evidence, but not all. For example, one might assign a probability to a hypothesis after receiving some evidence, and this probability is then their prior probability for another body of evidence which they receive later. Call this a relative prior.</p><p>From my knowledge of the ACE program and subsequent research, the results demonstrate a few points of interest. First, forecasters often, if not always, assign relative priors. That is, forecasters often assign initial probabilities on the basis of base rate statistics, news articles, or some kind of evidence-as opposed to no evidence at all. Second, they do so on the basis of processes that involve some degree of intuition. For example, a forecaster might read a newspaper article and have an intuition that the article influences some probability by a precise amount.</p><p>14 However, it would not solve another problem: the problem of explaining what it is in virtue of that such credences are well calibrated. That might require appealing to other more mysterious hypothetical frequencies and philosophical concepts. It also would not solve another problem: what to make of cases where two or more agents have well calibrated but differing credences for the same unique event. In such a case, is the probability of the unique event one credence or another, or some combination of the credences? Or is there instead a sense in which different probabilities attach to the same unique event without any such probability being "the" probability? While these are problems, they are not problems that I have space to discuss here (even though I think they are surmountable). My aim is simply to show that these ideas and results may provide some pieces of the puzzle about understanding probabilities for unique events, even if it does not provide them all.</p><p>More concretely, they might read that some world leader "intends" to sign a treaty, and they might raise the probability that they will sign that treaty by, say, 7%. But the article itself may contain no information that explicitly warrants that it should shift by that precise amount: the article may explicitly say only that the world leader intends to sign a treaty, but not that the probability of them actually signing it is then "raised by 7%". Here, what determines the exact quantity of the change is partly the forecaster's intuition about what the evidence means. The third point of interest is that these processes and relative priors can then be well calibrated, even when they involve such intuition.</p><p>I take these points to generalize to our inferences more generally: we often assign only priors that are relative in the sense that they take into account at least some evidence, and we can do so using intuition in a way so that these priors are well calibrated.</p><p>The problem of the priors, as it concerns the priors we confront in everyday life, is then about whether there are constraints on relative priors like these.</p><p>The account of trustworthiness helps to provide an answer-that is, a constraint on when a prior credence is trustworthy, even if it is based on intuition. More specifically, a relative prior is trustworthy when we have good reasons to think the credence is produced by a maximally inclusive and well calibrated process. In principle, this is a practically useful constraint: we could potentially use it to assess when priors are justified, just as people do when assessing the trustworthiness of forecasters given their track records.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Issues and Objections</head><p>So I have argued for a calibrationist solution to the practical problem of probabilistic inference. I will now consider various issues and objections-although these objections are sometimes raised against similar but distinct viewpoints. These objections can be grouped into various categories, including those about inclusivity, those about calibration and those about internalism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objections about inclusivity</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">Less-is-More effects</head><p>Some scholars-most notably Gerd Gigerenzer and Henry Brighton-have argued that there are contexts where processes that consider less evidence actually produce more accurate judgments. As an example, <ref type="bibr" target="#b12">Gigerenzer &amp; Brighton (2009)</ref> cite studies reporting that some regression models can do a better job of predicting particular phenomena when tallying-that is, when assigning equal or random values to specific terms in the regression model instead of trying to fine-tune those values in the light of the more specific evidence. They claim that this, coupled with some other examples, demonstrates a less-is-more effect-that is, the phenomenon where less time, information or computation produces more accurate judgments. This may be seen as evidence against the claim that a credence is trustworthy to the extent that it is produced by a maximally-inclusive process which considers all the evidence. After all, if less evidence results in more accuracy, then shouldn't a less inclusive process result in a more trustworthy credence? I do not deny that there are contexts where less-is-more effects exist. However, it is also clear that there are contexts where less-is-less effects exist-that is, where less evidence and thinking makes us less accurate. It is obvious people often have inaccurate judgments precisely because they were missing some evidence, such as false convictions that are eventually overturned with vindicating DNA evidence, to give one of countless examples <ref type="bibr" target="#b15">(Gross, 2017)</ref>.</p><p>The point is that a given context could be one where either "less-is-more" or where "less-is-less". It could also be one of the many contexts where we are prone to overconfidence.</p><p>In that case, TIC implies that to have a trustworthy credence from our inside perspective, we would need reasons to think that the credence is produced by a maximally inclusive and well calibrated process. This is actually compatible with less-is-more effects in a specific sense: our evidence in that context would presumably include evidence about whether we are in a less-is-more context-that is, where less information is better. If it does include such evidence, then that evidence also negates the evidential value of the less useful information, meaning that we no longer regard that information qua "evidence" as relevant to determining our credences. For example, suppose we are in a context where we know that tallying is better than trying to fine-tune the regression terms using more specific information. In that case, we know that that specific information should not be regarded as relevant, and so the maximally inclusive process would then ignore that irrelevant information, precisely because we know we are in a less-is-more context. For that reason, a maximally inclusive process would not take into account this other "evidence", precisely because our knowledge of the less-is-more effect means that that "evidence" is no longer regarded as evidentially relevant.</p><p>But if we are in a context where we lack evidence that we have a less-is-more effect, then I think it is fair to say that a credence is trustworthy to the extent that we have reasons to think it is produced by a maximally inclusive and well calibrated process. And this is simply because-by definition-a process is maximally inclusive when it takes into account all the things that we regard as relevant to the probability of the proposition in question. As such, if we regard the evidence as relevant, then surely our judgments about the trustworthiness of a credence should consider whether the relevant evidence is taken into account. TIC incorporates this.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">Maximality is Not Valuable</head><p>One might wonder why-or even deny-that maximal inclusivity is valuable. Suppose, for instance, we have two possible credences for one proposition-namely, the proposition that Jenny has Brown eyes. One credence is 0.99 and the other is 0.01. Both credences are produced by well calibrated processes. They only differ in how inclusive they are: one process takes into account more evidence than the other. Why, then, should we think that one credence is more valuable than the other if the relevant processes are equally well calibrated? What is the additional value of maximal inclusivity? My suggestion is that maximal inclusivity is valuable because it helps us to get closer to the truth in specific cases. For example, consider the process that produces a 0.99 credence that Jenny has brown eyes. Suppose this process considers two pieces of evidence: Jenny is a Mexican citizen, and 99% of Mexican citizens have brown eyes. Suppose then that the other process takes into account two further pieces of information: Jenny is a member of the Jenkins family-all of whom are Mexican citizens-and 1% of the Jenkins family have brown eyes. This is the process that produces a 0.01 credence that Jenny has brown eyes. In this case, we have two equally well calibrated processes, but one takes into account more evidence than the other.</p><p>The reason one process is more valuable than the other should be clear. In this specific case, the more inclusive process will more frequently produce a credence that is close to the truth in that specific case: plausibly Jenny is more likely to not have brown eyes, and a credence of 0.01 is much closer to this truth than a credence of 0.99. In general, then, I think the same moral applies to more inclusive processes: more inclusive processes will generate credences that are closer to the truth in specific cases, at least more frequently than less inclusive processes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Regarding Irrelevant Evidence as Relevant</head><p>One objection is that inclusive calibrationism falters because it claims trustworthiness is partly a matter of including relevant evidence and yet agents may include "relevant" evidence which should actually be excluded. We could imagine, for example, a fan of an indicted musician being confident that the musician is innocent of a horrendous crime, and merely because the musician's musical ability is so good. In this case, they regard the musician's ability as relevant to their innocence when presumably such an ability is not relevant at all. One might think this is a problem for my account because trustworthiness requires an agent to take into account all the "evidence which she regards as relevant to the proposition which the credence is about". My response to this objection is that according calibrationism, calibration also matters: if a credence forming process is maximally inclusive yet lacks evidence of calibration, then it is not trustworthy. In this way, calibration is meant to be a constraint about trustworthiness that ensures evidential inclusivity also tracks truth-that is, it ensures actually irrelevant evidence is not unduly regarded as relevant. In this sense, I think anyone will be miscalibrated if they believe strongly in the innocence of musicians based merely on their musical ability. Such a credence, to my mind, is indicative of untrustworthy ways of thinking about the world, be they wishful thinking or other epistemic vices. Consequently, I think a person like this would not obtain good track records of calibration for these kinds of credence-forming processes; thus, such credences would be untrustworthy.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objections about calibration</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.4.">The Generality Problem</head><p>One might object that calibrationism suffers from the generality problem. The problem was initially presented by others as a challenge to process reliabilism, but it also is relevant to this paper, and perhaps also to any theory of justification, as some claim <ref type="bibr" target="#b3">(Bishop, 2010;</ref><ref type="bibr" target="#b7">Conee &amp; Feldman, 1998)</ref>.</p><p>In the context of this paper, the generality problem involves the idea that how calibrated a process is depends on how we characterize it. For example, in forming your credence about Darwin's birth, we might characterize the process in different ways. Perhaps, for instance, the process is a process that makes inferences about the assertions of a biology teacher about a history of biology topic: in this case, it is well calibrated, since you have a credence of 98% in your biology teacher's assertion, and 98% of similar assertions from biology teachers are correct. But suppose the teacher has a doctorate, and we could instead characterize the process as a process that makes inferences about doctorate-holding teachers' assertions: in this case, it is not as well calibrated, since you have a credence of 98% in your teacher's assertion, but (we can suppose) 99.999% of such assertions from doctorate-holding teachers are correct. The worry is then that there is no correct way to characterize the process in order to evaluate how calibrated it is.</p><p>One prominent solution to the problem-from Comesaña (2006)-is of limited use here. Comesaña argues that any belief will be based on particular grounds. For instance, in our biology example, your credence is based on the grounds that your teacher is a biology teacher, not a doctorate-holding teacher. In our parlance, such grounds are the inputs of the cognitive process, inputs which the agent regards as relevant and which affect their credal output. Comesaña claims that such grounds then define the relevant type of process that should be evaluated (although he is concerned with reliability-not with calibration or trustworthiness). Pettigrew (2018) has endorsed Comesaña's ideas as a response to the generality problem in the context of formal epistemology, and we might try to follow suit. Perhaps we might claim, for instance, that in evaluating the trustworthiness of a process, we should consider the hypothetical calibration of the process that is defined by its grounds or its inputs. In this case, we would evaluate how hypothetically calibrated your process is by considering the proportion of the time that biology teachers (not doctorate-holding teachers) make true assertions about biological topics.</p><p>This might be an adequate way of thinking about hypothetical calibration, but it is not obviously adequate as part of a solution to the practical problem of when to trust our credences. When reasoning in real-world circumstances, we often need to consider combinations of inputs that we have never considered before. For example, suppose we are living in the past, and an agent from the ACE program is considering the probability that Hilary Clinton will win the election in 2016. They may have to consider a range of factors which affect the probability of success: being a woman, being in an American presidential election, running for election in the year 2016, and so forth. The agent then forms a credence about the candidate's election success, and each factor serves as an input in the process which produces this credence. But the agent may very well lack information about how calibrated such a process is given how unique the combination of inputs is. They have never considered that combination of evidence before. So it is not as though, for example, they can search their memory to recall all the times they had the same combination of evidence in order to recall how calibrated their processes were given that evidence. In this case, it is not clear that Comesaña's solution can help the agent ascertain the trustworthiness of her credence from her inside perspective.</p><p>However, another solution is available. Perhaps, for example, the agent from the ACE program knows that her predictions about political topics have an excellent record of calibration. Then, she can be quite confident that her credences about political topics will continue to be calibrated-even if she does not know how to specify and evaluate the particular inputs and process informing her credence. More generally, then, my proposal is that we can assess the calibration of a process against a reference class of processes in the same or similar domains, even if we cannot find an appropriate reference class involving the exact combination of evidence or "grounds" which inform such a process. This, I claim, is a rational and practically helpful way of evaluating the trustworthiness of credences. But not only that: it may frequently be the only way of evaluating trustworthiness given how frequently we have to consider unique combinations of evidence.</p><p>Of course, this does not solve every problem. For example, we could imagine someone who has to make inferences about a topic that is both political and economic-say, predictions about the GDP of some country following a political catastrophe. They might be well calibrated about political topics, but not about economic topics. How trustworthy, then, are her credences about this political and economic topic?</p><p>This, I claim, is a problem, but it is another unproblematic problem. To be sure, the problem does need a solution. However, it is simply a version of a problem which everyone faces-the reference class problem. For instance, suppose we want to know someone's probability of getting cancer. Suppose that they smoke and that 20% of smokers get cancer. But suppose they also exercise regularly and that 1% of regular exercisers get cancer. Ultimately, they are a smoker and a regular exerciser. What, then, is the probability of them getting cancer? This is a problem which everyone faces in one form or another, regardless of their views about trustworthiness or justification. We simply have a special case of it: evaluating the calibration of a process that concerns topics that are both political and economic.</p><p>There are some purported solutions to this problem, although it is not clear that any of them are satisfactory <ref type="bibr" target="#b22">(Kyburg &amp; Teng, 2001;</ref><ref type="bibr" target="#b35">Pollock, 2007;</ref><ref type="bibr" target="#b36">Reichenbach, 1949)</ref>. Regardless, the absence of any such solution should not count as a reason against this particular account of trustworthiness. In that sense, it is unproblematic. The reason for this is that it is unclear that any alternative account fares better, and, furthermore, if there is a solution to the problem, it may very well be compatible with this account. Additionally, we all need to make inferences from reference classes: many of us did this when reasoning about our risks of, say, dying from COVID given that we are young, old, immune-compromised or in some other reference class. The point is that we all need to make inferences on the basis of reference class information despite the reference class problem. Inferences about calibration are simply an instance of this, and they should therefore not be particularly objectionable.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.5.">Calibration is Not Epistemically Valuable</head><p>The critic might object that it is not obvious that calibration is epistemically valuable and, if that is the case, then it is not clear why it should matter for which credences we trust. <ref type="bibr" target="#b33">Pettigrew (2018)</ref> takes his claim further than this. He states "as is well known, being well calibrated is not in fact the aim of credence nor a source of epistemic value" (p. 27). But is this as "well known" as Pettigrew claims? At most, it would perhaps be widely believed, but even then, it is unclear how to reconcile this with, for example, <ref type="bibr" target="#b9">Dunn (2015)</ref> who argues that reliability is a matter of calibration, or the other philosophers that Pettigrew (2018) cites who, by his own words, "take" calibration "to be a source of epistemic value" (p. 27), including Bas van Fraassen, Abner Shimony and Marc Lange.</p><p>In any case, in section 3, I gave an argument to think calibration is a source of epistemic value insofar as it is an important ingredient that determines the trustworthiness of our credences. Consequently, I struggle to see how, as Pettigrew says, "being well calibrated is not in fact the aim of credence nor a source of epistemic value". At the very least, however, perhaps Pettigrew and I can agree that other ingredients are also valuable, such as how resolute or informative a well calibrated credence is-that is, how close it is to 1 or 0. Of course, Pettigrew has various specific objections to calibration which may underpin his perspective, so we shall consider each of these in turn.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.6.">Calibration is Too Easy</head><p>One objection Pettigrew (2018) raises is that calibration is "too easy to come by" (p. 27). He states:</p><p>Providing you have a credence in the negation of a proposition whenever you have a credence in that proposition, you can ensure that your credence are well calibrated by assigning 0.5 to each propositionwhatever the truth values of the propositions, your credences will be well calibrated. <ref type="bibr">(Pettigrew, 2018, p. 28)</ref> The thrust of the objection seems to be that calibration is "too easy to come by" in this example, calibration by itself is not useful or important, and this shows that calibration is not a source of epistemic value-or something like that. But this objection is still consistent with the possibility that calibration is still a source of epistemic value and a valuable and important ingredient for trustworthiness. Instead, it may simply be the case that the example shows other things are also valuable, such as having credences that are also maximally inclusive, or that are close to 1 or 0, or that have some other feature. The objection, then, does not undermine calibrationism.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.7.">Pettigrew's Two Credences</head><p>Pettigrew raises another objection to the value of calibration. Suppose, instead, that you have only two credences: a credence of 0.99 in p and a credence of 0.01 in the negation of p. He claims such credences are guaranteed to not be well calibrated. Presumably this is because, for example, if one only assigns 0.99 to one proposition, then there is no way that 99% of the propositions assigned a value of 0.99 could be true; if there is only one proposition in the set of propositions that are assigned a credence of 0.99, then either 100% of the propositions in that set are true or 0% of the propositions in that set are true. But if calibration was the source of epistemic value, then such credences, he claims, are guaranteed not to be well calibrated. Such credences are therefore guaranteed to be "less epistemically valuable" than credences of 0.5, even if p is true <ref type="bibr">(Pettigrew, 2018, p. 28)</ref>. This, he thinks, is wrong.</p><p>Several things can be said in response to this objection. First, as Dunn would say, what matters is not one's actual credences, but rather the hypothetical calibration of the process which produces such credences. Two credences-like those of Pettigrew's example-could then be very epistemically valuable if they result from a process that is hypothetically well calibrated. So that is one response which tries to preserve the intuition that Pettigrew's two credences could have some kind of epistemic value-at least as much value as the mid-level credences.</p><p>Second, the force of Pettigrew's objection is diminished when we consider it in the context of the practical problem of probabilistic inference, a problem which concerns a specific kind of internalistic value. Suppose you only have Pettigrew's two credences; you then have no credences about your past, about any other things you might remember, about the reliability of your cognitive faculties and the like. <ref type="bibr">15</ref> The only things you have credences about are p and its negation. For all you know, you could be terribly miscalibrated and inaccurate in normal circumstances, actual and hypothetical. Is your credence then really worthy of your trust from your perspective? I think not. The point is that Pettigrew's credences do lack a kind of epistemic value-trustworthiness-in the context of the practical problem of probabilistic inference. And TIC can explain why this is: because you lack good reasons to think that your credence forming processes are well calibrated. Note that this is true even if the credences have some kind of other externalist value-such as so-called Brier score accuracy.</p><p>In sum, it is not obvious that Pettigrew's objection defeats calibrationism, because we can preserve the intuition that his two credences could have some kind of epistemic value and because we can defend the idea that they lack another kind of internalistic epistemic value-namely, trustworthiness.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.8.">Uninformative Calibration</head><p>Tang (2016) also raises some problems for calibration. He asks us to consider a weather forecaster who knows that, in the long run, it rains on 20% of the days in a city. Consequently, she announces a probability of rain of 0.2 every day-no matter what. Such probability judgments are well calibrated, but they are not very useful. This, he claims, is a problem for calibration. In response, note that this objection does not show that calibration is irrelevant to trustworthiness. Instead, I suggest that, at most, it shows that we value other things aside from whether a credence is trustworthy. Ideally, we want credences that are trustworthy and informative. But this is consistent with calibration being an important element of trustworthiness. Consequently, I do not see any insurmountable problem arising from this objection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.9.">Calibration without Maximality</head><p>Tang (2016) raises another objection to calibration: that it is insufficient for justification. To see this, he asks us to imagine someone who forms credences that are calibrated without considering germane evidence. Perhaps, for example, he is thinking of the weather forecaster: she assigns a 20% probability of rain every day, and these probability assignments are well calibrated, even if she is aware of evidence that suggests a higher probability for a given day. He claims that such examples show that calibration is insufficient for justification. Tang is right is right to suggest calibration is insufficient for justification, at least if we interpret "justification" in a sense that is similar to how I think of trustworthiness.</p><p>However, I think the right response is simply to acknowledge that our processes should also be maximally inclusive in order to be fully trustworthy. This is the main claim of this paper, and it is one which is unharmed by Tang's objection: he claims more than calibration is needed, and so do I-because maximal inclusivity is also important.</p><p>In a sense, then, a number of objections-including some from Tang and Pettigrew-point out that calibration is epistemically insufficient; and this is fine, because calibrationism claims calibration is still necessary for trustworthiness, even though it is not sufficient for trustworthiness by itself. Let us now consider another class of objections challenging even the necessity of calibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.10.">Rational Miscalibration</head><p>Some scholars, notably Kevin Dorst (2023), think it is sometimes rational to have miscalibrated credences. He gives various examples. To be fair, he does not pose those as problems for calibrationism in this paper. That said, such examples could be reformulated as problems for calibrationism. Consequently, I will discuss some general strategies for responding to these kinds of examples.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 1: Good reasons despite (unknown) miscalibration</head><p>One of Dorst's examples of rational miscalibration involves Rajat. Rajat has rationally high credences in propositions about the "external world". But these propositions are false because, unbeknownst to him, he is a brain in a vat having hallucinations induced in him by a mad scientist. Another example from Dorst concerns Georgie. Georgie has high credences in propositions about geography, but those credences are miscalibrated because she formed them based on an outdated textbook provided by her teacher.</p><p>There are a lot of things that could be said in reply to these two examples. For instance, we might think that credences about an external world are actually not trustworthy if they assume that the external world straightforwardly matches our perception of it: perhaps credences about an apparent external world are trustworthy, but not credences about the external world as it exists beyond our perception. However, replies like these are complicated and at best secondary to my preferred line of response.</p><p>My preferred line of response to these two kinds of cases is that both Rajat and Georgie could have trustworthy credences despite being actually miscalibrated so long as they have good reasons to think their credences are produced by calibrated (and inclusive) processes. Put simply, the credences would be trustworthy because of good reasons-despite actual miscalibration. These examples, if anything, point out that one's reasons can be defeasible; one can have good reasons for thinking something even if that thing turns out to be false. In this case, one simply might simply have defeasible reasons to think their cognitive processes are well calibrated, but calibrationism requires only that one has such reasons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 2: Untrustworthiness despite seeming "rationality"</head><p>The Georgie case could be more complicated: perhaps she has no good reasons to think her credence forming processes are well-calibrated, but she still has her credences. Dorst might think these credences are rational since they are based on her teacher's textbook.</p><p>If this is the case, how could one respond to such an example of supposed untrustworthiness despite seeming rationality? Terms like "rationality" and "justification" often come with baggage, and conceptions of rationality can tend more towards internalist or externalist directions <ref type="bibr" target="#b43">(Wilcox, 2016)</ref>. I would think that my arguments still stand regardless of one's conception of rationality. These include the arguments that if one's processes are possibly hypothetically miscalibrated (in normal circumstances), then they are not trustworthy. Perhaps, for example, one might think it is "rational" to form credences based on the testimony of others. But even if it is "rational" to do as such, I would still not regard such credences as trustworthy. Why? Well, for all the reasons I gave earlier. For example, one could still be hypothetically miscalibrated and form, say, 99% credences in testimony-based propositions that are false 30% of the time, even if those processes are still "rational" according to one or another standard.</p><p>We may say something similar about Georgie's credences: her credences could be untrustworthy, even if they are rational according to some other standard.</p><p>That said, one might further object that I do presuppose a particular connection between calibration and rationality when I use the term "overconfidence". After all, does not the "over" in "overconfidence" imply too much confidence relative to some standards of rationality?</p><p>Well, not necessarily. "Overconfidence" is a technical term that refers to when our confidence for a set of propositions exceeds the proportion of those propositions that are true. But this term does not necessarily always imply irrationality, at least no more than any other term like "overcalibration" (which, it might be thought, perhaps unintuitively implies that one is too calibrated).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy 3: Hypothetical calibration despite actual miscalibration</head><p>Dorst presents another three cases which involve actual miscalibration in different ways.</p><p>In one case, a coin that is 60% biased toward heads is tossed 100 times, but it lands heads only 30 times, not 60 times. Before the tosses, presumably the rational credence was 60% confidence that any given toss would land heads, even though such credences turned out to be actually miscalibrated.</p><p>In another case, a coin is drawn from an urn which has 60 coins with heads on both sides and another 40 coins with tails on both sides. Then the coin is tossed 100 times. For each toss, Dorst thinks a 60% credence in a given toss landing heads is rational in advance of seeing any tosses, but those credences would be miscalibrated since either all or no tosses will land heads.</p><p>And in another case, someone takes a representative set of your rational credences, a subset of which are credences in true propositions while a subset of which are credences in false propositions (although you do not know which credences are in which subset). Dorst supposes that these credences are rational, but they are all miscalibrated: for all the true propositions, you will be underconfident in them, since 100% of them are true, and for all the false propositions, you will be overconfident in them, since 0% are true.</p><p>My response to these three cases is that they show that what is important is not primarily actual calibration, but rather hypothetical calibration in the normal circumstances, as explained in section 3.</p><p>Consider the first case of the biased coin: the cognitive process that produced your 60% credences would have been hypothetically calibrated if the biased-coin was tossed repeatedly in normal circumstances; you just happened to get extremely, extremely, extremely unlucky. (In fact, there is virtually a 0% probability that a coin would lands heads 30 times in 100 trials if it had a bias of 60%, as any binomial distribution calculator would tell you. It is instead more than 99.9% probable it would land heads at least 45 times.) Regardless, if you then had good reasons to think your cognitive process was hypothetically calibrated, you would have had trustworthy credences despite any actual miscalibration.</p><p>Now consider the second case of double-headed and double-tailed coins: the cognitive process that produced your 60% credences would have been hypothetically calibrated if we consider the outcome of a given flip as that flip could have happened relative to different draws of the coin. For any given flip, if a double-headed coin was drawn, it could have landed heads, and if a double-tailed coin was drawn, it could have landed tails, and out of all the possible draws, 60% of those draws would have made the coin land heads, since 60 of 100 coins are double-headed. In fact, this is arguably exactly why we think a credence of 60% is the right one; because the probability of a given flip landing heads should take into account the different possibilities about which coin was selected, whereby a given coin flip would have landed heads 60% of the time across these hypothetical possibilities. If you then had good reasons to think your cognitive process was hypothetically calibrated relative to those possibilities, then your credences would be trustworthy despite the fact that you know your credences will actually be miscalibrated in this case.</p><p>Finally, consider the last case. It is true that the credences would be miscalibrated when grouped according to truth and falsity, but this is true no matter what example we consider; it is also true for the calibrated forecaster in section 3, for example. What this clearly shows, however, is that, again, actual calibration according to any arbitrary reference class is not important. Instead, what matters is whether the credences are hypothetically calibrated relative to the normal circumstances in which the process would operate. For example, the calibrated forecaster in section 3 is hypothetically calibrated in the normal circumstances, and we can tell this because calibrated forecasters like this are calibrated year after year after year.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objections about internalism and externalism</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.11.">Externalism and Other Accounts of Reliabilism</head><p>The calibrationist account in this paper is similar to those articulated by <ref type="bibr">Tang (2016)</ref> and <ref type="bibr" target="#b9">Dunn (2015)</ref>.</p><p>Consequently, a question might arise as to what the differences are between my account and theirs, and whether my account addresses any problems that their accounts do not. So let us consider their accounts and how they relate to mine.</p><p>Tang <ref type="formula">2016</ref>articulates the following reliabilist account of when a credence is justified:</p><p>For any ∈ [0,1], any proposition p, and any subject a, a's credence of x in p is justified if and only if:</p><p>(1) it is based on some ground , where the objective probability of the credence having a true content given (that it based on) approximates or equals x, and (2) there is no more inclusive ground ' had by a such that the objective probability of the credence having a true content given (that is it based on) ' neither approximates nor equals x (p. 88)</p><p>There are a few concepts to unpack here. According to Tang, the "ground" for a credence is the evidence which the "subject" bases their credence on. For example, someone might have a credence of 0.9 that Darwin was born in 1809, and their ground for this might be that they heard their biology teacher assert that Darwin was born in 1809.</p><p>Tang (2016) also considers "objective probabilities to be hypothetical relative frequencies" (p. 81). For example, suppose an agent is in a world where a coin has never been tossed. They see a coin for the first time, observe that it is symmetrical and arrive at a credence of 0.5 in a coin toss landing heads based on the observed symmetry. According to Tang, this would be justified because, in that world, the relative frequency with which it would be true that the coin lands heads given that ground is approximately 0.5, and their credence approximates this relative frequency or objective probability. Dunn also offers a reliabilist account, but this account is of reliability, not of justification. More specifically, he aims to explicate the concept of the reliability of a process in terms of the calibration of that process. He thinks this is simply one epistemic virtue of a process, and other virtues might matter too (such as informativeness). Consequently, his position is consistent with the possibility that reliability is necessary but not sufficient for a belief to be justified.</p><p>In any case, he characterizes the reliability of a process as follows:</p><p>Calibration Reliability: To determine the reliability of a process :</p><p>(1) Construct a set of propositions that contains all the propositions that has actually assigned credence to and all the propositions the process would assign credence to in nearby counterfactual scenarios. (2) Partition this set of propositions according to the credence assigned to them.</p><p>(3) Let the score for each partition be the squared difference between the credence and the truth-ratio of propositions in that partition.</p><p>(4) The weighted average of the scores for each partition is the reliability of . <ref type="bibr" target="#b9">(Dunn, 2015</ref><ref type="bibr">(Dunn, , p. 1942</ref> Put simply, then, Dunn characterizes the reliability of a process in terms of the calibration of the credences which that process would assign in actual and nearby counterfactual scenarios. So those are two reliabilist accounts in the literature. They bear some similarities to the current proposal articulated and defended in this paper. Tang characterizes the justification of a credence in terms of grounds that are maximally inclusive and that produce truth with a hypothetical relative frequency which matches the credence. This is similar to my account which relates the trustworthiness of a credence to a process that is maximally inclusive of the evidence (or "grounds") and that is hypothetically calibrated in a similar sense. Dunn characterizes the reliability of a credence-producing process in terms of its hypothetical calibration, and my account also relates trustworthiness to hypothetical calibration.</p><p>The difference between my account and theirs, then, is that my account attempts to answer an internalist question. Tang and Dunn attempt to answer the question of when a credence is justified or when a process is reliable.</p><p>By their lights, an agent could have justified credences or a reliable process without knowing as such or without knowing anything of the facts that make this the case. In that sense, some of the factors that determine the application of their concepts are factors that are not necessarily cognitively accessible; they are externalist in this way. In contrast, I attempt to address the practical problem of probabilistic inference. Doing so requires an answer to the question of when our credences are trustworthy on the basis of factors that are cognitively accessible to us from the first-person perspective-from the inside view. In that sense, all such factors, then, are necessarily internalist, as mentioned in section 1.</p><p>This entails that our accounts of the concepts are not extensionally equivalent: in other words, their accounts would apply the concepts of justification and reliability to cases where I would not apply the concept of trustworthiness-and vice versa.</p><p>Let us show this with a case which may illustrate this point, although, to be fair, neither Dunn nor Tang discuss this specific case. This case is an adaption of a thought experiment first presented by Laurence <ref type="bibr" target="#b4">Bonjour (1980)</ref>.</p><p>Bonjour asks us to imagine a man named Norman who has a psychic ability that reliably generates accurate beliefs.</p><p>Let us adapt this case and suppose that this ability causes Norman to sometimes hear a grand angelic voice in his mind that asserts a particular proposition. Norman never hears voices in his head that sound as grand and angelic as this, and he normally would not believe anything just because of any voices he does hear. However, purely because the voice sounds so grand and angelic, and because it asserts a particular proposition, he assigns that proposition a 90% credence. As such, Norman then has a 90% credence in a given proposition based on the ground that he heard the grand angelic voice assert it. Furthermore, suppose that the hypothetical relative frequency with which these propositions are true is approximately 90%, and Norman's credence approximates this relatively frequency or objective probability. Following Bonjour, suppose also that Norman "possesses no evidence or reasons of any kind for or against the general possibility of such a cognitive power, or for or against the thesis that he possesses it" (even if we do possess evidence for or against this possibility) (p. 62). Now suppose we are considering the first time Norman hears the voice (although that voice will assert many propositions later, 90% of which are true). And again following Bonjour, suppose that in this case, the voice asserts "the President is in New York City", although Norman "has no [other] evidence either for or against this belief" (p. 60 and 62). Norman then has a 90% credence that the President is in New York, but he does not have good reasons to think it is produced by a well calibrated process. He does not have, for example, a track record indicating the frequency with which propositions asserted by the angelic voice are true. I suspect that Tang's account would say that Norman is justified in having this credence, and Dunn's account would say his credence forming process is a reliable one. Why is this? Well, for Tang's account, the credence of 90% meets the two conditions above: (1) it is based on the ground of the angelic voice he heard, and-by supposition-the objective probability of his credence having true content given that ground is approximately 90%, and, again by supposition, (2) there is no more inclusive ground ′ such that the objective probability of his credence having true content given ′ neither equals nor approximates 90%. And for Dunn's account, one could follow the process he outlines above to determine that the process assigns 90% credences to propositions that are true 90% of the time; consequently, his account would arguably deem the process well calibrated and reliable. <ref type="bibr">16</ref> Hence, it seems Norman's credence is justified and his process is reliable, according to Tang and Dunn's accounts respectively.</p><p>Importantly, the point of this is example is not to present a counter-argument against either Tang or Dunn's accounts; it is not an attack on their accounts at all.</p><p>Instead, my point is merely that this is an example where our accounts diverge in their extensions: the example would feature justification and reliability in their senses, but it would not feature trustworthiness in my sense. The reason for this is that, by stipulation, Norman has no good reasons to think his credence-forming process is one which is well calibrated. He lacks the relevant internalist factors that are necessary for trustworthiness. For example, perhaps for all he knows, 100% of the propositions asserted by the angelic voice are true, or perhaps 0% of them are true; so he does not know anything about the calibration of the process whereby he forms credences on the basis of that grand angelic voice. (Of course, he may later develop a good track record of calibration and become aware of it, in which case his credences could then be trustworthy. But there is no such track record in this example because this is the first time he hears this voice.) For that reason, Norman's credence is untrustworthy according to the calibrationism, even if it is justified and reliable in some externalist sense.</p><p>So although my calibrationist account is similar to Tang and Dunn's, it is importantly dissimilar to theirs in that it is internalist in its nature, and this means that the accounts are not extensionally equivalent.</p><p>If my arguments are sound, then, it should be clear that their externalist accounts do not commit one to an internalist solution to the practical problem of probabilistic inference. It is possible to be a reliabilist about justification and reliability in their externalist senses while endorsing a non-calibrationist account about trustworthiness. Perhaps, for instance, one could adopt a coherentist account of trustworthiness, according to which any credence is trustworthy so long as it coheres with all of their other credences. Indeed, Ernest Sosa takes a similar path in distinguishing a belief's aptness from its justification; a belief is apt in an externalist sense only if it is produced by an intellectual virtue which reliably produces true belief, and it is justified in an internalist sense just in case it coheres with one's epistemic perspective. <ref type="bibr" target="#b25">(Lemos, 2007;</ref><ref type="bibr" target="#b38">Sosa, 1991</ref><ref type="bibr" target="#b38">Sosa, , 2015</ref>. Hypothetically, then, one could similarly be a reliabilist about justification or reliability in their externalist senses while being a noncalibrationist about trustworthiness in its internalist sense. Consequently, the practical problem of probabilistic inference is unresolved by Tang and Dunn's arguments, even if such arguments are insightful and relevant in other ways.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.12.">Incoherence with Externalist Motivations</head><p>Earlier, I claimed that if we lack reasons to think that a credence is produced by a well calibrated process, then it is not trustworthy. In doing so, I appealed to two particular considerations: the sheer possibility that we are miscalibrated and the empirical studies suggesting that miscalibration is pervasive. The critic might object that these considerations are somewhat externalist: the possibility and pervasiveness of miscalibration are not necessarily considerations that are cognitively accessible. For example, someone might think that their credences are trustworthy simply because the credences "seem" right, even if they have not taken into account these considerations. The critic might think that if my account really is internalist, then it should not claim that trustworthiness should be affected by considerations that are not even present from one's first-person perspective.</p><p>This is a reasonable objection, and it is why I alluded to an "externalist-styled caveat" in the introduction. TIC is, I claim, internalist in one sense, but it is motivated by externalism in another sense.</p><p>Let me clarify what I mean. Ultimately, TIC is an epistemic standard: it says that a credence is trustworthy to the extent that we have good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process. In that way, it claims that trustworthiness is determined on the basis of specific criteria-whether you have good reasons to think the process is maximally inclusive and well calibrated.</p><p>Such criteria are internalist insofar as they are cognitively accessible: one can simply introspect to see whether they have reasons to think as such or not. Of course, the ordinary person might not be familiar with the technical terms of "calibration", "inclusivity" and the like, but they can nevertheless consider the relevant concept even if they do not think of them in those specific linguistic terms. The ordinary person can have a sense of whether they are ignoring evidence, or of how frequently an event may happen if they attach a high probability to it. In that sense, the relevant criteria are internalist.</p><p>However, even though the criteria are internalist, the reasoning for why those criteria are the relevant criteria is not internalist. When I make a claim about why those factors are the relevant factors, I may do so on the basis of considerations that are not necessarily cognitively accessible to the ordinary person-such as, for instance, the evidence of pervasive miscalibration. But that is consistent with me saying that, for these externalist reasons, specific internalist factors should determine for them whether their credences are trustworthy. The criteria are still internalist, even though the motivations for the criteria may be externalist.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.13.">Externalistically Better Processes</head><p>One might object to the calibrationist account in this paper with the following externalist-styled motivation. Suppose someone can form different credences about some particular proposition q based on either of two cognitive processes. One process is perfectly calibrated and includes all the evidence which the agent regards as relevant; it delivers a credence of 50% in the proposition q. The other process is less well calibrated, but it takes into account evidence which the agent is aware of but does not regard as relevant and has no reason to regard as relevant.</p><p>Yet suppose this additional evidence actually is relevant in a way that the agent is unaware of, and indeed the evidence, when interpreted correctly, is quite informative about the probability of the proposition under question. As a result, this process assigns a credence of 90% to the proposition q, even though the process is generally miscalibrated by 5% in the long-run.</p><p>Intuitively, the second credence is better: even though it is produced by a less calibrated process, it is more informative, the process is still pretty well-calibrated and the process takes into account more evidence that is more informative than the first process.</p><p>However, the TIC thesis implies that the first process is more trustworthy: after all, by supposition, the agent has good reason to believe their process is well-calibrated and maximally inclusive and they have no reason to believe the second process is better or takes into account more informative evidence.</p><p>Consequently, one might object to the TIC thesis, claiming that the second process is better and should not be deemed less trustworthy.</p><p>This objection, however, can be accommodated by calibrationism with several steps. The first is to acknowledge that, in some externalist sense, the second process simply is better, and for all the reasons listed above. This should be clear from the discussion of the previous objection in subsection 6.14: it is entirely compatible with calibrationism to say this second process is in some sense more externalistically reliable, or justified, or "trustworthy"-given some externalist sense of the term "trustworthy".</p><p>However, recall from the setup of the problem in section 1 that the practical problem of probabilistic inference is about what processes we should trust given our inside, internalistic perspective-not given some outside externalistic perspective. With this in mind, it is hard to say that the second process is worthy of more trust from the agent's inside perspective because (given the caveats about maximal inclusivity in 2.3) the first process includes all the evidence which the agent regards as relevant and the second processes uses evidence in a way which they have no reason to regard as relevant. As per section 1, calibrationism is meant to provide practically helpful guidance about what the agent should regard as trustworthy from their inside, internalistic perspective given factors that are cognitively accessible to them-not given factors that are unhelpful and irrelevant because they are externalistic and cognitively inaccessible to them. Consequently, I think calibrationism can survive the objection, both because calibrationism can affirm the second process' value in an externalist sense while denying its trustworthiness in an internalistic sense-that is, from the inside perspective of the agent themselves.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Objections about other issues</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.14.">High Standards</head><p>My argument in this paper claims that one's own credence is trustworthy to the extent that 1) their honest and thorough introspection indicates that it was formed by a maximally inclusive process AND 2) they have reasons to think it is of a kind that has a good track record of calibration. However, the critic might claim that this is radical and far too strong. Very few people meet these conditions, and so, if this claim is true, very few people would have trustworthy credences.</p><p>My response is twofold. First, to some extent, people do meet these conditions, but just not as much as they could. For example, people are often honestly introspective-not all the time, but some of the time. Furthermore, I claim people often do some kind of subconscious record keeping. After all, if they were constantly wrong about things, then their life experiences and disastrous decision-making should indicate this. Again, not all will take note of their track record as much as they should, but some will do so. Such commonplace introspective and subconscious record keeping then gives some people grounds to somewhat trust their credences. My point is that better introspection and subconscious record keeping is necessary for even greater trustworthiness.</p><p>But secondly, it is certainly possible that a plethora of credences are untrustworthy or, at the very least, much less trustworthy than credences could or ideally would be. And I think this is not a problem for my argument. There is no reason to think that most people have epistemically optimal psychologies. What's more, we humans know from psychology that there are many ways in which our psychologies are often biased and sub-optimal, and the aforementioned evidence of miscalibration and overconfidence supports this <ref type="bibr" target="#b13">(Gilovich et al., 2002)</ref>. As a result, widespread failures of record keeping, introspection and-consequently-credal trustworthiness would be neither surprising nor a concern for calibrationism.</p><p>This may seem radical, but the seeming radicalness of a standard should not necessarily count against it. Probably many now accepted standards once seemed radical centuries ago: take women's suffrage or the abolition of slavery, for example. Of course, these examples are very different to the epistemic standard espoused in this paper, but the general point still applies: what matters is not whether a standard is radical from society's current point of view, but rather whether there are good reasons to endorse that standard. I hope to have presented such reasons above, including the evidence of widespread miscalibration.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.15.">Pragmatic Neccessity of Trust</head><p>Of course, one might object that one can trust their credences even if they do not meet such standards, if only for the reason that we have to make decisions in our lives, and we cannot do so unless we trust our credences. However, this objection is not obviously correct. It is one thing to trust a credence as a faithful reflection of how the world is-or how the world is "likely" to be in some sense. But it is another thing to act as though something is true without having much credence in it. This is like the difference between believing that a map represents some terrain, and navigating the terrain with that map as though it represents that terrain, even if one is not confident in it as a representation. To make decisions, it often suffices to do something of the latter kind-to act as though something is true without undue trust in any opinion about its truth. Consequently, the demands of daily decisionmaking constitute no challenge to the standards in this paper.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.16.">Viciously Circular Meta-Inductions</head><p>One objection to calibrationism is that it involves a vicious meta-inductive circularity. Induction, as I understand it here, involves making inferences about unobserved features of reality based on observed features of reality. For example, one might inductively infer that the sun will rise tomorrow (an unobserved feature of reality) given that it has risen every day in one's memory (an observed feature of reality). One might also infer that the universe began with a big bang (an unobserved feature of reality) given that it has cosmic background radiation (arguably an observed feature of reality). <ref type="bibr">17</ref> A meta-induction is then an induction about inductions. In this paper, I propose using track records to inductively infer the hypothetical calibration of a credence-forming process, where such a process is itself an induction to a credence. This is a meta-induction insofar as it inductively infers the calibration of an inductive process.</p><p>One might object that my account is meta-inductively circular and that this is vicious. I disagree with this objection-or at least part of it. My account is meta-inductive for the reasons mentioned earlier. But it is neither circular nor vicious.</p><p>My account would be vicious if it aimed to solve the problem of induction by using induction but without presupposing induction.</p><p>But my account does not aim to do that. It does not aim to justify induction from scratch-that is, to justify induction without presupposing it.</p><p>As mentioned elsewhere, I think the problem of induction has no non-circular solution: induction can never be properly justified by some other justification without presupposing induction <ref type="bibr" target="#b43">(Wilcox, 2016)</ref>. This is a fact we all must embrace, and one that many-if not all-philosophers have embraced already <ref type="bibr" target="#b20">(Howson &amp; Urbach, 2006)</ref>.</p><p>Instead, the aim of my account is different: to use some inductions to ensure the trustworthiness of other inductions.</p><p>Of course, one might object that the former inductions are not trustworthy unless there are some other inductions which justify the former inductions from track records, and this can lead to an infinite regress.</p><p>But clearly an infinite regress is not feasible, and I do not think a normative account like mine should specify that the trustworthiness of a credence depends on doing infinitely many things in a way that can never be done. If that was the case, then all credences would be untrustworthy, but this is the wrong conclusion. Furthermore, I also think this is the wrong conclusion based on the wrong reasons: the trustworthiness of credences should not be ruled out a priori just because of an infinitely regressive requirement.</p><p>Quite simply, then, I have to postulate that some inductions are foundational. This is why I specified that the track record thesis applies only to "ordinary inductive contexts" as opposed to more "epistemologically foundational questions". There, I mentioned two examples of epistemologically foundational questions: whether an external world exists (as opposed to, say, being merely a dream) and whether our memory is reliable. I do not propose calibrationism as a constraint on credences about these questions which, I think, might rationally involve some "foundational" credences or assumptions.</p><p>To that list of foundational questions and topics, then, I also add some meta-inductive inferences from track records to inductive trustworthiness-but with a caveat.</p><p>The caveat is that some meta-inductive inferences from track records might be foundational whereas others will not.</p><p>In particular, I believe there are two kinds of meta-inductive inferences which I characterize abstractly as follows:</p><p>Singularly meta-inductive inference: Credence-forming process p is of a kind which has previously had a track record of kind r, so p is hypothetically calibrated and therefore its credences are trustworthy (if p is also inclusive).</p><p>Doubly meta-inductive inference: Track records of kind r [do/do not] correlate with hypothetical calibration, so it is [legitimate/illegitimate] to infer that "Credence-forming process p is of a kind which has previously had a track record of kind r, so p is hypothetically calibrated and therefore its credences are trustworthy (if p is also inclusive)". Some singularly meta-inductive inferences are permissibly foundational. For example, one may look at User 5265's large and impressive track record of geopolitical forecasts and then infer that their processes are hypothetically calibrated and their credences are trustworthy (if those processes are also inclusive, that is). My account would permit this as a foundational meta-inductive inference, not justified by other inductions.</p><p>However, other meta-inductive inferences may not be foundational. Perhaps, for example, some evidence shows that particular kinds of track records correlate with hypothetical calibration in surprising ways. In these cases, then, one might meta-inductively infer hypothetical calibration and trustworthiness from such a track record, but this meta-inference would be justified by a doubly meta-inductive inference about that inference.</p><p>So my accounts permits some foundational inferences, ones that can be singularly or doubly meta-inductive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="7.">Conclusion</head><p>This paper aimed to offer some novel contributions to the philosophical and psychological literatures that concern probability and rational or justified degrees of belief. First, I introduced the practical problem of probabilistic inference, the problem of specifying the conditions under which judgments of probability are trustworthy from the inside perspective. I then outlined one solution to the problem, the Trustworthiness/Inclusive Calibration thesis: a credence is trustworthy to the extent that one has good reasons to think that it is produced by a maximally inclusive, well calibrated cognitive process. This thesis resembles some accounts in the literature, although it differs from them in virtue of being internalist in nature. Regardless, to argue for this thesis, I offered a new argument that appeals to empirical results suggesting that hypothetical calibration exists and that miscalibration is pervasive. I then offered a more novel thesis-the Introspection/Track-Record thesis-about when an agent's credence is trustworthy as such: namely, when their honest and thorough introspection indicates the credence forming process is maximally inclusive and they know that the process is of a kind which has good observed calibration. I also offered the thesis that observed calibration is a necessary condition for trust in the credence-producing processes of others. I call all of these theses the inclusive calibrationist solution to the practical problem of probabilistic inference-or calibrationism for short. After arguing for calibrationism, I suggest that it can offer original solutions to two prominent problems: the problem of the priors and the problem of unique events. Lastly, I responded to a range of objections to my arguments. If my arguments are sound, they entail an important and worrying conclusion: many people's credences might be much less trustworthy than we would hope-that is, barring good track records.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1</head><label>1</label><figDesc>User 5265's calibration graph for year 1</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc></figDesc><table><row><cell cols="2">User 5265's calibration table for year 1</cell><cell></cell></row><row><cell>Middle value of the bin</cell><cell>Percentage of true propositions per</cell><cell>Number of forecasts per bin</cell></row><row><cell></cell><cell>bin</cell><cell></cell></row><row><cell>2.5%</cell><cell>1.9%</cell><cell>209</cell></row><row><cell>10%</cell><cell>10.9%</cell><cell>110</cell></row><row><cell>20%</cell><cell>15.3%</cell><cell>98</cell></row><row><cell>30%</cell><cell>20.8%</cell><cell>101</cell></row><row><cell>40%</cell><cell>40.3%</cell><cell>124</cell></row><row><cell>50%</cell><cell>47.1%</cell><cell>172</cell></row><row><cell>60%</cell><cell>59%</cell><cell>139</cell></row><row><cell>70%</cell><cell>80.5%</cell><cell>77</cell></row><row><cell>80%</cell><cell>80.6%</cell><cell>103</cell></row><row><cell>90%</cell><cell>91.3%</cell><cell>104</cell></row><row><cell>97.5%</cell><cell>97.3%</cell><cell>186</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head>Table 2</head><label>2</label><figDesc></figDesc><table><row><cell cols="2">User 5265's calibration table for year 2</cell><cell></cell></row><row><cell>Middle value of the bin</cell><cell>Percentage of true propositions per</cell><cell>Number of forecasts per bin</cell></row><row><cell></cell><cell>bin</cell><cell></cell></row><row><cell>2.5%</cell><cell>4.2%</cell><cell>983</cell></row><row><cell>10%</cell><cell>11.3%</cell><cell>1078</cell></row><row><cell>20%</cell><cell>19%</cell><cell>518</cell></row><row><cell>30%</cell><cell>30.9%</cell><cell>454</cell></row><row><cell>40%</cell><cell>35.9%</cell><cell>396</cell></row><row><cell>50%</cell><cell>47.2%</cell><cell>91</cell></row><row><cell>60%</cell><cell>65.9%</cell><cell>415</cell></row><row><cell>70%</cell><cell>69.9%</cell><cell>421</cell></row><row><cell>80%</cell><cell>78%</cell><cell>431</cell></row><row><cell>90%</cell><cell>86.2%</cell><cell>791</cell></row><row><cell>97.5%</cell><cell>94.9%</cell><cell>622</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">"Trust" in a credence, I think, should be regarded as a conceptual primitive which denotes the mental state or "feeling of assurance" which we would have if, to take some hypothetical examples, there was a benevolent infallible God who told us the credence is a perfectly good credence in every way or if we knew that it would rain 80% of the time when we had an 80% credence of rain (and there is no other credence we could have that is better or in some way closer to the truth). 2 This characterization of accessibility is somewhat similar to the characterization of so-called accessibility internalism in<ref type="bibr" target="#b39">Steup and Neta (2020)</ref>.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Others have also analyzed justification partly in terms of how inclusive one's grounds for a credence are. See, for example, Pettigrew (2018). 4 This is somewhat similar to<ref type="bibr" target="#b37">Seidenfeld's (1985)</ref> definition, although it also bears some conceptual dissimilarities too.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="5">Note also that Dunn (2015) has similar views about what it takes for a credence forming process to be reliable. He thinks that the reliability of such a process depends on how well calibrated its credences are in actual and nearby counterfactual scenarios.6  Dunn construes the reliability of a credence-forming process in terms of hypothetical calibration, but he says little about which (hypothetical) counter-factual circumstances are relevant. He merely says that "it's a difficult question in general" and that the hypothetical circumstances may depart from actual circumstances only by varying the accidental features of the agent's environment.<ref type="bibr" target="#b9">(Dunn, 2015</ref>(Dunn,  , p. 1941 Note that some scholars, notably Andrew Gelman and Deborah Nolan, think that one cannot bias a coin, but I am not convinced by their discussion since it might be possible to bias a coin with a magnetic strip (a mechanism they do not discuss, so far as I can tell).<ref type="bibr" target="#b11">(Gelman &amp; Nolan, 2002)</ref> In any case, the coin example is merely illustrative.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="8">These are occasionally called "calibration curves", but I prefer the term "graph" since the graph may depict a well calibrated straight line instead of what people ordinarily interpret as a "curve".<ref type="bibr" target="#b37">(Seidenfeld, 1985)</ref> 9 These graphs are from my analysis of the Good Judgment Project's data, currently accessible at the following website: https://dataverse.harvard.edu/dataset.xhtml?persistentId=doi:10.7910/DVN/BPCDH5.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="15">Technically, there is a sense in which you could have credences about these things if p is some long conjunctive statement about each of them. However, I do not think this is the kind of example which Pettigrew has in mind.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="16">Dunn utilizes the concept of "nearby counterfactual scenarios" in his account. It is not clear as to exactly what a "nearby counterfactual" scenario is, as he himself acknowledges. In any case, perhaps he would appeal to this notion to somehow avoid the applying the concept of reliability to Norman's psychic powers.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="17">Some would regard this example of so-called "abduction" as distinct from "induction", yet it is not necessary to distinguish these two concepts for the purposes of my discussion here.</note>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Office of the Director of National Intelligence</title>
		<ptr target="https://www.iarpa.gov/index.php/research-programs/ace" />
		<imprint>
			<date type="published" when="2018-03-28" />
		</imprint>
	</monogr>
	<note>Aggregative Contingent Estimation</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Clinical skills in junior medical officers: A comparison of self-reported confidence and observed competence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Barnsley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Lyon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Ralston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Hibbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Cunningham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">C</forename><surname>Gordon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Field</surname></persName>
		</author>
		<idno type="DOI">10.1046/j.1365-2923.2004.01773.x</idno>
		<ptr target="https://doi.org/10.1046/j.1365-2923.2004.01773.x" />
	</analytic>
	<monogr>
		<title level="j">Medical Education</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="358" to="367" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Overconfidence as a Cause of Diagnostic Error in Medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">S</forename><surname>Berner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Graber</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.amjmed.2008.01.001</idno>
		<idno>S2-S23</idno>
		<ptr target="https://doi.org/10.1016/j.amjmed.2008.01.001" />
	</analytic>
	<monogr>
		<title level="j">American Journal of Medicine</title>
		<imprint>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page">121</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Why the generality problem is everybody&apos;s problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Bishop</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11098-009-9445-z</idno>
		<ptr target="https://doi.org/10.1007/s11098-009-9445-z" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">151</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="285" to="298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Externalist Theories of Empirical Knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bonjour</surname></persName>
		</author>
		<idno type="DOI">10.1111/J.1475-4975.1980.TB00396.X</idno>
		<ptr target="https://doi.org/10.1111/J.1475-4975.1980.TB00396.X" />
	</analytic>
	<monogr>
		<title level="j">Midwest Studies in Philosophy</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="53" to="73" />
			<date type="published" when="1980" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<monogr>
		<title level="m" type="main">Improving metacognition in the classroom through instruction, training, and feedback. Metacognition and Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Callender</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Franco-Watkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Roberts</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11409-015-9142-6</idno>
		<ptr target="https://doi.org/10.1007/s11409-015-9142-6" />
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="215" to="235" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A well-founded solution to the generality problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Comesaña</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11098-005-3020-z</idno>
		<ptr target="https://doi.org/10.1007/s11098-005-3020-z" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">129</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="27" to="47" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The generality problem for reliabilism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Conee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Feldman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">89</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="29" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Being Rational and Being Wrong</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Dorst</surname></persName>
		</author>
		<ptr target="https://journals.publishing.umich.edu/phimp/article/id/597/" />
	</analytic>
	<monogr>
		<title level="j">Philosophers&apos; Imprint</title>
		<imprint>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page">23</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Reliability for degrees of belief</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dunn</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11098-014-0380-2</idno>
		<ptr target="https://doi.org/10.1007/s11098-014-0380-2" />
	</analytic>
	<monogr>
		<title level="j">Philosophical Studies</title>
		<imprint>
			<biblScope unit="volume">172</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1929" to="1952" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Why the unskilled are unaware: Further explorations of (absent) self-insight among the incompetent</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ehrlinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Johnson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Banner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunning</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruger</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.obhdp.2007.05.002</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2007.05.002" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">105</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="98" to="121" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">You can load a die</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gelman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Nolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The American Statistician</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="308" to="311" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
	<note>but you can&apos;t bias a coin</note>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Homo Heuristicus: Why Biased Minds Make Better Inferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Brighton</surname></persName>
		</author>
		<idno type="DOI">10.1111/j.1756-8765.2008.01006.x</idno>
		<ptr target="https://doi.org/10.1111/j.1756-8765.2008.01006.x" />
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="107" to="143" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Heuristics and biases: The psychology of intuitive judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Thomas</forename><surname>Gilovich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Griffin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2002" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">What is Justified Belief?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Goldman</surname></persName>
		</author>
		<idno type="DOI">10.1007/978-94-009-9493-5_1</idno>
		<ptr target="https://doi.org/10.1007/978-94-009-9493-5_1" />
	</analytic>
	<monogr>
		<title level="m">Justification and Knowledge</title>
		<meeting><address><addrLine>Netherlands</addrLine></address></meeting>
		<imprint>
			<publisher>Springer</publisher>
			<date type="published" when="1979" />
			<biblScope unit="page" from="1" to="23" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">What We Think, What We Know and What We Think We Know about False Convictions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gross</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ohio State Journal of Criminal Law</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="753" to="786" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Rate of false conviction of criminal defendants who are sentenced to death</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Gross</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>O'brien</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Kennedy</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1306417111</idno>
		<ptr target="https://doi.org/10.1073/pnas.1306417111" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">20</biblScope>
			<biblScope unit="page" from="7230" to="7235" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Interpretations of Probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Hajek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Can medical students accurately predict their learning? A study comparing perceived and actual performance in neuroanatomy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">R</forename><surname>Hall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Stephens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">G</forename><surname>Seaby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Andrade</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">F</forename><surname>Lowry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">J C</forename><surname>Parton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Border</surname></persName>
		</author>
		<idno type="DOI">10.1002/ase.1601</idno>
		<ptr target="https://doi.org/10.1002/ase.1601" />
	</analytic>
	<monogr>
		<title level="j">Anatomical Sciences Education</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="488" to="495" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Forecasting forecaster accuracy: Contributions of past performance and individual differences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Atanasov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgment and Decision Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="323" to="362" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Howson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Urbach</surname></persName>
		</author>
		<title level="m">Scientific Reasoning: The Bayesian Approach</title>
		<imprint>
			<date type="published" when="2006" />
		</imprint>
	</monogr>
	<note>3rd ed). Open Court</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Unskilled and unaware of it: How difficulties in recognizing one&apos;s own incompetence lead to inflated self-assessments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kruger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Dunning</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-3514.77.6.1121</idno>
		<ptr target="https://doi.org/10.1037/0022-3514.77.6.1121" />
	</analytic>
	<monogr>
		<title level="j">Journal of Personality and Social Psychology</title>
		<imprint>
			<biblScope unit="volume">77</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1121" to="1134" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Uncertain inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kyburg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Teng</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2001" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Counting Deaths Due to Medical Errors-Reply</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">L</forename><surname>Leape</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Berwick</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Bates</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.288.19.2405-JLT1120-2-3</idno>
		<ptr target="https://doi.org/10.1001/jama.288.19.2405-JLT1120-2-3" />
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">288</biblScope>
			<biblScope unit="issue">19</biblScope>
			<biblScope unit="page">2405</biblScope>
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Culture and Probability Judgment Accuracy: The Influence of Holistic Reasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Lechuga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Wiebe</surname></persName>
		</author>
		<idno type="DOI">10.1177/0022022111407914</idno>
		<ptr target="https://doi.org/10.1177/0022022111407914" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">42</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="1054" to="1065" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">An introduction to the theory of knowledge</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">M</forename><surname>Lemos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Cultural influences on confidence: Country and gender</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Lundeberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Fox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Brown</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Elbedour</surname></persName>
		</author>
		<idno type="DOI">10.1037/0022-0663.92.1.152</idno>
		<ptr target="https://doi.org/10.1037/0022-0663.92.1.152" />
	</analytic>
	<monogr>
		<title level="j">Journal of Educational Psychology</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="152" to="159" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Accuracy of forecasts in strategic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barnes</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1406138111</idno>
		<ptr target="https://doi.org/10.1073/pnas.1406138111" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the National Academy of Sciences of the United States of America</title>
		<meeting>the National Academy of Sciences of the United States of America</meeting>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="page" from="10984" to="10989" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Geopolitical forecasting skill in strategic intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Barnes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="127" to="137" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Tracking accuracy of strategic intelligence forecasts: Findings from a long-term Canadian study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Mandel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Irwin</surname></persName>
		</author>
		<idno type="DOI">10.1002/ffo2.98</idno>
		<ptr target="https://doi.org/10.1002/ffo2.98" />
	</analytic>
	<monogr>
		<title level="j">Futures and Foresight Science</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="3" to="4" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Physicians&apos; diagnostic accuracy, confidence, and resource requests: A vignette study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N D</forename><surname>Meyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">L</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Meeks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Rao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Singh</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamainternmed.2013.10081</idno>
		<ptr target="https://doi.org/10.1001/jamainternmed.2013.10081" />
	</analytic>
	<monogr>
		<title level="j">JAMA Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">173</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="1952" to="1961" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">The effects of advanced monitoring on hemodynamic management in critically ill patients: A pre and post questionnaire study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Perel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Saugel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Teboul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L N G</forename><surname>Malbrain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">J</forename><surname>Belda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fernández-Mondéjar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kirov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wendon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Lussmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Maggiorini</surname></persName>
		</author>
		<idno type="DOI">10.1007/s10877-015-9811-7</idno>
		<ptr target="https://doi.org/10.1007/s10877-015-9811-7" />
	</analytic>
	<monogr>
		<title level="j">Journal of Clinical Monitoring and Computing</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="511" to="518" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Accuracy, Risk, and the Principle of Indifference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pettigrew</surname></persName>
		</author>
		<idno type="DOI">10.1111/phpr.12097</idno>
		<ptr target="https://doi.org/10.1111/phpr.12097" />
	</analytic>
	<monogr>
		<title level="j">Philosophy and Phenomenological Research</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title level="m" type="main">What is justified credence? Episteme</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Pettigrew</surname></persName>
		</author>
		<idno type="DOI">10.1017/epi.2018.50</idno>
		<ptr target="https://doi.org/10.1017/epi.2018.50" />
		<imprint>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Should we confirm our clinical diagnostic certainty by autopsies?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Podbregar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Voga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Krivec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Skale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Parežnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Gabršček</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00134-001-1129-x</idno>
		<ptr target="https://doi.org/10.1007/s00134-001-1129-x" />
	</analytic>
	<monogr>
		<title level="j">Intensive Care Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1750" to="1755" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">Probable Probabilities (with Proofs)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Pollock</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<monogr>
		<title level="m" type="main">The theory of probability: An inquiry into the logical and mathematical foundations of the calculus of probability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reichenbach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1949" />
			<publisher>University of California Press</publisher>
		</imprint>
	</monogr>
	<note>2d ed.</note>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Calibration, Coherence, and Scoring Rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Seidenfeld</surname></persName>
		</author>
		<idno type="DOI">10.1086/289244</idno>
		<ptr target="https://doi.org/10.1086/289244" />
	</analytic>
	<monogr>
		<title level="j">Philosophy of Science</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="274" to="294" />
			<date type="published" when="1985" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Knowledge in Perspective: Selected Essays in Epistemology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Sosa</surname></persName>
		</author>
		<idno type="DOI">10.1093/ACPROF:OSO/9780198719694.001.0001</idno>
		<ptr target="https://doi.org/10.1093/ACPROF:OSO/9780198719694.001.0001" />
	</analytic>
	<monogr>
		<title level="m">Judgment and Agency</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
	<note>Judgment and Agency</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Epistemology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steup</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Neta</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">The Stanford Encyclopedia of Philosophy</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Bayesian Epistemology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Talbott</surname></persName>
		</author>
		<idno type="DOI">10.1093/mind/fzv199</idno>
		<ptr target="https://doi.org/10.1093/mind/fzv199" />
	</analytic>
	<monogr>
		<title level="m">Reliability Theories of Justified Credence. Mind</title>
		<editor>Tang, W. H.</editor>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page" from="63" to="94" />
		</imprint>
	</monogr>
	<note>The Stanford Encyclopedia of Philosophy</note>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Expert political judgment: How good is it? How can we know? Princeton University Press. The Forecasting Collaborative</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tetlock</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<date type="published" when="2005" />
		</imprint>
	</monogr>
	<note>Insights into accuracy of social scientists&apos; forecasts of societal change</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Probability judgment accuracy for general knowledge. Cross-national differences and assessment methods</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Whitcomb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Önkal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">P</forename><surname>Curley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Benson</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.3960080105</idno>
		<ptr target="https://doi.org/10.1002/bdm.3960080105" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="51" to="67" />
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<title level="m" type="main">From relative frequencies to Bayesian probabilities</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilcox</surname></persName>
		</author>
		<ptr target="https://researchspace.auckland.ac.nz/handle/2292/31095" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Human Judgment: How Accurate is it, and How Can it Get Better</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilcox</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
			<publisher>Springer</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wilcox</surname></persName>
		</author>
		<title level="m">Measures of Accuracy</title>
		<imprint/>
	</monogr>
	<note>Work in progress</note>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Diagnostic errors in the intensive care unit: A systematic review of autopsy studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Winters</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Custer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Galvagno</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Colantuoni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Kapoor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Goode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Robinson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nakhasi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Pronovost</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ Quality &amp; Safety</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="894" to="902" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Cultural Differences in Probabilistic Thinking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">N</forename><surname>Wright</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Whalley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Choo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K.-O</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Tan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Wisudha</surname></persName>
		</author>
		<idno type="DOI">10.1177/002202217893002</idno>
		<ptr target="https://doi.org/10.1177/002202217893002" />
	</analytic>
	<monogr>
		<title level="j">Journal of Cross-Cultural Psychology</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="285" to="299" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">General Knowledge Overconfidence: Cross-National Variations, Response Style, and &quot;Reality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">G G</forename><surname>Bush</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.1997.2696</idno>
		<ptr target="https://doi.org/10.1006/obhd.1997.2696" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">70</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="87" to="94" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Beliefs about overconfidence, including its cross-national variation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shinotsuka</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.1996.0012</idno>
		<ptr target="https://doi.org/10.1006/obhd.1996.0012" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="138" to="147" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shinotsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Patalano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Sieck</surname></persName>
		</author>
		<idno type="DOI">10.1006/obhd.1998.2771</idno>
		<ptr target="https://doi.org/10.1006/obhd.1998.2771" />
		<title level="m">Cross-Cultural Variations in Probability Judgment Accuracy: Beyond General Knowledge Overconfidence? Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="volume">74</biblScope>
			<biblScope unit="page" from="89" to="117" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Probability judgment across cultures</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J.-W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">R</forename><surname>Sieck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Choi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Price</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Heuristics and biases: The psychology of intuitive judgment</title>
		<editor>T. Gilovich, D. Griffin, &amp; D. Kahneman</editor>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="2002" />
			<biblScope unit="page" from="271" to="291" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Probability judgment accuracy: China, Japan, and the United States</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Yates</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Ronis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">F</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Shinotsuka</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Toda</surname></persName>
		</author>
		<idno type="DOI">10.1016/0749-5978(89)90048-4</idno>
		<ptr target="https://doi.org/10.1016/0749-5978(89)90048-4" />
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="volume">43</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="145" to="171" />
			<date type="published" when="1989" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
