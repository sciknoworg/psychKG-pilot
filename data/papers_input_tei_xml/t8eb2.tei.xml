<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">It Only Takes One: The Psychology of Unilateral Decisions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Lewis</surname></persName>
							<email>joshua.lewis@nyu.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Stern School of Business</orgName>
								<orgName type="institution">New York University</orgName>
								<address>
									<settlement>New York</settlement>
									<region>NY</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Carter</forename><surname>Allen</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Haas School of Business</orgName>
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley, Berkeley</settlement>
									<region>CA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Christoph</forename><surname>Winter</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Faculty of Law</orgName>
								<orgName type="institution">Instituto Tecnológico Autónomo de México</orgName>
								<address>
									<settlement>Mexico City</settlement>
									<country key="MX">Mexico</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Harvard University</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
							<affiliation key="aff4">
								<orgName type="department">Institute for Law &amp; AI</orgName>
								<address>
									<settlement>Cambridge</settlement>
									<region>MA</region>
									<country key="US">USA</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucius</forename><surname>Caviola</surname></persName>
							<affiliation key="aff5">
								<orgName type="department">Global Priorities Institute</orgName>
								<orgName type="institution">University of Oxford</orgName>
								<address>
									<settlement>Oxford</settlement>
									<country key="GB">UK</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">It Only Takes One: The Psychology of Unilateral Decisions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:57+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Sometimes, one decision can guarantee that a risky event will happen. For instance, it only took one team of researchers to synthesize and publish the horsepox genome 1 , thus imposing its publication even though other researchers might have refrained for biosecurity reasons 2,3. We examine cases where everybody who can impose a given event has the same goal but different information about whether the event furthers that goal. Across 8 experiments (including scenario studies with elected policymakers, doctors, artificial-intelligence researchers, and lawyers and judges and economic games with laypeople, N = 1,518, and 3 supplemental studies, N = 847) people behave suboptimally, balancing two factors. First, people often impose events with expected utility only slightly better than the alternative based on the information available to them, even when others might know more. This approach is insufficiently cautious, leading people to impose too frequently, a situation termed the unilateralist&apos;s curse 4. Second, counteracting the first factor, people avoid sole responsibility for unexpectedly bad outcomes, sometimes declining to impose seemingly desirable events. The former heuristic typically dominates and people unilaterally impose too often, succumbing to the unilateralist&apos;s curse. But when only few people can impose, who know the stakes are high, responsibility aversion reduces over-imposing. Main In unilateralist situations, multiple actors can independently guarantee that a risky event will happen, even if nobody else believes it is desirable 4. In other words, the risky event can be &quot;imposed&quot; by multiple people-the &quot;potential imposers&quot;. For example, virologists have historically avoided synthesizing live viruses, as doing so could pose a safety risk by providing a proof-of-concept for engineered pandemics 2,3. But in 2016, a research team controversially synthesized a live copy of horsepox and, in 2018, they published the finding in an open-access journal 1. This event made it public knowledge that active virus synthesis was possible. Most people with the capability to undertake and publish such a finding did not. Yet it only took one team to impose publication, despite others&apos; opposition. Many high-stakes decisions share this structure. In February 2023, it only took one Meta LLaMa user to leak the AI model&apos;s weights for those weights to become publicly accessible 5. It only took one leader, France&apos;s Charles de Gaulle, to veto the United Kingdom&apos;s original application to join the European Union 6. In the 1990s, it took just one airline, American Airlines, to precipitate an extreme price war that drastically reduced profits across the industry 7. Ideally, potential imposers should pool their information, deliberate, and defer to the majority 4,8. For example, in 1936, Leo Szilard, Edward Teller, and Enrico Fermi discussed whether a finding about nuclear chain reactions should be published. Szilard later wrote, &quot;Teller and I thought that it should not. Fermi thought that it should. But after a long discussion, Fermi took the position that after all this is a democracy; if the majority was against publication he would abide by the wish of the majority&quot; 9. Without this discussion, Fermi may have published unilaterally.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>However, communication in unilateralist scenarios is not always possible. In business, collusion is often illegal <ref type="bibr" target="#b9">10</ref> . In science, when a researcher makes a discovery that could be seriously misused, she does not know who else has made the same discovery or will do so in the future. She may need to decide unilaterally.</p><p>In these unilateralist situations, it is natural to worry about perverse incentives, greed, and malevolence. Undoubtedly, these factors pose dangers. However, unilateralist situations are challenging to navigate even for benevolent agents who all share the same goal <ref type="bibr" target="#b3">4</ref> . The challenge for benevolent agents is our focus. Specifically, we examine situations in which all potential imposers share a common goal, have different views about which event better achieves that goal, and cannot communicate. For example, a patient may seek the same treatment from multiple doctors. The doctors might care equally about the patient's welfare but have different beliefs about the merits of the treatment. While they might each anticipate that the patient may see other doctors, they are unlikely to find each other to discuss the case. Likewise, multiple scientists might discover the same finding, all care equally about societal welfare, have different views on whether publishing the finding would do more harm or good, and be unlikely to find each other to discuss the merits of publishing. What is the optimal way to approach these situations?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Naive Approach: Deciding as Usual</head><p>In typical decisions, people often choose whatever option seems best to them <ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12</ref> . Even if they prefer one option only slightly, why choose the alternative that they prefer less? It is typically adaptive to choose the best-seeming option in both personal choices <ref type="bibr" target="#b10">11,</ref><ref type="bibr" target="#b11">12</ref> and in group decisions via majoritarian votes <ref type="bibr" target="#b3">4,</ref><ref type="bibr" target="#b7">8</ref> .</p><p>How would one apply this approach to unilateral situations? One could treat the situation as a choice between the imposable event and the alternative (e.g., the choice between a finding being published and kept private). If you think the imposable event is even slightly better than the alternative, impose it, otherwise, do not. We call this approach decision as usual. However, unilateral situations are not "usual" decisions. One cannot simply choose for a scientific reality to remain unpublished forever. One cannot simply choose for an imposable event to never occur.</p><p>Even if one does not impose it, somebody else might. This difference matters. For illustration, imagine a stylized scenario in which you are one of 100 independent researchers who have all discovered the same potentially dangerous research finding. Any one of you can publish the finding, guaranteeing its publication and imposing this event on the world. All of you share the same goal of maximizing societal welfare, but you all have different evidence about whether publication helps achieve it. Unfortunately, you do not know each other's identities and cannot communicate. Instead, you must each decide on your own whether to unilaterally publish the finding and thereby impose the event of its publication.</p><p>In this situation, decision as usual is suboptimal and leads to too much imposing <ref type="bibr" target="#b3">4</ref> (see Supplementary Materials section 3.4 for a more general derivation of the kinds of actions that decision as usual will bias people towards, beyond pure unilateralist situations). To intuit why, suppose that all 100 researchers decide "as usual", i.e., they publish the finding as long as it seems even slightly better to them that the information is public. In this case, the finding will then be published if even just one of them believes that publication would be even slightly positive. Suppose that in reality, the risks of publishing outweigh the benefits. At least one of the 100 researchers will probably have misleading evidence to the contrary (as portrayed in <ref type="figure">Figure   1</ref>). If they decide as usual, they will publish the finding, even though doing so would undermine their own goal of maximizing societal welfare. It is as if the decision was left entirely to the most optimistic of the 100 decisionmakers, with no attempt to compensate for this selection bias. In sum, publication will probably occur-whether or not it is desirable. This is the unilateralist's curse. <ref type="figure">Figure 1</ref>: a visual depiction of the unilateralist's curse. In this example, each of ten researchers can independently publish a finding with potential for misuse. Each researcher has an independent estimate of the information's societal value. If each researcher decides whether to publish the finding based solely on her private evaluation of the information's societal value (decision as usual), it will only take one agent to think the information is beneficial for it to be published, leading to a collective bias towards publishing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The Optimal Approach: Conditional Reasoning and Increased Caution</head><p>If decision as usual leads people to impose too often, can people do better?</p><p>Commonsensically, potential imposers should try to compensate for the bias towards over-imposing. The more people there are who can impose a given event, the greater the bias from decision as usual, and the more extra caution is required. It seems plausible that people might intuit these facts. Indeed, such intuitions would approximate a rational decision procedure based on conditional reasoning. In auctions, conditional reasoning is a solution to the "winner's curse", the phenomenon in which the winning bidders systematically overpays <ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref><ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref> . In unilateralist situations, it is a solution to the unilateralist's curse. In this context, conditional reasoning entails that decisionmakers decide as they hypothetically would if they knew their decision would make a difference <ref type="bibr" target="#b3">4</ref> .</p><p>Let us illustrate this approach with the 100-researchers example. First, consider that, when deciding whether to unilaterally publish the research, you are unaware of whether your decision will make a difference. On the one hand, you could be in a non-influenceable world, one in which your publishing decision will not make a difference because at least one other researcher will publish anyway. On the other hand, you could instead be in an influenceable world, one in which your decision will make a difference because none of the other researchers will publish. For simplicity, assume that, beyond determining whether the finding is published at all, any other costs and benefits of publishing are evenly balanced (see Supplementary Information section 3.4 for the implications of relaxing this assumption). Then, to decide rationally, you need only consider the influenceable world where your decision makes a difference (see Supplementary Information section 3.1.1 for a more formal argument).</p><p>This conditional reasoning should make you more cautious about publishing. Why?</p><p>Recall that, in the influenceable world, all 99 other researchers, who all care about societal welfare, have decided not to publish. These other researchers might have evidence that is unavailable to you. Their decision to refrain would suggest that publishing is more dangerous than you thought. Suppose that your available evidence suggested the world would be only slightly better off with publication. If you knew that all 99 other researchers would not publish, and your evidence were only slightly in favor of publication making the world better off, you would probably conclude that your available evidence was misleading; the 99 who would not publish may know something you don't. Although stronger evidence might still justify you publishing, the weak evidence you have would be insufficient to outweigh the knowledge that nobody else would publish. Overall, compared to decision as usual, the conditional reasoning approach demands stronger evidence to impose an event. It thus entails more caution and mitigates the group-level bias towards imposing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The present research</head><p>How do people behave in practice? Although it seems unlikely that people would do formal conditional reasoning <ref type="bibr" target="#b16">17</ref> , people might have intuitions that approximate it <ref type="bibr">11 , motivating</ref> well-calibrated caution about imposing. Alternatively, people's decision-making heuristics might be better adapted to more typical decisions than the special case of unilateralist situations. If so, people might naively behave as if unilateralist situations are usual decisions, and thus they may impose any event that appears even slightly better than the alternative.</p><p>We explore these possibilities across 8 experiments (N = 2,365). By using a variety of samples from populations with real decision-making power, we hope to ensure our results will be more robust and applicable to real-world unilateralist scenarios. In Experiments 1-4, we emphasize external validity by describing scenarios that are relevant to the experiment's respective sample population: elected policymakers, doctors, lawyers and judges, and artificial intelligence (AI) researchers. In Experiment 5, we emphasize internal validity using a controlled, incentive-compatible economic game. Experiments S1, S2, and S3 in the Supplementary Information (sections 1.3, 1.4, and 1.5) are variations of the incentive-compatible game in <ref type="bibr">Experiment 5.</ref> In all our experiments and with all our samples, we find that most people do not use conditional reasoning nor any heuristic that accurately approximates it. Instead, people often treat unilateralist scenarios as if they were a simple choice between the imposable event and the alternative. When people do exercise caution about imposing, this caution is poorly calibrated. It seems to result from a desire to avoid sole responsibility for the outcome, rather than from conditional reasoning. People thus ignore factors which would change the optimal decision (e.g., the number of other people who can impose the relevant event, Experiments 2-5 and S2).</p><p>Conversely, people respond to some irrelevant factors which do not change the optimal decision, such as the stakes of the event (Experiment 5 and S2). Overall, people seem too willing to impose in unilateralist situations (Experiment 5, and S1-S3).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiments Policymakers do not use conditional reasoning with vetos</head><p>In Experiment 1, we tested whether policymakers use the appropriate conditional reasoning strategy when using veto powers. We recruited a sample of elected US local government policymakers (N = 478). We described a scenario in which local policymakers could each veto a new tax plan, thus unilaterally imposing the continuation of the current tax plan. To test whether participants decide as if they use conditional reasoning, we manipulated between subjects whether participants knew that nobody else would use their veto (meaning their own decision would be pivotal, n = 225) or were ignorant about how others would vote (n = 253). If participants applied conditional reasoning, they would behave the same way in both cases, as their decision only makes a difference if it turns out no others veto the plan (for a more formal argument, see Supplementary Information section 3.1.1). However, more participants said they would veto when they did not know the other policymakers' voting intentions (72.7%) than when they knew nobody else would veto it (51.6%, χ² = 21.94, p &lt; .001, 95% confidence interval of mean difference [13.1%, 32.0%]). This result is consistent with a naive decision-as-usual approach, with participants simply vetoing if they perceive the new tax plan to be at all worse than the existing tax plan.</p><p>There are potential alternative explanations for this difference. Perhaps participants wanted to vote with the majority, and presumed the majority of the board would veto. Such an explanation might be surprising because we told all participants that the vote was anonymous and the scenario gave no hint as to how other board members might vote. Moreover, in Experiment S1, we conceptually replicate this result in an anonymous, controlled economic game. Still, to ensure the robustness of this apparent lack of conditional reasoning, we explored it using additional paradigms over Experiments 2-5.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Doctors, legal experts, and AI researchers are insensitive to the number of potential imposers</head><p>When there are more potential imposers, one might expect there to be a stronger group bias in favor of imposing. Indeed, to achieve socially optimal behavior, each potential imposer should then require stronger evidence to impose <ref type="bibr" target="#b3">4</ref> . This is because the decision will only matter when this greater number of other decisionmakers have all refrained, which would be stronger evidence that the imposable event was undesirable than if there were fewer other decisionmakers. If people appropriately apply conditional reasoning, their decisions would reflect this consideration; they would be more cautious about imposing when there were more potential imposers (see Supplementary Information section 3.1.2 for a more formal argument).</p><p>However, if people decide as usual and impose any imposable event that they judge even slightly better than the alternative, then the number of other potential imposers will be irrelevant to their decisions. To distinguish between these possibilities, Experiments 2, 3, and 4 tested whether more potential imposers lead to greater caution about imposing among medical doctors, legal experts, and AI researchers.</p><p>We first explored a medical context. A unilateralist's curse may arise if a patient seeks the same treatment from multiple doctors who could each prescribe it unilaterally. In Experiment 2, we surveyed 200 U.S. doctors (collected from YouGov) to test whether they prescribe drugs more cautiously when a patient is seeing many other physicians. We asked all participants how certain they would need to be to prescribe a treatment both if they were in the only doctor and also if there were 10 other doctors who could also prescribe it. Only 17% (95% CI [12.1%, 22.9%]) gave a higher confidence threshold with 10 other doctors (less than 50% with binomial test, p &lt; .001). Based on a paired t-test, the average confidence threshold (measured from 50% to 100%) did not significantly differ across conditions (M solo = 84.5%, SD solo = 10.6%, M others = 84.5%,</p><formula xml:id="formula_0">SD others = 10.8%, t(199) = 0.17, p = .866, mean difference 95% CI [-0.7%, 0.8%], d = 0.01).</formula><p>These results suggest that doctors do not approach these situations using conditional reasoning or any other strategy that would yield optimal behavior.</p><p>We next explored a legal context. A unilateralist situation may arise if a business seeks legal approval in multiple jurisdictions for an activity with global implications. For the global implications to be realized, it only takes one local jurisdiction to legalize the activity. Thus, Experiment 3 (N = 300) asked a sample of legal experts (containing 265 lawyers and 35 judges) how certain they would need to be to rule that an activity was legal when that activity's legality was also being decided upon elsewhere. Specifically, we manipulated whether it was being decided upon in 99 other courts versus only one other court. The activity in question involved bioengineering groups publishing the DNA of a potentially lethal virus. The argument in favor of legality was that it could accelerate vaccine development. But, because the DNA would become public knowledge globally if it was published in any jurisdiction, it only takes one court to rule in favor. Replicating the finding in Experiment 2, very few participants (6.7%, 95% CI [4.1%, <ref type="bibr" target="#b9">10</ref>.1%]) provided a higher threshold for the 99-other-cases condition than the one-other-case condition (less than 50% with binomial test, p &lt; .001), and the average confidence threshold in the many-cases condition was close to the average threshold in the few-cases condition (M few = 85.1%, SD few = 14.3%, M many = 85.0%, SD many = 14.4%, t(299) = 0.11, p = .916, mean difference 95% CI [-0.9%, 1.0%], d = 0.00).</p><p>We then explored an artificial intelligence (AI) research context. AI is a field where certain information might be dangerous to release, e.g., the weights of large language model like LLaMa 2, which were leaked on 4chan in 2023 <ref type="bibr" target="#b4">5</ref> . Such information will be public if just one researcher leaks it, an archetypical unilateralist situation. Experiment 4 (N = 200) asked a sample of AI researchers how certain they would need to be that it was better that some information was public for them to release the information themselves. We told the researchers that the information would have benefits in terms of advancing capabilities but drawbacks in terms of precipitating long-term AI-related risks. We manipulated whether the information could be published by 2 or 29 other researchers. Again, very few participants (12.5%, 95% CI [8.3%, <ref type="bibr" target="#b16">17</ref>.9%]) provided a higher threshold for the 29-other-cases condition than the 2-other-case condition (less than 50% with binomial test, p &lt; .001, 95% CI), and the average confidence threshold in the many-cases condition was close to the average threshold in the few-cases condition (M few = 79.6%, SD few = 16.4%, M many = 79.0%, SD many = 16.4%, t(199) = 1.25, p = .211, mean difference 95% CI [-0.3%, 1.5%], d = 0.04).</p><p>In all these scenarios, there are possible alternative explanations for why participants were just as willing to impose when there were many imposers. Perhaps, when there were more doctors treating the patient, participants concluded that the patient might require treatment more.</p><p>Perhaps, when there were more courts considering the case, participants concluded that the case must be more reasonable. Perhaps, when there were more AI researchers with access to the information, participants concluded that it was less dangerous to publish. In all these cases, the confounding factors should in principle have affected participants actual confidence (which participants were not instructed to provide) rather than the threshold for the minimum confidence that they would require to impose (which participants were instructed to provide for our dependent variable), but we cannot rule out that participants' actual confidence affected their judgments nonetheless. Thus, to ensure a greater degree of experimental control in Experiment 5, we used an abstract, incentive compatible economic game. We also explored what other psychological factors might contribute to participants' decisions.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Do social factors mitigate the unilateralist's curse?</head><p>The results so far appear inconsistent with conditional reasoning, but they cannot be explained by decision as usual alone. For example, in Experiments 2, 3, and 4, across scenarios, participants needed on average between 79.0% and 85.1% confidence to impose. If participants used a pure decision-as-usual approach, then we would have expected them to require just 51% confidence. So, while not behaving optimally, participants were still more cautious than decision as usual would suggest. It seems that other factors influence judgments besides decision as usual and conditional reasoning. What are they?</p><p>We hypothesized a role for responsibility aversion. In particular, people might anticipate the most intense satisfaction, regret, praise or blame when they are solely responsible for whatever occurs <ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19</ref> . Importantly, people only risk incurring sole responsibility when they impose. If they refrain, their lack of action only matters if everybody else refrains too, in which case responsibility is shared. In contrast, if somebody is the only one to impose an event, they are solely responsible for the outcome. In general, people care about negatives more than positives <ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b20">21</ref> , regret more than satisfaction <ref type="bibr" target="#b21">22</ref> , and losses more than gains <ref type="bibr" target="#b22">23</ref> . People might thus be responsibility averse. If so, people would be more reluctant to impose than decision as usual would entail.</p><p>If responsibility aversion deters imposing, however, it does so suboptimally. For example, in terms of optimal behavior, potential imposers should be more cautious when there are more of them. However, more potential imposers make it less likely that any of them will end up with sole responsibility from being the only one to impose. Accordingly, they become less concerned about responsibility <ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> and care less about potential blame or regret. They are thus less cautious with more potential imposers, in direct opposition of optimal behavior. This aspect of responsibility aversion could explain why, in Experiments 2 and 3, participants' level of caution was so insensitive to the number of potential imposers, despite the rational case for more caution when the number is greater.</p><p>Importantly, responsibility aversion also suggests another potential lever for mitigating the bias towards imposing: increasing the perceived stakes of the decision. Next, we test these implications of responsibility aversion.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>The unilateralist economic game</head><p>In Experiment 5, Prolific participants (N = 340) played an incentive-compatible economic game. We designed the game to allow participants to impose events such that we could identify optimal and suboptimal behavior. We first described this game to participants. In the game, each participant would be grouped with other participants. As a group, they would receive the contents of either Box A or Box B. Importantly, one box (counterbalanced) was imposable. If anyone in the group opened that imposable box, the group would receive its contents and forgo the contents of the non-imposable box. The group would receive the contents of the non-imposable box only if nobody opened the imposable box. (Note, this setup made the non-imposable option seem like the default or status quo, as in many unilateralist situations.</p><p>However, Experiment S2 replicated all the Experiment 5 results when neither box was default, ruling out default effects as alternative explanations.)</p><p>One of the boxes contained bonus money, while the other was empty. Each player was given an independent, private signal about which box contained the bonus. They all knew that all their signals were independent from each other and that it was possible for their own signal to be wrong and others' signals to be correct. The strength of each participant's signal was randomly drawn from integer percentages between 51% and 100%. For instance, a participant might learn that the imposable box contained the bonus with 52% strength, in which case that signal would have a 52% chance of being correct. (For robustness, in the supplemental Experiment S1, we use a similar incentive-compatible economic game in which everybody had a signal of the same strength, and find that people impose substantially more than is optimal.) All participants included in our analyses passed 9 comprehension questions, ensuring they understood each of these instructions (see Methods).</p><p>For a well-powered test of our hypotheses, we wanted a fine-grained measure of participants' caution about imposing. Therefore, participants did not decide directly whether to open the imposable box (although supplemental experiments S1 and S3 involve similar incentive-compatible economic games in which participants did decide whether to impose directly, and that direct decision-format leads to substantially more over-imposing). Instead, participants decided how strong their signal would have to be (in favor of imposing) for them to do so. In other words, before seeing the strength and direction of their signal, participants pre-committed to a confidence threshold. If their signal strength turned out to be at least as high as that threshold and was in favor of the imposable box, they would automatically open it.</p><p>Otherwise, they would not.</p><p>We wanted to test how participants responded to unilateralist scenarios with different monetary amounts at stake and different numbers of potential imposers. To this end, we had participants each play this game four times (with one time being randomly selected to count for real and determine participants' bonus payments). Across each participant's four games, we orthogonally manipulated both factors in a 2 (other potential imposers: 2 vs. 20) by 2 (amount in winning box: $0.01 vs. $1.00) within-subjects design. (We could use a larger stakes manipulation in Experiment S2, since its reward was hypothetical.)</p><p>We start by testing our hypotheses about the number of potential imposers. Note, for all these analyses, we used regression with clustered standard errors, as participants provided multiple observations. To achieve optimal outcomes, participants should be more cautious about imposing when there are 20 others (Nash equilibrium = 94% confidence threshold) than 2 others (Nash equilibrium = 75% confidence threshold; see Supplementary Information section 3.2) <ref type="bibr" target="#b25">26</ref> . Surprisingly, given the vast difference between the optimal thresholds in these scenarios, the effect of group size was not significant (75.8% average certainty threshold with 2 others vs.</p><p>76.3% with 20 others, SD 2 = 13.3, SD 20 = 13.9, b = 0.49, clustered SE = 0.44, t(339) = 1.10, p = .271, mean difference 95% CI [-0.4%, 1.3%], d = 0.04, see <ref type="figure">Figure 2</ref>). In exploratory one-sample t-tests, we compared the average thresholds to the optimal thresholds. With 2 others, participants' thresholds were not significantly different from the optimal threshold (t(339) = 1.31, p = .190, mean difference 95% CI [-0.4%, 1.9%], d = 0.07), but with 20 others, participants' thresholds were insufficiently cautious by a large margin (t(339) = -29.25, p &lt; .001, mean difference 95% CI [-18.9%, -16.6%], d = 1.59). Participants' lack of caution is striking because this design artificially increases caution, for two reasons. First, status quo bias (with respect the default, non-imposable box) would increase caution <ref type="bibr" target="#b22">23,</ref><ref type="bibr" target="#b26">27</ref> . In Experiment S2, in which there was no default, participants were insufficiently cautious even with only two other potential imposers. Second, the threshold dependent variable may increase caution, as it emphasizes that a strong signal is valuable <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> . In Experiment S3, when given a simple binary choice after having observed the signal, participants were much more willing to impose than is optimal even with two other potential imposers and with not-imposing being the default option.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2:</head><p>The average confidence threshold in each group size and bonus amount condition. Panel 1 shows pooled participant responses in each group size condition; compared to the optimal Nash Equilibrium, participants are too cautious when there are 2 others, and not cautious enough when there are 20 others. Panel 2 shows pooled participant responses in each bonus amount condition; although the bonus amount does not affect the optimal level of caution, participants are more cautious when the stakes are greater. Panel 3 shows responses for each combination of group size condition and bonus amount condition. We observed a small but significant interaction effect (p = .015) such that the effect of the group-size manipulation was larger when the stakes were higher. Boxplots are group means +/-one standard error (clustered in Panels 1 and 2).</p><p>We hypothesized that responsibility aversion deterred imposing more effectively when there were 2 other imposers vs. 20, potentially explaining why people's level of caution is relatively insensitive to the number of imposers. To test this hypothesis, we measured participants' responsibility concern (averaging two items described in the Methods). In line with our hypothesis about responsibility aversion, we found that participants were less concerned about responsibility when there were more imposers (M 2 = 3.66, SD 2 = 1. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Mediation analysis relies on a correlational association between participants'</head><p>responsibility concern and confidence thresholds. To test a causal relationship, we exploited our stakes manipulation. We would expect responsibility concern to be greater with $1.00 than $0.01 prizes, as when stakes are higher, people tend to be more risk averse <ref type="bibr" target="#b23">24,</ref><ref type="bibr" target="#b24">25</ref> . Indeed, as with the number of imposers, this stakes manipulation affects responsibility concern, with greater concern at $1.00 (M = 3.59, SD = 1.52) than at $0. Importantly, the stakes have no impact on the optimal way for a group to play the game (i.e., the Nash equilibrium maximizes the probability of winning independent of the stakes; see </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>In unilateralist situations, it takes just one individual to impose an event for that event to occur, even if all other potential imposers refrain. These situations require a sophisticated form of reasoning, and throughout our experiments, participants approach them suboptimally.</p><p>Particularly when there are many potential imposers, they impose events too frequently, even for their own good. This is the unilateralist's curse.</p><p>Our findings reveal a key psychological factor that mitigates the tendency to impose: responsibility aversion. Based on this insight, we suggest several interventions. The implications are far reaching for society and particularly important for science.</p><p>Publishing scientific knowledge is one domain where well-meaning people can unilaterally impose potentially dangerous knowledge on the world, like the team that published the horsepox genome. Although peer review may sometimes limit any danger, it only takes one editor to decide to publish. There are real dilemmas here, as scientific freedom has immense benefits. But at a minimum, we as scientists must understand the stakes.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head><p>We preregistered all experiments on aspredicted.org and we post data, code, survey files, and preregistrations on https://researchbox.org/2234&amp;PEER_REVIEW_passcode=BQOKXJ. The full materials for each experiment are in the Supplementary Information, section 2. We only report preregistered analyses in the results section, which includes all preregistered analyses except for several tests examining participants' beliefs about the efficacy of different voting procedures in Experiment 1 (we report these analyses in section 1.1 of the Supplementary Information). We report two-sided p-values. We report all conditions, measures, and data exclusions. We did not deviate from preregistered manual exclusion rules for any experiments..</p><p>Research protocols were approved by the Institutional Review Board at New York University.</p><p>Participants consented to participate in all experiments. We did not use deception.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Sample size determination and randomization</head><p>We preregistered our sample sizes and exclusion rules before data collection (we manually excluded participants for repeat responses in Experiments 3, 5, and S1-S3, and for failing an attention check or failing to complete the whole survey in Experiments 5 and S1-S3).</p><p>We determined sample sizes for Experiments 1 and 2 based on what YouGov and CivicPulse could guarantee and for Experiments 3, 4, and S1-S3 using informal rules-of-thumb. To implement randomization and counterbalancing, we used Qualtrics survey software except in Experiment 2 where we used YouGov's survey software.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>Experiment 1 examined whether policymakers use conditional reasoning when deciding whether to veto a policy. We surveyed 478 elected U.S. local government policymakers (318 men, 155 women, see Supplementary Information section 1.1 for a breakdown of birth year, political party, and ethnic minority status) from a voluntary panel organized by CivicPulse, a non-profit researching local government. We preregistered to use all responses. There were no comprehension questions. This experiment was a 2-minute part of a 10-minute survey incorporating other experiments for unrelated projects.</p><p>First, participants read the following vignette:</p><p>Imagine that a new tax plan for the next fiscal year has been proposed for your governing board to vote on. Furthermore, assume that according to your governing board's rules, the new plan will only be adopted if all board members vote unanimously in favor of it.</p><p>You are not sure whether the tax plan would be better or worse than the current one for your jurisdiction. If you were forced to guess, you might as well flip a coin.</p><p>In a between-subjects manipulation, half of the participants then read "the vote is anonymous, but you find out via a colleague that everybody else plans to vote in favor of the new tax plan," while the other half simply read "the vote is anonymous." Note, although we specified anonymity, we did not specify whether information or evidence could be shared between members of the governing board. Although the bias from decision as usual is larger when more information is private vs. shared, as long as all information is not perfectly common knowledge, we would still expect governing board members to update their views based on others' decisions, at least to some extent. Therefore, we would still predict some difference between conditions if participants decided based on decision as usual.</p><p>All participants were then asked the following question:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>On your secret ballot, would you vote in favor of or against the new plan? -Vote in favor of the new plan -Vote against the new plan, effectively vetoing it</head><p>On the next page, we assessed participants' preferences for different voting procedures using the following matrix question (order of items randomized):</p><p>Thinking more broadly about how policy decisions get made, please rate each of the following decision-making processes below in terms of how likely or unlikely you think they would be to achieve the best policies in general. 1 (extremely unlikely) -5 Within subjects, participants responded to two scenarios, one in which they were the only doctor who could prescribe a treatment (solo condition), the other in which they were one of 10 doctors who could prescribe it (multiple condition, order randomized). Here is each scenario when it was displayed first (wording specific to solo condition in curved parentheses)/[wording specific to multiple condition in square brackets]: On the following page, participants saw the opposite condition, with the word "instead" inserted after "imagine". Above the slider for the second condition, a statement read, for reference, in the case in which you were (the only doctor) [one of ten doctors] with the particular speciality, you said you would need to be X% confident, where X% was their judgment for the first condition displayed, and the slider value was positioned at X% by default.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>In Experiment 3, we recruited a sample of 300 legal experts (183 men, 81 women, 36 other/unanswered, M age = 59.56, SD age = 11.78) containing 265 lawyers and 35 judges on a voluntary basis by finding email-addresses online and emailing them over the course of 3 months, from August to October 2023. We originally preregistered that, until November 2023, we would recruit exclusively judges, and after that date we would recruit the remaining sample via a combination of judges, lawyers, law academics, and law students. However, our initial response rate from judges was very low (less than 20 valid responses in the first month) so we began recruiting lawyers on September 24th, 2023.</p><p>In a within-subjects design, we asked participants to imagine that they were a judge deciding on one of either 2 or 100 court cases concerning the same issue. Here is what participants read on the first page (in the 2-cases condition)/[in the 100-cases condition]:</p><p>Imagine that there are <ref type="bibr" target="#b1">(2)</ref> Assume that the law mandates you to decide by weighing the risks and benefits from it being legal in your jurisdiction.</p><p>Note, the last line in the scenario is important because, to correctly weigh the risks and benefits from it being legal in one's jurisdiction, one has to consider the possibility that it will be legal in other jurisdictions anyway. To do so correctly requires conditional reasoning. If we had instead written "decide by weighing the risks and benefits from it being legal anywhere," this language would be essentially requiring them to decide as usual.</p><p>After answering a comprehension check ensuring participants understood the independent, private, and unilateral nature of their decision, they were asked the following question:</p><p>To make your decision, you will need to rely on your personal certainty estimate about whether the benefits of releasing the DNA information outweigh the risks.</p><p>Imagine you finally had to make your decision one way or the other. How certain do you think you would need to feel that the benefits outweighed the risks to rule in favor of making it legal? Slider: 50 (completely uncertain) -100 (completely certain) On the following page, participants read "Now consider this scenario:" followed by the opposite condition, this time without the comprehension check.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 4</head><p>In Experiment 4, we recruited a sample of 200 artificial intelligence researchers (22 female, 170 male, M age = 32.93, SD age = 8.44). We obtained a list of email addresses for AI researchers from the authors of Sandkühler et al. (2023) <ref type="bibr" target="#b29">30</ref> . This list was originally compiled by web scraping and manually identifying email addresses of authors who published in 2022 at a selection of top-tier machine learning conferences (NeurIPS, ICML, ICLR, AAAI, JMLR, and IJCAI). We contacted these participants in early May 2024.</p><p>Within subjects, participants responded to two scenarios. In one scenario, they were one of three AI researchers with the option to unilaterally publicize a finding, and in the other, they were one of 30 AI researchers who could do so. To ensure participants were sufficiently uncertain about the pros and cons of the information being public, we emphasized two potential risks that we intended to seem speculative and hard to quantify. Specifically, we randomized between-subjects whether participants read that the information could increase the risk of "dangerous, power-seeking" AI systems existing at some point or whether they read that it could increase the risk of "suffering, sentient" systems existing. Here is what participants read on the first page (in the 3-cases condition)/[in the 30-cases condition], assuming they were assigned to the "dangerous, power-seeking" condition:</p><p>Imagine you were one of (3) <ref type="bibr" target="#b29">[30]</ref>  For you to release the information, how certain (in terms of a probability between 50% and 100%) would you need to be that it would be better for the information to be public? Slider: 50 (completely uncertain) -100 (completely certain)</p><p>On the following page, participants saw the opposite condition, beginning with "Now imagine instead" rather than "Imagine".</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 5</head><p>Experiment 5 investigated how participants' caution about imposing depends on the number of potential imposers and the stakes of their decision. We collected a sample of 340 valid participants (183 female, 151 male, M age = 41.39, SD age = 13.67) online via Prolific.</p><p>Across the first seven pages, participants were instructed (1) that they would make decisions in a game with other participants; (2) that the goal of the game was to cooperate with other players to earn a real money bonus for everyone in the group; (3) that there were two boxes, Box A and Box B, one of which contained the bonus (each with a 50% chance); (4) that the group would receive the contents of one of the boxes by default (the non-imposable box, counterbalanced to be Box A or B), but that any player could independently decide to open the other (imposable) box instead, in which case the whole group would receive only that imposable box's contents; <ref type="bibr" target="#b4">(5)</ref> and that each player would receive an independent signal about which box contained the bonus that could range from 51%-100% likely to tell the truth (see Supplementary Information section 2.5 for the exact text of instructions and comprehension questions).</p><p>Participants were also instructed that <ref type="bibr" target="#b5">(6)</ref>  After reading the instructions of the game and answering a total of nine comprehension questions about them, participants set their threshold for each of the four rounds of the game.</p><p>These four rounds were manipulated in a 2 (other decisionmakers: 2 vs. 20) by 2 (bonus amount: $0.01 vs. $1.00) within-subjects manipulation. The following text is an example of what participants could have seen on the page following the game instructions, assuming Box B was the imposable box, and they were assigned to play with 2 other decisionmakers and a $1.00 bonus in the first round:</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Round 1</head><p>You are now playing the game for real. We will assign you to a real group and may determine your bonus payment according to the decisions that you and the other group members make on this page. So please make this decision carefully.</p><p>In this round, you will be grouped with 2 other participants.</p><p>In this round, the winning box contains $1.00 for each player.</p><p>The survey software has now conducted the virtual coin-flip to determine which virtual box contains the $1.00 bonuses.</p><p>You will be given a signal ranging from 51% to 100% likely to tell the truth. Each player will now decide their threshold for how certain their signal would need to be in favor of <ref type="bibr">Box</ref>  Before they could advance, participants were then required to correctly type both the number of other participants they would be grouped with for the round and the bonus amount for the round. After they did so, the survey displayed the following question:</p><p>On the slider below, please indicate how certain your signal would need to be (in favor of Box B) for you to open Box B. Slider: 51 (not at all certain) -100 (completely certain)</p><p>On the page after they set their threshold in each round, participants were shown their signal (and its strength) for that round so they knew whether or not the signal would lead to them opening the imposable box.</p><p>We were also interested in directly assessing the influence of participants' degree of responsibility concern on their thresholds. We collected a measurement of responsibility concern after obtaining all participants' thresholds for the four rounds. Specifically, across the following four pages, a summary of each round was displayed, including a reminder of the participant's chosen threshold and the following two questions:</p><p>How worried were you about being the only person to choose Box B when it was empty (meaning the whole group would get no bonus)? 1 (not concerned at all) -7 (extremely concerned)</p><p>How reassured were you that, if you wrongly chose Box B, you probably wouldn't have been the only one (meaning your decision wouldn't make a difference to the outcome)? 7 (not reassured at all) -1 (extremely reassured)</p><p>On the final page, we asked participants an additional question to confirm that they viewed higher thresholds as more cautious (indeed, 73.2% did; t(339) = 14.39; p &lt; .001):</p><p>Please select which option seems more cautious to you: </p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>52, M 20 = 2.98, SD 20 = 1.40, b = -0.68, clustered SE = 0.08, t(339) = -8.97, p &lt; .001, mean difference 95% CI [-0.80, -0.56]). Based on mediation analysis, responsibility concern appeared to reduce the effect size of the group-size manipulation (indirect effect = -0.97, 95% CI [-1.40, -0.60]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>01 (M = 3.05, SD = 1.44, b = 0.54, clustered SE = 0.07, t(339) = 7.91, p &lt; .001, mean difference 95% CI [0.42, 0.65], d = 0.36).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Supplementary</head><label></label><figDesc>Information section 3.2) 26 . Thus, if higher stakes nonetheless increase caution, it would be evidence that responsibility aversion plays a causal role. Indeed, participants were more cautious at $1.00 (M = 78.2%, SD = 12.1%) than $0.01 (M = 73.8%, SD = 14.6%, b = 4.41, clustered SE = 0.73, t(339) = 6.07, p &lt; .001, mean difference 95% CI [3.3%, 5.6%], d = 0.33), and responsibility concern once again played a mediating role (indirect effect = 0.59, 95% CI [0.30, 0.91]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>( 2 Experiment 2</head><label>22</label><figDesc>extremely likely) -Policy decided based on unanimity (as in above scenario) -Policy decided based on majority -Policy decided based on delegation to a single board member Experiment assessed whether doctors require greater certainty to prescribe drugs to patients if they know a patient is seeing many other physicians. We collected a sample of 200 U.S. doctors (84 female, 116 male; M birthyr = 1972.68, SD birthyr = 16.99; to interpret birth year, note we collected data in May 2023) via YouGov.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>Imagine you are (the only doctor)[one of ten doctors] with a particular specialty working at a local hospital. (You will see the patient and you must decide whether to prescribe the patient the medication.) [All of you will see a patient separately, and each of you must decide whether to prescribe the patient a medication.] The patient will take the medication if any of you prescribe it, but will not acquire it otherwise. [Assume that, due to medical privacy laws, neither you nor the other doctors will know each other's decision when you decide yourselves.] How confident would you need to be that the benefits of the patient taking the medication would outweigh the harms in order for you to prescribe it? Please enter a percentage between 50% and 100%. Slider: 50 (completely uncertain) -100 (completely certain)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>rather than deciding whether to open the imposable box directly, each player would determine their signal-strength threshold for opening the imposable box in each round--that player would open the imposable box if and only if their signal indicated that the imposable box contained the bonus with a percentage confidence at least as great as their threshold, and (7) they would play four completely independent rounds of the game, only one of which would count for real.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>First, where possible, policymakers should limit the number of people who can impose a single event. A canonical example of such a policy is the US president's sole authority to sanction a nuclear attack. While imperfect, this system is far superior to having multiple military personnel able to unilaterally start a nuclear war. Second, potential imposers should have training which helps them understand when their decisions have high stakes (see Experiments 5 and S2 for stakes manipulations). Third, potential imposers should pre-commit to the minimum level of evidence they would require to impose a given event (see Experiment S3). We discuss policy solutions in a bit more detail in Supplementary Information section 4.1. Societally, the unilateralist's curse is increasingly relevant. As technology progresses, more people could have the power to impose irreversible events on everybody. For example, multiple actors might be able to create and share AI models, synthesize diseases, disseminate fake news, or publicize individuals' private data. Similarly, multiple governments could unilaterally deregulate dangerous technologies such as gene editing, with global implications.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>researchers who could release some new information. If the information were public, it would advance beneficial AI progress, but also considerably increase the risk of dangerous, power-seeking AI systems existing at some point.</figDesc><table><row><cell>Suppose you and each of the other researchers had a one-day opportunity to</cell></row><row><cell>anonymously release this information, but could not communicate with each other about</cell></row><row><cell>the decision. Instead, each of you must decide whether to release the information on your</cell></row><row><cell>own.</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head></head><label></label><figDesc>B for them to open it. This threshold will determine what actually happens when their signal is revealed. If the signal is at least as certain as their threshold in favor of Box B, then they will open Box B. Otherwise, they will not open Box B, and other group members' decisions will determine which box is opened. Remember that the 2 other participants in your group will also receive signals about which box contains the $1.00 bonuses (which may be different from yours). Also remember that if Box B contains the bonuses, only one person in your group must choose to open Box B for everyone in your group to receive $1.00. However, if Box A contains the bonuses, every person in your group must choose not to open Box B in order for you all to receive $1.00.</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>-</head><label></label><figDesc>Deciding to open Box B only if your signal indicates Box B with 51% strength or more -Deciding to open Box B only if your signal indicates Box B with 99% strength or more -They seem equally cautious</figDesc><table /><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Construction of an infectious horsepox virus vaccine from chemically synthesized DNA fragments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Noyce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lederman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Evans</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS One</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">188453</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Foundations for engineering biology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Endy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">438</biblScope>
			<biblScope unit="page" from="449" to="453" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Synthetic biology and biosecurity: challenging the &apos;myths&apos;. Front Public Health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Jefferson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lentzos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Marris</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">115</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Unilateralist&apos;s Curse and the Case for a Principle of Conformity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Bostrom</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Douglas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sandberg</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc Epistemol</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="page" from="350" to="371" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title level="m" type="main">Meta LLaMa leak raises risk of AI-linked harms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Analytica</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
			<publisher>Emerald Expert Briefings</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Gaulle&apos;s First Veto: France, the Rueff Plan and the Free Trade Area</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M B</forename><surname>Lynch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>De</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Contemp. Eur. Hist</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="111" to="135" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Causes and consequences of airline fare wars</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Morrison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Winston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">E</forename><surname>Bailey</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">W</forename><surname>Carlton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Brook. Pap. Econ. Act. Microecon</title>
		<imprint>
			<biblScope unit="page">85</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The robust beauty of majority rules in group decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hastie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Kameda</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="494" to="508" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Szilard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Reminiscences</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1968" />
		</imprint>
		<respStmt>
			<orgName>Charles Warren Center for Studies in American History, Harvard University</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Regulating Collusion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chassang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Ortner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Econom</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="177" to="204" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: models of bounded rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="650" to="669" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Betting on one good reason: The take the best heuristic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Simple heuristics that make us smart 75-95</title>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Competitive Bidding in high-risk situations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">C</forename><surname>Capen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">V</forename><surname>Clapp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">M</forename><surname>Campbell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Pet. Technol</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="641" to="653" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">The Winner&apos;s Curse and Public Information in Common Value Auctions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">H</forename><surname>Kagel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am. Econ. Rev</title>
		<imprint>
			<biblScope unit="volume">76</biblScope>
			<biblScope unit="page" from="894" to="920" />
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Anomalies: The Winner&apos;s Curse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Thaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Perspect</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="191" to="202" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">The Origin of the Winner&apos;s Curse: A Laboratory Study</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Charness</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Levin</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American Economic Journal: Microeconomics</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="207" to="236" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Thinking</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Fast</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Slow</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<publisher>Macmillan</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Shared responsibility in collective decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>El Zein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bahrami</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="554" to="559" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Responsibility is divisible by two, but not by three or four: Judgments of responsibility in dyads and groups</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Teigen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Brun</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Soc. Cogn</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="15" to="42" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Negative information weighs more heavily on the brain: the negativity bias in evaluative categorizations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Ito</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Larsen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">K</forename><surname>Smith</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Cacioppo</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Pers. Soc. Psychol</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="page" from="887" to="900" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Negativity Bias, Negativity Dominance, and Contagion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rozin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">B</forename><surname>Royzman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Pers. Soc. Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="296" to="320" />
			<date type="published" when="2001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Regret Theory: An Alternative Theory of Rational Choice Under Uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loomes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Sugden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econ J</title>
		<imprint>
			<biblScope unit="volume">92</biblScope>
			<biblScope unit="page" from="805" to="824" />
			<date type="published" when="1982" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Anomalies: The Endowment Effect, Loss Aversion, and Status Quo Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Knetsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Thaler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Perspect</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="193" to="206" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">The Utility of Wealth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Markowitz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1952" />
		</imprint>
		<respStmt>
			<orgName>University of Chicago, Cowles Commission for Research in Economics</orgName>
		</respStmt>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Decision Making Over Time and Under Uncertainty: A Common Approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Prelec</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Loewenstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manage. Sci</title>
		<imprint>
			<biblScope unit="volume">37</biblScope>
			<biblScope unit="page" from="770" to="786" />
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m" type="main">Nash equilibrium of identical agents facing the Unilateralist&apos;s Curse</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Armstrong</surname></persName>
		</author>
		<ptr target="https://www.fhi.ox.ac.uk/wp-content/uploads/Nash-equilibrium-of-identical-agents-facing-the.pdf" />
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Status quo bias in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Samuelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Zeckhauser</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Risk Uncertain</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="7" to="59" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Contingent weighting in judgment and choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sattath</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Slovic</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Rev</title>
		<imprint>
			<biblScope unit="volume">95</biblScope>
			<biblScope unit="page" from="371" to="384" />
			<date type="published" when="1988" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Intuitive confidence: choosing between intuitive and nonintuitive alternatives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Simmons</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Nelson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="409" to="428" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<monogr>
		<title level="m" type="main">Expert Survey on Progress in AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Sandkühler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Korzekwa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Brauner</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
