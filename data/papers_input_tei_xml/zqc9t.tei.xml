<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Decision-making times reveal that people&apos;s thinking plans adapt to the problem they are trying to solve</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Danielle</forename><forename type="middle">K</forename><surname>Ongchoco</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Joshua</forename><surname>Knobe</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Julian</forename><surname>Jara-Ettinger</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Yale University</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Decision-making times reveal that people&apos;s thinking plans adapt to the problem they are trying to solve</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T14:27+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>Computational modeling, Thinking</keywords>
			</textClass>
			<abstract>
				<p>Much of our thinking focuses on deciding what to do in situations where the space of possible options is often too large to evaluate exhaustively. Previous work has found that people do this by learning the general value of different behaviors, and prioritizing thinking about high-value options in new situations. Is this good action bias always the best strategy, or can thinking about low-value options sometimes become more beneficial? Can people adapt their thinking accordingly based on the situation? And how do we know what to think about in novel events? Here, we developed a block-puzzle paradigm that enabled us to measure people&apos;s thinking plans and compare them to a computational model of rational thought. Our results suggested that people can quickly estimate the apparent value of different options and use this to guide what to think aboutin particular, the potentially high-value options (Experiment 1). But when the situation made it more beneficial to focus on potentially negative options, participants-like our model-focused on low-value options, leaving them less time to think about high-reward choices (Experiment 2). Our results suggest that thinking plans are flexible: what we think about depends on the structure of the problems we are trying to solve.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.">Introduction</head><p>We often have to make decisions involving a wide array of options: actions we can take, things we can say, or people we can interact with. Intuitively, much of our thinking involves considering different options in anticipation of a decision, as when we think about what we want to eat for dinner, or what we want to say before a meeting. But we don't have the time and computational resources to consider every option before we have to make a choice (see Lieder <ref type="bibr" target="#b18">&amp; Griffiths 2020</ref><ref type="bibr" target="#b17">&amp; Griffiths , 2017</ref><ref type="bibr" target="#b27">Vul et al. 2014</ref>). So we face a complex selection problem:</p><p>Given that we can only think a few thoughts at a time, what should we think about?</p><p>A growing body of computational and empirical work suggests that people solve this problem through a 'good-action bias' <ref type="bibr" target="#b0">(Bear et al. 2020;</ref><ref type="bibr" target="#b13">Icard et al. 2017;</ref><ref type="bibr" target="#b19">Mattar &amp; Daw 2018)</ref>: Over time, people learn the values associated with different options or behaviors in a broad class of situations. Then, when people face a specific situation and can only consider a small number of options about how to behave within it, they tend to consider the options that they have determined to generally have high value in that broader class of situations.</p><p>This process leads to more accurate representations of the high-value options (e.g. <ref type="bibr" target="#b12">Icard et al. 2018;</ref><ref type="bibr" target="#b7">Gelly &amp; Silver 2011)</ref>.</p><p>Despite the power and usefulness of a good-action bias, this strategy is only useful in situations where people have readily available value representations associated with different possible options. Yet, many important decisions often come in the context of novel situations, where relevant past experiences can be scarce, or carry little value information for the context that we're in. In these situations, what do people tend to think about?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.1.">What do we think about?</head><p>There are least two possibilities for what happens when people face entirely new situations. A first possibility is that the good-action bias reflects a thinking strategy that people use across the board. When faced with a new situation, people might initially represent all options as having roughly equal value (with high uncertainty). In such situations, people might show no systematicity in what they choose to think about-thinking about both high and low value options, as the values are unknown to them-with the good-action bias becoming visible once people have gotten the opportunity to begin refining their value estimates <ref type="bibr" target="#b3">(Callaway et al. [2021b]</ref>). Alternatively, however, people might quickly build an initial estimate of value based on superficial cues of the environment.</p><p>This would allow people to prioritize thinking about potentially valuable options from the start. As we will see, whether these generalizations of the good-action bias are useful depends on the structure of the decision problem, as there are certain structures in which they may not be appropriate.</p><p>In contrast, another possibility is that the good-action bias is limited in scope, and people can generate and use different thinking strategies based on the context that they're in. In other words, in the same way we can create ad-hoc action plans in a novel physical task (as when we figure out which path to take based on the layout of a new room), people may also be able create ad-hoc "thinking plans" in a novel thinking task. Thus, people might be able to execute thinking plans that are not necessarily aligned with the good-action bias, depending on the problem that they're attempting to solve. This said, generating novel ad-hoc thinking plans requires time and computational resources <ref type="bibr" target="#b10">(Griffiths et al. [2015]</ref>). If we were able to do this quickly, this would suggest a sophisticated mechanism that generates thinking plans while working around computational intractability.</p><p>The present study aims to explore these possibilities. How do people know what to think about in novel situations? Do their strategies reflect a generalized form of the good-action bias? Or can people flexibly adapt to the right strategy based on the structure of the problem at hand?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="1.2.">The present studies</head><p>To answer these questions, we developed an experimental paradigm that allows us to determine what people have (and have not) thought about in a novel situation under time pressure. Participants saw novel incomplete block-puzzles and an array of six different puzzle-piece options <ref type="figure">(Figure 1</ref>), some of which had potentially high values, while others had potentially low values. Puzzle pieces </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>(b) Decision Phase</head><p>Which piece is better? <ref type="figure">Figure 1</ref>: The two-part design of the experiments. Participants first went through a (a) thinking phase where they were allowed to freely evaluate how well each of the six pieces fit into the base (bottom piece) (b) Decision phase where participants were asked to to choose between two pieces. varied in their surface features (e.g. their size), which provided information about their apparent value. Participants could then solve the puzzle by mentally rotating the various puzzle pieces to see which pieces fit and which did not, which in turn revealed their value. Because mental rotation is a relatively slow cognitive operation ( <ref type="bibr" target="#b6">[Cooper, 1975;</ref><ref type="bibr" target="#b25">Shepard &amp; Metzler, 1971]</ref>), this approach enabled us to probe whether participants had previously thought about a puzzle piece by measuring their reaction time; a slow reaction would suggest that the participant is evaluating the puzzle piece (i.e., performing a mental rotation and computing its value) only after being asked about it, while a fast reaction time would suggest that the participant had already mentally rotated the piece and computed ts value before being asked.</p><p>Participants first completed a thinking phase, where they could freely think about different puzzle pieces (via mental rotation; <ref type="figure">Figure 1a</ref>), followed by a decision phase, where participants were explicitly prompted to select the best piece from a subset of pieces ( <ref type="figure">Figure 1b)</ref>. Therefore, participants' response times could reveal whether they had already considered the value of the pieces presented to them in the decision phase: participants should be faster when deciding between two pieces that they had already evaluated, and slower when they hadn't thought about some (or all) of the presented pieces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>This paradigm enabled us to test what people think about in novel situations,</head><p>as a function of the context that they're in. In Experiment 1, we first considered a situation where observable cues contained information about the apparent value of different pieces, and we tested whether these cues influenced what people chose to think about first. Participants were told that only puzzle pieces that fit into the main structure (shown in yellow in <ref type="figure">Figure 1a</ref>) would give them points, and that the object's final size, after attaching the puzzle piece, would determine the number of points that they obtain. Therefore, participants could estimate the apparent value of a piece based on its size, but would need to think about (and mentally rotate) it to discover its exact value.</p><p>Beyond what thinking strategy people will use in novel situations, we were also interested in whether people flexibly adapt their thinking plans depending on the situation itself. To see if people don't just default to potentially highvalue options, we also needed to identify situations where a better strategy would be to think of potentially low-value options (therefore acting against a good-action bias). To explore this possibility, we formalized our block-puzzle paradigm in a computational framework and varied different task parameters to explore the space of decision problems. This allowed us to identify contexts in which the best strategy would be to think about potentially low-value options first, which we then test in Experiment 2.</p><p>Altogether, these experiments allowed us to probe what people would think in a range of decision-problems, varying different dimensions: a case where there was an equal number of high and low-value options versus a case where there were more low-value options; a case where there was a potentially high-value option (needle in the stack) versus a case where there was a potentially really low-value option (snake in the stack); and a case where the critical low-value option (the 'snake') could be more or less difficult to find.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.">Computational Framework</head><p>To formalize the problem of which options would be best to think about, we used partially-observable Markov decision processes (POMDP; <ref type="bibr" target="#b4">Cassandra 1998;</ref><ref type="bibr" target="#b26">Sutton et al. 1998)</ref>. POMDPs were originally developed in robotics and AI to model action-planning in complex spatial environments under partial information, but more recent work has shown that this framework can be used not only to model decisions between different physical actions but also decisions between different thought processes (see <ref type="bibr">Callaway et al. 2021a;</ref><ref type="bibr" target="#b5">Chen et al. 2021;</ref><ref type="bibr" target="#b9">Griffiths et al. 2019;</ref><ref type="bibr" target="#b18">Lieder &amp; Griffiths 2020)</ref>. Thus, here we adapted the framework to implement a space of thinking actions rather than physical actions. Before introducing our model, we will begin by briefly introducing POMDPs in the context in which they are classically used.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.1.">Classical uses of POMDPs</head><p>To illustrate the logic of POMDPs, consider a simple situation where an agent's goal is to take an object in a house. To achieve this, the agent must first find the object and then retrieve it. To formalize this problem, POMDPs define a state space S consisting of all possible physical states of the world.</p><p>In a case like this one, the state space would include the combination of any position where the agent and the object might be at any given time point. Given this state space, the agent's goals can be represented as a reward function R that assigns a numerical reward to combinations of states and actions. In this example, the goal can be encoded as a reward function that returns a high positive value in states where the agent is holding the object.</p><p>To obtain these rewards, the agent can take sequential actions (from a set of actions A) that change the state of the world. The relationship between actions and states is captured by the transition function T , where T (s, a, s ) represents the probability that the world will change from state s to s when the agent takes action a. For instance, an agent taking the action 'walk north' in a state should assign a high probability to the state where the agent is now one spot north of where they used to be.</p><p>At their core, POMDPs assume that agents can have partial or incomplete knowledge about the world. For instance, the agent may know their position in space but not know where the object is located. To achieve this, POMDPs introduce belief representations, expressed as probability distributions over the state space. To model how the agent's beliefs change as they move in space, POMDPs introduce an observation function O which determines what information is made available to the agent in different states, where O(i, s, a) is the probability that the agent receives information i when taking action a in state s. For instance, a simple observation function might encode that the agent can see whether the object is present or absent in any room as soon as she enters it. Formally, this is achieved by defining a space of observations, and specifying which observations are associated with each state through an observation function (which can include probabilistic components).</p><p>Given the six-tuple defined above-a state space, an action space, an observation space, a reward function, a transition function, and an observation function-it is possible to compute the series of actions that, given an agent's knowledge, maximize the long-term rewards that the agent obtains (requiring one additional parameter, λ, that specifies how rewards are discounted over time). Computing the exact solution to a POMDP is computationally demanding and often intractable in practice, particularly in problems with large state spaces. Nonetheless, research in the past two decades has led to the development of multiple algorithms that provide approximate solutions to POMDPs (such as by not computing the actions that would be associated with implausible belief states that the agent could have), making them a useful practical framework for determining rational action under imperfect information <ref type="bibr" target="#b11">(Hsu et al. 2008;</ref><ref type="bibr" target="#b22">Ng &amp; Jordan 2000;</ref><ref type="bibr" target="#b16">Kurniawati et al. 2008</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="2.2.">Modeling thinking through POMDPs</head><p>Although POMDPs are most typically used to model choices between physical actions, they can also be used to model choices between different thoughts.</p><p>For simplicity, we explain this model structure in the context of Experiment 1a (a more comprehensive presentation is available in the Supplemental Materials).</p><p>Here, participants were presented with a puzzle like the one shown in <ref type="figure">Figure   1a</ref>, and they learned that pieces that do not fit into the puzzle have no value, and pieces that fit into the puzzle have larger values whenever they increase the overall number of blocks in the structure. After being given time to think about whichever pieces they like (i.e., rotating them mentally to see if they fit in the puzzle during the thinking phase), participants were asked to quickly determine which of two puzzle pieces had higher value (decision phase). Although the full problem is ultimately encoded in a single POMDP, we first explain the components at use during the thinking phase, and then turn to the ones used in the decision phase.</p><p>In this context, the apparent value of a puzzle piece can be determined visually: the larger the piece, the more likely it is to be valuable. The true value of a piece, however, can only be revealed by thinking about it (i.e., mentally rotating it to test if it fits in the puzzle or not). Thus, our model represents each piece in terms of its apparent value, determined by its size, and its true value, which equals the apparent value when the piece fits into the puzzle, and when it does not. Given the two hypotheses about each piece (the true value either equals the apparent value or 0), we defined the state space as every possible setting over which pieces' true value matches the apparent value and which do not (i.e., in the case with six pieces, the state space consists of 2 = states).</p><p>To model the thinking phase, we gave our model the ability to execute thinking actions, which revealed the true value of whichever piece the agent chose to think about (through an observation). While the thinking actions do not have any causal impact on the state space, there was always a small probability that, at any given point, the state space may switch to a decision phase (capturing the idea that the participant knew that at any point they might get asked to choose a piece among a subset). To model this component, we included an additional set of states, where each state encoded a forced choice between two possible pieces selected from a uniform distribution (as in <ref type="figure">Fig 1a)</ref>.</p><p>To select a piece, the agent could take a 'selection' action, obtaining a reward depending on which piece they picked.</p><p>These specifications enabled us to use the POMDP framework to compute what sequence of thinking actions were best suited to the decision problem, with the goal of maximizing the agent's expected reward in the decision phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.">Experiment 1</head><p>In Experiment 1, we first sought to test what people think about in a novel situation where the apparent value of different choices can be estimated based on superficial observable cues. Participants saw a display like the one shown in <ref type="figure">Figure 1a</ref>. The value of each piece was given by the final size of completed puzzle, after the piece was attached (and 0 value for pieces that did not fit the base puzzle). Thus, each piece's size gave a superficial cue about its apparent value, but participants needed to mentally rotate each piece to test if it indeed fit the puzzle. We first confirmed that, in a context like this one, our model predicts that people should prioritize thinking about potentially high-value pieces, and we then tested this effect empirically.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.1.">Model Simulations and Results</head><p>To determine what people should think about in this situation, we implemented this puzzle in our computational framework (section 2.2). Because people can sometimes make reasoning errors, our model included a small probability that a mental rotation would lead to an incorrect conclusion (i.e., believing that a piece fits when it does not, or believing that a piece does not fit when it does).</p><p>To achieve this, we included a certainty parameter, which we varied from 95% (i.e., a 5% chance of making a reasoning error) to 100% (i.e., full confidence of no reasoning error) in steps of 1%, each implemented on a separate POMDP.</p><p>In these models, the probability of switching from the thinking phase to the decision phase was set to 30% and we used a future discount parameter of 0.95. These parameters were all set prior to model evaluation. After training each POMDP (i.e., computing the optimal policies), we obtained an expected thinking plan by running 100 simulations under each certainty parameter with a random set of puzzle pieces (set to always have two large pieces, two medium pieces, and two small pieces to match the experiment). To ensure that all simulations revealed the full thinking plan, we modified the simulations dynamics to ensure that the model would not switch to the decision phase until after the model had the chance to think of all pieces. That is, the model's training reflected the belief that the agent might be prompted to make a decision before having had the opportunity to think about all six pieces, but the simulations were modified to stay in the thinking phase long enough for us to observe the model's full thinking pattern. We then averaged the performance of all simulations over all certainty values to obtain an expected thinking plan. <ref type="figure" target="#fig_1">Figure 2a</ref> shows the results from this simulation. As this simulation shows, our model always uses the first two time-steps to think about the two pieces that have the highest probability of being valuable. Afterwards, the model shifts to thinking about intermediate-value pieces. Note that our model continues to assign some probability to considering the highest-value pieces in steps 3 and 4. This reflects the performance of the models that believe reasoning errors are likely. In these cases, our model believes it is better to double check potentially high-value pieces to confirm their true value. Finally, the model only begins considering the lowest-value pieces at the very end of the task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.">Experiment 1a</head><p>Experiment 1a tested a situation where the value of pieces was correlated with size: larger pieces that fit into the puzzle were more valuable than smaller pieces that fit into the puzzle. However, pieces that did not fit into the puzzle had no value, regardless of their size. After the thinking phase-where participants could freely focus on different pieces to check if they'd fit into the puzzle-participants were asked to select the best option among either two large pieces or two small pieces. We predicted that, if participants prioritize thinking about potentially high-value options, their response time should be significantly lower when asked to select which is better of two large pieces relative to when asked to select which is better of two small pieces.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.1.">Method</head><p>All methods and analyses were pre-registered (http://aspredicted.org/ blind.php?x=rd2bd2). Data and code for all experiments reported here are available on:</p><formula xml:id="formula_0">https://osf.io/n8em7/?view_only=9f9bb51af6b24fdaa1eebc2a041ce910.</formula><p>Participants. Sixty participants from the Yale and New Haven community participated. Three additional participants were recruited but excluded from the study based on pre-registered criteria (see Results). The sample size was determined based on a power analysis run on pilot data (see Supplemental Materials for details).</p><p>Apparatus. Stimuli were presented using custom software written in Python with the PsychoPy libraries <ref type="bibr" target="#b23">(Peirce et al. 2019)</ref> and were displayed on a monitor with a 60Hz refresh rate. Participants completed the study on a 13-inch MacBook Air with a 1440 x 900 resolution.</p><p>Stimuli. Each trial consisted of a yellow puzzle base and six blue puzzle pieces (see <ref type="figure">Figure 1a</ref> for an example). Each participant was presented with a randomly generated puzzle base, which always had three to four blocks missing at the top. Each of the six puzzle pieces options consisted of the three/four blocks that were missing, along with additional blocks that determined the value of the piece. For example, a piece with a value of 7 points is one that locks into the puzzle base after being rotated and had 7 additional blocks that go beyond the puzzle's 5x4 rectangular shape (e.g., the upper leftmost piece in <ref type="figure">Figure 1a</ref>). Critically, some puzzle pieces did not have the correct shape to lock into the puzzle and therefore had value 0 (e.g., the lower middle piece in <ref type="figure">Figure   1a</ref>, which has an apparent value of 7, but its true value is 0 because it does not fit into the puzzle). The six puzzle pieces were randomly generated but always consisted of three pairs of apparent values: two potentially high-value options (apparent value: 7), two potentially medium-value options (apparent value: 5), and two potentially low-value options (apparent value: 3). In each pair, one piece would always fit (true value equals its apparent value), and the other would not (true value equals 0). Procedure and Design. Participants first read a brief set of task instructions where they learned the logic of the task and they were told that their goal was to earn as many points as possible. A 'Total Points' counter was visible on the top-left of the screen throughout the entire experiment. Participants were then shown a sample block-puzzle, and were asked questions about these different options to test their understanding of the task and the point system. Participants obtained points for correct answers, which we used as an exclusion criteria for people who did not understand the task. To ensure that participants would not just look for puzzle pieces whose bottom part resembled the structure of the missing section of the puzzle base, they were told that the pieces can only be rotated but never simply flipped. After these instructions, participants were shown a new block-puzzle. At the start of the thinking phase, participants were told that six pieces would now appear above the puzzle, in two rows of 3 pieces each (as in <ref type="figure">Figure 1a</ref>). Participants were told that they did not have to do anything but just look and study the pieces. Once the puzzle pieces appeared, participants were given five seconds to study them, with a countdown timer shown above the puzzle. When the countdown timer reached 0, the task automatically switched to the decision phase. Here, two of the six pieces turned green (as in <ref type="figure">Figure 1b</ref>) and participants were asked "Which piece is better?" Critically, half of our participants were tasked with identifying which is better of the two potentially high-value options, and the other half were tasked with identifying which is better of the two potentially low-value options. To incentivize participants to really think about the options during the thinking phase, they were also told that they would get bonus points for responding quickly.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.2.">Results</head><p>Three participants were excluded because their mean performance in the comprehension questions was 2 standard deviations below the grand popula- The model could think about the potentially high-value pieces (green), the medium-value pieces (purple), or the low-value pieces (red). Our rational model suggests that the best strategy is to begin by thinking about the high-value pieces, followed by mediumvalue pieces, and then finally the low-value pieces. There was no significant difference between the percentage of people who responded accurately when choosing between potentially high-value options vs.</p><p>potentially low-value options (86.67% vs. 66.67%, Fisher's exact: p = .125).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.2.3.">Discussion</head><p>The results from Experiment 1a revealed that people asked to identify which is better of two potentially high-value pieces were about twice as fast as people asked to identify which is better of two potentially high-value pieces. This suggests that participants prioritized thinking about potentially high-value options during the free thinking phase, producing the response time benefit in the decision phase. Thus, in novel situations, people may adopt a strategy of thinking of the options that appear likely to have high values. This aligns with the sequence of thinking actions from our computational framework, and suggests that people may be adopting the best strategy (as determined by our model),</p><p>given the decision problem.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.">Experiment 1b</head><p>In Experiment 1a, potentially high-value options always had more blocks, while potentially low-values options always had fewer blocks. Might people simply have been attracted to larger pieces, independent of their value? To ensure that our results were not just a matter of the brute number of blocks, Experiment 1b flipped the size-value relationship: smaller puzzle pieces were now more valuable than larger puzzle pieces.</p><p>3.3.1. Method.</p><p>This experiment and stimuli was identical to Experiment 1a, except as noted.</p><p>Seventy new participants from the Yale and New Haven community participated.</p><p>Two additional participants were recruited but excluded in the study based on pre-registered criteria (see Results). The sample size was determined before data collection began based on a power analysis run on pilot data (see Supplemental Materials for details).</p><p>Participants first read a brief set of task instructions that explained the logic of the task. In contrast to Experiment 1a, participants learned that the number of additional blocks in a piece that fits now reflected the number of points that would be deducted. For instance, if a piece fit into the puzzle base and had 7 additional blocks, then 7 points would be deducted. If the piece did not fit, then 10 points would be deducted. In this case, the potentially high-value pieces were the ones with fewer blocks, and the potentially low-value pieces were the ones with more blocks. Participants began with a score of 50 points and the thinking and decision phase proceeded in the same way as Experiment 1a. All methods and analyses were pre-registered (http://aspredicted.org/blind.php?x=bw5n59).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.3.2.">Results and Discussion</head><p>Two participants were excluded because their mean performance in the comprehension questions was 2 standard deviations below the grand population mean. These participants were replaced, until a total of 70 participants was While we found a marginal difference between the percentage of people who responded accurately when choosing between potentially high-value options vs.</p><p>potentially low-value options (71.43% vs. 91.43%, Fisher's exact: p=.062), accuracy was nonetheless high in both conditions. And this marginally higher accuracy when choosing between low-value options may reflect participants' determination to not make a wrong choice. Thus, our results suggest that people are not just attracted to thinking about visually larger puzzle pieces, and they instead thought about particular puzzle pieces based on the pieces' underlying values.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.">Experiment 1c</head><p>So far, the results from Experiments 1a-1b suggest that people prioritize thinking about potentially high-value options, even in novel situations. This strategy produced a response time benefit when people had to decide between two potentially high-value options, relative to when they had to decide between two potentially low-value options. What is the scope of this advantage? One possibility is that the reaction time benefit is specific to puzzle pieces that participants mentally rotated during the thinking phase (recalling their value during the decision phase). Alternatively, however, it is possible that participants not only learned the specific value of pieces that they thought about, but also learned a general strategy for how to quickly think about good puzzle pieces. If this is the case, then participants should show a reaction time advantage over good pieces, even when these pieces weren't available during the thinking phase.</p><p>To explore this possibility, Experiment 1c replicated Experiment 1a, with the difference that, in the decision-making phase, participants were shown puzzle pieces that were not in the thinking phase. If participants learned the specific value of pieces that they had mentally rotated, the reaction time benefit should disappear. However, if participants learned general strategies for how to quickly evaluate the true value of good puzzle pieces, then we should see a reaction time difference, even for new puzzle pieces. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="3.4.2.">Results and Discussion</head><p>One participant was excluded because their mean performance in the comprehension questions was 2 standard deviations below the grand population mean. This participant was replaced, until a total of 60 participants was reached.</p><p>Response accuracy and response times for the single trial were recorded for each participant. Only response times where participants responded correctly were included in the analysis. This time, participants who chose between potentially high-value options were in fact slower (M=4.54s, SD=2.51s) than participants who chose between potentially low-value options (M=2.52s, SD=1.12s), as de- ANOVA. There was no main effect of choice type, F (1, 88) = 0.12, p = .728, η 2 = .002, or of choice value, F (1, 88) = 0.33, p = .570, η 2 = .004. Crucially, there was a significant interaction, F (1, 88) = 20.99, p &lt; .001, η 2 = .193. These results suggest that participants in Experiments 1a-1b had a reaction time benefit for potentially high-value pieces because they learned their specific value during the thinking phase, and not because they developed a general strategy for thinking about those pieces more quickly during the decision phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.">Experiment 2</head><p>Experiment 1 showed that, in novel situations, people can preferentially think about options that are likely to be of high-value. This behavior was consistent with our computational model, which predicted that a rational thinking strategy should prioritize thinking about options with a higher expected value.</p><p>At the same time, this experiment only considered situations where thinking about the good was the best strategy. We therefore do not know if people have a good-action bias in all situations, or if they can revise this strategy when necessary.</p><p>To test this possibility, we used our computational framework to search for problems where the best strategy would be to think about low-value options first, and tested if participants can adjust their thinking strategy accordingly. As we show below, this search led to a task structure that we call "snake in the stack."</p><p>This task is structurally similar to the tasks that we used in Experiment 1, with the difference that we introduced a "snake": a piece that comes with a relatively larger cost for participants. In this type of situation, our model predicts that the best strategy is to first find the snake (i.e., think about potentially low-value pieces) and then switch to thinking about potentially good options.</p><p>The strategy derived by our model implies that the amount of time used to think about good pieces depends on how quickly one finds the bad piece.</p><p>For instance, if a participant was lucky and happened to identify the bad piece on their first try, this would give them enough time to also evaluate high-value pieces and show the same reaction time benefit from Experiment 1. However, if a participant is unlucky and slow to find the bad piece, this would come at the cost of not having the opportunity to evaluate the high-value pieces, and the reaction time benefit from Experiment 1 should disappear.</p><p>To test this effect experimentally, participants in Experiment 2 were told that large pieces had higher expected values, but that one of the small pieces would lead to a very high cost. Half of the participants were then shown a puzzle were all of the small puzzle pieces were snakes (Easy-Snake condition). Participants searching for the snake in this condition would always find one on the first try (perhaps believing they got lucky). The other half of participants were shown a puzzle were none of the small pieces were snakes (Impossible-Snake condition).</p><p>Participants searching for the snake in this condition would therefore fail to find it, no matter how long they spent (perhaps believing they made a rotation error). At the end of the thinking phase, all participants were prompted to select which is better of two high-value pieces. If participants simply prioritize thinking about good pieces (as in Experiment 1), our manipulation should have no effect on participants, as they would not take more or less time searching for the snake. However, if participants switch their thinking strategy by first searching for the snake before thinking about good options, then participants in the Easy-Snake condition should be faster in the decision phase relative to participants in the Impossible-Snake condition (because only participants in the Easy-Snake condition had the time to evaluate the high-value pieces).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.1.">Model Simulation and Results</head><p>To search for problem structures where the good-action bias no longer applies, we modified the decision problem along two dimensions: (1) the number of options an agent could choose between in the decision phase (set to either 2, 3, 4, 5 and 6 out of 6), and (2) the number of low-value options in the puzzle among which the snake could be hidden (set to 2, 3, 4, or 5). For instance, the problem where number of choices = and number of apparent snakes = corresponds to a puzzle with two large (i.e., potentially high-value) pieces and four small (i.e., potentially low-value) pieces, one of which is believed to be the snake. At the decision phase, the model would be allowed to select one of three randomly selected pieces to win (or lose) points.</p><p>We trained POMDPs to solve all 20 problems in the 5 x 4 parameter space (see Supplemental Methods for full implementation details). We then began by testing whether any region in this space led to strategies that prioritized thinking about bad options. <ref type="figure" target="#fig_6">Figure 3</ref> shows the results from this analysis, coding the first thinking action chosen by the model. When the agent can choose among all, or nearly all, the options during the decision phase (rightmost columns), the model begins by searching for high-value options. This makes sense: when the agent can choose from all options, knowing the option with the highest value should suffice. However, when the agent will have to select the best piece from a limited subset (e.g. two options; leftmost column), the model no longer prioritizes the potentially high-value options. Instead, it allocates time depending on the number of apparent snakes. The higher the number of apparent low-value options, the more the agent thinks about them (indicated by how the green squares turn red as we increase the number of low-value options along the y-axis in <ref type="figure" target="#fig_6">Figure 3</ref>). This again makes sense: the more low-value options, the more likely that one of them will be part of the decision phase, in which case knowing whether the piece is the snake or not is critical.</p><p>Of the space of 20 models, we chose a setting with four low-value options where a decision phase with two pieces (third row, leftmost column). We chose this setting because it was one of the closest to Experiment 1 (critically involving only two choices at the decision phase), but where our analysis suggested that  : First actions of each model systematically varying the number of apparent low-value options (among which one was is a "snake" that provides negative cost), as well as the number of choices the agent is during the decision phase.</p><p>people might prioritize thinking about bad options. Within this setting, the time an agent devotes to evaluating potentially high-value options depends on whether an agent finds the snake immediately or not. As we discussed above, if the agent finds the snake on the first try, then it can switch to thinking about the two high-value pieces. But if it never finds the snake, it will keep thinking about the apparent snakes until time runs out (or at least realizes or determines that it's futile to search for the snake). To probe this intuition, we tested our model in two modified situations. In one condition, we gave the POMDP policy a puzzle where all low-value options were snakes (Easy-Snake condition).</p><p>In the other condition, we gave the POMDP policy a puzzle where none of the low-value options were snakes (Impossible-Snake condition). Critically, the POMDP was always trained under the assumption that one (and only one) of the small puzzle pieces would be a snake. Testing the POMDP on these new problems therefore created situations where the POMDP would be led to believe it had found the unique snake on its first try in the Easy-Snake condition, and that it had failed to find the snake in the Impossible-Snake condition. <ref type="figure" target="#fig_7">Figure   4a</ref>-b, show our model's thinking strategies across both conditions. In the Easy-Snake the model first searches for the snake (considering low-value options) and immediately switches to evaluate high-value options on the second action, having believed that it found the snake. In contrast, in the Impossible-Snake condition, the model devotes more time searching for the snake, at the cost of being unable to spend as much time evaluating the potentially high-value pieces. Given these thinking strategies, we then asked what people will do in these situations. Will participants also recognize that the best strategy is to search for the snake and then switch to evaluating potentially high-value options? If they do, participants in the Impossible-Snake condition should be significantly slower at identifying which is better of two high-value options relative to participants in the Easy-Snake condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.2.">Method</head><p>This experiment was identical to Experiment 1a, except as noted. Seventy new participants participated. Three additional participants were recruited but excluded from the study based on pre-registered criteria (see Results). The sample size was determined before data collection began based on a power analysis run on pilot data (see Supplemental Materials for details).</p><p>Participants first read a brief set of task instructions that explained the logic of the task. Here, participants were told that the six puzzle pieces consisted of two potentially high-value options (where one fit and the other did not) and</p><p>four potentially low-value options (where three pieces fit and only one did not [the snake]). Participants were told that choosing the small piece that did not fit would lead to a decrease in their score of 10 points. In the Easy-Snake condition, all of the low-value options did not fit-in which case any option people think of should be the snake. In a Impossible-Snake condition, none of the low-value options did not fit-in which case people would never actually be able to find a snake. Participants began the task with a score of 0. In the decision phase, participants were always asked to decide between the two potentially high-value options. All methods and analyses were pre-registered (https://aspredicted.org/blind.php?x=im62yy).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="4.3.">Results and Discussion</head><p>Three participants were excluded because their mean performance in the comprehension questions was 2 standard deviations below the grand population mean. These participants were replaced, until a total of 70 participants was reached. Response accuracy and response times for the single trial were recorded for each observer. Only response times where participants responded correctly were included in our analysis. Participants in the Easy-Snake condition re-sponded faster to the potentially high-value options (M=2.11s, SD=1.67s) than participants in the Impossible-Snake condition (M=2.89s, SD=1.33s; t(46.36)=2.60, p=.013, d=0.70 over the logarithm of the distributions; see <ref type="figure" target="#fig_7">Figure 4c</ref>). Including the incorrect answers did not yield any different results, t(57.25)=2.85, p=.006, d=0.68). There was no significant difference in accuracy across the Easy-Snake and Impossible-Snake conditions (62.86% vs. 80.00%, Fisher's exact: p=.185).</p><p>This pattern of results suggests that people in the Impossible-Snake condition might have fixated more on the apparent snakes, giving them less time to think about the potentially high-value options. Implicit in this is that people must have started thinking about the potentially low-value options first-ultimately suggesting that they flexibly switched their thinking strategy to think about the worst options instead of the best options this time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.">General Discussion</head><p>People often think about possible actions they can perform even before they are faced with any actual decision. A question arises about which specific actions people tend to consider when they are engaged in this type of cognition. To make progress on this question, we used computational methods to determine which actions would be best to consider in various different settings and conducted a series of experiments to determine which actions people actually do tend to consider.</p><p>Computationally, we formalized this class of problems as a partially observable Markov decision process (POMDP), with thinking itself treated as a type of action. We then found the best thinking plan for a number of different specific decision problems. The results indicated that there are certain decision problems for which the best strategy is to think about the potentially high-value options and others for which the best strategy is to think about the potentially low-value options.</p><p>More specifically, the results revealed an interaction between (a) the number of options the agent is able to consider at decision time and (b) the proportion of options that are low-value. When the number of options the agent is able to consider at decision time is high, it is always best to consider the potentially high-value options. By contrast, when the number of options the agent is able to consider at decision time is low, the best strategy depends on the proportion of options that are low-value (especially if some of these options are extremely bad, as in the "snake" in the stack). When that proportion is small, the best strategy is to consider the potentially high-value options, whereas when that proportion is large, the best strategy is to consider the potentially low-value options.</p><p>We then conducted a series of experiments that provided evidence about which options people actually tend to consider. To do so, we developed an experimental paradigm in which participants went through a "thinking phase" followed by a "decision phase." In the thinking phase, participants were given a number of different options and had the opportunity to think about whichever options they wanted to. Then, in the decision phase, participants were confronted with just two of these options and asked to choose between them. Reaction times in the decision phase thereby provided evidence about which options participants were considering in the thinking phase. Specifically, the shorter a participant's reaction time in response to a pair of options in the decision phase, the more reason we have to conclude that the participant already considered those options in the thinking phase.</p><p>Using this method, Experiments 1a-c looked at decision problems for which the formal model indicated that the best strategy would be to think about the high-value options. In those experiments, the results indicated that participants actually did tend to think about the high-value options. Experiment then turned to decision problems for which the formal model indicated that the best strategy would be to think about the low-value options, and in that experiment, the results indicated that people did indeed tend to think about the low-value options. Taken together, the studies therefore suggest that people are able to respond flexibly, thinking about either high-value options or low-value options depending on which strategy is best for the specific decision problem they face.</p><p>These results leave us with a puzzle. On one hand, we have evidence that people show a remarkable level of sophistication and flexibility in determining which actions to consider. But, on the other, there is strong reason to suspect that the actual cognitive process people use to make this determination involves relatively little computation. For example, in our studies, participants could devote computation to thinking about which of the six options they should think about, but to the extent that they do this, they will have less computation available to actually think about the options themselves. Thus, it would never make sense to devote more computation to this task than would have been required just to think about all six options. This problem becomes even more important when considering how POMDPs are associated with high computational demands, suggesting that people are not using that same approach when they face this problem. So then, how do people actually solve the problem they faced in these experiments?</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.1.">Exploring the underlying process</head><p>Future work should continue to explore people's ability to show this sort of flexibility in determining which options to think about. Such work will require a mixture of computational and empirical research.</p><p>At a computational level, we face further questions about the conditions under which it is best to think about potentially good options vs. potentially bad options. In the present paper, we looked at two specific dimensions along which decision problems could vary, but future research could continue this investigation by looking at other dimensions. Such research would presumably uncover other possible decision problems for which the best strategy is to think about potentially high-value options as well as other possible decision problems for which the best strategy is to think about potentially low-value options.</p><p>Work in this area might eventually lead to the development of more general theories that specify the conditions under which the best strategy is to think about potentially high-value vs. potentially low-value options. Such theories would not be limited just to one particular setting but would provide more general insights about when each strategy is best. For example, it might turn out that all possible decision problems that have certain features will be problems for which the best strategy is to think about potentially low-value options.</p><p>To the extent that we are able to develop such an account, we open up the possibility of a new explanation of the effects observed in the present studies. It might be that people are not determining which options to consider by using a process that is even remotely like solving a POMDP. Instead, it might be that people are simply checking for certain features that serve as reliable cues to whether it is better to think of potentially high-value or potentially low-value options. Future empirical studies could directly test specific hypotheses of this form.</p><p>If we do find that people are responding to certain characteristics that are reliable indicators of which options are best to consider, we would face a further question as to how people come to be able to identify these in the first place.</p><p>One possible answer would be that people never need to learn them. Instead, the use of these features could simply be built into people's decision-making mechanisms. A second possibility would be that people are actually learning the use of these features over the course of numerous episodes of decision-making.</p><p>If people are indeed learning to use the relevant features, a question would arise as to how this learning takes place. One possible answer would be that people are making use of familiar mechanisms of model-free learning (e.g., <ref type="bibr" target="#b8">Gläscher et al. 2010)</ref>. On this view, people would have to be capable of model-free learning at an extremely abstract level. For example, over the course of numerous episodes of playing chess, people would have to be learning not only about the game of chess in particular but also about very abstract patterns regarding which options tend to be most worth thinking about. The development of algorithms for such learning is an important problem for future research-which some researchers have in fact already begun to address <ref type="bibr" target="#b15">(Jain et al. 2019)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.2.">Flexibility and inflexibility</head><p>Our results are also striking in light of existing research that suggests that the mechanism people use to figure out which options to consider are highly inflexible. Specifically, a number of studies suggest that people show an inflexible tendency to think of options that are generally good and statistically frequent <ref type="bibr" target="#b0">(Bear et al. 2020;</ref><ref type="bibr" target="#b21">Morris et al. 2021;</ref><ref type="bibr" target="#b24">Phillips et al. 2019)</ref>. For many decision problems, it will be helpful to think about options that are statistically frequent and generally good, but these studies seem to suggest that people tend to think about those options even when the decision problem is structured in such a way that it is obviously not helpful to think about those options.</p><p>For example, in one study, participants were asked to name the food they would least want for dinner <ref type="bibr" target="#b21">(Morris et al. 2021)</ref>. Clearly, in answering this question, it is helpful to think about foods that are generally bad, but the results indicated that participants actually showed a tendency to think first of foods that are generally good. Results like this one seem to suggest that there is an inflexible cognitive mechanism that generates options for people to consider when planning.</p><p>One way in which the present studies depart from previous work, however, is in the type of situation and options that participants were presented with. In previous studies, people were typically asked about options and situations for which people must already have had model-free values (e.g., how many hours of TV to watch a day). In such cases, it may be that the pre-existing value assignment gives rise to the inflexible mode of thought that previous studies have observed. In contrast, the present studies look at the options people think about in novel situations, where they do not already have model-free values with the various options. The absence of model-free values may have allowed for the flexibility observed in our experiments.</p><p>Another important distinction between the present studies and previous work is that between the conditions under which an option "comes to mind" and the conditions under which people actually simulate forward what would happen if they chose an option. Within existing research on which options come to mind, there is some evidence that the options that come to mind are determined by an inflexible mechanism. Yet, despite this, it might be that people make use of a more sophisticated and flexible mechanism to determine which simulations to run. Thus, in the present studies, it might turn out that the options with potentially high value are the first that come to mind in all conditions, but then it might be that people make use of a different psychological mechanism to determine which simulations to run, and that this mechanism sometimes selects the options with potentially low value.</p><p>To the extent that this latter answer turns out to be correct, a further question arises as to how far the flexibility extends. The present studies explore people's thinking in a context in which they are aiming to achieve a specific goal, but much of our thinking is not goal-directed-as in mind-wandering, in which people are not trying to address any particular decision problem (e.g. <ref type="bibr" target="#b14">Irving &amp; Thompson 2018;</ref><ref type="bibr" target="#b20">Mooneyham &amp; Schooler 2013)</ref>. We therefore face a question about which options people tend to simulate during mind wandering.</p><p>When people's minds are wandering, do they also show the sort of flexibility observed in the present studies? For example, does the degree to which they think about potentially high-value vs. potentially low-value options depend in part on the number of options they expect to be choosing between at decision time? Regardless of what the answer to this question turns out to be, such research promises to give us a real insight into the scope or boundary conditions of the phenomena we have been exploring here.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="5.3.">Conclusion</head><p>When people face a choice from a set of options, they often face a difficult problem. They find themselves faced with so many different options that it would not be possible to consider them all, and they therefore need to have some way of picking out certain specific options that are especially worthy of consideration.</p><p>In a series of studies, we looked at the options people tend to consider and found that people appear to be selecting options using remarkably sophisticated criteria. People don't simply show a general tendency to consider the potentially high-value options. Instead, they consider the high-value options on certain decision problems and the low-value options on others. A key task now will be to explain how people are able to show this flexibility and how to reconcile the flexibility they show on the sort of problems in this current study with inflexibility they show on other, seemingly related problems.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.">Supplementary Information</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.1.">POMDP Implementation Details for Experiment</head><p>To implement the experiment design formally, all pieces were designed so that they could only take one of four possible values: 0, 3, 5, and 7 (determined by the number of additional blocks the puzzle piece added after fitting into the block). In any given context, each piece could take on two possible states, capturing the possibility that the piece's true value matched the observed one or that it did not. For instance, the largest piece could have state 'appears to have value 7 but its true value is 0', or 'accurately appears to have value 7'. These representations produced a set of 64 basic states (2 6 ) for any given trial.</p><p>We then supplemented each of these basic states with a corresponding decision state, which identified a subset of actions that the agent can choose from. For instance, if the decision phase asked participants to choose one of two pieces, this would result in an additional 15 decision states (as there were 15 ways to select two objects from a set of six options) associated with each of the 64 basic states. Thus, our task state space consisted of 1024 states: 64 basic thinking states, and 960 (64*15) possible decision states.</p><p>We next defined the state of actions as consisting of six thinking actions and six selection options (one associated with each piece). To model the result of these actions, we assumed that a thinking action reveals the true value of the selected piece. We defined the observation space as consisting of four possible observations-0, 3, 5, and 7. To account for human reasoning errors, we varied the probability of getting a correct observation (i.e., believing that a piece fits when it does not, or believing that a piece does not fit when it does). To achieve this, we included a certainty parameter, which we varied from 95% (i.e., a 5% chance of making a reasoning error) to 100% (i.e., full confidence of no reasoning error) in steps of 1%, each implemented on a separate POMDP.</p><p>In these models, the probability of switching from the thinking phase to the decision phase was set to 30%. By contrast, we assumed that a selection always produces no observation (formally captured by adding an additional 'empty' observation). Thus, choosing to think about a piece provides information about the world, but choosing one piece does not.</p><p>To model the state-space change, we assumed that during the thinking phase, a thinking action had a 70% probability of leaving the world unchanged, and a 30% probability that the world would switch to the decision-making phase, with a discount parameter of 0.95. Critically, this probability is independent of which thinking action the agent takes. Thus, this probability does not represent a causal relation between thinking and state change. It instead expresses the idea that thinking requires time and that there is always a possibility that time will run out and the agent will have to make a choice. In contrast to thinking actions, selection actions always terminated the task. Whenever selection actions were chosen during the thinking phase, the task was terminated with no reward.</p><p>Similarly, selecting a piece that was not available for choice during the final phase also terminated the task with no reward, but selecting one of the pieces offered yielded the reward associated with the piece.</p><p>Finally, we assumed that agents' initial beliefs only assigned a positive probability to states where the observable values matched the sizes of the pieces, but leaving the true values unknown.</p><p>With these specifications, it is now possible to use POMDPs to compute how participants should prioritize different thinking actions as a function of different task variables, including the costs and reward of different actions, as well as the number of pieces that the agent will ultimately be able to select from. To estimate this solution, we used the SARSOP algorithm (Successive Approximations of the Reachable Space under Optimal Policies; <ref type="bibr" target="#b16">Kurniawati et al. 2008)</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.2.">POMDP Implementation Details for Experiment</head><p>We explored 20 different decision problems: 5 different choice parameters x 4 different snake parameters. In the choice parameter, we tested what strategy the agent would use when given 2, 3, 4, 5, or 6 choices in the decision phase.</p><p>In the snake parameter, we tested what strategy the agent would use when there were 2, 3, 4, or 5 possible snakes (of the 6 puzzle pieces). To account for the mismatch of beliefs from the possible states, we introduced 'noise' to the observations, such that the probability of getting the correct observation was set to 97%, and the 3% distributed among other possible observations. In the actual simulation the policy, we then 'hacked' the simulation, such that the agent always obtained observations of the piece not fitting in the 'easy snake' condition, and observations the piece fitting in the 'impossible snake' condition.</p><p>The agent received a reward of -500 if it selected the piece was the designated 'snake' of the stack.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head n="6.3.">Power Analyses</head><p>A pilot experiment on 16 participants was initially run for Experiment 1a, which suggested a sample size of n=27 per group to obtain a power of 98%. We rounded this up to n=30 per group (for a total of n=60), and this served as the sample size for Experiments 1a and 1c. For Experiment 1b, pilot experiments suggested a sample size of n=35 per group to obtain a power of 98% (for a total of n=70). This was then matched to be the sample size for Experiment 1b and 2.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>(a) Model predictions about what pieces to think about as a function of time step in Experiment 1.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>(b) Results from Experiment 1a. The bars depict mean response times in each condition. Error bars reflect 95% confidence intervals. (c) Results from Experiment 1b. (d) Results from Experiment 1c.tion mean. These participants were replaced, until a total of 60 participants was reached. Response accuracy and response times for the single trial were recorded for each participant. Only response times where participants responded correctly were included in the analysis. Participants who chose between the potentially high-value options responded faster in the decision phase (M=2.56s, SD=1.77s) than participants who chose between the potentially low-value options (M=5.20s, SD=3.82s), as depicted inFigure 2b(t(43.37) = 3.65, p &lt; .001, d = 1.06 over the logarithm of the reaction time). Including the incorrect answers did not yield any different results, t(55.41) = 3.51, p &lt; .001, d = 0.91.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>reached. Response accuracy and response times for the single trial were recorded for each participants. Only response times where participants responded correctly were included in the analysis. Participants who chose between the potentially high-value options responded faster in the decision phase (M=2.37s, SD=1.73s) than participants who chose between the potentially low-value options (M=3.99s, SD=2.23s), as shown in inFigure 2c(t(40.37) = 3.88, p &lt; .001, d = 1.08 over the logarithm of the reaction time). Including the incorrect answers did not yield any different results (t(65.24) = 4.14, p &lt; .001, d = 0.99).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>picted inFigure 2d(t(41.76) = 4.10, p &lt; .001, d = 1.21 over the logarithmic transformations of the distributions). Including the incorrect answers again did not yield any different results (t(55.15) = 2.77, p = .007, d = 0.72). There was no significant difference between the percentage of people who responded accurately when choosing between potentially high-value options vs. potentially low-value options (76.67% vs. 76.67%, Fisher's exact: p=1). To compare these results with those of Experiment 1a, we ran a 2 choice types (old vs. novel) x 2 choice values (potentially high-value options vs. potentially low-value options)</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head>Figure 3</head><label>3</label><figDesc>Figure 3: First actions of each model systematically varying the number of apparent low-value options (among which one was is a "snake" that provides negative cost), as well as the number of choices the agent is during the decision phase.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Figure 4 :</head><label>4</label><figDesc>(a)  Model predictions about what pieces to think about as a function of time step in the Easy-Snake condition of Experiment 2. The model prioritized searching for the snake, and then switched to evaluating the two high-value options. (b) Model predictions in the Impossible-Snake condition. The model, by prioritizing searching for the snake, spends the majority of time thinking about low-value pieces, at the cost of not being able to consider the high-value pieces. (c) Results from Experiment 2. The bars depict mean response times in each condition and error bars reflect 95% confidence intervals.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head></head><label></label><figDesc>3.4.1. MethodThis experiment was identical to Experiment 1a, except as noted. Sixty new participants from the Yale and New Haven community participated. One additional participant was recruited but excluded from the study based on preregistered criteria (see Results). The sample size was determined before data collection began based on a power analysis run on pilot data (see Supplemental Materials for details). During the decision phase, a new pair of high-value or low-value options were generated and presented to the participants. All methods and analyses were pre-registered (http://aspredicted.org/blind.</figDesc><table /><note>php?x=bw5n59).</note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">What comes to mind?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bear</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bensinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knobe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">194</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Das</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Rational use of cognitive resources in human planning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behavior</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Fixation patterns in simple choice reflect optimal information sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS computational biology</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="page">1008863</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">A survey of pomdp applications</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Cassandra</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Working notes of AAAI 1998 fall symposium on planning with partially observable Markov decision processes</title>
		<imprint>
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Apparently irrational choice as optimal sequential decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Howes</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the AAAI Conference on Artificial Intelligence</title>
		<meeting>the AAAI Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="page" from="792" to="800" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Mental rotation of random two-dimensional shapes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">A</forename><surname>Cooper</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognitive Psychology</title>
		<imprint>
			<date type="published" when="1975" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="20" to="43" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Monte-carlo tree search and rapid action value estimation in computer go</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gelly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Silver</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">175</biblScope>
			<biblScope unit="page" from="1856" to="1875" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">States versus rewards: dissociable neural prediction error signals underlying model-based and model-free reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gläscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Doherty</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="585" to="595" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Doing more with less: meta-reasoning and meta-learning in humans and machines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Chang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Grant</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Krueger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Opinion in Behavioral Sciences</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="24" to="30" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Rational use of cognitive resources: Levels of analysis between the computational and the algorithmic</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="page" from="217" to="229" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">A point-based pomdp planner for target tracking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Rong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE International Conference on Robotics and Automation</title>
		<imprint>
			<biblScope unit="page" from="2644" to="2650" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">On the instrumental value of hypothetical and counterfactual thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knobe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="517" to="522" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Normality and actual causal strength</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">F</forename><surname>Icard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Kominsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Knobe</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">161</biblScope>
			<biblScope unit="page" from="80" to="93" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">The philosophy of mind-wandering. The Oxford Handbook of Spontaneous Thought</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><forename type="middle">C</forename><surname>Irving</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Thompson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="page" from="87" to="96" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Measuring how people learn how to plan</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">R</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Callaway</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Annual Meeting of the Cognitive Science Society</title>
		<meeting>the Annual Meeting of the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="1956" to="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sarsop: Efficient point-based pomdp planning by approximating optimally reachable belief spaces</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kurniawati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hsu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Lee</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Robotics: Science and Systems</title>
		<imprint>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Strategy selection as rational metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">124</biblScope>
			<biblScope unit="page" from="762" to="794" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Resource-rational analysis: understanding human cognition as the optimal use of limited computational resources</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="page">43</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Prioritized memory access explains planning and hippocampal replay</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">G</forename><surname>Mattar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature neuroscience</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="page" from="1609" to="1617" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">The costs and benefits of mindwandering: a review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Mooneyham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Schooler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Canadian Journal of Experimental Psychology/Revue canadienne de psychologie expérimentale</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="11" to="18" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Generating options and choosing between them rely on distinct forms of value representation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Adam End Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1731" to="1746" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Pegasus: A policy search method for large mdps and pomdps</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">Y</forename><surname>Ng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">I</forename><surname>Jordan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Uncertainty in Artificial Intelligence Proceedings</title>
		<imprint>
			<date type="published" when="2000" />
			<biblScope unit="page" from="406" to="415" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Psychopy2: Experiments in behavior made easy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Peirce</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Gray</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Simpson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Macaskill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Höchenberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Sogo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Kastman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">K</forename><surname>Lindeløv</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavior Research Methods</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="195" to="203" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">How we know what not to think</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Phillips</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morris</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="1026" to="1040" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Mental rotation of three-dimensional objects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Shepard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Metzler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">171</biblScope>
			<biblScope unit="page" from="701" to="703" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Introduction to reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>MIT Press Cambridge</publisher>
			<biblScope unit="volume">135</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">One and done? optimal decisions from very few samples</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Vul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive science</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="599" to="637" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
