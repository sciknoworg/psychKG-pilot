<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Social truth queries: Development of a new user-driven intervention for countering online misinformation</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
				<date type="published" when="2023-03">March 2023</date>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Madeline</forename><surname>Jalbert</surname></persName>
							<email>mjalbert@uw.edu</email>
							<affiliation key="aff0">
								<orgName type="department">Center for an Informed Public</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Morgan</forename><surname>Wack</surname></persName>
							<affiliation key="aff0">
								<orgName type="department">Center for an Informed Public</orgName>
								<orgName type="institution">University of Washington</orgName>
								<address>
									<settlement>Seattle</settlement>
									<region>WA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Pragya</forename><surname>Arya</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">University of Southern California</orgName>
								<address>
									<settlement>Los Angeles</settlement>
									<region>CA</region>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Luke</forename><surname>Williams</surname></persName>
							<affiliation key="aff2">
								<orgName type="department">Politics Department</orgName>
								<orgName type="institution">Pomona College</orgName>
								<address>
									<settlement>Claremont</settlement>
									<region>CA</region>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="institution">United States</orgName>
							</affiliation>
						</author>
						<title level="a" type="main">Social truth queries: Development of a new user-driven intervention for countering online misinformation</title>
					</analytic>
					<monogr>
						<imprint>
							<date type="published" when="2023-03">March 2023</date>
						</imprint>
					</monogr>
					<idno type="DOI">10.1037/mac0000142</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:51+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>The spread of false information on social media is a growing problem that has necessitated the development of interventions to reduce its impact. We tested the potential effectiveness of social &quot;truth queries&quot;-user replies that draw attention to truth-as a novel intervention for reducing the impact of false information shared on social media. Participants were shown Tweets containing false information that appeared with user replies containing truth queries (Experiments 1-3), no replies (Experiments 1-3), or user replies unrelated to truth (Experiments 2-3) and asked to judge either the truth of the information contained in the Tweet or their likelihood of sharing it. We consistently found that social truth queries reduce belief in and reported intent to share Tweets containing false information compared to no replies or replies unrelated to truth. The findings suggest the usefulness of truth queries as a simple, flexible, user-driven approach to addressing online misinformation.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The spread of false information on social media is a growing problem necessitating the development of novel interventions to reduce its impact. Corrective messaging is a commonly proposed strategy and can often be effective in reducing belief in false information <ref type="bibr" target="#b0">(1)</ref><ref type="bibr" target="#b1">(2)</ref><ref type="bibr" target="#b2">(3)</ref>.</p><p>However, implementing corrective messaging on social media presents unique challenges. False information spreads rapidly online, and fact-checking can take time and substantive effort even in optimal use cases <ref type="bibr" target="#b3">(4)</ref>. Additionally, individuals may not trust the legitimacy of the fact-checking services that perform corrections, and social media companies may not be incentivized or have the resources to implement these corrections themselves <ref type="bibr" target="#b4">(5)</ref>. And while corrections made by other users can be effective <ref type="bibr" target="#b5">(6)</ref><ref type="bibr" target="#b6">(7)</ref><ref type="bibr" target="#b7">(8)</ref>, individuals may be hesitant to directly call out their peers or lack fact-checking resources to do so effectively or efficiently.</p><p>The difficulty of scaling fact-checking to match the spread of online misinformation has led to the development of alternative strategies that, instead of presenting users with explicit fact-checks, encourage users to consider the truth of information before deciding to share it. As discussed in further detail below, these strategies have demonstrated promise for improving the quality of misinformation shared online. Building off these approaches, we test the potential effectiveness of a novel strategy developed through insights from activists in the Global South that utilizes social "truth queries" as a flexible, low-cost, user-driven strategy to reduce the impact of misinformation spread on social media. Evidence from these tests highlights the potential of truth queries as an innovative and effective tool for countering the spread of online misinformation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Attention to Truth and Accuracy Nudges</head><p>While consuming information online, users may not stop to consider whether it is true.</p><p>Indeed, in daily life, evidence suggests that the default assumption is that information is true unless there are cues present to indicate that a communication may be uncooperative <ref type="bibr" target="#b8">(9)</ref><ref type="bibr" target="#b9">(10)</ref><ref type="bibr" target="#b10">(11)</ref><ref type="bibr" target="#b11">(12)</ref>.</p><p>Additionally, even when we can correctly determine whether something is true, we may instead focus on factors unrelated to truth when deciding what to share. When communicating with others, people often have goals other than accuracy, such as entertainment and forming social bonds <ref type="bibr" target="#b12">(13)</ref><ref type="bibr" target="#b13">(14)</ref><ref type="bibr" target="#b14">(15)</ref><ref type="bibr" target="#b15">(16)</ref>. The affordances of social media platforms lead users to seek out positive rewards in the form of likes and comments, which can take priority over the sharing of accurate information. Sharing habits built off these rewards may also turn to habitual sharing over time, making people less sensitive to the consequences of their sharing <ref type="bibr" target="#b16">(17)</ref>. In other words, there is a disconnect between people's sharing behavior and their judgments of information accuracy <ref type="bibr" target="#b17">(18,</ref><ref type="bibr" target="#b18">19</ref>).</p><p>An alternative approach to corrective messaging focuses on interventions that disrupt typical information processing tendencies and cue people to consider truth. Research suggests that giving people a reason to be skeptical and attend to truth can effectively increase critical analysis and reduce subsequent belief in false information <ref type="bibr" target="#b19">(20,</ref><ref type="bibr" target="#b20">21)</ref>. For example, Jalbert, Newman, and <ref type="bibr" target="#b24">Schwarz (2020)</ref> found that warning people that some information they were about to encounter was false reduced the impact of viewing that information on later belief. Similarly, drawing attention to truth can also reduce the intent to share false information on social media. In one set of studies, participants who were asked to explain how they knew headlines were true before deciding to share reported lower intentions of sharing fake (but not true) news stories <ref type="bibr" target="#b21">(22)</ref>. In another study, respondents asked to judge accuracy before sharing a post reduced their intent to share both true and false headlines, with the impact being greater for the false headlines.</p><p>Sharing intent decreased even further for both true and false headlines when participants were additionally asked to provide their rationale for why they believed the headlines were or were not accurate <ref type="bibr" target="#b22">(23)</ref>.</p><p>Along the same lines, recent research has also investigated the use of accuracy "nudges" (also called accuracy primes or prompts) to improve the quality of information shared online.</p><p>These nudges involve asking people to judge the truth of a single headline with the goal of getting users to shift attention to the truth of subsequent information they encounter. These nudges have been found to reduce the intent to share false headlines and increase the quality of information shared <ref type="bibr" target="#b23">(24)</ref>. Similar to the findings about the effect of warnings of false information on later truth judgments <ref type="bibr" target="#b24">(25)</ref>, accuracy nudges seem to be effective not necessarily because they increase how much people think about information, but rather because they change what people are thinking about, with increased consideration of the information's veracity <ref type="bibr" target="#b25">(26)</ref>.</p><p>Strategies that orient users to consider information truth have advantages over traditional fact-checking approaches because they can be implemented quickly, are scalable, and do not require analysis of the quality of news. Unfortunately, these strategies also have their limitations: they disrupt the user's normal experience on social media, often involve additional effort on the part of the user, and require that users maintain a focus on accuracy for all posts they encounter. While this focus may be possible in short experimental sessions, it is likely unrealistic to continue for long periods of social media use, as users will return to using social media in habitual ways. In addition, strategies integrated into social media platforms also require buy-in from social media companies to implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Present Strategy: Social Truth Queries</head><p>In light of the limitations of existing strategies, organizations have started to develop their own community-driven strategies to combat the spread of harmful information online. One such non-profit organization is the Centre for Analytics and Behavioural Change, which created Democracy Yethu Kaofela, a project targeting election-related misinformation in South Africa.</p><p>This project mobilizes community volunteers to respond to misinformation online using techniques developed by a team of in-house dialogue facilitators with the goal of reducing the impact of this misinformation on future viewers. These replies do not require explicit fact-checking and often take the form of questions. For example, a user might reply "how do you know this is true?" or "where did you learn this?".</p><p>Inspired by the approach used by Democracy Yethu Kaofela and the success they have observed, we aimed to test key principles behind this intervention. Specifically, we investigated whether the presence of user replies containing questions asking about truth or truth criteriacould reduce other users' belief in and intent to share social media posts containing false information.</p><p>Research on judgment suggests that people utilize a limited set of truth criteria when deciding whether or not a claim is true <ref type="bibr" target="#b20">(21,</ref><ref type="bibr" target="#b26">(27)</ref><ref type="bibr" target="#b27">(28)</ref><ref type="bibr" target="#b28">(29)</ref>: Compatibility (Is the claim compatible with other things they believe?), coherence (Is it internally coherent?), credibility (Does it come from a credible source?), consensus (Do others believe it?), and evidence (Is there supporting evidence?). When evaluating whether something is true, people will typically consider somebut not all -of these criteria. In addition to directly drawing attention to truth by explicitly asking if the information is true, we anticipate that people can be cued to consider truth by drawing attention to criteria bearing on truth.</p><p>We coin the term "truth queries" to refer to questions that draw attention to these truth criteria or to truth more generally. This represents the first time these types of questions have been defined and systematically tested as a strategy for addressing false information. In our studies, we created and tested a set of these truth queries that appeared as user replies to social media posts containing false information. For example, a reply drawing attention to the information source might ask, "where did you learn this information?", while a reply drawing attention to the amount of evidence for the information might ask, "what is the evidence for this?". Allowing users to utilize an array of truth queries that appeal to different truth criteria creates a flexible approach that does not require a user to post a specific response, but rather choose a response they prefer that matches the context of the correction. Current interventions focusing on attention to accuracy usually ask the same question over and over, which may have a reduced impact over time as people adapt to the question. Here, users may adapt their responses from an array of different truth queries to fit the specific context. In addition to the flexible nature of the response options, this truth query strategy has several advantages over existing attention to accuracy: it can be implemented by social media users themselves, is integrated into the viewer's normal social media experience, and can be targeted at specific posts containing problematic false information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Social Truth Queries: Beyond Attention to Accuracy</head><p>Social truth queries may be effective for reasons beyond merely getting users to consider accuracy. This strategy involves other users sharing replies that express uncertainty or doubt about the content of social media posts, communicating that there may be a lack of social consensus around that information. This information is important given how people look to the beliefs of others as a way to assess accuracy. The perception that a belief is widespread fosters its acceptance -if many people believe something, there must be something to it <ref type="bibr" target="#b29">(30)</ref>. Consistent with this idea, previous research has found that people use the comments of other users as cues to the credibility of the information, with comments expressing concerns regarding information credibility reducing users perceived credibility <ref type="bibr" target="#b30">(31)</ref>. In addition, people are more likely to share -and less likely to fact-check something -when it has indicators of high social engagement on social media such as likes and shares <ref type="bibr" target="#b33">(32)</ref>. In the absence of these user replies or other cues to truth, people often nod along with the information presented. Truth queries may disrupt these assumptions and communicate to readers that a claim is controversial.</p><p>An additional consideration is that, because user replies are often shared directly on the post containing the false information (such as on Twitter), sharing the post also means sharing the attached reply expressing uncertainty. Given the motivation of people to affiliate and receive the approval of others <ref type="bibr" target="#b35">(33)</ref>, people may be less willing to share a post on social media when a comment questioning its truth comes attached to it, separate from whether or not they believe the information in the post to be true.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Present Investigations</head><p>We conducted three online studies with Amazon MTurk workers (Experiment 1-2) and Prolific workers (Experiment 3) to investigate the effectiveness of social truth queries -user replies containing questions asking about truth or truth criteria -as a novel approach to reduce belief in and the intent to share false information posted on social media. Our experiments followed the same basic methodology. In all three of our studies, participants (Experiment 1 N = 200, Experiment 2 N = 600, Experiment 3 N = 600) were asked to view a series of Tweets containing false information. These posts appeared either with user replies containing truth queries (Experiments 1-3), user replies unrated to truth (Experiments 1-2), or no replies (Experiments 1-3). Participants were randomly assigned to judge either the truth of the information contained in each post or rate how likely they would be to share each post.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>In Experiment 1, we investigated whether posts containing false information were judged to be less true and less likely to be shared when they appeared with user replies containing social truth queries that draw attention to truth and truth criteria, such as evidence or source credibility (e.g., "How do you know that?", "What proof is there that they're doing this?", "Can you share where you learned this?") compared to when they appeared with no replies (for details, see methods).</p><p>As predicted, Tweets containing false information were judged to be significantly less true when they appeared with a truth query reply, M = 2.91, 95% CI  ; N = 300, Prolific workers) viewed a series of Tweets and for each, answered the question "Is the information contained in this above Tweet true or false" on an unlabeled six-point scale from "Definitely true" (coded as 6) to "Definitely false" (coded as 1). In Experiment 1, participants rated 8 key Tweets containing false information, 4 of which appeared with a user reply containing a truth query and 4 of which appeared with no reply. In Experiment 2, participants rated 6 key Tweets (2 with a social truth query reply, 2 with no reply, 2 with a neutral, non-truth related reply), and in Experiment 3, participants rated 24 Tweets (8 with a social truth query reply, 8 with no reply, 8 with a neutral, non-truth related reply). Tweets were presented in a randomized order along with 4 filler Tweets. ; N = 300, Prolific workers) viewed a series of Tweets and for each, answered the question "How likely would you be to share this Tweet online?" on an unlabeled six-point scale from "Extremely unlikely" (coded as 1) to "Extremely likely" (coded as 6). In Experiment 1, participants rated 8 key Tweets containing false information, 4 of which appeared with a user reply containing a truth query and 4 of which appeared with no reply. In Experiment 2, participants rated 6 key Tweets (2 with a social truth query reply, 2 with no reply, 2 with a neutral, non-truth related reply), and in Experiment 3, participants rated 24 Tweets (8 with a social truth query reply, 8 with no reply, 8 with a neutral, non-truth related reply). Tweets were presented in a randomized order along with 4 filler Tweets.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>One possible concern with interpreting the result of Experiment 1 is whether it was our truth query replies specifically that reduced ratings of truth and sharing, or whether the effect could generally be caused by the mere presence of any reply. Thus, in Experiment 2, we included an additional within-subjects condition in which participants saw the Tweets containing misinformation appearing with replies that were not related to truth or truth criteria -in other words, neutral, non-truth-related replies. For example, in response to a post containing false information related to McDonalds, a neutral reply might be, "I just got home from McDonalds! Didn't get ice cream though". We expected that Tweets that appeared with truth queries would be judged as less true and less likely to be shared compared to when they appeared with these neutral replies.</p><p>There was a significant overall effect of reply condition on truth ratings, F (2, 1488) = 8.01, p &lt; .001. Posts appearing with truth queries were rated to be less true, M = 3.12, 95% CI </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Both Experiments 1 and 2 found that posts containing false information were judged to be less true and less likely to be shared when they appeared with user replies containing truth queries compared to when they appeared with no replies (Experiments 1-2) or with a neutral, non-truth related reply (Experiment 2). In these two studies, we always paired each Tweet with the same truth query that was created specifically for that Tweet. In Experiment 3, we created generally applicable truth query replies that could appear with different Tweets (see <ref type="table" target="#tab_0">Table 1</ref>). We then varied which Tweet appeared with which of our eight total truth queries between participants. This allowed us to test the generalizability of our truth queries and see if there were certain types of truth queries (e.g., ones that appeal to specific truth criteria) that may be driving our observed effects, or whether a variety of truth queries appealing to different truth criteria may be used to reduce the impact of false information spread on social media. Hypothesis and analysis for this experiment were preregistered at https://aspredicted.org/cc6v3.pdf. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Analysis by Reply</head><p>We then looked at the individual impact of each of the eight truth queries used in Experiment 3. Beta statistics and 95% CIs by truth query (compared to both no reply and neutral replies) can be found in <ref type="figure">Figures 3 and 4</ref> respectively, with full statistics reported in the Supplementary Materials (see <ref type="table" target="#tab_0">Table S1</ref> and S2). These analyses failed to reveal that any specific truth queries were consistently driving the observed effects on truth and sharing judgments.</p><p>Rather, a broad range of truth queries appeared to be effective in reducing truth and sharing ratings across different Tweets. As the impact of each truth query reply utilizes a different subset of six Tweets, we do not wish to put too much on any one b or direct comparison between any of our truth criteria here. However, we do find it encouraging that a broad range of truth criteria demonstrate effectiveness on a variety of Tweets. <ref type="figure">Fig. 3</ref>. Beta statistics and 95% CIs by truth query for the difference in truth and sharing ratings between posts appearing with each truth query compared to when those same posts appeared with no replies. <ref type="figure">Fig. 4</ref>. Beta statistics and 95% CIs by truth query for the difference in truth and sharing ratings between posts appearing with each truth query compared to when those same posts appeared with no replies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Effect Size Analyses</head><p>For truth ratings, the total effect size across  <ref type="figure" target="#fig_1">Figure S1</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Across three studies, we found a consistent effect of user replies containing truth queries on truth and sharing judgments: Tweets containing false information that appeared with truth queries were judged to be significantly less true and significantly less likely to be shared compared to Tweets that appeared with no replies (Experiments 1-3) and Tweets that appeared with neutral replies unrelated to truth (Experiments 2-3). These effects were driven by a broad range of truth queries appealing to various truth criteria, such as evidence and social consensus.</p><p>In Experiment 3, we systematically created and tested a set of eight truth queries appealing to different truth criteria. This allowed us to demonstrate the effectiveness of a variety of truth queries, and see that this effectiveness was not limited to specific Tweet-truth query reply pairings (Experiment 3).</p><p>At a more basic level, this work for the first time defines "truth queries" -questions that draw attention to truth or criteria used to access truth (21, 27-29) -and demonstrates their potential utility. More broadly, our findings provide compelling evidence for the potential generalizability and flexibility of using social truth queries as a novel strategy for individual users to address a broad range of online misinformation. Importantly, this intervention addresses gaps that exist in current misinformation interventions in several key ways: it is user-driven, flexible, does not require formal fact-checking, and is integrated into a user's normal social media experience.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Potential Mechanisms and Applications</head><p>Our findings that social truth queries reduced belief in and the intent to share false information are in line with research demonstrating the impact of drawing attention to truth on these outcomes <ref type="bibr" target="#b19">(20)</ref><ref type="bibr" target="#b20">(21)</ref><ref type="bibr" target="#b21">(22)</ref><ref type="bibr" target="#b22">(23)</ref><ref type="bibr" target="#b23">(24)</ref>. When people browse and share information online, they may not stop to consider its veracity and assume truth as a default. In addition, other motives, such as entertainment and seeking the approval of peers through the form of engagement may take precedence over accuracy goals. People may also share information -including false information -out of habit <ref type="bibr" target="#b16">(17,</ref><ref type="bibr" target="#b36">34)</ref>. Cues that lead users to shift attention to information truth may shift these patterns of behavior and allow people to catch false information before sharing <ref type="bibr" target="#b37">(35)</ref> and increase the relevance of information truth as a criterion to consider before sharing.</p><p>The effectiveness of the broad range of different truth queries also indicates that direct appeals to truth may not be necessary to be effective. Merely drawing attention to the criteria people use to judge truth -such as the information's source or the presence of evidence -may have a similar effect. An exciting implication of this finding is that existing attention to accuracy interventions, such as accuracy nudges <ref type="bibr" target="#b18">(19,</ref><ref type="bibr" target="#b23">24)</ref> or pausing to consider truth (22) may be able to utilize a broader range of prompts that appeal to various truth criteria rather than relying on the same question each time.</p><p>We also suspect that truth queries are likely to be effective for reasons beyond attention to accuracy, such as perceptions of social consensus and concerns about self-presentation. As our truth queries were posted by other users, they may also convey that there is a lack of social Another consideration is the impact of truth queries on belief in credible information.</p><p>While we only tested the impact of truth queries targeting false information, users may also choose to ask these questions on posts containing credible information. Past research utilizing existing attention-to-accuracy interventions has reported mixed findings on their impact on true information. For example, while some research has found that pausing to consider truth only reduced the reported likelihood of sharing false -but not true -news headlines <ref type="bibr" target="#b21">(22)</ref>, other research has found that being asked to judge accuracy can reduce the sharing of both true and false news headlines <ref type="bibr" target="#b22">(23)</ref>. We suspect the impact of these truth queries depends on the nature and content of these posts.</p><p>The effectiveness of social truth queries is also likely to depend on the specific affordances of the online environment. For example, as some algorithms prioritize post engagement in deciding what posts users see, one consideration is whether the addition of truth queries could have the unintended consequence of exposing more users to problematic information. Platforms also vary in how post comments are presented to users, and truth queries may be more effective on platforms where they have a higher degree of visibility to other users.</p><p>Future research may fruitfully investigate the conditions under which social truth queries are maximally effective in reducing the impact of false information.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion</head><p>While additional research is needed to investigate the use of this strategy in different contexts-including those that more closely resemble real online information environments-our initial work provides promising evidence for the effectiveness of social truth queries, a simple, flexible, user-driven strategy for reducing the impact of misinformation online.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>Experimental Design. Experiment 1 used a 2 (reply type: truth query or no reply) level within-subjects design, with each participant making either truth or sharing judgments (between subjects). We counterbalanced which half of the Tweets appeared with a truth query reply between participants to control for item effects.</p><p>Participants. We used CloudResearch to recruit online workers located in the United</p><p>States from Mechanical Turk. Participants met CloudResearch's requirements for approved participants and had completed 100+ HITs with a 95%+ HIT approval rating. We additionally used CloudResearch's filters to select participants that regularly used Twitter. Participants were required to take the survey on a computer (not a tablet or phone). The study was estimated to take 10 minutes or less and participants were paid $1.33 for their time.</p><p>Based on a medium effect size of d = 0.50, a sample size of 54 would be required to detect an effect of a repeated measures design, with a correlation between repeated measures of .5, α = .05, power (1-β) = .95, and two-tailed, according to G*Power <ref type="bibr" target="#b38">(36)</ref>. We chose to overpower from this and recruit 200 participants, 100 per between-subjects condition. In total, Materials.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post content creation.</head><p>We created stimuli in the form of Tweets, which were based on myths that had been fact-checked on Snopes and found to be false. To create the content of the Tweets containing false information, we turned these myths into posts that resembled the types of posts present on Twitter. This content was then normed for truth (N = 48) and sharing (N = 48)</p><p>by Mechanical Turk users recruited through CloudResearch. Participants met CloudResearch's requirements for approved participants and had completed 100+ HITs with a 95%+ HIT approval rating. In this norming, participants rated a series of 20 statements in the form of plain text that they were told were posts made on Twitter. For each, participants judged either truth ("Is the information contained in this above Tweet true or false", unlabeled six-point scale from "Definitely true" (coded as 6) to "Definitely false" (coded as 1)) or sharing ("If you were to see the above Tweet on social media, how likely would you be to share it?", unnumbered 6-point response scale from "Extremely unlikely" (coded as 1) to "Extremely likely" (coded as 6)).</p><p>Eight statements from this norming were then selected and made into the format of Tweets. Statements were selected such that they were rated in the middle of truth (median truth ratings 2 or 3 on the 6-point scale). From there, we created two counterbalances out of the eight key Tweets such that half of the claims would appear with truth queries for some participants and the other half would appear with truth queries for other participants. Claims were similar in truth ratings (M truth CB 1 = 3.09; CB 2 = 3.01), and sharing ratings (M sharing CB 1 = 2.19; CB 2 = 2.31) across counterbalances.</p><p>Reply creation. Next, we created truth query replies to match each of our selected Tweets. These replies were intended to draw attention to the truth of the post or to criteria relevant to truth (such as evidence or information source) without doing any type of fact-checking. Examples include "Can you share where you learned this?" and "What proof is there that they're doing this?".</p><p>Tweet creation. To create realistic-looking Tweets and replies, we selected stock photos and created names and handles from common U.S. first and last names from census data. We checked that the names we selected were not the same as any well-known celebrities and that the handles we created were currently unused. Examples of one of these Tweets appearing with their truth query reply can be seen in <ref type="figure">Figure 5</ref>.  <ref type="figure">5</ref>. Examples of Twitter stimuli used in Experiment 1. These images represent the versions that appeared with the truth query replies. Versions in the no reply condition showed the same main Tweet but were cropped right above the reply.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure.</head><p>Twitter Judgments. Participants were told that they would see a series of 12 Tweets (posts made on Twitter) and their responses and were asked to imagine that they came across these Tweets while using Twitter. Participants were randomly assigned to make either truth ratings or sharing ratings (between subjects) for each Tweet.</p><p>Participants in the truth rating conditions answered the question "Is the information contained in this Tweet true or false" and made their response on a six-point unnumbered scale with the endpoints "Definitely true" (coded as 6) on the left and "Definitely false" (coded as 1)</p><p>on the right. Participants in the sharing rating condition answered the question "How likely would you be to share this Tweet online?" on a six-point unnumbered scale with the endpoints "Extremely unlikely" (coded as 1) on the left and "Extremely likely" (coded as 6) on the right.</p><p>Participants were additionally informed that some of the Tweets had responses from other users, and that for these Tweets they should consider the Tweet from the original poster when answering the question. They were also told to not search online when completing the studies, and if they were unsure of an answer, to make their best guess.</p><p>Participants then saw the 12 Tweets presented: eight key Tweets containing false information (half with a truth query reply and half with no reply) and four fillers containing true information. These Tweets appeared one at a time in random order and participants made their ratings as they appeared. For the eight key Tweets, participants saw one of the two possible counterbalances, such that four Tweets that were presented with truth query replies in one counterbalance appeared with no replies in the other counterbalance, and the four Tweets that appeared with no replies then appeared with truth query replies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Individual difference measures.</head><p>After making these ratings, participants completed a seven-item Cognitive Reflection Test (CRT): The first three items were a reworded version of the <ref type="bibr">Frederick (2005, 37)</ref> via <ref type="bibr">Shenhav et al. (2012, 38)</ref>, followed by the four-item CRT by <ref type="bibr">Thomson &amp; Oppenheimer (2016, 39)</ref>. We included these measures to explore whether individual differences in tendencies to utilize intuitive (vs. analytical) processing moderated the impact of truth queries on judgments of truth and sharing. We failed to find evidence that this was the case and do not discuss these measures further in this manuscript, but a full report of this analysis can be found in the Supplementary Materials section 2.</p><p>Demographics. Finally, participants answered a few demographic questions including age, gender, and political orientation.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>Experimental Design. Experiment 2 used a 3 (reply type: truth query, neutral reply, or no reply) level within-subjects design, with each participant making either truth or sharing judgments (between subjects). We additionally counterbalanced which Tweets appeared with which reply across participants to control for item effects.</p><p>Participants. As in Experiment 1, we used CloudResearch to recruit online workers located in the United States from Mechanical Turk that met CloudResearch's requirements for approved participants and had completed 100+ HITs with a 95%+ HIT approval rating. We additionally used CloudResearch's filters to select participants that regularly used Twitter.</p><p>Participants were again required to take the survey on a computer (not a tablet or phone). The study was estimated to take 10 minutes or less and participants were paid $1.33 for their time.</p><p>Based on a small effect size of Cohen's d of 0.20, a sample size of 257 would be required to detect an effect of a repeated measures design with three levels, with a correlation between repeated measures of .5, α = .05, power (1-β) = .95, and two-tailed, according to G*Power <ref type="bibr" target="#b38">(36)</ref>.</p><p>We chose to slightly over-power from this number and recruit 600 participants total, 300 per Tweet had a version with no response, a version with a truth query, and a version with a neutral response. The truth query and neutral responses both came from the same user profile and were identical other than the content of the response itself.</p><p>We selected six total Tweets to use from our original norming. As in Experiment 1, we counterbalanced our Tweet-reply pairings such that each Tweet could appear in each reply condition between participants. To do this, we divided our six Tweets into three sets of two two with no replies) and four fillers. To control for item effects, we randomized which set of two Tweets appeared with truth queries, neutral replies, and no replies between participants.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Experimental Design. The basic design for Experiment 3 was the same as for Experiment 2. We used a 3 (reply type: truth query, neutral reply, or no reply) level within-subjects design, with each participant making either truth or sharing judgments (between subjects). We additionally counterbalanced which Tweets appeared in which reply condition between participants, and, when Tweets appeared in the truth query condition, we varied which truth queries they appeared with between participants. This allowed us to control for item effects and test the effectiveness of different truth queries across items.</p><p>Participants. Participants were Prolific users located in the U.S. who reported using</p><p>Twitter and had a minimum approval rating of 95%. Based on the same power analysis as in Experiment 2, we again aimed to recruit 600 participants. Overall, 600 participants completed the study (M age = 36.23, SD = 12.22; 288 male, 292 female, 16 other, 4 prefer not to say), 300 in the truth judgment condition and 300 in the sharing judgment condition. Participants were required to take the survey on a computer (not a tablet or phone). The study was estimated to take 10 minutes or less and participants were paid $1.50 for their time.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials.</head><p>Post content creation. Materials were again Tweets that we created to contain false information. This time, in addition to myths fact-checked on Snopes, we also adapted additional false claims that were fact-checked on other online sources or used as materials by <ref type="bibr">Ecker, Lewandowsky, and Chadwick (2020, 40)</ref> into the content of our Tweets.</p><p>The contents of our Twitter posts were normed on Prolific using participants recruited with the same filters as our main study. We normed 56 claims total, with each participant rating either the first half or last half of the Tweets on truth (Is this information contained in this Tweet true or false, Definitely true; Definitely false), sharing (How likely would you be to share this Tweet online? (Extremely unlikely, Extremely likely) and familiarity (How familiar are you with the information contained in this Tweet?; Not at all familiar; Extremely familiar). We recruited 240 participants total, with each claim being rated on truth, sharing, and familiarity by 39-41 participants.</p><p>From this norming, we selected 24 claims to be used as the content of Tweets in our study. Claims were selected to be ambiguous in terms of truth (M = 3.47, ranging between 3.00 Reply creation. For this study, we created a set of eight general truth queries that could be used interchangeably in response to different posts. These claims were created to draw attention to different truth criteria <ref type="bibr" target="#b20">(21,</ref><ref type="bibr" target="#b28">29)</ref> or truth generally. A list of these eight replies by relevant truth criteria can be found in <ref type="table" target="#tab_0">Table 1</ref>. We then assigned our eight possible truth queries to each of the eight Tweets in each of the three sets we had created earlier. For each set, we created two different Tweet-response counterbalances such that the same Tweet did not always appear with the same truth query. Truth query replies were paired with Tweets in the following way: To create the first counterbalance, we fully randomized the assignment of the truth queries to the Tweets. For the second counterbalance, we randomized this assignment again, with the condition that each Tweet would have to appear with a truth query from a different category than the first order (e.g., a Tweet couldn't appear with questions related to, say, credibility in both counterbalances). In one instance where the truth query did not follow well given the wording of the Tweet (Tweet: "Why is Starbucks replacing single-use plastic straws with paper straws in single-use plastic packaging? It makes no sense" Truth query: "Does that make sense given what else you know?") we used the next randomized option. We again additionally created neutral, non-truth-related replies that match the content of each Tweet. Each Tweet always appeared with the same neutral reply when in the neutral condition.</p><p>Procedure. The procedure was again identical to Experiments 1 and 2, except this time participants rated 28 Tweets total: 24 key Tweets (eight with truth query replies, eight with neutral replies, and eight with no replies) and four fillers. Which set of eight Tweets appeared with each reply type was randomized between participants, and participants were additionally randomly assigned to one of the two counterbalances of Tweets-truth query pairings for the eight Tweets they saw with truth query replies.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Statistical Analysis</head><p>Data for all studies was analyzed using multilevel modeling with the lme4 package (version 1.1-30) and lmerTest (version 3.1-3) packages in RStudio. We performed separate analyses for the truth and sharing judgments. To investigate the impact of reply condition on truth and sharings ratings, we conducted a mixed effect analysis with reply condition as a fixed factor and item and participant as random factors. We additionally tested for random slopes of reply condition across item and person, but our models failed to converge so we did not include any random slopes in the final models. A parallel analysis using a fixed effect approach is additionally reported for all studies in the Supplementary Materials section 1.</p><p>In Experiment 3, we systematically created and varied a set of eight truth queries. We counterbalanced which Tweets appeared with each of the eight truth queries between participants (for details, see method). This allowed us to investigate whether the impact of truth queries was generalizable across different types of truth queries by looking at truth and sharing ratings by individual truth queries. With our counterbalancing, each of our truth queries appeared with 6 of the 24 total key Tweets used in this study. Thus, for these analyses, we limited our comparisons to the ratings of those 6 Tweets when they appeared with a specific truth query to those same 6</p><p>Tweets when they appeared with no reply or a neutral reply. We then ran the same mixed effect analysis as before for each truth query.</p><p>Finally, as all of our three studies utilized a similar design, we performed a mini-meta analysis for both truth and sharing ratings across our three studies using Comprehensive Meta-Analysis Software (version 4) to get an overall estimate of effect size. Due to the small number of studies, tau-squared was pooled across studies, following recommendations by <ref type="bibr">Borenstein, Hedges, Higgins, &amp; Rothstein (2009, 41)</ref>. A random effects model was used and effect sizes were fixed across sub-groups and corrected for small sample biases <ref type="bibr" target="#b43">(41)</ref>. We grouped our effects into two subgroups: the difference in ratings between posts that appeared with truth query replies and posts that appeared with no replies, and the difference in ratings between posts that appeared with truth query replies and posts that appeared with neutral, non-truth-related replies.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>[2.51, 3.32], compared to when they appeared without this reply, M = 3.11, 95% CI [2.70, 3.51], t (692) = 2.35, p = 0.02, b = 0.20 (95% CI [0.03, 0.36]). We also found a significant effect of reply type on sharing ratings. Participants said they would be less likely to share these Tweets when they appeared with a truth query reply, M = 2.49, 95% CI [2.11, 2.86], than when they appeared without this reply, M = 2.70, 95% CI [2.32, 3.07], t (692) = 2.28, p = 0.02, b = 0.21, 95% CI [0.03, 0.39]). See Figures 1 and 2 density plot of mean participant truth and sharing ratings by reply condition for this Experiment and Experiments 2 and 3.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Fig. 1 .</head><label>1</label><figDesc>Density plots showing mean truth ratings by participant across Experiments. In these Experiments, participants (American Twitter users, Experiment 1 N = 100, Amazon MTurk workers; Experiment 2 N = 299, Amazon MTurk workers; Experiment 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Fig. 2 .</head><label>2</label><figDesc>Density plots showing mean sharing ratings by participant across Experiments. In these Experiments, participants (American Twitter users, Experiment 1 N = 100, Amazon MTurk workers; Experiment 2 N = 301, Amazon MTurk workers; Experiment 3</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head>[ 2 .</head><label>2</label><figDesc>62, 3.63], than posts with no replies, M = 3.27, 95% CI [2.78, 3.78]), t (1488.0) = -2.00, p = 0.046, b = -0.15 (95% CI [0.00, -0.30]), and posts with neutral replies, M = 3.43, 95% CI [2.92, 3.93], t (1488.0) = 4.00, p &lt; 0.001, b = 0.30 (95% CI [0.16, 0.45]). When comparing posts with no replies and posts with neutral replies, those with neutral replies were rated to be significantly more true, t (1488.0) = 2.00, p = 0.045, b = 0.15 (95% CI [0.00, 0.30]). In addition, we again found a significant overall effect of reply type on sharing ratings, F (2, 1498) = 5.74, p = .003, with participants responding that they would be less likely to share Tweets when they appeared with a truth query reply, M = 2.46, 95% CI [2.00, 2.93], than when they appeared with no reply, M = 2.63, 95% CI [2.17, 3.09], t (1498.0) = 2.18, p = 0.029, b = 0.17 (95% CI [0.02, 0.32]), or with a neutral reply, M = 2.72, 95% CI [2.25, 3.18], t (1498) = 3.34, p &lt; .001, b = .26, 95% CI [0.11, 0.40]. Participants did not differ in their ratings of how likely they would be to share posts with neutral replies compared to posts with no reply, t (1498.0) = 1.16, p = 0.248, b = 0.09 (95% CI [-0.06, 0.24]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>all conditions was d = -0.33, 95% CI [-0.47, -0.19]. There was no evidence of a significant difference between the size of the effect when looking at the difference between truth query replies and no replies, d = -0.32, 95% CI [-0.48, -0.11] compared to the difference between truth query replies to neutral replies, d = -0.39, 95% CI [-0.59, -0.16], Q (1) = 0.29, p = .588. For sharing ratings, the total effect size across all conditions was d = -0.16, 95% CI [-0.21, -0.12]. There was again no evidence of a significant difference between the size of the effect when looking at the difference between truth query replies and no replies, d = -0.17, 95% CI [-0.23, -0.11] compared to the difference between truth query to neutral replies, d = -0.16, 95% CI [-0.22, -0.10], Q (1) = 0.03, p = .873. A forest plot of all effect sizes can be found in the Supplementary Materials (see</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>consensus surrounding the information. Communicating to users that information is disputed among peers may decrease belief in that information as individuals look to what others believe as a way to assess truth (30). A lack of perceived consensus may additionally reduce the desire to share the post if the truth query reply remains on the original post due to individual self-presentation motives. Limitations and Future Directions While our initial results are promising, the complex nature of the online information environment lends itself to additional considerations. The impact of social truth queries likely depends on contextual factors such as the content of the original post, the characteristics of the users involved, and the presence of additional post engagement. Our studies focused on Tweets containing false information about non-political topics involving unfamiliar users, with minimal engagement outside of our neutral or truth query replies. The influence of truth queries may look different if, say, that false information pertained to polarized topics, came from a familiar user, or had already received high levels of engagement.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>200 participants completed the study, (M age = 38.25, SD = 11.80; 124 male, 72 female, 3 other, 1 prefer not to say), with 100 in the truth judgment condition and 100 in the sharing judgment condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head>Fig.</head><label></label><figDesc>Fig. 5. Examples of Twitter stimuli used in Experiment 1. These images represent the versions that appeared with the truth query replies. Versions in the no reply condition showed the same main Tweet but were cropped right above the reply.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head>and 4 . 3 = 3 .</head><label>433</label><figDesc>83), be above floor levels on sharing ratings (M = 2.32, ranging between 1.90 and 2.72), and not be too familiar (M = 2.07, range: 1.15 -3.45). These 24 claims were then divided into three sets of eight claims, with each set having similar truth (M CB 1 = 3.44; CB 2 = 3.48, CB 50), sharing (M CB 1 = 2.31; CB 2 = 2.35, CB 3 = 2.30), and familiarity (M CB 1 = 2.14; CB 2 = 2.02, CB 3 = 2.05) ratings.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 .</head><label>1</label><figDesc>Truth Queries and Their Corresponding Truth Criteria for Experiment 3. Replicating our prior experiments, we found a significant effect of reply condition on truth judgments, F (2, 6876.7) = 38.59, p &lt; .001. Once again, Tweets containing false information were judged to be less true when they appeared with a truth query reply, M = 3.15, 95% CI [2.94, 3.36], compared to when they appeared without this reply, M = 3.45, 95% CI [3.24, 3.66], t (6876) = -7.61, p &lt; .001, b = -0.30 (95% CI [-0.38, -0.22]) or when they appeared with a neutral reply, M = 3.45, 95% CI [3.24, 3.66], t (6876) = -7.59, p &lt; .001, b = -0.30 (95% CI [-0.38, -0.22]). Unlike in Experiment 2, we did not find a significant difference in truth ratings for posts appearing with a neutral reply vs. with no reply, t (6878) = -0.016, p = .988, b &lt; 0.01</figDesc><table><row><cell>Truth Query</cell><cell>Truth Criteria</cell></row><row><cell>1. Does that make sense given everything</cell><cell>Compatibility: Is it compatible with other</cell></row><row><cell>else you know?</cell><cell>things I know?</cell></row><row><cell>2. Where did you learn this?</cell><cell>Credibility: Does it come from a credible</cell></row><row><cell>3. How do you know that?</cell><cell>source?</cell></row><row><cell>4. Do other people believe that?</cell><cell>Consensus: Do other people believe it?</cell></row><row><cell>5. What evidence is there for that?</cell><cell>Evidence: Is there supporting evidence?</cell></row><row><cell>6. Is there proof of that?</cell><cell></cell></row><row><cell>7. Why would that be the case?</cell><cell>General appeal to truth</cell></row><row><cell>8. How do you know this is true?</cell><cell></cell></row></table><note>Turning to sharing ratings, we again found a significant overall effect of reply type on sharing ratings, F (2, 6875.3) = 15.56, p &lt; .001. Participants reported they would be less likely to share these Tweets when they appeared with a truth query reply, M = 2.17, CI [2.02, 2.33]), than when they appeared without this reply, M = 2.33, 95% CI [2.18, 2.49], t (6875.2) = -4.59, p &lt; .001, b = -0.16 (95% CI [-0.23, -0.09]) or when they appeared with a neutral, non-truth related reply, M = 2.35, 95% CI [2.19, 2.51], t (6875.3) = 5.043, p &lt; .001, b = 0.18 (95% CI [0.11, 0.24]). Like in Experiment 2, participants did not differ in their ratings of how likely they would be to share posts that appeared with a neutral reply compared to when they appeared with no reply, t (6875.4) = 0.458, p = 0.647, b = 0.02 (95% CI [-0.05, 0.08]).</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>judgment (truth or sharing) condition. Overall, 600 participants completed the study (M age = 38.99, SD = 12.47; 324 male, 268 female, 4 other), 299 in the truth judgment condition and 301 in the sharing judgment condition.</figDesc><table><row><cell>Materials. Our materials were similar to the Tweets used in Experiment 1 with the</cell></row><row><cell>addition of new neutral (non-truth related) responses to some of the Tweets. Examples of neutral,</cell></row><row><cell>non-truth-related replies include "I just got home from McDonalds! Didn't get ice cream though"</cell></row><row><cell>in response to a Tweet containing false information about McDonalds ice cream and "My</cell></row><row><cell>nephews are in a tag phase right now. It's a good one because they wear themselves out!!" in</cell></row><row><cell>response to a Tweet containing false information about "tag" being an acronym. Thus, each</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>The procedure was an exact replication of Experiment 1, except for the specific Tweets that participants rated. While Experiment 1 had 12 Tweets total (four key Tweets with truth queries, four key Tweets with no replies, four fillers), in Experiment 2, participants rated 10 Tweets total, with six key Tweets (two with truth queries, two with neutral replies, and</figDesc><table><row><cell>Tweets with similar truth and sharing ratings from our earlier norming (truth: M CB 1 = 2.86, CB</cell></row><row><cell>2 = 3.05, CB 3 = 3.23, sharing: M CB1 = 2.54, CB 2 = 2.21, CB 3 = 2.37).</cell></row><row><cell>Procedure.</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We would like to give our sincere thanks to Jenna-Lee Strugnell and Stef Snel of Democracy Yethu Kaofelo for bringing their innovative dialogue facilitation methods to our attention. These studies would not have been possible without their determined efforts.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>All supplemental materials, stimuli, data, and syntax for the experiments in this paper are available at https://osf.io/jbcy6/. Data and materials availability: All stimuli, data, syntax, and supplemental analysis for this experiment and other experiments in this paper are included in the supplemental materials available at https://osf.io/jbcy6/.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Funding</head></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">Debunking: A Meta-Analysis of the Psychological Efficacy of Messages Countering Misinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Chan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jamieson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Albarracín</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="page" from="1531" to="1546" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">How to unring the bell: A meta-analytic approach to correction of misinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Murphy</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. Monogr</title>
		<imprint>
			<biblScope unit="volume">85</biblScope>
			<biblScope unit="page" from="423" to="441" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Searching for the backfire effect: Measurement and design considerations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Swire-Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Degutis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lazer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Res. Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="286" to="299" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The Quest to Automate Fact-Checking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Adair</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Hamilton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tremayne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Yang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Yu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 2015 Computation + Journalism Symposium</title>
		<meeting>the 2015 Computation + Journalism Symposium</meeting>
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Trust and distrust in online fact-checking services</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">B</forename><surname>Brandtzaeg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Følstad</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Commun. ACM</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="page" from="65" to="71" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">I Don&apos;t Think That&apos;s True, Bro!&quot; Social Corrections of Misinformation in India</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Badrinathan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Chauchard</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">The International Journal of Press/Politics</title>
		<imprint>
			<biblScope unit="page">194016122311587</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">See Something, Say Something: Correction of Global Health Misinformation on Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bode</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Vraga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Health Commun</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="1131" to="1140" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Addressing COVID-19 Misinformation on Social Media Preemptively and Responsively</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">K</forename><surname>Vraga</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Bode</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Emerg. Infect. Dis</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="page" from="396" to="403" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Grice</surname></persName>
		</author>
		<title level="m">Logic and Conversation</title>
		<imprint>
			<publisher>Brill</publisher>
			<date type="published" when="1975" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Sperber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wilson</surname></persName>
		</author>
		<title level="m">Relevance: communication and cognition</title>
		<meeting><address><addrLine>Cambridge, Mass</addrLine></address></meeting>
		<imprint>
			<publisher>Harvard University Press</publisher>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
	<note>The Language and thought series</note>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Judgment in a Social Context: Biases, Shortcomings, and the Logic of Conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Advances in Experimental Social Psychology</title>
		<imprint>
			<date type="published" when="1994" />
			<publisher>Elsevier</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Cognition and communication: Judgmental biases, research methods, and the logic of conversation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Cognition and communication: Judgmental biases, research methods, and the logic of conversation</title>
		<meeting><address><addrLine>Mahwah, NJ, US</addrLine></address></meeting>
		<imprint>
			<publisher>Lawrence Erlbaum Associates Publishers</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Towards a psychology of collective memory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hirst</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Manier</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Memory</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="183" to="200" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Conversational remembering: Story recall with a peer versus for an experimenter</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Hyman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="49" to="66" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title level="m" type="main">Creating false autobiographical memories: Why people believe their memory errors&quot; in Ecological approaches to cognition: Essays in honor of Ulric Neisser</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">E</forename><surname>Hyman</surname><genName>Jr</genName></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Lawrence Erlbaum Associates Publishers</publisher>
			<biblScope unit="page" from="229" to="252" />
			<pubPlace>Mahwah, NJ, US</pubPlace>
		</imprint>
	</monogr>
	<note>Emory symposia in cognition</note>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Spinning the stories of our lives</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Marsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Appl. Cogn. Psychol</title>
		<imprint>
			<biblScope unit="volume">18</biblScope>
			<biblScope unit="page" from="491" to="503" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Sharing of Misinformation is Habitual, Not Just Lazy or Biased</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Gizem</forename><surname>Ceylan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ian</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Wendy</forename><surname>Wood</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proc. Natl. Acad. Sci</title>
		<meeting>Natl. Acad. Sci</meeting>
		<imprint/>
	</monogr>
	<note>In press</note>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Developing an accuracy-prompt toolkit to reduce COVID-19 misinformation online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Berinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Cole</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Gully</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<idno type="DOI">10.37016/mr-2020-71</idno>
	</analytic>
	<monogr>
		<title level="j">Harv. Kennedy Sch. Misinformation Rev</title>
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Shifting attention to accuracy can reduce misinformation online</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Epstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mosleh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">A</forename><surname>Arechar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Eckles</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">592</biblScope>
			<biblScope unit="page" from="590" to="595" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Misinformation and Its Correction: Continued Influence and Successful Debiasing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">K H</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Seifert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol. Sci. Public Interest</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="106" to="131" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">When (fake) news feels true: Intuitions of truth and the acceptance and correction of misinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jalbert</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Psychological insights for understanding COVID-19 and media and technology</title>
		<meeting><address><addrLine>New York, NY, US</addrLine></address></meeting>
		<imprint>
			<publisher>Routledge/Taylor &amp; Francis Group</publisher>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Pausing to consider why a headline is true or false can help reduce the sharing of false news</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fazio</surname></persName>
		</author>
		<idno type="DOI">10.37016/mr-2020-009</idno>
	</analytic>
	<monogr>
		<title level="j">Harv. Kennedy Sch. Misinformation Rev</title>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Exploring Lightweight Interventions at Posting Time to Reduce the Sharing of Misinformation on Social Media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Jahanbakhsh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">X</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Berinsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Karger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc. ACM Hum.-Comput. Interact</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="42" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Accuracy prompts are a replicable and generalizable approach for reducing the spread of misinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat. Commun</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page">2333</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Only Half of What I&apos;ll Tell You is True: Expecting to Encounter Falsehoods Reduces Illusory Truth</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jalbert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Appl. Res. Mem. Cogn</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="602" to="613" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Thinking more or thinking differently? Using drift-diffusion modeling to illuminate why accuracy prompts decrease misinformation sharing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">230</biblScope>
			<biblScope unit="page">105312</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Metacognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<ptr target="http://content.apa.org/books/14341-006" />
	</analytic>
	<monogr>
		<title level="m">APA handbook of personality and social psychology</title>
		<editor>M. Mikulincer, P. R. Shaver, E. Borgida, J. A. Bargh</editor>
		<meeting><address><addrLine>Washington</addrLine></address></meeting>
		<imprint>
			<publisher>American Psychological Association</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="203" to="229" />
		</imprint>
	</monogr>
	<note>Attitudes and social cognition</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">Of fluency, beauty, and truth: Inferences from metacognitive experiences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Metacognitive diversity: An interdisciplinary approach</title>
		<meeting><address><addrLine>New York, NY, US</addrLine></address></meeting>
		<imprint>
			<publisher>Oxford University Press</publisher>
			<date type="published" when="2018" />
			<biblScope unit="page" from="25" to="46" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Making the truth stick &amp; the myths fade: Lessons from cognitive psychology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Schwarz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Newman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Leach</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Sci. Policy</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="85" to="95" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">A Theory of Social Comparison Processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Festinger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Hum. Relat</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page" from="117" to="140" />
			<date type="published" when="1954" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Kluck</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">C</forename><surname>Schaewitz</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Doubters are more convincing than advocates. The impact of user comments and ratings on credibility perceptions of false news stories on social media</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Krämer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Stud. Commun. Media</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page" from="446" to="470" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Exposure to social engagement metrics increases vulnerability to misinformation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Avram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Micallef</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Patil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Menczer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Harv. Kennedy Sch</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<monogr>
		<title/>
		<idno type="DOI">10.37016/mr-2020-033</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Social Influence: Compliance and Conformity</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Cialdini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">J</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Annu. Rev. Psychol</title>
		<imprint>
			<biblScope unit="volume">55</biblScope>
			<biblScope unit="page" from="591" to="621" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Building and breaking social media habits</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Bayer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">A</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Tokunaga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr. Opin. Psychol</title>
		<imprint>
			<biblScope unit="volume">45</biblScope>
			<biblScope unit="page">101303</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Fake news, fast and slow: Deliberation reduces belief in false (but not true) news headlines</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Bago</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Pennycook</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">149</biblScope>
			<biblScope unit="page" from="1608" to="1613" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Power 3: A flexible statistical power analysis program for the social, behavioral, and biomedical sciences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Faul</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Erdfelder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-G</forename><surname>Lang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Buchner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behav. Res. Methods</title>
		<imprint>
			<biblScope unit="volume">39</biblScope>
			<biblScope unit="page" from="175" to="191" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cognitive Reflection and Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Frederick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Econ. Perspect</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="25" to="42" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Divine intuition: Cognitive style influences belief in God</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Rand</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Greene</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J. Exp. Psychol. Gen</title>
		<imprint>
			<biblScope unit="volume">141</biblScope>
			<biblScope unit="page" from="423" to="428" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Investigating an alternate form of the cognitive reflection test</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">S</forename><surname>Thomson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">M</forename><surname>Oppenheimer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Judgm. Decis. Mak</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="99" to="113" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">Can corrections spread misinformation to new audiences? Testing for the elusive familiarity backfire effect</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><forename type="middle">K H</forename><surname>Ecker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lewandowsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Chadwick</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Research: Principles and Implications</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page">41</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Borenstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">V</forename><surname>Hedges</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P T</forename><surname>Higgins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Rothstein</surname></persName>
		</author>
		<title level="m">Introduction to Meta-Analysis</title>
		<meeting><address><addrLine>Ltd, Chichester, UK</addrLine></address></meeting>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title/>
		<idno type="DOI">10.1002/9780470743386</idno>
		<ptr target="http://doi.wiley.com/10.1002/9780470743386" />
		<imprint/>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
