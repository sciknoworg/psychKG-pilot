<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main"></title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Stefano</forename><surname>Palminteri</surname></persName>
							<email>stefano.palminteri@ens.fr</email>
							<affiliation key="aff0">
								<orgName type="laboratory">Laboratoire de Neurosciences Cognitives et Computationnelles</orgName>
								<orgName type="institution">INSERM</orgName>
								<address>
									<settlement>Paris</settlement>
									<country>France (</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">ENS</orgName>
								<address>
									<addrLine>Département d&apos;Etudes Cognitives</addrLine>
								</address>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="institution">PSL Research University</orgName>
								<address>
									<settlement>Paris</settlement>
									<country>France (</country>
								</address>
							</affiliation>
							<affiliation key="aff3">
								<orgName type="department">Institute for Cognitive Science</orgName>
								<orgName type="institution">Higher School of Economics</orgName>
								<address>
									<settlement>Moscow</settlement>
									<country>Federation of Russia (</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Maël</forename><surname>Lebreton</surname></persName>
							<affiliation key="aff4">
								<orgName type="department">Swiss Center for Affective Science</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country>Switzerland (</country>
								</address>
							</affiliation>
							<affiliation key="aff5">
								<orgName type="department">Department of Basic Neuroscience</orgName>
								<orgName type="laboratory">Laboratory for Behavioural Neurology and Imaging of Cognition (LabNIC)</orgName>
								<orgName type="institution">University of Geneva</orgName>
								<address>
									<settlement>Geneva</settlement>
									<country>Switzerland. (</country>
								</address>
							</affiliation>
							<affiliation key="aff6">
								<orgName type="institution">Paris School of Economics</orgName>
								<address>
									<settlement>Paris</settlement>
									<country key="FR">France</country>
								</address>
							</affiliation>
						</author>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:43+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>Highlights: • In human reinforcement learning, outcomes are encoded in a context-dependent manner • Context-dependence transforms objective outcomes into subjective outcomes • Context-dependence includes reference point rescaling and range adaptation • These processes have both desirable and undesirable behavioural consequences Abstract A wealth of evidence in perceptual and economic decision-making research suggests that the subjective value of one option is determined by other available options (i.e. the context). A series of studies provides evidence that the same coding principles apply to situations where decisions are shaped by past outcomes, i.e. in reinforcement-learning situations. In bandit tasks, human behavior is explained by models assuming that individuals do not learn the objective value of an outcome, but rather its subjective, context-dependent representation. We argue that, while such outcome context-dependence may be informationally or ecologically optimal, it concomitantly undermines the capacity to generalize value-based knowledge to new contextssometimes creating apparent decision paradoxes. * This paper presents a comprehensive computational framework of how reinforcement learning can be integrated with homeostatic principles, where outcomes are processed as a function of the internal state of the agent.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>The view that perceptions, sensations and evaluations depend on their context was already a central tenant of the late 19th century's Gestalt psychology theory <ref type="bibr" target="#b0">[1]</ref> and of early Utility theory <ref type="bibr" target="#b1">[2]</ref>. A century later, the pervasiveness of perceptual illusions and decision-making biases, combined with decades of research in psychology, economics and neurosciences, consolidated the notion that perceptual and economic decisions are highly susceptible to contextual effects <ref type="bibr" target="#b2">[3]</ref>. A significant fraction of contextual effects seems to result from two fundamental computations: reference-point centring and range adaptation <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref>.</p><p>In most ecological and real-life situations, decisions are arguably strongly influenced by the retrospective recollection of past outcomes experienced in similar situations <ref type="bibr" target="#b6">[7]</ref>. Yet, in these experience-based decisionsrealm of the reinforcement-learning framework -, the notion of outcome context-dependence has been mostly neglected, until recent times <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9]</ref>. Here, we review recent experimental work demonstrating that, in human reinforcement learning, outcomes are encoded and remembered as a function of the learning context.</p><p>By building on earlier work in perceptual decision-making, we consider outcome contextdependence as a manifestation of adaptive coding. Adaptive coding formalizes the idea that the (neural) representation of a variable is constrained by its underlying statistical distribution (the context <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>). Analogously, in reinforcement learning, outcome encoding is influenced by the distribution of outcomes experienced in the same or similar contexts.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome reference point-dependence in reinforcement learning</head><p>Harry <ref type="bibr">Helson (1898</ref><ref type="bibr">Helson ( -1977</ref>'s adaptation-level (AL) theory constitutes the first systematic empirical investigation and theoretical formalization of the reference point-dependence of perceptual judgments <ref type="bibr" target="#b9">[10]</ref>. AL theory postulates that perceptual features (such as luminosity, loudness and weight) are evaluated relative to a norm (or adaptation level) as follows:</p><formula xml:id="formula_0">= − ̅</formula><p>where is the judgement of a particular stimulus on a specific attribute, is the objective value of the same stimulus in the perceptual attribute under consideration, and ̅ is the norm, namely the arithmetic mean of all stimuli relevant to defining the context. The norm constitutes a reference point, usually defined as the running average of similar stimuli recently or simultaneously sampled, which is used as a point of comparison to judge the currently experienced stimulus (centring). By importing the AL core intuition into the realm of economic judgment and decision-making, Kahneman and Tversky proposed that the utility of an expected outcome does not reflect its objective value, but rather a sense of gain or loss, relative to a reference point. Reference-point dependence is therefore an intrinsic feature of prospect theory (PT <ref type="bibr" target="#b10">[11,</ref><ref type="bibr" target="#b11">12]</ref>).</p><p>In a recent study, we tested if reference point-dependence affects the way outcomes are encoded (and stored in memory) in human reinforcement learning [**13]. Our behavioral paradigm joins a learning phase with a transfer phase <ref type="bibr" target="#b14">[14,</ref><ref type="bibr" target="#b15">15]</ref>. Initially, during the learning phase, participants had to choose between options presented as fixed pairs of cues that were associated with a probabilistic outcome. The type of outcome defined the learning context: 'gain' (i.e. reward maximization) or 'loss' (i.e. punishment minimization) ( <ref type="figure" target="#fig_0">Figure 1A)</ref>. In the transfer phase, participants were required to express their option preference for each pairwise possible combination, including hybrid combinations of options from different learning contexts ( <ref type="figure" target="#fig_0">Figure 1B)</ref>. Two key behavioral results emerged: i) during learning phase, accuracy was well above chance and remarkably similar in the gain and the loss contexts; ii) option preferences in the transfer phase violated the strictly monotonic ranking dictated by their expected values ( <ref type="figure" target="#fig_0">Figure 1A-B)</ref>. More specifically, we found a significant preference for the small-loss option over the small-gain option. Crucially, these two key effects violate the predictions of outcome encoding by a standard Q-learning algorithm. In the learning phase, the standard model predicts lower performance in the loss condition: a phenomenon due to an intrinsic asymmetry in reinforcement rate in the gain and loss contexts (a.k.a. the punishment learning paradox <ref type="bibr" target="#b16">[16]</ref><ref type="bibr" target="#b17">[17]</ref><ref type="bibr" target="#b18">[18]</ref>. In the transfer phase the standard model predicts a strictly monotonic ranking of option preferences as a function of their objective values (see Box 1). By following the intuition of AL and PT theories, we proposed a model that learns the value of a reference-point and uses it to dynamically center the outcomes before computing the optionspecific prediction error ( <ref type="figure" target="#fig_0">Figure 1C)</ref>. We refer to this model as the REFERENCE model. This model successfully explains symmetrical gain-loss performance in the learning phase and the suboptimal preference pattern in the transfer phase. Moreover, it outperforms the standard Qlearning model in a broad range of conditions, arguing in favor of outcome reference-point dependence in reinforcement-learning. This result has been replicated not only in our laboratory, but also in other studies and featuring different designs, including social learning <ref type="bibr" target="#b19">[19]</ref> and different option contingencies, arrangements and manipulations [*20 <ref type="bibr">-22]</ref>. combinations. Here, we focus on the most informative combinations (AC and BC). The hallmark of outcome reference-point dependence is the preference for C over B in the BC comparison (green bar). While these behavioral signatures observed in both the learning and the transfer phase strikingly contrast with a model assuming objective outcome encoding (white dots), they are well captured by the REFERENCE model (black dots). Of note, choice pattern in the AC is also informative and indicates that the centering is only partial. (C) Evolution of the contextual variables (top panel) and subjective outcomes (bottom panel). The top panel illustrates the canonical temporal evolution of the reference points in the gain and loss contexts. Halfway through the learning phase, the reference points cross the expect value of the small gain/loss options. The bottom panel illustrates the resulting evolution of the average subjective outcomes for each option. Symmetrically to the top panel, roughly halfway through the learning phase, the subjective value of the outcomes of the EV 25 and EV -25 options started to be subjectively 'perceived' as negative and positive, respectively.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Outcome range-adaptation in reinforcement learning</head><p>In the late 20th century, Allen Parducci revealed the presence of context-dependence in affective judgements of happiness, pleasure and pain, and formalized his findings in the range frequency (RF) theory <ref type="bibr" target="#b25">[23]</ref>. Of particular interest to our review is Parducci's 'range principle', which describes the subjective judgement of a stimulus as:</p><formula xml:id="formula_1">= − −</formula><p>where is the objective value of the stimulus in the perceptual attribute under consideration, while and are the highest and lowest values presented in the relevant context, bounding the range of possible outcomes. Essentially, the range principle states that subjective valuation is adapted to the underlying distribution of stimuli through a normalization rule. Recently, <ref type="bibr">Kontek</ref> and Lewandoswky translated this idea into description-based decision-making by proposing the range-dependent utility model as an alternative to PT [*24]. The model assumes that the prospective valuation of the expected payoff of lotteries is range-adapted and accounts for several known behavioral paradoxes <ref type="bibr" target="#b28">[25]</ref>.</p><p>In a couple of recent studies, we tested if the range principle also applies to outcome encoding and retrospective retrieval from memory in reinforcement learning [**26,**27]. We built upon the previous behavioral paradigms to include systematic manipulation of outcome magnitudes, generating learning contexts with different outcome ranges. As in the previous study, the learning phase was followed by a transfer phase, which included new combinations of options <ref type="figure" target="#fig_1">(Figure 2A-B)</ref>. Again, two key results emerged from these studies: i) accuracy was very similar in the small and the big magnitude contexts; ii) in the transfer phase, participants' choice-elicited preferences were not consistent with the objective outcome values. Notably, options that were locally correct in the small magnitude contexts were systematically preferred to options that were locally incorrect in the big magnitude contexts, despite their objective expected values having the opposite ranking. A standard Q-learning model (with objective outcomes and softmax decision rule <ref type="bibr" target="#b33">[28]</ref>) fails to predict this pattern, because its choice probabilities (and therefore accuracy) are strongly affected by the relative magnitudes of the option values. In line with RF theory, we proposed a model that learns the range of possible outcomes and uses it to dynamically rescale the outcomes before computing the option-specific prediction error ( <ref type="figure" target="#fig_1">Figure 2C)</ref>. This model, referred to as the RANGE model (see Box 1), satisfactorily captures the key behavioral effects. In our last study <ref type="bibr" target="#b31">[27]</ref>, we also modulated the difficulty of the learning phase in two ways: by manipulating outcome information (partial vs. complete feedback) and by manipulating the task structure (blocked vs interleaved design). We found that outcome range adaptation was more pronounced in the easiest settings (block design, complete feedback), consistent with the idea that these manipulations enabled the participants to identify the context-relevant variables more easily. Crucially, as predicted by the RANGE model, this result was accompanied by a reduction in the subjects' ability to successfully extrapolate option values in the transfer phase. This finding is in striking opposition to the almost universally shared intuition that reducing task difficulty should lead, if anything, to more accurate and rational behavior <ref type="bibr" target="#b34">[29,</ref><ref type="bibr" target="#b35">30]</ref>.</p><p>Another recent study investigated choices in a reinforcement learning paradigm featuring repeated choices between a deterministic (i.e. risk-free) and a probabilistic (i.e. risky) option. Results showed that the outcome range matters in subjective outcome values [*31]. Specifically, the authors convincingly demonstrated that risk preferences were strongly driven by an increased saliency of the extreme (i.e. the highest and the lowest possible) outcomes presented locally, in a given context, rather than being attached to any specific objective outcome value. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Dependence of irrelevant alternatives in human reinforcement learning</head><p>In the first part of this review, we provided evidence generalizing two manifestations of contextual influences to reinforcement learning: reference-point dependence and range normalization. However, the notion of context in psychology and economics is much richer, encompassing many other dimensions <ref type="bibr" target="#b38">[32]</ref>. Particularly relevant for economic decision-making is the notion of the choice set or menu. In fact, standard normative theories assume that decision-makers (should) evaluate options in a way that the relative probability of choosing, say, option A over B, should be independent of the presence of a third alternative, say C (the so-called independence of irrelevant alternatives axiom, IIA <ref type="bibr" target="#b33">[28]</ref>). Despite being intuitive, IIA is quite often violated in descriptionbased decisions <ref type="bibr" target="#b39">[33]</ref>. A recent study actually demonstrated that such contextual effects induced by the choice set also occur in reinforcement learning [**34]. The authors designed several behavioral paradigms, where participants choose between three options whose expected values were designed to elicit classic violations of IIA. However, the expected values were to be learned by trial-anderror. Their results reveal that similar outcomes 'inhibit' each other, whereas the most dissimilar (hence salient) outcomes 'stand out'. This bottom-up attentional bias can be captured by a computational model that decreases the subjective value of an outcome as a function of the cumulative sum of the perceived similarity between a given outcome and others concomitantly presented <ref type="bibr" target="#b0">1</ref> . As a result, this study illustrates that contextual effects created by the choice set also extend to reinforcement learning scenarios. In these scenarios, contextual effects produce preference patterns that sometime oppose those observed in decision among lotteries, thus providing a new instance of the experience-description gap <ref type="bibr" target="#b7">[8,</ref><ref type="bibr" target="#b8">9,</ref><ref type="bibr" target="#b42">35]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Relation to behavioral economics research and alternative computational frameworks</head><p>We reviewed converging evidence in support of the idea that the subjective value of an outcome is strongly influenced by the learning context, derived from the distribution of other and past outcomes <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b19">19,</ref><ref type="bibr" target="#b20">20,</ref><ref type="bibr" target="#b29">26,</ref><ref type="bibr" target="#b31">27,</ref><ref type="bibr" target="#b36">31,</ref><ref type="bibr" target="#b40">34]</ref>. This body of work suggests that context plays a role in virtually all types of decision-making, possibly via the recycling of similar neural computational processes and constraints <ref type="bibr" target="#b2">[3]</ref><ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref>.</p><p>Contextual factors, such as the reference point, are central to theories of description-based decisions (such as PT). Although experimental evidence suggests that the reference point is dynamically updated by the choice history, the exact algorithm and mechanisms remain to be specified <ref type="bibr" target="#b43">[36,</ref><ref type="bibr" target="#b44">37]</ref>, thus weakening the theory <ref type="bibr" target="#b45">[38]</ref>. Importing learning models into the decision-bydescription framework and leveraging functional neuroimaging methods could prove useful in bridging this gap, both at the normative and descriptive levels <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b46">39]</ref>. We also proposed that range adaptation can be implemented via a range normalization mechanism, based on the learned maximum and minimum possible outcomes <ref type="bibr" target="#b31">[27,</ref><ref type="bibr" target="#b36">31]</ref>. Although reinforcement learning traditionally relies on behavioral paradigms featuring unidimensional outcomes (the numeric reward), multi-attribute choice is another canonical situation in which the choice menu has been shown to be critical <ref type="bibr" target="#b39">[33]</ref>. In this context, range normalization could apply to each attribute separately, generating and explaining the decoy effects observed in classical description-based decisions with a computationally tractable mechanism <ref type="bibr" target="#b47">[40]</ref>. Context effects in choice can be understood through an alternative computational formalism, the decision-by-sampling (DbS) framework <ref type="bibr" target="#b48">[41]</ref>. The DbS framework supposes that the subjective value of an option comes from a series of ordinal comparisons with outcomes drawn from memory. Since subjective values come from comparisons with other options, context-effects arise naturally from the DbS formalism <ref type="bibr" target="#b49">[42]</ref>. Furthermore, DbS could provide a unified framework for description-(sampling from distributions) and experience-based (sampling from memory) decision-making. Particularly relevant for our treatment, a recent elegant study showed that DbS concomitantly generates range effects and achieves efficient coding of information [*43].</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>What are the functional roles of outcome context-dependence in reinforcement learning?</head><p>Converging evidence shows that outcome context-dependence systematically induces suboptimal choices when options are extrapolated beyond their original learning contexts in the transfer phase <ref type="figure" target="#fig_0">(Figure 1-2)</ref>. This is particularly striking as similar behavioural findings have been found in distant species, such as rodents <ref type="bibr" target="#b52">[44]</ref> and birds [ <ref type="bibr">*45,46]</ref>. Identifying predictable sources of biases is always puzzling, because evolutionary forces should have, in principle, negatively selected for processes leading to suboptimal choices. Our work shows that context dependency can, of course, improve learning performance in specific conditions (loss avoidance, small magnitude). However, most of these beneficial learning effects could be achieved by normalizing value signals at the choice phase, rather than at the learning and memorization phase, without bearing the costs of irrational preferences in the transfer phase. We speculate two possible functional roles for this learning bias. First, outcome context-dependence could simply result from adaptive and efficient (neural) coding principles, thereby optimizing information processing during learning <ref type="bibr" target="#b3">[4,</ref><ref type="bibr" target="#b4">5]</ref>. Alternatively, while context-dependent learning induces suboptimal choices in our laboratory setting, they may be evolutionarily rational, meaning that they generate, on average, optimal performance in the environments where they evolvede.g. in environments where the resources are highly volatile <ref type="bibr" target="#b56">[47,</ref><ref type="bibr" target="#b57">48]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Option value learning or direct policy learning?</head><p>A whole spectrum of models exists in the reinforcement learning framework, ranging from models assuming that expected values are learned for individual options (such as Q-learning), to models assuming that choice policies are learnt without intermediate option values representations (such as direct policy learning) [*49]. The latter hypothesis was backed up by evidence from a couple of studies on humans, where direct policy learning methods better explained subjects' choices in complete feedback tasks, at least in some critical trials <ref type="bibr" target="#b20">[20,</ref><ref type="bibr" target="#b60">50,</ref><ref type="bibr" target="#b61">51]</ref>. However, while the empirical data reviewed here clearly falsify the Q-learning's assumption that option-values are learned on a context-independent (or objective) scale, they also reject the equally extreme predictions of direct policy learning, by showing residual effect of outcome valence and magnitude in option value preferences <ref type="figure" target="#fig_0">(Figure 1 and Figure 2)</ref>  <ref type="bibr" target="#b12">[13,</ref><ref type="bibr" target="#b29">26,</ref><ref type="bibr" target="#b31">27]</ref>. We therefore propose a hybrid scenario where option-specific values are computed, but based on subjective outcomes that are encoded in a context-dependent manner.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Open questions</head><p>The present demonstration of context-dependent outcome encoding <ref type="figure" target="#fig_0">(Figure 1 and Figure 2</ref>) relies on a combination of an instrumental learning phase and of a transfer phase eliciting preference as instrumental choices (e.g., in a procedural manner). Whereas recent evidence suggests that the Pavlovian learning system presents similar outcome encoding constraints <ref type="bibr" target="#b62">[52]</ref>, future studies should investigate address whether the same mechanism generalizes to other learning (Pavlovian, instrumental, goal directed) and representational (declarative, episodic) systems <ref type="bibr" target="#b63">[53,</ref><ref type="bibr" target="#b64">54]</ref>. Finally, although we focused our review on situations, where context-dependent reinforcement learning concurrently benefits the learning phase and undermines generalization, an exhaustive investigation of learning and transfer environments could potentially identify situations where this trade-off can be tipped in favor of better generalization.</p><p>To conclude, investigating the effects of past outcomes on learning opens up a promising window, not only to define and formalize contextual effects (Box 2), but also to understand how the subjective, hedonic perception of outcomes shapes preferences. Deciphering the mechanisms and properties of reference-point dependence and range adaptation may also be key to appreciating the neurobiological encoding of learning and decision-related variables [** <ref type="bibr">13,39,*55,56]</ref>.</p><p>Box Reinforcement-learning models with outcome context dependence.</p><p>Both the REFERENCE <ref type="bibr" target="#b12">[13]</ref> and the RANGE <ref type="bibr" target="#b31">[27]</ref> models build on a standard Q-learning model, applied to a two-armed bandits task with complete feedback information <ref type="bibr" target="#b68">[57]</ref>. For each pair of cues (i.e. state ), the REFERENCE model learns a reference point ( ), often referred to as context-or state-value ( ), which is updated as follows:</p><formula xml:id="formula_2">( ) ← ( ) + * ( ( ) + ( ) 2 −<label>(</label></formula><p>)) ( ) and ( ) are the outcome of the chosen and unchosen option respectively, while is a learning rate (0 &lt; &lt; 1) 2 (see <ref type="figure" target="#fig_0">Figure 1C</ref> for the temporal evolution of the variable). ( ) is then used to calculate the subjective outcome for each option as follows:</p><p>( ( )) = ( ) − ( ) The RANGE model infers two context-level variables:</p><p>( ) and ( ), which are updated as follows:</p><p>( ) ← ( ) + * (max ( (: )) − ( )), max( (: )) &gt; ( ) ← ( ) + * (min ( (: )) − ( )), min( (: )) &lt; where ( (: )) and ( (: )) are respectively the highest and lowest possible outcomes observed in a given trial, while is a learning rate (0 &lt; &lt; 1) (see <ref type="figure" target="#fig_1">Figure 2C</ref> for the temporal evolution of the variable). In this formulation, ( ) / ( ) can only increase / decrease: it suits only tasks where the range does not change over time. The model could easily accommodate situations where the range changes over time, by simply assuming that ( ) is updated at a smaller rate when the observed outcome is smaller than the current estimation of ( ) (the opposite holds true for ( )) <ref type="bibr" target="#b25">[23]</ref>. This variable is then used to calculate the subjective outcome for each option as follows <ref type="bibr" target="#b2">3</ref>  2 Of note, the model proposed by Klein et al. (2017) is a special case of the REFERENCE model described (when = 1). <ref type="bibr" target="#b2">3</ref> In the denominator '+1' is added for computational convenience. It could be replaced by a free-parameter to account for task-specific differences, akin to a semi-saturation term governing the efficiency of the normalization <ref type="bibr" target="#b4">[5]</ref>.</p><p>Where is a learning rate (0 &lt; &lt; 1). Both models make decisions with a standard 'softmax' decision rule with a fixed temperature parameter. These models have been shown to satisfactorily account for the behavioral patterns in both the learning phase and transfer phase (see <ref type="figure" target="#fig_0">Figure 1C</ref> and <ref type="figure" target="#fig_1">Figure 2C)</ref>, which falsify several plausible alternative formulations in reinforcement learning (actor-critic, habit learning <ref type="bibr" target="#b17">[17,</ref><ref type="bibr" target="#b69">58]</ref>) and in neuroeconomics (subjective utility, divisive normalization <ref type="bibr" target="#b1">[2,</ref><ref type="bibr" target="#b70">59]</ref>). As a final remark, even if the two models are not mathematically nested, the subtraction of ( ) at the numerator of the range normalization rules indicates that the RANGE model also implies the possibility that objectively negative outcomes can be reframed as subjectively positive.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Box 2: multiple definitions of context</head><p>This quote from Parducci clearly illustrates how broadly the term context can be interpreted <ref type="bibr" target="#b25">[23]</ref>:</p><p>"The term context refers to a conceptual representation of a set of events, real or imaginary, determining the dimensional judgement of any particular event" (p. 36). In this box we summarize the meaning of context in the main studies reviewed here, building on an analogy to its definition in perceptual and value-based decision-making <ref type="bibr" target="#b5">[6,</ref><ref type="bibr" target="#b71">60]</ref>. In visual cognition, 'spatial' context refers to objects simultaneously presented with a target stimulus. Since spatial contextual effects do not require inferring a hidden contextual variable, as all relevant information is immediately given, in reinforcement learning, we can see this concept as the simultaneous presentation of outcomes affecting the subjective value of an outcome. While this definition of context becomes ambiguous when the outcome of the chosen option is displayed alone, it has been used to build models of complete feedback paradigms [*20,**34]. 'Temporal' context refers to objects presented in the (more or less recent) past. This is how contextual effects are defined in the REFERENCE and the RANGE models [**13,**27]. In this case, outcome context-dependence is driven by hidden contextual variables (such as reference point, or the maximum possible reward), whose values are inferred from the history of past outcomes. This definition of context applies to both partial and feedback tasks, since it does not require simultaneous presentation of all feedback information. A corollary question concerns the time horizon for temporal context integration. Evidence suggests that contextual variables can be computed simultaneously over different time scales <ref type="bibr" target="#b72">[61,</ref><ref type="bibr" target="#b73">62]</ref>. Both the 'spatial' and the 'temporal' definitions of context given above are implicit, i.e. they are not attached to any particular cue. However, evidence suggests that contextual information can be attached to explicit value-neutral stimuli (e.g. visual cues, background colors) that can then be used to generalize contextual information to new options, without the need to experience the relevant outcomes <ref type="bibr">[63,*64]</ref>. Finally, we mainly focused on external contexts (i.e. derived from stimuli). However, the internal state of an organism can also contribute to define a context. There is ample evidence that the level of satiation or the current energetic budget strongly influences memory and decision-making <ref type="bibr" target="#b77">[65]</ref>. Accordingly, the recently developed framework of homeostatic reinforcement learning postulates that the subjective value of an outcome is determined by whether a given outcome moves toward (or away from) a homeostatic set-point <ref type="bibr">[66,*67]</ref>, defining an alternative formulation of outcome context-dependence in reinforcement learning. It is important to disambiguate the term 'state', which has different meanings in different fields. In ethology and foraging research 'state' refers to the internal (physiological) status of the organism <ref type="bibr" target="#b56">[47]</ref>, while in animal and reinforcement learning literature, it mainly refers to a node in a Markov decision-process, roughly synonym of what we refer to as "external context" <ref type="bibr" target="#b68">[57]</ref>.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>References * of interest</head></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>reference point-dependence in RL: task, results and model variables. (A) Learning phase contexts (top panel) and typical behavior (bottom panel). Subjects are presented for several trials with two learning contexts: AB (gain-maximization context) and CD (loss-minimization context). Feedback is probabilistic. Accuracy typically starts at chance level and progressively increases, reaching a similar plateau in both learning contexts. (B) Transfer phase contexts (top panel) and typical behavior (bottom panel). After the learning phase, symbols are re-arranged in new</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>range adaption in RL: task, results and model variables. (A) Learning phase contexts (top panel) a typical behavior (bottom panel).Subjects are presented for several trials with two learning contexts: AB (big-magnitude context) and CD (small magnitude context). Feedback is probabilistic. Accuracy typically starts at chance and progressively increases reaching a quite similar plateau in both learning contexts. (B) Transfer phase contexts (top panel) and typical behavior (bottom panel). After the learning phase, symbols are re-arranged in new combinations. Here, we focus on the most informative combinations (AC and BC). The hallmark signature of outcome range adaptation is the preference for C over B in the BC comparison (green bar). While these behavioral signatures observed in both the learning and the transfer phases strikingly contrast with a model assuming objective outcome encoding (white dots), they are well captured by the RANGE model (black dots). Of note, choice pattern in the AC is also informative, as it indicates that the range adaptation is only partial. (C) Evolution of the contextual variables (top panel) and subjective outcomes (bottom panel). The top panel illustrates the canonical temporal evolution of the ranges in the big and small magnitudes contexts. To the end of the learning phase, the ratio between the expected value of the options and the range values become similar in the big and small magnitude contexts. Crucially, Rmax and Rmin updates are conditional of R &gt; Rmax and R&lt;Rmin, respectively (see Box1). The bottom panel illustrates the evolution of the average subjective outcomes for each option. Notably, approximately halfway through the learning phase, the subjective value of the outcomes of the EV2.5 and EV0.75 cross over.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Finally, both models assume that option values (: , ) are updated following the standard update rule:( , ) +1 = ( , ) + * ( ( ( ) ) − ( , ) )</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="1">Of note, while the authors investigated only the complete feedback case, they argue that their model could be easily extended to the partial feedback case, by assuming that outcome comparison occurs between the presented outcome and previous outcomes stored in memory. To our knowledge, this hypothesis remains to be empirically verified.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conflict of interest statement</head><p>Nothing declared</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">T</forename><surname>Fechner</surname></persName>
		</author>
		<title level="m">Elemente der psychophysik. Breitkopf und Härtel; 1860</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Specimen theoriae novae de mensura sortis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Bernoulli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Comment Acad Sci Imp Petropolitanae</title>
		<imprint>
			<biblScope unit="volume">1738</biblScope>
			<biblScope unit="page" from="175" to="192" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Maps of Bounded Rationality: Psychology for Behavioral Economics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am Econ Rev</title>
		<imprint>
			<biblScope unit="volume">93</biblScope>
			<biblScope unit="page" from="1449" to="1475" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Normalization as a canonical neural computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carandini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Heeger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="51" to="62" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Efficient coding and the neural representation of value</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Ann N Y Acad Sci</title>
		<imprint>
			<biblScope unit="volume">1251</biblScope>
			<biblScope unit="page" from="13" to="32" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Value normalization in decision making: theory and evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Clithero</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr Opin Neurobiol</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="970" to="981" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">A framework for studying the neurobiology of value-based decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rangel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">R</forename><surname>Montague</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page" from="545" to="556" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">The description-experience gap: a challenge for the neuroeconomics of decision-making under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Garcia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cerrotti</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philos Trans R Soc B Biol Sci</title>
		<imprint>
			<biblScope unit="volume">376</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The description-experience gap in risky choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="517" to="523" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title level="m" type="main">Adaptation-level theory: an experimental and systematic approach to behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Helson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1964" />
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Prospect Theory: An Analysis of Decision under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Econometrica</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="page">263</biblScope>
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Replicating patterns of prospect theory for decision under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Ruggeri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Alí</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Berge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Bertoldo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">D</forename><surname>Bjørndal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cortijos-Bernabeu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Davison</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Demić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Esteban-Serna</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Friedemann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
			<biblScope unit="page" from="622" to="633" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Contextual modulation of value signals in reward and punishment learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Joffily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coricelli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="page">8096</biblScope>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">This study investigates reference-point dependence human reinforcement learning, showing that the REFERENCE model represents an efficient computational solution to punishment avoidance problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>The paper also present neurophysiological evidence supporting the computational assumptions of the REFERENCE model</note>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">By Carrot or by Stick: Cognitive Reinforcement Learning in Parkinsonism</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">C</forename><surname>Seeberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O'</forename><surname>Reilly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">306</biblScope>
			<biblScope unit="page" from="1940" to="1943" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Dopamine-dependent prediction errors underpin reward-seeking behaviour in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Pessiglione</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Flandin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">442</biblScope>
			<biblScope unit="page" from="1042" to="1045" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">A temporal difference account of avoidance learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Moutoussis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">P</forename><surname>Bentall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Williams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Netw Comput Neural Syst</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="137" to="160" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Two-factor theory, the actor-critic model, and conditioned avoidance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">V</forename><surname>Maia</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Learn Behav</title>
		<imprint>
			<biblScope unit="volume">38</biblScope>
			<biblScope unit="page" from="50" to="67" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><forename type="middle">H</forename><surname>Mowrer</surname></persName>
		</author>
		<title level="m">Learning Theory and Behavior</title>
		<imprint>
			<publisher>John Wiley &amp; Sons</publisher>
			<date type="published" when="1960" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Partial Adaptation of Obtained and Observed Value Signals Preserves Information about Gains and Losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baddeley</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tobler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schultz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="page" from="10016" to="10025" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Learning relative values in the striatum induces violations of normative decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">A</forename><surname>Klein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ullsperger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Jocham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">16033</biblScope>
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Transfer phase performance is undermined by outcome context-dependent learning as</title>
	</analytic>
	<monogr>
		<title level="m">* This study investigates context-dependent reinforcement learning in humans coupling behavioral and neural analyses</title>
		<imprint/>
	</monogr>
	<note>13,25,26</note>
</biblStruct>

<biblStruct xml:id="b22">
	<monogr>
		<title level="m" type="main">Neurophysiological data are consistent with the notion of relative outcome encoding</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Contextual influence on confidence judgments in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Bacily</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Engelmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page">1006973</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">The elusive effects of incidental anxiety on reinforcement-learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C-C</forename><surname>Ting</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Engelmann</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/7d4tc</idno>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen in press</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title level="m">Parducci A: Happiness, pleasure, and judgment: The contextual theory and its applications</title>
		<imprint>
			<publisher>Lawrence Erlbaum Associates, Inc</publisher>
			<date type="published" when="1995" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Range-Dependent Utility</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kontek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lewandowski</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag Sci</title>
		<imprint>
			<biblScope unit="volume">64</biblScope>
			<biblScope unit="page" from="2812" to="2832" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">This study provides an axiomatic basis for a range-dependent utility model, adapting Parducci&apos;s range-frequency theory to decision-making under risk. The model is shown to account for several known decision paradoxes</title>
		<imprint/>
	</monogr>
	<note>including Allais&apos; paradox</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Risk Uncertain</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Reference-point centering and range-adaptation enhance human reinforcement learning at the cost of irrational preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coricelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">4503</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title level="m" type="main">This study reveals the co-existence of reference-point dependence and range adaptation in human reinforcement learning. Among other results, it also shows that contextual biases are positively correlated with an explicit understanding of the task structure</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Two sides of the same coin: Beneficial and detrimental consequences of range adaptation in human reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Rustichini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Sci Adv</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">340</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">This study investigates range adaptation in human reinforcement learning. It provides evidence in favor of the RANGE model (described in Box 1) over eight experiment and by re-analyzing data from</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<imprint/>
	</monogr>
	<note>25]. The paper also explores the paradoxical relation between learning and transfer phase performance</note>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Individual Choice Behavior: A Theoretical Analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Courier Corporation</title>
		<imprint>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Rational choice and economic behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Day</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory Decis</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page" from="229" to="251" />
			<date type="published" when="1971" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Rationality for Economists?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">L</forename><surname>Mcfadden</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Risk Uncertain</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="73" to="105" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Living near the edge: How extreme outcomes and their neighbors drive risky choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mcmillan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Xu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Spetch</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">147</biblScope>
			<biblScope unit="page" from="1905" to="1918" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">* By investigating risk preferences in human reinforcement learning, this study found that they are not determined by the value of the outcomes per se, but rather they are driven by over-representation in memory of the contextually more salient outcomes</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">Chapter 24 -The Neurobiology of Context-Dependent Valuation and Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">De</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neuroeconomics</title>
		<editor>Glimcher PW, Fehr E</editor>
		<imprint>
			<publisher>Academic Press</publisher>
			<biblScope unit="volume">2014</biblScope>
			<biblScope unit="page" from="455" to="476" />
		</imprint>
	</monogr>
	<note>Second Edition</note>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Cognitive and Neural Bases of Multi-Attribute, Multi-Alternative, Value-based Decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">M</forename><surname>Turner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="251" to="263" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">How similarity between choice options affects decisions from experience: The accentuation-of-differences model</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">S</forename><surname>Spektor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gluth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fontanesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">52</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">This compelling study investigates classical IIA violations in human reinforcement learning and provides clear evidence for outcome context-dependence in several experiments. The results are consistent with an attentional bias, where similar outcomes are reciprocally inhibited</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">*</forename></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">The Effect of Experience on Context-dependent Decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Lejarraga</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Behav Decis Mak</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="535" to="546" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A cross-cultural study of reference point adaptation: Evidence from China, Korea, and the US</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Arkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Hirshleifer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Jiang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Lim</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organ Behav Hum Decis Process</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="99" to="111" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Reference-Point Formation and Updating</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Baucells</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Weber</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Welfens</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag Sci</title>
		<imprint>
			<biblScope unit="volume">57</biblScope>
			<biblScope unit="page" from="506" to="519" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Searching for the Reference Point</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Baillon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Bleichrodt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Spinu</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag Sci</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="page" from="93" to="112" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Rigoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neural processes mediating contextual influences on human choice behaviour</title>
		<imprint>
			<date type="published" when="2016" />
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="page">12416</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">A Range-Normalization Model of Context-Dependent Choice: A New Model and Evidence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soltani</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">D</forename><surname>Martino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Camerer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">1002607</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Decision by sampling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognit Psychol</title>
		<imprint>
			<biblScope unit="volume">53</biblScope>
			<biblScope unit="page" from="1" to="26" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Does the brain calculate value?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Vlaev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Stewart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">D</forename><surname>Brown</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="546" to="554" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Decision by sampling implements efficient coding of psychoeconomic functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Bhui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="page">985</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<monogr>
		<title level="m" type="main">* This theory paper shows how decision-by-sampling can normatively emerge as a way to efficiently represent information in a noisy channel. The paper also shows that the resulting model displays behavior compatible with Parducci&apos;s range-frequency principle</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Flaherty</surname></persName>
		</author>
		<title level="m">Incentive Relativity</title>
		<imprint>
			<publisher>Cambridge University Press</publisher>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Context-dependent utility overrides absolute memory as a determinant of choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pompilio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kacelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proc Natl Acad Sci</title>
		<imprint>
			<biblScope unit="volume">107</biblScope>
			<biblScope unit="page" from="508" to="512" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<monogr>
		<title level="m" type="main">* To our knowledge, this study (in European starlings) is the first one to demonstrate contextdependent outcome encoding in an instrumental learning paradigm combining a learning (training) and a test (transfer) phase. This design served as a base for later studies in humans</title>
		<imprint/>
	</monogr>
	<note>26,27</note>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Context-Dependent Preferences in Starlings: Linking Ecology, Foraging and Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Vasconcelos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Monteiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kacelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS ONE</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">64934</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">The ecological rationality of state-dependent valuation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Trimmer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Houston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">119</biblScope>
			<biblScope unit="page">114</biblScope>
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">An Adaptive Response to Uncertainty Generates Positive and Negative Contrast Effects</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Mcnamara</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">W</forename><surname>Fawcett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">I</forename><surname>Houston</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">340</biblScope>
			<biblScope unit="page" from="1084" to="1086" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<monogr>
		<title level="m" type="main">The case against economic values in the orbitofrontal cortex (or anywhere else in the brain)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hayden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/7hgup</idno>
		<imprint>
			<biblScope unit="volume">2020</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Thought-provoking opinion paper challenging the common assumption that the brain represents expected value and arguing in favor of heuristic decision-making and direct policy learning</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Signals in human striatum are appropriate for policy update rather than value prediction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Li</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci Off J Soc Neurosci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="page" from="5504" to="5511" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title level="m" type="main">Regret in Experience-Based Decisions: The Effects of Expected Value Differences and Mixed Gains and Losses</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Hayes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wedell</surname></persName>
		</author>
		<idno type="DOI">10.31234/osf.io/xaeyn</idno>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Decomposing the effects of context valence and feedback information on speed and accuracy during reinforcement learning: a metaanalytical approach using diffusion decision modeling</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Fontanesi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn Affect Behav Neurosci</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="page" from="490" to="502" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Chapter 24 -Multiple Forms of Value Learning and the Function of Dopamine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>O'doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">F</forename><surname>Camerer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Fehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Poldrack</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Neuroeconomics</title>
		<imprint>
			<publisher>Academic Press</publisher>
			<date type="published" when="2009" />
			<biblScope unit="page" from="367" to="387" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">Memory systems of the brain: A brief history and current perspective</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Squire</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Neurobiol Learn Mem</title>
		<imprint>
			<biblScope unit="volume">82</biblScope>
			<biblScope unit="page" from="171" to="177" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">Assessing inter-individual differences with task-related functional neuroimaging</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="897" to="905" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<monogr>
		<title level="m" type="main">* This perspective papers claims (and mathematically demonstrates) that hypotheses concerning the normalization of the outcome signals bear heavy consequences on how neural data (especially functional magnetic resonance) should be analyzed and interpreted in modelbased fMRI approaches</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">BOLD Subjective Value Signals Exhibit Robust Range Adaptation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">M</forename><surname>Cox</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Neurosci</title>
		<imprint>
			<biblScope unit="volume">34</biblScope>
			<biblScope unit="page" from="16533" to="16543" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<monogr>
		<title level="m" type="main">Reinforcement learning: An introduction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Habits without values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="page">292</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">The Normalization of Consumer Valuations: Context-Dependent Preferences from Neurobiological Constraints</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Manag Sci</title>
		<imprint>
			<biblScope unit="volume">67</biblScope>
			<biblScope unit="page" from="93" to="125" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Adaptive neural coding: from biological to behavioral decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Webb</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Curr Opin Behav Sci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="91" to="99" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Multiple timescales of normalized value coding underlie adaptive choice behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Zimmermann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">W</forename><surname>Glimcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="page">3206</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title level="m" type="main">Adaptive Value Normalization in the Prefrontal Cortex Is Reduced by Memory Load</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Holper</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ldv</forename><surname>Brussel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Schmidt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schulthess</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">J</forename><surname>Burke</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Louie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Seifritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tobler</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="page">4</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<analytic>
		<title level="a" type="main">Rational choice, context dependence, and the value of information in European starlings (Sturnus vulgaris)</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Freidin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kacelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Science</title>
		<imprint>
			<biblScope unit="volume">334</biblScope>
			<biblScope unit="page" from="1000" to="1002" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<analytic>
		<title level="a" type="main">Encoding Context Determines Risky Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Madan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Spetch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Fmds</forename><surname>Machado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mason</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="743" to="754" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title level="m" type="main">*This paper clearly shows that information about outcome range can be attached to external cues (background images in this case), thus influencing the valuation of newly presented options</title>
		<imprint/>
	</monogr>
	<note>It also shows that contextual endpoints (Rmax and Rmin) are preferentially remembered</note>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">State-Dependent Decisions Cause Apparent Violations of Rationality in Animal Choice</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Schuck-Paim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Pompilio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kacelnik</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLOS Biol</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page">402</biblScope>
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">Where Does Value Come From?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Juechems</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Summerfield</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="836" to="850" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<monogr>
		<title level="m" type="main">Homeostatic reinforcement learning for integrating reward collection and physiological stability</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Keramati</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Gutkin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2014" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">4811</biblScope>
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
