<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Distributional Dual-Process Model Predicts Strategic Shifts in Decision-Making Under Uncertainty 10</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mianzhi</forename><surname>Hu</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<settlement>College Station</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hilary</forename><forename type="middle">J</forename><surname>Don</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<settlement>College Station</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
							<affiliation key="aff1">
								<orgName type="institution">University College London</orgName>
								<address>
									<settlement>London</settlement>
									<country key="GB">United Kingdom</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Darrell</forename><forename type="middle">A</forename><surname>Worthy</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Texas A&amp;M University</orgName>
								<address>
									<settlement>College Station</settlement>
									<country key="US">United States</country>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Ph</forename><forename type="middle">D</forename><surname>Student</surname></persName>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution" key="instit1">Texas A&amp;M University</orgName>
								<orgName type="institution" key="instit2">TAMU College Station</orgName>
								<address>
									<postCode>4235, 77845-4235</postCode>
									<region>TX</region>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Distributional Dual-Process Model Predicts Strategic Shifts in Decision-Making Under Uncertainty 10</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T11:45+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<abstract>
				<p>In an uncertain world, human decision-making often involves adaptively leveraging different strategies to maximize gains. These strategic shifts, however, are overlooked by many traditional reinforcement learning models. Here, we incorporate parallel evaluation systems into distribution-based modeling and propose an entropy-weighted dual-process model that leverages Dirichlet and multivariate Gaussian distributions to represent frequency and value-based 35 decision-making strategies, respectively. Model simulations and empirical tests demonstrated that our model outperformed traditional RL models by uniquely capturing participants&apos; strategic change from value-based to frequency-based learning in response to heightened uncertainty. As reward variance increased, participants switched from focusing on actual rewards to using reward frequency as a proxy for value, thereby showing greater preference for more frequently rewarded but less valuable options. These findings suggest that increased uncertainty encourages the compensatory use of diverse evaluation methods, and our dual-process model provides a promising framework for studying multi-system decision-making in complex, multivariable contexts.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Human decision-making has been extensively studied through the lens of expected value (EV) or expected utility (EU), which quantitatively defines the anticipated outcome of choosing a given option, adjusted by subjective weightings for, for example, outcome valence, probability, and magnitude <ref type="bibr" target="#b0">[1]</ref><ref type="bibr" target="#b1">[2]</ref><ref type="bibr" target="#b2">[3]</ref> . Since the 17 th century, EV and EU typically reflect holistic, unitary, and deterministic measures of utility, which can be rational, or, more often, biased under conditions of uncertainty and/or incomplete information <ref type="bibr" target="#b3">[4]</ref><ref type="bibr" target="#b4">[5]</ref><ref type="bibr" target="#b5">[6]</ref><ref type="bibr" target="#b6">[7]</ref> . Researchers have long sought to develop computational models that can accurately specify the cognitive pathways people use to adjust their expectations, usually in the context of repeated reinforcement learning (RL) and under constraints of limited time and resources <ref type="bibr">[8]</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref> . Yet, the applicability and effectiveness of many current RL models still vary significantly across different contexts <ref type="bibr">8,</ref><ref type="bibr">9,</ref><ref type="bibr">11</ref> , suggesting that EV may 74 not be best represented as a singular value <ref type="bibr" target="#b11">[12]</ref><ref type="bibr" target="#b12">[13]</ref><ref type="bibr" target="#b13">[14]</ref> , nor do individuals consistently adhere to one 75 single decision-making strategy <ref type="bibr" target="#b14">[15]</ref><ref type="bibr" target="#b15">[16]</ref><ref type="bibr" target="#b16">[17]</ref> .</p><p>Emerging evidence from neural and behavioral modeling studies suggests that, rather 77 than aiming for a definite EV, people are more likely to process incoming information in a 78 probabilistic manner, continuously updating their internal representations of expected outcomes 79 as distributions <ref type="bibr" target="#b11">12,</ref><ref type="bibr" target="#b17">[18]</ref><ref type="bibr" target="#b18">[19]</ref><ref type="bibr" target="#b19">[20]</ref> . Building upon this, we propose that distribution-based modeling with parallel evaluation systems can be leveraged to address the limitations of both singular EV representations and adaptive strategy switching. In this framework, each system represents expected outcomes as distinct distributions, which are updated independently using only relevant aspects of the outcome information and weighted by their associated statistical dispersion (i.e., entropy) to inform final decisions. In this work, we demonstrate that an entropy-weighted dual-85 process model that integrates two simple distribution functions-namely the Dirichlet and the 86 multivariate Gaussian distribution-can effectively capture frequency-based and value-based 87 decision-making strategies, adapt to diverse RL contexts, and elucidate the underlying rationale 88 behind trial-by-trial decisions. 89</p><p>In instance-based RL, a critical finding from previous research on adaptive decision-90 making reveals that decisions are guided not only by the EV of rewards but also by their 91 frequencies <ref type="bibr" target="#b3">4,</ref><ref type="bibr">[9]</ref><ref type="bibr">[10]</ref><ref type="bibr">[11]</ref><ref type="bibr" target="#b20">21,</ref><ref type="bibr" target="#b21">22</ref> . Reward frequency sometimes serves as a proxy for the perceived value of an option, giving people an intuitive sense of which option provides more rewards. When 93 making decisions based on experience, people tend to undervalue infrequently rewarded, less 94 familiar options, often leading to a disproportional preference for more frequently rewarded 95 options even when they yield suboptimal long-term payoffs <ref type="bibr">8,</ref><ref type="bibr">11,</ref><ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b22">23</ref> . Interestingly, these frequency effects manifest only between pairs of options with marginal value differences, while in cases 97</p><p>where the difference is more discernible, the frequency of reinforcement has little impact on 98 decision-making <ref type="bibr">11,</ref><ref type="bibr" target="#b22">23</ref> . 99</p><p>Supporting this, cross-model comparison studies 9,11 also show that frequency-sensitive models (e.g., Decay models) better fit participants' behavior than mean-centered models (e.g., the Delta model) in more information-intensive, memory-demanding scenarios, such as fouroption tasks or an omniscient version of the Iowa Gambling Task (IGT) where participants have full information about the outcomes of all decks regardless of their choices. However, this advantage dissipates in simpler tasks, such as binary choice tasks and the original IGT. These findings point to a potential multivariable interplay among reward value, frequency, and self-106 perceived uncertainty, where individuals tend to make rational, value-based decisions when they are able to fully process option values, whereas under conditions of high value uncertainty, they may consult a more intuitive, reflexive decision-making system that prioritizes the frequency of rewards as a proxy for value, leading to habitual behavioral patterns favoring the safe option.</p><p>Unfortunately, many existing RL models fail to account for this uncertainty-driven strategic shift, as they either computationally overlook the role of uncertainty, or lack the flexibility to accommodate alternative decision-making strategies. Among those models that do incorporate uncertainty, asymmetric RL models <ref type="bibr" target="#b23">24</ref> that assign different learning rates for positive 114 versus negative prediction errors have been shown to account for risk sensitivity in both neural 115 and behavioral data. Similarly, the mean-variance utility model from the economics literature also discounts an option's EV by its estimated variance <ref type="bibr" target="#b24">25</ref> . However, as our simulation results 117 later demonstrate, these models do not predict a shift in preference from more valuable options 118 under low value uncertainty to more frequently rewarded options under high value uncertainty. 119</p><p>This is because these models apply the same level of discounting to the EVs of all options when reward variance is uniformly elevated, leaving no mechanism to differentiate preferences. Without a supplementary system to aid in the decision-making process under such conditions, these uncertainty-sensitive models fail to capture frequency effects in environments where variance is equally high across all options.</p><p>To empirically test our model and explore these nuanced interactions, we presented participants with four options (A, B, C, D) across three randomly assigned levels of reward variance: low variance (LV), moderate variance (MV), and high variance (HV). Rewards for each option were randomly drawn from a normal distribution with constant mean values (A = 0.65, B = 0.35, C = 0.75, D = 0.25) and the assigned variance level. The task consisted of two phases 11 . In the first phase, participants underwent 150 training trials with feedback, selecting from either AB or CD pairs. In each pair, one option (i.e., A and C) yielded significantly higher rewards than the other (i.e., B and D). However, AB pairs were presented twice as often as CD pairs (i.e., 100 AB trials versus 50 CD trials), resulting in A providing more frequent rewards than C, despite having a lower average reward value (A: 0.65, C: 0.75). After the training phase, participants proceeded to the transfer phase, where they selected from the remaining combinations (i.e., AD, BD, CA, CB) without feedback. We were particularly interested in examining selections from the new CA pair to gauge participants' subjective evaluation of C versus A, as this pair presents a scenario where the more frequently rewarded option (A) has a lower average payoff than the other option (C).</p><p>We hypothesized that 1) EV in multivariable scenarios is better represented as an entropy-weighted sum of estimations from parallel distributional evaluative systems than a singular value generated by a fixed learning rule; 2) in our task, people's preference for the more frequent but less rewarding option, A, would increase with higher reward variance due to increased entropy-or reduced confidence-in value-based processing and the need to explore alternative evaluation strategies; 3) this shift in preference would be correlated with increased model-inferred weights on frequency-based processing and a corresponding decreased reliance in value-based processing.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>This study was approved by Texas A&amp;M University Institutional Review Board (IRB2021-1008M). Participants were 293 undergraduate students from Texas A&amp;M University, who received partial course credit for their participation and provided informed consent. The mean age was 19.13 years (SD = 1.58), with 65% of participants self-identifying as women (Women = 169, Men = 91, Missing = 33). Demographic information for 33 of the 293 participants was not collected due to technical issues. However, as most participants were firstyear students enrolled in the introductory psychology course, the overall distribution of age and sex is very unlikely to be significantly impacted by the missing data. Race and ethnicity information was not collected but is expected to align with the typical demographic profile of first-year psychology students at Texas A&amp;M University. Participants were randomly allocated into the LV (n = 93), MV (n = 100), and HV (n = 100) conditions. No participant was excluded from our analysis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedures</head><p>The experiment was run on Windows lab computers using Psychtoolbox 3 for MATLAB. The procedures are fundamentally the same as <ref type="bibr" target="#b10">Don et al. (2019)</ref>. <ref type="figure" target="#fig_0">Figure 1</ref> shows an example trial sequence of the task. Participants were instructed that they would make repeated choices on each trial, and they would gain or lose rewards for each choice. They were told their goal was to gain as many points as possible, so they should try to learn which options are most rewarding. Choice options were four fractal images, presented in different pair combinations. The fractals each participant saw were randomly drawn from a pool of 12 images and the order of the 4 selected images were randomly arranged on screen. Further, the AB and CD option pairs' placement was also randomized onscreen. AB and CD were always together as a pair, but the order of each pair varied for each participant. As an example, some potential orderings of the option could include: ABCD, CDAB, BACD, etc. The reward structure is shown in <ref type="table" target="#tab_0">Table 1</ref>.</p><p>In the training phase, participants made choices between option A versus option B, or option C vs option D. There were 100 AB trials, and 50 CD trials, with each trial type randomly distributed over the 150 training trials. Rewards were centered at each deck's mean value (A 176 = .65, B = .35, C = .75, D = .25). For the HV condition, rewards were normally distributed with 177 the standard deviation mirroring that of a binomial distribution. For decks A and B, this was 178 (.65 × .35) .5 = .48, and for C and D this was (.75 × .25) .5 = .43. For the MV condition, the standard deviation in rewards was half that of the HV condition (i.e., .24 for AB; .22 for CD), 180 and the LV condition was a quarter of those in the HV condition (i.e., .12 for AB; .11 for CD) 181</p><p>After training, participants were told they would now choose between different option 182 pairs. Transfer test trials included 25 of each AC, AD, BC and BD trials, in random order. No 183 feedback was provided for choices in the test phase. 184</p><p>This study was not preregistered; however, our experiment was carefully designed and 185 provided clear predictions regarding the expected direction of the effects. Data distribution was 186 assumed to be normal but this was not formally tested. 187  Example Trial Sequences. During the first 150 training trials, participants selected from either the AB or the CD pair.</p><p>Option labels were randomized (e.g., Option S could correspond to A, B, C, or D in the reward schedule). The total virtual points earned were displayed at the top of the screen. After each selection, participants received feedback on the number of points gained. In the subsequent 100 transfer trials, participants chose from the remaining four option combinations (i.e., 25 trials for each)-CA, BD, AD, and CB-without cumulative point displays or feedback. They were instructed to rely on knowledge acquired during the training phase to maximize their points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model</head><p>In our model, we innovatively leverage two widely used distribution functions-the Dirichlet and multivariate Gaussian distributions-to represent frequency-based and value-based decision-making processes, respectively, thereby minimizing presumptions and manual engineering <ref type="bibr" target="#b25">26</ref> . The multivariate Gaussian distribution, akin to a univariate normal distribution, defines the EV distribution of each option solely based on the reward's mean and variance, without retaining a tally of past rewards. Previous models have included additional parameters to account for aspects of subjective utility such as loss aversion and discounting of large rewards <ref type="bibr">3 , 207</ref> but in this work, since most rewards were gains, and rewards were normally distributed, we 208 assumed that rewards were processed veridically, rather than as subjective utility. As a result, we 209 focused on testing simpler models that do not make assumptions regarding subjective utility. 210</p><p>Additionally, as Yechiam (2019) pointed out, EU is often linear and symmetrical when the 211 absolute magnitude of EVs is relatively small (e.g., below 100), making a subjective utility 212 function unnecessary in such cases <ref type="bibr" target="#b26">27</ref> . In our paradigm, the magnitude of outcomes ranged between 0 and 1, which falls well within this range. During model comparison, however, we included one model-the mean-variance utility model-which incorporates a shaping parameter for the utility function.</p><p>In contrast, the Dirichlet distribution, as a multivariate extension of the Beta distribution, records only the number of successes and is commonly used as an a priori distribution to estimate the probabilities of multiple events with binary outcomes (i.e., successes and failures) <ref type="bibr" target="#b27">28,</ref><ref type="bibr" target="#b28">29</ref> . In our model, we use the Dirichlet distribution to track the success frequencies 220 across the four options, essentially recording how many times each option has been chosen and 221 yielded a rewarding outcome. Given that our RL paradigm involves mostly gains, we define a 222 "success" as receiving a reward higher than the average of the estimated mean values across all 223 four options in the Gaussian process. On each trial, if the received reward exceeds this overall average, one success is added to the chosen option in the Dirichlet function. This causes the distribution function to allocate slightly more probability density to that option for future selections. Although the defining a "success" in the Dirichlet distribution may initially require input from the Gaussian process, this information is quickly converted into an offline tally of past rewarding instances (i.e., the α parameter in the Dirichlet distribution). During decisionmaking, the Dirichlet distribution involves only the retrieval of this tally, which is hypothesized to be less resource-consuming than the Gaussian process.</p><p>These two distribution functions allow us to dissociate the impact of reward frequency from actual reward values. The Dirichlet and multivariate Gaussian distributions share few 233 elements in generating the posterior distribution. The Dirichlet distribution retains only the 234 number of successes per option, while the Gaussian distribution estimates the underlying value 235 distributions. The contrast between these two distributions becomes particularly evident when 236 considering an option that has been rewarded frequently but with small rewards. The Dirichlet 237 distribution would assign a high probability mass to this option because of its high reward frequency, whereas the multivariate Gaussian distribution would show little preference, as the small rewards do not significantly alter the perceived average value for that option (see <ref type="figure" target="#fig_1">Figure   2)</ref>.</p><p>A major challenge with integrating multiple decision-making systems is determining their relative weight. Previous studies juxtaposing two processes often use a constant weight parameter to reflect the overall preference for one process over the other <ref type="bibr" target="#b14">15,</ref><ref type="bibr" target="#b16">17,</ref><ref type="bibr" target="#b29">[30]</ref><ref type="bibr" target="#b30">[31]</ref><ref type="bibr" target="#b31">[32]</ref><ref type="bibr">[33]</ref> . However, this 244 approach assumes that the same weight is applied to each choice the participant makes, which is 245 likely not the case, especially in cross-comparisons among multiple options. For instance, in our 246 task, people probably do not apply the same weight when choosing between options A and B, 247</p><p>where A is clearly better than B, as they would when choosing between options A and C, where 248 the difference is more ambiguous.</p><p>To address this, we conceptualize that individuals should give greater weight to the estimation process with less uncertainty. In modeling terms, this implies that the distribution with lower entropy should be given a higher weight. Gaussian entropy reflects confidence in the estimated value of an option (e.g., "How sure am I that option A is worth this much?"), while 253</p><p>Dirichlet entropy reflects confidence in the observed frequency of rewards for an option (e.g., 254</p><p>"How sure am I that option A has yielded this many rewards so far?"). In this work, the term "uncertainty" refers specifically to value uncertainty in the Gaussian process, influenced by our reward variance manipulation. In contrast, frequency uncertainty, represented by the statistical dispersion of the Dirichlet distribution, will be referred to separately as "frequency." This modeling approach creates a delicate balance between uncertainty and EV, where the impact of EV differences will be proportional to the level of uncertainty within the estimation process. In other words, an estimation process will have a large impact only when the EV difference is substantial, and the individual is confident about the difference. Specifically, uncertainty in a given distribution function f(x) is estimated using differential entropy h(x) <ref type="bibr">34</ref> : 263</p><formula xml:id="formula_0">ℎ( ) = − � ( )log[ ( )]<label>(1)</label></formula><p>and the weight for the Dirichlet process wD is calculated as: 265</p><formula xml:id="formula_1">= 1 • 2 ℎ( ) 1 • 2 ℎ( ) + (1 − 1 ) • 2 ℎ( ) (2)</formula><p>where h(G) and h(D) represent the differential entropies for the multivariate Gaussian and Dirichlet distributions, respectively (see Supplementary Methods for the definition of individual distribution functions). The term 2 h(x) converts differential entropy into effective volume, which can be interpreted as the size of the space occupied by a continuous random variable x 34 . It also 270</p><p>assures that the measure of uncertainty is always positive. The parameter w1 denotes the subjective preference for the Dirichlet distribution, analogous to a constant weight parameter, which captures people's baseline reliance on the Dirichlet process. Crucially, the overall Dirichlet weight, wD, is the product of the objective weight-calculated as the proportion of 274 inversed Dirichlet entropy relative to the cumulative inversed entropy-and the subjective 275 weight, which accounts for individual differences. This combined weight is then applied to the 276 probabilities generated from a SoftMax rule. The predicted probability that option j will be chosen on trial t, � ( )� is calculated as:</p><formula xml:id="formula_2">� ( )� = • • , ( ) ∑ • , ( ) ( ) 1 + (1 − ) • • , ( ) ∑ • , ( ) ( ) 1 (3) where = 3 − 1 (0 ≤ ≤ 5)</formula><p>, and c is a log inverse temperature parameter that determines how consistently the option with the higher expected value is selected <ref type="bibr">35</ref> . When c = 0, choices are random; as c increases, the option with the highest EV is selected more often. The EVs are the mathematically defined expectations for their respective distributions. In the multivariate Gaussian distribution, the EV for option j, EVj,G, is the estimated mean, µj. In the Dirichlet distribution, EVj,D is the proportion of the estimated frequency, αj, divided by the sum of all 285 frequency estimates,</p><formula xml:id="formula_3">∑ =1 .</formula><p>We compared our dual-process model to five established RL models. The Delta and Decay models represent the best-performing examples from the two major classes of RL learning models with demonstrated effectiveness 9 . The Delta model <ref type="bibr">[35]</ref><ref type="bibr">[36]</ref><ref type="bibr" target="#b36">[37]</ref> , one of the most widely used mean-centered RL models, updates the EV of an option solely based on recency-weighted 290 prediction errors and assumes no changes for unchosen options. In contrast, the Decay model <ref type="bibr">11,</ref><ref type="bibr" target="#b20">21</ref> , which excels in decision-making scenarios with unequal reward frequencies, adds the raw reward value to an option's EV but assumes that the EV decays for every time point the option is not chosen. We also compared our model to two uncertainty-sensitive models that account for reward variance. The risk-sensitive Delta model <ref type="bibr" target="#b23">24</ref> follows the same updating rule as the Delta model but applies asymmetric learning rates for positive versus negative prediction errors. The mean-variance utility model <ref type="bibr" target="#b24">25</ref> , drawn from the economics literature, discounts an option's EV by its variance to incorporate risk sensitivity. Finally, we compared the dual-process model to a classic example from the sampler model class, the Adaptive Control of Thought-Rational (ACT-R) model <ref type="bibr" target="#b37">38,</ref><ref type="bibr" target="#b38">39</ref> . We used a slightly modified version of the ACT-R model introduced by Erev and colleagues (2010) for applications in repeated RL tasks 8 . This ACT-R 301 model probabilistically retrieves past experiences to guide future actions. It calculates the 302 activation level for each previous experience of choosing an option and aggregates activated 303 experiences to determine the EV using a probability-weighted sum. The computational 304 mechanisms of these alternative models are detailed below. 305 once and yielded a reward of 0.5. This results in equal probability mass being assigned to each option in both Dirichlet and Gaussian distributions, indicating no a priori preference. Next, if B is selected again and yields a reward of 0.6, both distributions become biased towards B because this increases both the tally of B yielding a reward and the average value of B so far. Now, if B is selected 100 times, with a reward of 0.6 each time, the tally of B yielding a reward above average becomes 102, causing the Dirichlet distribution to favor B almost exclusively. In contrast, the Gaussian distribution shows little change because it primarily processes the average value of B, which approximates 0.6 over time. In this scenario, the Dirichlet distribution predicts a close-to-1 probability of selecting B again, while the Gaussian distribution only gives a probability slightly higher than 0.5. Finally, imagine that on trial 102, A is selected and yields a reward of 0.95. This does not significantly affect the Dirichlet distribution, as the overwhelming advantage of B still exists. However, the Gaussian distribution changes considerably, now favoring A, as the average value for A increases significantly from 0.5 to 0.725, higher than 0.599 for B. At this point, the two distributions diverge in their predictions: the Dirichlet distribution continues to favor B very strongly, while the Gaussian distribution predicts a higher probability of choosing A over B due to its higher average reward value.</p><p>Here, α denotes the vector for the number of successes and µ represents the vector for the mean values. For simplicity, neither the decay and learning rates nor the uncertainty are included here. The distribution plots represent the posterior Dirichlet and multivariate Gaussian distributions generated using the corresponding parameter sets.</p><p>Blue dots indicate data points randomly sampled from the posterior distributions. For each posterior, 5,000 data points were randomly sampled, with the x-, y-, and z-axes representing the actual values of the sampled data points.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Alternative Models</head><p>The Delta rule <ref type="bibr">[35]</ref><ref type="bibr">[36]</ref><ref type="bibr" target="#b36">[37]</ref> updates the EV by incorporating the prediction error between the EV from the last trial and the actual reward received in the current trial. EVt+1 for option j is defined as: 333</p><formula xml:id="formula_4">, +1 = , + ⋅ � − , � ⋅ (4)</formula><p>where Ij is a term recording option choice via a value of 1 if option j is chosen on trial t, and 0 otherwise; rt is the reward value; and α is the learning parameter, ∈ (0,1), with higher α indicating greater emphasis on most recent samples. In this model, no memory of previous trials is retained, making it mean-centered. Consequently, when prediction errors are minimal, the EV will not increase significantly regardless of the number of rewards received.</p><p>The Decay model 11,21 updates the EV of option j on trial t as:</p><formula xml:id="formula_5">, +1 = , ⋅ (1 − ) + ⋅ (5)</formula><p>where A is the decay parameter, ∈ (0,1), with higher A indicating higher weights given to recent outcomes. In this model, the EV for each option will decay over time and only increase when a reward for that option is received. Thus, the more frequent the reward, the greater the EV, making the Decay model sensitive to reward frequencies.</p><p>The risk-sensitive Delta model 24 applies asymmetric learning rates for positive and negative prediction errors and then updates EV in the same manner as the standard Delta model. 347</p><p>Specifically, 348</p><formula xml:id="formula_6">, +1 = � , + + ⋅ ( ) ⋅ if ( ) &gt; 0, , + − ⋅ ( ) ⋅ if ( ) &lt; 0,<label>(6)</label></formula><p>349 where ( ) represents the prediction error, ( ) = − , ; α + and αdenote the learning rate for positive and negative prediction errors, respectively, ∈ (0,1). This model has been shown to effectively account for risk sensitivity in decision-making <ref type="bibr" target="#b23">24</ref> .</p><p>Another risk-sensitive model, the mean-variance utility model <ref type="bibr" target="#b24">25</ref> , discounts the EV of an option by its estimated variance. Specifically:</p><formula xml:id="formula_7">= − 2 2<label>(7)</label></formula><p>355 where µ and σ 2 represent the mean and variance of the outcomes for option j; and λ quantifies subjective risk aversion. A higher λ indicates greater risk aversion. In economics, this model typically excludes recency effects or the discounting of past outcomes. However, for its application in psychology, we update its mean and variance using a Delta rule:</p><formula xml:id="formula_8">, +1 = , + ⋅ ( ) ⋅ ;<label>(8)</label></formula><p>, +1 2 </p><formula xml:id="formula_9">= , 2 + ⋅ � ( ) 2 − , 2 � ⋅ (9)</formula><formula xml:id="formula_10">, = � =1 , − + ( )<label>(10)</label></formula><p>where tj,k is the number of trials since the kth time option j was selected, α is the decay rate, and 371 ( ) is a random value chosen from a logistic distribution with variance 2 2 /3, = where = 3 − 1 (0 ≤ ≤ 5). Then, the reward value of any experience that exceeds the 376 activation level τ will be weighted by the corresponding Pi to calculate the weighted sum as the EV for option j. For Pi &gt; τ, the EV is calculated as:</p><formula xml:id="formula_11">= � ∈{ | &gt; } ⋅ (12)</formula><p>where ri is the actual reward value for experience i. This method allows the ACT-R model to stochastically integrate past experiences and predict the probability of selecting option j based on the weighted contributions of all relevant experiences.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Simulation</head><p>To evaluate how each of the six models would adapt to various RL scenarios, we randomly sampled 5,000 reward schedules while maintaining the same basic task structure: 1) C &gt; A &gt; B &gt; D, with at least a 0.01 mean difference; 2) , ∈ (0.5, 1) and , ∈ (0, 0.5); 3) 386 AB trials presented twice as often as CD trials during the training phase; 3) reward standard 387 deviation ∈ (0.11, 0.48). For each reward schedule, we ran 1,000 simulations to predict 388 preferences in CA trials. Across a wide range of reward ratios and variances, we generated two 389 sets of model surfaces: one showing the predicted proportion of C choices in CA trials and another showing the proportion of simulated agents displaying a disproportionate preference for the more frequently rewarded option A. The reward ratio between two options is calculated as 392</p><formula xml:id="formula_12">1 + 2</formula><p>, and choosing C less frequently than this ratio indicates a disproportionate preference for A. Previous research <ref type="bibr" target="#b39">40</ref> demonstrated that simulating the entire surface of computational models 394 can reveal underlying model properties and task dynamics that might be missed when focusing 395 solely on specific reward schedules.</p><p>To avoid simulation result variations caused by differing schedules, the same 5,000 397 generated reward schedules were applied to all models. During these simulations, parameters 398</p><p>were randomly drawn from uniform distributions. The learning rate α and decay parameter A values were bounded between 0 and 1, c between 0 and 5, τ between -2 and 0, and all weight parameters, including λ, were constrained between 0 and 1 <ref type="bibr">11,</ref><ref type="bibr">35</ref> . Randomized trial sequences in both training and transfer phases were generated and shuffled for simulation. For traditional model simulations presented in the supplementary materials, we followed the same procedure but increased the sample size, simulating 10,000 virtual agents for each condition.</p><p>In the post-hoc simulation, we randomly sampled 10,000 parameter sets with replacement from the individualized best-fitting parameters obtained during model fitting (akin to bootstrapping). These sampled best-fitting parameters were then used to simulate the model with randomized trial sequences, allowing us to estimate the model's ability to replicate empirical behavioral patterns. For each model, we calculated the percentage of choosing the optimal option in each pair (e.g., A in AB trials, C in CA trials) as predicted by the simulations. The root mean squared error (RMSE) was then computed between the actual and predicted percentage of choosing the optimal option across six trial types to estimate model performance.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Fitting and Evaluation</head><p>We used the maximum likelihood (ML) approach for model fitting. The negative log likelihood of the parameter set θ, given observed data y and model M, ( � | , ), is minimized using the minimize function in the SciPy library in Python. To avoid local minima, we ran the optimization 200 times for each participant with randomly selected starting points for each parameter. Data from both training and transfer phases were used during model fitting.</p><p>We computed the Akaike Information Criteria (AIC) <ref type="bibr" target="#b40">41</ref> and Bayesian Information Criteria 419 (BIC) <ref type="bibr" target="#b41">42</ref> for each individual participant for each model, and used these indices to calculate AIC and BIC weights for model comparison <ref type="bibr" target="#b42">43</ref> . AIC is calculated as:</p><formula xml:id="formula_13">= −2ln � � � , � + 2 (13)</formula><p>where K is the number of free parameters in the model. BIC is calculated as:</p><formula xml:id="formula_14">= −2l n � � � , � + ln( )<label>(14)</label></formula><p>where N is the number of observations. In our study, N equals the 250 trials for each participant. The AIC and BIC weights are calculated as:</p><formula xml:id="formula_15">(AIC/BIC) = ex p − 1 2 Δ (AIC/BIC) ∑ =1 ex p − 2 Δ (AIC/BIC)<label>(15)</label></formula><p>where Δ (AIC/BIC) = AIC /BIC − (AIC/BIC). Higher AIC or BIC values indicate worse model fit, whereas higher AIC-and BIC-weights indicate greater support for the model relative to all comparison models. We also calculated the Bayes Factor (BF10) as BF10, Model1 = exp ( BICmodel2−BICmodel1 2 ) <ref type="bibr" target="#b43">44</ref> . A BF10 higher than 3 is generally considered significant, representing a moderate sized effect <ref type="bibr" target="#b43">44</ref> .</p><p>In addition, we applied Variational Bayesian Model Selection (VBMS) <ref type="bibr" target="#b44">45</ref> criteria, which are designed for group-level model comparisons. VBMS treats the model as a random variable and estimates the parameters of a Dirichlet distribution, which are then used to define a multinomial distribution that provides the probability of each model generating the data for a randomly selected subject. Specifically, the posterior Dirichlet parameters, α, represent the estimated frequency of each model being the one that generates the data for a given subject. The posterior multinomial parameter, rk, describes the probability that data from a randomly chosen subject is generated by a specific model k. Finally, the exceedance probability, φk, quantifies the likelihood that a particular model k is more likely than any other model in the set to generate group-level data. We used BIC to approximate the log evidence (see <ref type="table">Supplementary Table 3</ref> for results using AIC as the log evidence) and all three metrics were calculated for model comparisons.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model-Recovery and Parameter-Recovery</head><p>To assess the significance of the findings obtained in the model fitting analyses, we conducted model recovery and parameter recovery analyses <ref type="bibr" target="#b45">46</ref> . These analyses assessed whether 447 the data generated by the dual-process model could be accurately recovered by itself and whether 448 the fitting process could retrieve the underlying parameter set that generated the data. Briefly, we 449 simulated datasets using all six main models: the dual-process model, Delta, risk-sensitive Delta, 450 mean-variance utility, Decay, and ACT-R. Each simulated dataset was then fit by all models to 451 assess how well the data generated by Model A can be best fit (i.e., recovered) by Model A compared to other models. This process was repeated 100 times for each condition, with 30 random starting parameter sets used during the fitting of the simulated data. Since we were 454 testing a new model and the "true" parameter range was largely unknown, we did not manually 455 set any additional boundaries on the parameters. Therefore, all simulations for all models were 456 conducted using parameters drawn from their entire possible range. 457</p><p>The results were presented in two matrices. The confusion matrix reports the probability 458 that Model A fits the data best given the data was generated by Model A, P (fit model | simulated 459 model), while the inversion matrix reports the probability that Model A generated the data given 460 it was best fit by Model A, P (simulated model | fit model). For both matrices, a higher score 461 indicates better recovery performance. 462</p><p>This simulation process also provided insights into parameter recovery. For this, the 463 underlying parameter sets used during simulation were recorded and correlated with the best-464 fitting parameter sets recovered by the same model. Ideally, the data generated by a Model A 465 with given parameters can be fit by Model A to recover those parameters, leading to a high 466 correlation between the generating parameter set and the recovered parameter set <ref type="bibr" target="#b45">46</ref> . A higher correlation indicates better parameter recovery.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>A Priori Model Simulations</head><p>As shown in <ref type="figure" target="#fig_2">Figure 3a</ref>, the dual-process model was the only model sensitive to both reward ratio and variance: it predicted fewer C choices in CA trials with both higher variance and lower reward ratio. In contrast, the Delta, risk-sensitive Delta, mean-variance utility, Decay and ACT-R models showed a sharp increase in the proportion of C choices as reward ratio increased, whereas their surfaces remained nearly flat across the variance axis. This indicates that these models primarily focused on reward value differences while ignoring the impact of uncertainty. Similarly in <ref type="figure" target="#fig_2">Figure 3b</ref>, the dual-process model predicted an increasing proportion of simulated agents displaying frequency effects with both higher reward variance and lower reward ratio. The Decay model predicted frequent occurrences of frequency effects overall, even with high reward ratios, but showed little sensitivity to changes in reward variance. The other four models predicted minimal changes as reward variance varied. In our paradigm, the two uncertaintysensitive models failed to adapt to different levels of reward variance because they discounted the EV of all options equally when all options had the same level of reward variance. This uniform discounting prevented relative EV differences from changing with altered reward variance, as these models computationally overlooked the role of reward frequency. We closely examined the underlying cause of dual-process model's sensitivity to reward 541 variance. As predicted, higher variance increases the statistical dispersion in the Gaussian process, which in turn reduces its objective weight. In contrast, the Dirichlet process remains 543 relatively unaffected, as the frequency with which simulated agents receive above-average 544 rewards from options A and C does not vary significantly across different levels of variance. 545</p><p>Assuming a uniformly distributed personal preference for the two processes, the decreased 546 objective weight of the Gaussian process results in a higher overall weight for the Dirichlet 547 process, which, in turn, favors A and leads to fewer selections of option C in CA trials. 548</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral Results 549</head><p>To validate our model predictions, 293 participants completed the task (LV: 93; MV: 100; 550 HV: 100).  <ref type="figure" target="#fig_2">Supplementary Figure 3)</ref>. This could reflect a 559 classic exploitation-exploration tradeoff in time-constrained scenarios, where participants must 560 balance efforts to take advantage of known rewards with exploring the unknown 561 environment <ref type="bibr" target="#b15">16,</ref><ref type="bibr" target="#b46">47</ref> . Under low uncertainty, participants quickly identified and committed to better options, whereas under high uncertainty, they were more motivated to explore, as no clear target for exploitation emerged <ref type="bibr" target="#b46">47,</ref><ref type="bibr" target="#b47">48</ref> . 564</p><p>For the critical CA trials, shown in <ref type="figure" target="#fig_5">Figure 4b</ref>, we conducted one-sample t-tests to compare the proportion of C choices against a chance level of .5 and the objective reward ratio between the two alternatives. In CA trials, the reward ratio is  Behavioral Results. (a) Participants in the LV condition showed the highest accuracy in selecting the optimal option during training, with performance decreasing as uncertainty increased in MV and HV conditions. This trend suggests that greater uncertainty led to poorer learning, likely due to an exploration-exploitation tradeoff where participants were more inclined to explore in high-uncertainty scenarios rather than commit to a known optimal option. Here, the optimal option refers to the option whose distribution, from which the outcomes are drawn, has a higher mean and thus provides better long-term payoffs with infinite draws. Accordingly, the ranking is C &gt; A &gt; B &gt; D. (b) During CA trials, participants showed a preference for the better option C in the LV condition, no clear preference in the MV condition, and a preference for the less rewarding but more frequently rewarded option A in the HV condition.  conditions, which cannot be attributed to either of the individual processes alone (Supplementary <ref type="table" target="#tab_0">Table 1</ref>). Notably, in addition to the six previously described models, we also fit a purely objective model where the distributional weights were entirely determined by the objective weight. We found that even the purely objective version of the dual-process model fits better 609 than many current RL models, suggesting that simply accounting for the weighting of multiple 610 processes by their respective entropy-without considering individual differences-was already 611 sufficient to surpass models that assume a single decision-making strategy (Supplementary <ref type="table" target="#tab_0">Table  612</ref> 1). 613 Model Fitting Results. This table summarizes the model fitting results. The parameter c is the inverse log temperature parameter. A higher c means the participant is more likely to stick with the option that has a theoretically higher EV. We made a slight modification to the original implementation of the ACT-R model 8 by applying the same version of the SoftMax rule used in the other five models. This modification did not significantly affect model fit. The α or A parameter represents the level of recency effects, indicating how strongly people rely on recent outcomes to make their next decision. A higher α or A signifies more rapid decay of past experiences and greater reliance on recent samples. The third parameter in the risk-sensitive Delta model, α -, represents the asymmetric learning rate for negative prediction errors. In the mean-variance utility model, the third parameter, λ, represents subjective utility curve, with a higher λ indicating higher risk-aversion. In the ACT-R model, τ represents the memory retrieval threshold, where only past experiences with an activation level above τ can be retrieved and considered in the calculation of EV. AIC, BIC, AIC-weight and BIC-weight represent indices for model fit. Lower AIC and BIC values indicate better model fit, while higher AIC-and BIC-weights suggest a stronger relative advantage for the corresponding model. AIC-and BIC-weights sum to one. BF 10 presents the BF difference between the corresponding model and our dual-process model. Typically, an AIC or BIC difference of 0-2 means little support for the better model, 4-7 indicates moderate support, and a difference of 10 or more signifies substantial support. A BF 10 greater than 3 is considered significant (see <ref type="table" target="#tab_3">Supplementary Table 2</ref> for full BF tables). Finally, the last three columns present results for VBMS results with BIC being used as the log evidence.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model Fitting Results 597</head><p>Post-hoc simulations using the individualized best-fitting parameters also showed that the dual-process model has the lowest RMSE among all models across conditions (dualprocess: .029; Delta: .040; risk-sensitive Delta: .044; mean-variance utility: .044; Decay: .095; ACT-R: .052; see <ref type="figure" target="#fig_5">Supplementary Table 4</ref> for details). The dual-process model replicated participants' choice patterns in CA trials most successfully, whereas the Decay model predicted consistent frequency effects irrespective of reward variance, and the remaining four models failed to recover any frequency effects during post-hoc simulations across the three levels of reward variance ( <ref type="figure" target="#fig_5">Supplementary Figure 4)</ref>.</p><p>Recovery results showed that the dual-process model successfully recovered 67% of data generated by itself in the LV condition, 75% in the MV condition, and 81% in the HV condition (Supplementary <ref type="figure" target="#fig_9">Figure 5</ref>). All three model parameters demonstrated significant correlations between the best-fitting parameters and the generating parameters, indicating satisfactory model and parameter recovery performance  <ref type="figure">Supplementary Figure 6</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Post-hoc Analysis</head><p>Now that we know the dual-process model outperforms many existing RL models across different reward variance levels, what does this tell us about the trial-by-trial decision-making process? To explore this, we closely examined participants' best-fitting parameters, weight distributions between C and A, and their ultimate choices in CA trials. To explore the relationship between the involvement of the Dirichlet process and the observed preference shift, we conducted a multilevel mixed-effects logistic regression to predict 669 the probability of choosing the optimal option C based on the overall weight of the Dirichlet 670 process in CA trials, Choosing C ~ Dirichlet weight + Condition + (1|Participant). After 671 adjusting for condition, we found that higher Dirichlet weights were closely associated with a 672 lower likelihood of selecting C (b = -3.071±0.358, z = -8.569, p &lt; .001, 95% CI = [-3.815, -673 2.374]), suggesting a direct link between Dirichlet-based processing and frequency effects. 674</p><p>Importantly, this effect could not be mediated by variations in any other parameters or 675 misestimations in the Gaussian value-based process (Supplementary . By examining the distribution of objective weights, we found that very few participants ever considered the Dirichlet process when the reward variance was low. However, as uncertainty increased, reliance on reward frequency grew proportionally. This indicates that as variance rose, participants became less able to rely on a single decision-making strategy. The increased uncertainty prompted them to consult multiple estimation methods, such as using reward frequency as a proxy for value.</p><p>Lastly, we examined reaction times between Dirichlet-and Gaussian-oriented decisions 700</p><p>during CA trials to infer the mental effort involved in utilizing different decision-making strategies. A GLM analysis (Reaction Time ~ Dirichlet Weight + Condition) indicated that participants generally took longer to decide in the HV condition than in the LV condition (b = 0.155±0.053, t = 2.921, p = .004, 95% CI = [0.051, 0.258]). A quartic version of the model revealed that Gaussian-oriented decisions required slightly longer processing times than Dirichlet-oriented decisions (b = -3.058±1.812, t = -1.688, p = .092, 95% CI = [-6.610, 0.494]), 706</p><p>whereas participants hesitated the most when the decision involved both processes with nearly 707 equal weights (b = 5.113±1.812, t = 2.822, p = .005, 95% CI = <ref type="bibr">[1.562, 8.665]</ref>). This suggests that value-based decisions, which are likely to involve more rigorous calculations and EV estimations, might be more computationally demanding than frequency-based decisions, but the cognitive load is at its highest when multiple processes must be carefully considered before making the decision. We also observed slight rebounds in reaction time when the weight approached either extreme (i.e., Dirichlet weight close to 0 or 1)-in other words, when a decision was modeled as being almost entirely reliant on one decision-making system. This pattern suggests that individuals might experience tension when relying solely on one system, prompting a brief re-evaluation of the decision. However, this explanation is highly speculative, and further empirical support is needed. uncertainty as the key factor driving the shift toward Dirichlet frequency-based processing. This pattern is hypothesized to be caused by the combined influence of unequal reward frequency and increasing reward variance, while we found that increased reward variance alone was sufficient to produce a similar pattern of Dirichlet weight changes (see <ref type="figure">Supplementary Figure 8</ref>). Error bar represents 95% confidence interval. N = 93 participants in the LV condition, 100 participants in the MV condition, and 100 participants in the HV condition.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>While it has been increasingly acknowledged that using a fixed learning rule to generate singular EVs provides a limited view on how people adjust their expectations <ref type="bibr" target="#b48">[49]</ref><ref type="bibr" target="#b49">[50]</ref><ref type="bibr" target="#b50">[51]</ref> , developing 735 alternative approaches to quantitatively theorize behavioral decision-making remains 736 challenging. For this purpose, our parallel distributional model provides a novel and 737 parsimonious framework for understanding decision-making, particularly in complex, 738 multifaceted scenarios. Deeply rooted in recent accounts of the "Bayesian brain" hypothesis <ref type="bibr" target="#b12">13,</ref><ref type="bibr" target="#b13">14,</ref><ref type="bibr" target="#b17">18,</ref><ref type="bibr" target="#b18">19</ref> , distributional representations of expectations have achieved notable success in explaining a wide range of human behaviors-many of which, just like frequency effects, 741 appear irrational <ref type="bibr" target="#b51">52,</ref><ref type="bibr" target="#b52">53</ref> . We extended this approach by demonstrating that distributional models can accommodate multiple dissociable estimation processes, thereby becoming highly generalizable across a variety of decision-making contexts.</p><p>In our decision-making task with three levels of reward variance, we found that participants preferred the more valuable option C over the more frequently rewarded option A in the low variance condition. With moderate variance, their choices became random, while with high variance, participants significantly favored the more frequently rewarded option A. Within the framework of our dual-process model, which juxtaposes frequency-and value-based systems, we identified a proportional increase in reliance on the frequency-based system as variance increased, which maps nicely onto participants' behavior. Model fitting further showed that the 751 dual-process model significantly outperformed comparison models and accurately captured the 752 observed preference changes. Together, these findings suggest that participants transition from a 753 value-dominant strategy to a dual-process approach, with increasing reliance on reward 754 frequency under conditions of high value uncertainty. This reliance reflects the use of reward 755 frequency as a heuristic for value when estimating the underlying value distribution becomes 756 increasingly challenging. 757 Related to our model, there have been some attempts to develop a dual-process 758 framework. For example, Miller et al. (2019) juxtapose a habitual system with a goal-directed 759 system, arbitrated by action-outcome contingency and habitization strength. While this 760 framework is conceptually similar to our model, their habitual system relies solely on a tally of 761 past choices without encoding the valence. Yet, later research <ref type="bibr" target="#b22">23</ref> shows that frequency effects are not merely contingent on the act of selection, suggesting that valence may still play a role in the frequency-based system. In addition, without a distributional representation of the EV space, the measures of action-outcome contingency and habitization strength-somewhat analogous to the entropy measures in our value-and frequency-based systems-depend on separate, manually tuned calculations (e.g., habitization strength as the distance from the mean) <ref type="bibr" target="#b53">54</ref> . This approach 767 may lack the mathematical rigor and generalizability compared to the estimation of statistical dispersion through well-established distributional functions.</p><p>That said, the unique feature of this dual-process model lies in the entropy-based online weighting approach. This approach builds upon a rich behavioral modeling literature showing that decision-making is strongly influenced by uncertainty <ref type="bibr" target="#b54">[55]</ref><ref type="bibr" target="#b55">[56]</ref><ref type="bibr" target="#b56">[57]</ref> . Higher uncertainty encourages exploration and learning <ref type="bibr" target="#b19">20,</ref><ref type="bibr" target="#b50">51</ref> , raising the "model temperature" during decision-making because individuals may deviate from a strictly value-based logic and consult alternative calculative 774 mechanisms. However, most current efforts to incorporate uncertainty as a modulator of learning 775 nevertheless rely on the Delta rule <ref type="bibr" target="#b19">20,</ref><ref type="bibr">58</ref> , and therefore, are inherently limited in their ability to 776 explain behaviors that stem from alternative strategies, such as frequency effects. The challenge of formally defining and estimating uncertainty in a streamlined RL model without distributional representations often complicates its integration into a multi-system framework. Interestingly, 779</p><p>one of the few studies that remotely addressed this issue in a model-based versus model-free 780 framework used Dirichlet priors to estimate the level of uncertainty 59 . Moreover, uncertainty in one process does not necessarily translate into uncertainty across the entire environment. For instance, in our task, one might be unsure about the value difference between C and A (i.e., high Gaussian entropy) but confident that A has yielded much more cumulative rewards than C (i.e., low Dirichlet entropy). This could encourage individuals to switch decision-making strategies, driven by reduced cognitive efforts needed to ascertain the difference and risk-aversion. Therefore, the presented distribution-based dual-process model excels by recognizing how each process independently responds to the environment, with a unified and straightforward quantitative measure of uncertainty.</p><p>By introducing entropy as a weighting parameter for multiple parallel processes, we also implicitly introduced the idea that greater potential EV differences demand more rigorous validation. In our model, the frequency-based Dirichlet distribution is defined on a simplex, meaning that its components always sum up to one. This constraint reduces the potential statistical dispersion of the distribution but inherently limits the maximum distance between alternative options. In contrast, the multivariate Gaussian distribution is defined over the entire real space, allowing differences between options to be infinitely large but requiring a growing number of samples or a very small variance to validate the difference as reward values scale. The Dirichlet system can be seen as a distilled version of the Gaussian system. Since defining a "reward" inevitably requires input from the value-based system, reward encoding between the two systems is not guaranteed to operate entirely in parallel. Over time, however, detailed decision-making contexts (e.g., precise reward values) may fade into a simplified, offline tally of past outcomes classified in a binary way (i.e., rewarding/non-rewarding). This distinction is reflected in the difference in computational complexity between the Dirichlet and Gaussian distributions. This distillation process reduces the amount of information that needs to be retained and facilitates future retrieval of information stored in the Dirichlet system. This tradeoff captures the balance between accuracy and cognitive efficiency. As the costs (e.g., cognitive effort, sample size) needed to validate decisions in the value-based system become prohibitively high, they may outweigh the potential gains from choosing a slightly better option, thereby encouraging a transition towards the simpler, frequency-based system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Limitations</head><p>One limitation of the current dual-process model is that the subjective Dirichlet weight parameter (w1) exhibited relatively lower stability during parameter recovery compared to the other two parameters. This may be because, in our paradigm, the subjective weight of the frequency-based system becomes less relevant when external value uncertainty is either extremely high or extremely low. In such cases, people are strongly biased toward either the frequency-or value-based system, regardless of their subjective preference. This is supported by 816 the model-fitting results, which demonstrate that the purely objective dual-process model performed relatively well and successfully captured much of the dynamics involved in strategy switching. However, the inclusion of the subjective Dirichlet weight parameter still significantly improved model fit over the purely objective version, suggesting that this parameter captured meaningful variability in participant behavior for at least a subset of individuals whose preferences were not entirely determined by external uncertainty. This parameter may play a more critical role in future studies exploring individual differences in decision-making, 823 especially when external uncertainty is held constant. 824</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Conclusion 825</head><p>In conclusion, our findings of adaptive learning and decision-making in RL reconcile many findings of frequency effects in high variance (i.e., similar or higher than a binomial variance) experimental paradigms, such as the ABCD task 11,23 , IGT <ref type="bibr">[60]</ref><ref type="bibr">[61]</ref><ref type="bibr">[62]</ref> , and Soochow Gambling Task <ref type="bibr" target="#b21">22,</ref><ref type="bibr">63</ref> , with other findings where decision-making appears to be primarily value-829 driven <ref type="bibr">[64]</ref><ref type="bibr" target="#b65">[65]</ref><ref type="bibr" target="#b66">[66]</ref><ref type="bibr" target="#b67">[67]</ref> . The dynamic interplay of reward variance, frequency, and uncertainty suggests that 830 there is no definitive answer to which factor is more influential in RL, as it ultimately depends on 831 the context. Methodologically, our model provides an exploratory approach to RL modeling by 832 dissociating decision-making strategies rather than attempting to map out the entire cognitive 833 pathway. The flexibility of such modeling framework not only allows for more accurate 834 capturing of behavioral decision-making under various contexts, but also paves the way for future developments, such as adding biased priors or incorporating additional processes, which could broaden its potential to explain a wider range of human behaviors.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Example Trial Sequences.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>The Updating Mechanisms of the Dirichlet and Multivariate Gaussian 306 Distributions. 307 The Updating Mechanisms of the Dirichlet and Multivariate Gaussian Distributions. This figure illustrates the basic mechanisms of our dual-process model, comparing how the Dirichlet and multivariate Gaussian distributions process reward information. Imagine we have three options: A, B, and C. As the prior, each option has been selected</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head>Figure 3 :</head><label>3</label><figDesc>Model Simulation Results. Model Simulation Results. (a) Simulated model surfaces showing the proportion of C choices in CA trials reveal that 488the dual-process model uniquely demonstrates sensitivity to both increased variance and lower reward ratios. In 489 contrast, the other five models exhibit sharp declines in frequency effects as reward ratio increases but remain 490 largely insensitive to variance. Color represents the difference between the reward ratio and the C choice rate, with blue indicating frequency effects (i.e., a preference for the more frequently rewarded option A) and red indicating a stronger preference for C than predicted by the reward ratio. (b) Model surfaces for the proportion of simulated agents showing frequency effects further highlight that the dual-process model uniquely predicts a higher prevalence 494 of frequency effects with both increased variance and lower reward ratios. The Delta, risk-sensitive Delta, mean-495 variance utility, and ACT-R models again show sharp declines in frequency effects as reward ratio increases while 496 remaining unresponsive to changes in variance. The Decay model, while consistently predicting strong frequency 497 effects, also displays limited sensitivity to variance (see alsoSupplementary Figure 1and 2 for traditional 498 simulations limited to the three experimental conditions). The color bar is normalized to represent the percentage of 499 simulated agents displaying frequency effects. (c) The heatmap shows that higher reward variance and lower reward 500 ratios result in a stronger reliance on the Dirichlet distribution. (d) The scatterplot shows that increased objective 501 Dirichlet weights are positively correlated with greater preference for A in CA trials, supporting the hypothesis that 502 greater uncertainty enhances reliance on frequency-driven processes, which is directly related to more prevalent 503 frequency effects. In these figures, "variance" conceptually refers to reward variance rather than statistical variance. 504 As indicated in the brackets, the values represent the standard deviation of the normal distributions from which the 505 rewards are drawn. 506 Statistically, this pattern was confirmed through logistic regression models. Logistic 507 regression predicting the proportion of C choices by reward ratio and variance (Proportion of C Choices ~ Reward Variance × Reward Ratio) showed that, across all six models, the proportion of C choices in CA trials generally had a positive relation with the reward ratio (dual-process: b = 13.581±2.561, z = 5.303, p &lt; .001, 95% CI = [8.599, 18.641]; Delta: b = 18.537±2.914, z = 6.361, p &lt; .001, 95% CI = [12.882, 24.309]; risk-sensitive Delta: b = 18.494±2.913, z = 6.348, p &lt; .001, 95% CI = [12.841, 24.264]; mean-variance utility: b = 18.662±2.908, z = 6.418, p &lt; .001, 95% CI = [13.020, 24.421]; Decay: b = 7.494±2.360, z = 3.175, p = .001, 95% CI = [2.875, 12.130]; ACT-R: b = 17.774±3.149, z = 5.644, p &lt; .001, 95% CI = [11.671, 24.020]), indicating more C choices as reward ratio increased. However, only in the dual-process model did the regression model find a significant interaction effect, where increased reward variance attenuated the positive association between reward ratio and C choices (b = -15.826±7.907, z = -2.002, p = .045, 95% CI = [-31.373, -0.368]). For the other five models, the interaction effects were nonsignificant (Delta: b = -15.144±8.960, z = -1.690, p = .091, 95% CI = [-32.742, 2.391]; risksensitive Delta: b = -15.093±8.956, z = -1.685, p = .092, 95% CI = [-32.682, 2.434]; mean-521 variance utility: b = -16.009±8.933, z = -1.792, p = .073, 95% CI = [-33.556, 1.473]; Decay: b = 0.145±7.472, z = 0.019, p = .985, 95% CI = [-14.508, 14.792]; ACT-R: b = -7.692±9.701, z = -0.793, p = .428, 95% CI = [-26.740, 11.300]). A second set of logistic regression models predicting the proportion of simulated agents showing frequency effects by reward ratio and variance (Proportion of Frequency Effects ~ Reward Variance × Reward Ratio) revealed similar results. While all models, except for the Decay model, predicted a lower prevalence of frequency effects as reward ratio increased (dualprocess: b = -13.456±2.505, z = -5.371, p &lt; .001, 95% CI = [-18.405, -8.581]; Delta: b = -16.633±2.809, z = -5.920, p &lt; .001, 95% CI = [-22.194, -11.178]; risk-sensitive Delta: b = -16.566±2.810, z = -5.895, p &lt; .001, 95% CI = [-22.129, -11.110]; mean-variance utility: b = -16.649±2.801, z = -5.944, p &lt; .001, 95% CI = [-22.194, -11.210]; Decay: b = -3.182±2.417, z = -1.316, p = .188, 95% CI = [-7.915, 1.563]; ACT-R: b = -15.542±3.108, z = -5.000, p &lt; .001, 95% 533 CI = [-21.705, -9.518]), only the dual-process model predicted that this negative relationship 534 would be mitigated by increased reward variance (dual-process: b = 23.913±7.730, z = 3.094, p 535 =.002, 95% CI = [8.816, 39.126]; Delta: b = 16.278±8.612, z = 1.890, p = .059, 95% CI = [-536 0.570, 33.200]; risk-sensitive Delta: b = 16.098±8.612, z = 1.869, p = .062, 95% CI = [-0.750, 537 33.644]; mean-variance utility: b = 16.774±8.585, z = 1.954, p = .051, 95% CI = [-0.020, 538 33.644]; Decay: b = -0.535±7.663, z = -0.070, p = .944, 95% CI = [-15.557, 14.495]; ACT-R: b = 539 7.902±9.482, z = 0.833, p = .405, 95% CI = [-10.648, 26.531]). 540</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>Figure 4ashows the proportion of optimal choices for each trial type during both 551 training and transfer phases.Logistic regression analyses (Proportion of Optimal Option ~ Condition + Trial Type) indicated that participants were generally less likely to select the optimal option in the MV condition compared to the LV condition (b = -0.273±0.023, z = -11.892, p &lt; .001, 95% CI = [-0.228, -0.318]), and in the HV condition compared to the MV condition (b = -0.518± 0.021, z = -25.020, p &lt; .001, 95% CI = [-0.559, -0.478]) across all trial types, indicating poorer learning with increased uncertainty. During training, we observed slower increases in optimal choices (i.e., A and C) with higher variance (MV-LV: F5,955 = 2.34, p = .040, 2 = .012; HV-MV: F5,990 = 15.76, p &lt; .001, 2 = .074;</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>in favor of option 567 C. Intriguingly, participants showed a significant preference for the theoretically better option C 568 in the LV condition (chance-level: t(92) = 3.051, p = .003, d = .316; reward-ratio: t(92) = 2.107, p = .038, d = .219; 95% CI = [0.540, 0.691]), no statistically significant preference for either option in the MV condition (chance-level: t(99) = 1.513, p = .134, d = .151; reward-ratio: t(99) = 0.441, p = .660, d = .044; 95% CI = [0.484, 0.617]), and a significant preference for the less rewarding but more frequently rewarded option A in the HV condition (chance-level: t(99) = -2.133, p = .035, d = .213; reward-ratio: t(99) = -3.260, p = .002, d = .326; 95% CI = [0.370, 0.495]). These results map nicely onto the predictions of our dual-process model by indicating that, as hypothesized, the impact of unequal reward frequency on decision-making escalates with increased value uncertainty. When the underlying value is harder to gauge, individuals are more likely to rely on their intuitive sense of how frequently an option has yielded an above-average reward.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head>Figure 4 :</head><label>4</label><figDesc>Behavioral Results.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_6"><head></head><label></label><figDesc>These results align with the predictions of the dual-process model, indicating that unequal reward frequencies have a stronger influence when reward uncertainty is higher. Dashed line refers to the reward ratio (0.536) while solid line refers to the random chance (0.5) choice rate. (c) Histograms across LV, MV, and HV conditions show that participants' distribution of choices shifted with increasing uncertainty. Under low variance, participants favored the optimal option more consistently, while in the HV condition, choices were more dispersed, reflecting greater exploration and less commitment to the optimal choice. Error bar represents 95% confidence interval. N = 93 participants in the LV condition, 100 participants in the MV condition, and 100 participants in the HV condition.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_7"><head></head><label></label><figDesc>(c: Pearson r = .905, p &lt; .001, 95% CI = [.882, .924]; α: Pearson r = .836, p &lt; .001, 95% CI = [.798, .867]; w1: Pearson r = .209, p &lt; .001, 95% CI = [.315, .098];</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_8"><head></head><label></label><figDesc>General linear model (GLM) analyses (Model Parameter ~ Condition) revealed that, in the dual-process model, the inverse log temperature parameter (c) significantly decreased from LV to HV (b = -0.337±0.087, t = -3.881, p &lt; .001, 95% CI = [-0.507, -0.167]) and from MV to HV (b = -0.282±0.085, t = -3.313, p = .001, 95% CI = [-0.449, -0.115]), but not from LV to MV (b = -0.055±0.087, t = -0.629, p = .530, 95% CI = [-0.225, 0.116]). The decreased c with increased reward variance was consistent across models (Model Parameter ~ Condition + Model; LV-MV: b = -0.176±0.063, t = -2.793, p = .005, 95% CI = [-0.300, -0.053]; MV-HV: b = -0.448±0.062, t = -7.222, p &lt; .001, 95% CI = [-0.570, -0.326]), indicating a general increase in random choice behavior from LV to HV as captured by all RL models. The learning/decay rate (α) did not significantly vary across conditions in the dual-process model (LV-MV: b = 0.020±0.054, t = 0.364, p = .716, 95% CI = [-0.086, 0.125]; MV-HV: b = 0.064±0.053, t = 1.212, p = .227, 95% CI = [-0.039, 0.167]; LV-HV: b = 0.083±0.054, t = 1.553, p = .121, 95% CI = [-0.022, 0.189]). Similarly, the subjective Dirichlet weight parameter (w1) showed no significant differences between conditions (LV-MV: b = -0.061±0.056, t = -1.093, p = .275, 95% CI = [-0.171, 0.048]; MV-HV: b = -0.024±0.055, t = -0.444, p = .657, 95% CI = [-0.132, 0.083]; LV-666 HV: b = -0.085±0.056, t = -1.529, p = .127, 95% CI = [-0.195, 0.024]).</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_9"><head>Figure 5 :</head><label>5</label><figDesc>Behavioral Results Explained by Model-Inferred Dirichlet Weights. Behavioral Results Explained by Model-Inferred Dirichlet Weights. (a) A 3-dimensional scatterplot reveals that higher Dirichlet weights were consistently associated with a greater likelihood of choosing option A in CA trials, empirically validating the predictions of the dual-process model. (b) Bar plots show that overall Dirichlet weights significantly increased from LV to HV conditions, supporting the hypothesis that greater variance leads to increased reliance on frequency-based processing. (c) Reaction times, modeled as a quartic regression, indicate that participants experienced the greatest cognitive load when Gaussian and Dirichlet processes had nearly equal weights and both required careful evaluation. (d) Histograms show that subjective Dirichlet weights remained nearly constant across conditions, while objective Dirichlet weights increased with variance, highlighting environmental</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1 : Reward Structure.</head><label>1</label><figDesc>-rate Moderate Variance N(M,SD) .65(.24) .35(.24) .75(.22) .25(.22) base-rate 2 High Variance N(M,SD) .65(.12) .35(.12) .75(.11) .25(.11) Reward Structure. N(M,SD) indicates continuous normal distributions of rewards for each option. M is the mean and SD is the standard deviation. "Base-rate" indicates how frequently each choice pair is presented during training, relative to the other choice pair. For example, 2:1 means the first pair is presented twice as often as the second pair.</figDesc><table><row><cell>188</cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell></cell><cell></cell><cell>Option</cell><cell></cell><cell></cell></row><row><cell>Group</cell><cell>A</cell><cell>B</cell><cell>C</cell><cell>D</cell></row><row><cell>Low Variance</cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note>N(M,SD) .65(.48) .35(.48) .75(.43) .25(.43)base</note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_1"><head></head><label></label><figDesc>where, again, ( ) represents the prediction error, ( ) = − , ; and α denotes the learning 361 rate, ∈ (0,1). 362 Finally, the ACT-R model is a sampler model that represents a classic abstraction of the 364 declarative memory system. As described in Erev et al. (2010), each trial is coded into an 365 experience chunk that includes the participant's selection and the corresponding reward r. When 366 option j is presented again, the agent considers all previous experiences selecting option j and 367 recalls the experiences that exceed the activation level. The activation level of experience i is 368 calculated as: 369</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_3"><head>Table 2</head><label>2</label><figDesc>presents the model fitting results. Across all reward variance levels, the dual-598 process model consistently demonstrated a substantial advantage over all other models, with the 599 only exception of the risk-sensitive Delta model in the MV condition, where performance was 600 comparable. In the HV condition, it had a mean AIC advantage of 14.06 and a mean BIC 601 advantage of 12.05 over the other five well-established RL models, corresponding to a BF10 of 65.75 over Delta, 8.89 over risk-sensitive Delta, 111.01 over mean-variance utility, 99.40 over 603 Decay, and 9.918 × 10 6 over ACT-R. This advantage was equally large in the MV (AIC-604 advantage: 14.71; BIC-advantage: 12.70) and LV (AIC-advantage: 18.18, BIC-advantage: 16.17)</figDesc><table /><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_4"><head>Table 2 : Model Fitting Results. 614 Best c</head><label>2</label><figDesc>Best α/α + /A Best w 1 /τ/λ/α -AIC avg BIC avg AIC weight BIC weight BF 10 VB α VB r k VB φ k LV</figDesc><table><row><cell>Delta</cell><cell>2.556</cell><cell>.320</cell><cell></cell><cell>186.520 193.563 &lt;.001</cell><cell>.001</cell><cell cols="2">732.959 12.629 .128 &lt;.001</cell></row><row><cell cols="2">Risk-Sensitive Delta 2.742</cell><cell>0.316</cell><cell>0.310</cell><cell>175.397 185.962 .057</cell><cell>.057</cell><cell cols="2">16.389 15.830 .160 &lt;.001</cell></row><row><cell cols="2">Mean-Variance Utility 2.324</cell><cell>0.241</cell><cell>12.424</cell><cell>182.421 192.985 .002</cell><cell>.002</cell><cell cols="2">549.121 11.031 .111 &lt;.001</cell></row><row><cell>Decay</cell><cell>0.935</cell><cell>.180</cell><cell></cell><cell>197.625 204.668 &lt;.001</cell><cell cols="3">&lt;.001 1.891 × 10 5 11.636 .118 &lt;.001</cell></row><row><cell>ACT-R</cell><cell>1.952</cell><cell>.483</cell><cell>-0.844</cell><cell>191.576 202.140 &lt;.001</cell><cell cols="3">&lt;.001 5.342 × 10 4 2.965 .030 &lt;.001</cell></row><row><cell>Dual-Process</cell><cell>2.356</cell><cell>0.301</cell><cell>0.688</cell><cell>169.804 180.368 .941</cell><cell>.940</cell><cell>-</cell><cell>44.909 .454 .999</cell></row><row><cell>MV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Delta</cell><cell>2.379</cell><cell>.322</cell><cell></cell><cell>212.609 219.652 .002</cell><cell>.012</cell><cell cols="2">36.492 18.649 .176 .027</cell></row><row><cell cols="2">Risk-Sensitive Delta 2.339</cell><cell>0.399</cell><cell>0.314</cell><cell>201.217 211.782 .594</cell><cell>.589</cell><cell cols="2">0.713 28.780 .272 .581</cell></row><row><cell cols="2">Mean-Variance Utility 2.227</cell><cell>0.306</cell><cell>7.235</cell><cell>210.062 220.627 .007</cell><cell>.007</cell><cell cols="2">59.394 9.676 .091 &lt;.001</cell></row><row><cell>Decay</cell><cell>0.949</cell><cell>.204</cell><cell></cell><cell>224.370 231.413 &lt;.001</cell><cell cols="3">&lt;.001 1.306 × 10 4 19.352 .183 .036</cell></row><row><cell>ACT-R</cell><cell>1.641</cell><cell>.491</cell><cell>-0.977</cell><cell>226.832 237.396 &lt;.001</cell><cell cols="3">&lt;.001 2.601 × 10 5 2.997 .028 &lt;.001</cell></row><row><cell>Dual-Process</cell><cell>2.302</cell><cell>0.321</cell><cell>0.627</cell><cell>201.894 212.458 .413</cell><cell>.409</cell><cell>-</cell><cell>26.546 .250 .355</cell></row><row><cell>HV</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row><row><cell>Delta</cell><cell>1.784</cell><cell>.381</cell><cell></cell><cell>264.439 271.482 .002</cell><cell>.013</cell><cell cols="2">65.748 22.846 .216 .085</cell></row><row><cell cols="2">Risk-Sensitive Delta 1.774</cell><cell>0.357</cell><cell>0.385</cell><cell>256.916 267.48 .010</cell><cell>.098</cell><cell cols="2">8.890 13.557 .128 &lt;.001</cell></row><row><cell cols="2">Mean-Variance Utility 1.838</cell><cell>0.398</cell><cell>11.305</cell><cell>261.965 272.53 .008</cell><cell>.008</cell><cell cols="2">111.011 10.095 .095 &lt;.001</cell></row><row><cell>Decay</cell><cell>0.876</cell><cell>.264</cell><cell></cell><cell>265.266 272.309 .002</cell><cell>.009</cell><cell cols="2">99.404 24.899 .235 .162</cell></row><row><cell>ACT-R</cell><cell>0.971</cell><cell>.422</cell><cell>-1.112</cell><cell>284.766 295.33 &lt;.001</cell><cell cols="3">&lt;.001 9.918 × 10 6 3.011 .028 &lt;.001</cell></row><row><cell>Dual-Process</cell><cell>2.019</cell><cell>0.385</cell><cell>0.602</cell><cell>252.546 263.110 0.888</cell><cell>0.872</cell><cell>-</cell><cell>31.593 .298 .752</cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_5"><head>Table 5</head><label>5</label><figDesc></figDesc><table><row><cell>&amp; Supplementary</cell></row></table><note></note></figure>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgements</head><p>The authors received no specific funding for this work.</p></div>
			</div>

			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data Availability</head><p>Data presented in the current study can be accessed in Open Science Framework (https://osf.io/ks3nd/). 840</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Code Availability</head><p>Codes for statistical analyses and computational models mentioned in this study are available through Open Science Framework (https://osf.io/ks3nd/). </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Author Contributions 844</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Competing interests</head><p>The authors declare no competing interests.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">Prospect Theory: An Analysis of Decision Under Risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<idno type="DOI">10.1142/9789814417358_0006</idno>
		<imprint>
			<biblScope unit="volume">1979</biblScope>
			<biblScope unit="page" from="99" to="127" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Advances in prospect theory: Cumulative representation of uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tversky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1007/BF00122574</idno>
	</analytic>
	<monogr>
		<title level="j">J Risk Uncertain</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="297" to="323" />
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<analytic>
		<title level="a" type="main">Comparison of Decision Learning Models Using the Generalization Criterion Method</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Ahn</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Stout</surname></persName>
		</author>
		<idno type="DOI">10.1080/03640210802352992</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1376" to="1402" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Reliance on small samples, the wavy recency effect, and similarity-based learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Plonsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Teodorescu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0039413</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">122</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="621" to="647" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Maximization, learning, and economic behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1402846111</idno>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">111</biblScope>
			<biblScope unit="issue">supplement_3</biblScope>
			<biblScope unit="page" from="10818" to="10825" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: Models of bounded rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.103.4.650</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="650" to="669" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">Heuristic Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Gaissmaier</surname></persName>
		</author>
		<idno type="DOI">10.1146/annurev-psych-120709-145346</idno>
	</analytic>
	<monogr>
		<title level="j">Annu Rev Psychol</title>
		<imprint>
			<biblScope unit="volume">873</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="451" to="482" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">A choice prediction competition: Choices from experience 875 and from description</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.683</idno>
	</analytic>
	<monogr>
		<title level="j">J Behav Decis Mak</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">9</biblScope>
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Comparison of basic assumptions embedded in learning 877 models for experience-based decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yechiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03193783</idno>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="387" to="402" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">Instance-based learning: Integrating sampling and repeated decisions 880 from experience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Gonzalez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Dutt</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0024558</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">118</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="523" to="551" />
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Learning reward frequency over 882 reward probability: A tale of two learning rules</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Don</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Otto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Cornwall</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Davis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Worthy</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.cognition.2019.104042</idno>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">193</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Precision and the Bayesian brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Yon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">D</forename><surname>Frith</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Current Biology</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">17</biblScope>
			<biblScope unit="page" from="1026" to="1032" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Bayes in the brain-on Bayesian modelling in neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Colombo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seriès</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Br J Philos Sci</title>
		<imprint/>
	</monogr>
	<note>Published online 2012</note>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">A Bayesian foundation for individual learning under uncertainty</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Mathys</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnhum.2011.00039</idno>
	</analytic>
	<monogr>
		<title level="j">Front Hum Neurosci</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<date type="published" when="2011" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">States versus Rewards: Dissociable Neural Prediction Error Signals Underlying Model-Based and Model-Free Reinforcement Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gläscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2010.04.016</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">66</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="585" to="595" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">A meta-analytic review of two modes of 894 learning and the description-experience gap</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">U</forename><surname>Wulff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mergenthaler-Canseco</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Hertwig</surname></persName>
		</author>
		<idno type="DOI">10.1037/bul0000115</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Bull</title>
		<imprint>
			<biblScope unit="volume">144</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="140" to="176" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Reference-point centering and range-adaptation enhance human reinforcement learning at the cost of irrational preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bavard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Lebreton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Khamassi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Coricelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Palminteri</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41467-018-06781-2</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Commun</title>
		<imprint>
			<biblScope unit="volume">9</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4503</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">A Bayesian approach to the evolution of perceptual and cognitive systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">S</forename><surname>Geisler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Diehl</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cogn Sci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="379" to="402" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">The Bayesian brain: the role of uncertainty in neural coding and computation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Knill</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Pouget</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends Neurosci</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="712" to="719" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">An Approximately Bayesian Delta-Rule Model Explains the Dynamics of Belief Updating in a Changing Environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Heasly</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.0822-10.2010</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">37</biblScope>
			<biblScope unit="page" from="12366" to="12378" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Predicting how people play games: Reinforcement learning in experimental games with unique, mixed strategy equilibria. American economic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">E</forename><surname>Roth</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1998" />
			<biblScope unit="page" from="848" to="881" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Immediate gain is long-term loss: Are there foresighted decision makers in the Iowa Gambling Task?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Huang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="DOI">10.1186/1744-9081-4-13</idno>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Functions</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Frequency effects in action versus value learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">J</forename><surname>Don</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Worthy</surname></persName>
		</author>
		<idno type="DOI">10.1037/xlm0000896</idno>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Learn Mem Cogn</title>
		<imprint>
			<biblScope unit="volume">48</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1311" to="1327" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Neural Prediction Errors Reveal a Risk-Sensitive Reinforcement-Learning Process in the Human Brain</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Edlund</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1523/JNEUROSCI.5498-10.2012</idno>
	</analytic>
	<monogr>
		<title level="j">The Journal of Neuroscience</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="551" to="562" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Approximating expected utility by a function of mean and variance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Levy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Markowitz</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Am Econ Rev</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="308" to="317" />
			<date type="published" when="1979" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Models that learn how humans learn: The case of decision-making and its disorders</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dezfouli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Ramos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">W</forename><surname>Balleine</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1006903</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">1006903</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<analytic>
		<title level="a" type="main">Acceptable losses: the debatable origins of loss aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yechiam</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00426-018-1013-8</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Res</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1327" to="1339" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<monogr>
		<title level="m" type="main">A Bayesian analysis of some nonparametric problems. The annals of statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">S</forename><surname>Ferguson</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page" from="209" to="230" />
		</imprint>
	</monogr>
	<note>Published online 1973</note>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Modeling individual differences using Dirichlet processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">J</forename><surname>Navarro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Steyvers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">D</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2005.11.006</idno>
	</analytic>
	<monogr>
		<title level="j">J Math Psychol</title>
		<imprint>
			<biblScope unit="volume">50</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="101" to="122" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Dopamine Enhances Model-Based over Model-Free Choice Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Wunderlich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Smittenaar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2012.03.042</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">75</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="418" to="424" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<analytic>
		<title level="a" type="main">Of goals and habits: age-related and individual differences in goal-directed decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eppinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">R</forename><surname>Heekeren</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.3389/fnins.2013.00253</idno>
	</analytic>
	<monogr>
		<title level="j">Front Neurosci</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Electrophysiological correlates reflect the integration of 935 model-based and model-free decision information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Eppinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Walter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Li</surname></persName>
		</author>
		<idno type="DOI">10.3758/s13415-016-0487-3</idno>
	</analytic>
	<monogr>
		<title level="j">Cogn Affect Behav Neurosci</title>
		<imprint>
			<biblScope unit="volume">936</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="406" to="421" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Intrinsic rewards explain context-sensitive valuation in 938 reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Molinaro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Age</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pbio.3002201</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Biol</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">7</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Differential Entropy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">M</forename><surname>Cover</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Thomas</surname></persName>
		</author>
		<idno type="DOI">10.1002/047174882X.ch8</idno>
	</analytic>
	<monogr>
		<title level="j">Elements of Information Theory</title>
		<imprint>
			<biblScope unit="volume">941</biblScope>
			<biblScope unit="page" from="243" to="259" />
			<date type="published" when="2005" />
			<publisher>Wiley</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Evaluating the reliance on past choices in adaptive learning models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Yechiam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ert</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2006.11.002</idno>
	</analytic>
	<monogr>
		<title level="j">J 943 Math Psychol</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="75" to="84" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<analytic>
		<title level="a" type="main">Advances in modeling learning and decision-making in neuroscience</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Age</forename><surname>Collins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41386-021-01126-y</idno>
	</analytic>
	<monogr>
		<title level="j">Neuropsychopharmacology</title>
		<imprint>
			<biblScope unit="volume">47</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="104" to="118" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">S</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Barto</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Cogn Neurosci</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="126" to="134" />
			<date type="published" when="1999" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">ACT: A simple theory of complex cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">American psychologist</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page">355</biblScope>
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">ACT-R: A Theory of Higher Level Cognition and Its Relation to Visual Attention</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Anderson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Matessa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lebiere</surname></persName>
		</author>
		<idno type="DOI">10.1207/s15327051hci1204_5</idno>
	</analytic>
	<monogr>
		<title level="j">Hum Comput Interact</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="439" to="462" />
			<date type="published" when="1997" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">When Does Model-Based Control Pay Off?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">A</forename><surname>Cushman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Gershman</surname></persName>
		</author>
		<idno type="DOI">10.1371/journal.pcbi.1005090</idno>
	</analytic>
	<monogr>
		<title level="j">PLoS Comput Biol</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page">1005090</biblScope>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">A new look at the statistical model identification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Akaike</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">IEEE Trans Automat Contr</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="716" to="723" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<monogr>
		<title level="m" type="main">Estimating the dimension of a model. The annals of statistics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Schwarz</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1978" />
			<biblScope unit="page" from="461" to="464" />
		</imprint>
	</monogr>
	<note>Published online</note>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">AIC model selection using Akaike weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="192" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">A practical solution to the pervasive problems of p values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Wagenmakers</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychon Bull Rev</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="779" to="804" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Bayesian model selection for group studies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Stephan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><forename type="middle">D</forename><surname>Penny</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Daunizeau</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Moran</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Friston</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuroimage.2009.03.025</idno>
	</analytic>
	<monogr>
		<title level="j">Neuroimage</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1004" to="1017" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title level="a" type="main">Ten simple rules for the computational modeling of behavioral data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">C</forename><surname>Wilson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">G</forename><surname>Collins</surname></persName>
		</author>
		<idno type="DOI">10.7554/eLife.49547</idno>
	</analytic>
	<monogr>
		<title level="j">Elife</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Should I stay or should I go? How the human brain manages the trade-off between exploitation and exploration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">D</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">M</forename><surname>Mcclure</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<idno type="DOI">10.1098/rstb.2007.2098</idno>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">362</biblScope>
			<biblScope unit="page" from="933" to="942" />
			<date type="published" when="1481" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Chasing Unknown Bandits: Uncertainty Guidance in Learning and Decision Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<idno type="DOI">10.1177/09637214221105051</idno>
	</analytic>
	<monogr>
		<title level="j">Curr Dir Psychol Sci</title>
		<imprint>
			<biblScope unit="volume">31</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="419" to="427" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A dual system model of preferences under risk</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Mukherjee</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0017884</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="243" to="255" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">A dynamic dual process model of risky decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Diederich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Trueblood</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000087</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">125</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="270" to="292" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Learning the value of information in an uncertain world</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Tej</forename><surname>Behrens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Woolrich</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Walton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Mfs</forename><surname>Rushworth</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1954</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1214" to="1221" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">A rational model of the Dunning-Kruger effect supports insensitivity to evidence in low performers</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Jansen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">N</forename><surname>Rafferty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-021-01057-0</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="756" to="763" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">Bayesianism and wishful thinking are compatible</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">E</forename><surname>Melnikoff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Strohminger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nat Hum Behav</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="692" to="701" />
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Habits without values</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">J</forename><surname>Miller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">A</forename><surname>Ludvig</surname></persName>
		</author>
		<idno type="DOI">10.1037/rev0000120</idno>
	</analytic>
	<monogr>
		<title level="j">Psychol Rev</title>
		<imprint>
			<biblScope unit="volume">126</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="292" to="311" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Cortical substrates for exploratory decisions in humans</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Seymour</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Dolan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename></persName>
		</author>
		<idno type="DOI">10.1038/nature04766</idno>
	</analytic>
	<monogr>
		<title level="j">Nature</title>
		<imprint>
			<biblScope unit="volume">441</biblScope>
			<biblScope unit="issue">7095</biblScope>
			<biblScope unit="page" from="876" to="879" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Uncertainty</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2005.04.026</idno>
	</analytic>
	<monogr>
		<title level="j">Neuromodulation, and Attention. Neuron</title>
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="681" to="692" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Uncertainty-based competition between prefrontal and dorsolateral striatal systems for behavioral control</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Daw</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Niv</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Dayan</surname></persName>
		</author>
		<idno type="DOI">10.1038/nn1560</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Neurosci</title>
		<imprint>
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1704" to="1711" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Knowing how much you don&apos;t know: a neural organization of 998 uncertainty estimates</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Bach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">J</forename><surname>Dolan</surname></persName>
		</author>
		<idno type="DOI">10.1038/nrn3289</idno>
	</analytic>
	<monogr>
		<title level="j">Nat Rev Neurosci</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="572" to="586" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Neural Computations Underlying Arbitration between 1000 Model-Based and Model-free Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">W</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Shimojo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Doherty</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">P</forename></persName>
		</author>
		<idno type="DOI">10.1016/j.neuron.2013.11.028</idno>
	</analytic>
	<monogr>
		<title level="j">Neuron</title>
		<imprint>
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="687" to="699" />
			<date type="published" when="1001" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title level="m" type="main">Is deck B a disadvantageous deck in the Iowa 1003 Gambling Task? Behavioral and Brain Functions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">L</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Hsieh</surname></persName>
		</author>
		<idno type="DOI">10.1186/1744-9081-10043-16</idno>
		<imprint>
			<date type="published" when="2007" />
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page">16</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<monogr>
		<title level="m" type="main">Executive and motivational processes in adolescents with 1006</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">E</forename><surname>Toplak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Jain</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tannock</surname></persName>
		</author>
		<imprint>
			<biblScope unit="page">61</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<analytic>
		<title level="a" type="main">Behavioral and Brain Functions</title>
		<idno type="DOI">10.1186/1744-9081-1-8</idno>
	</analytic>
	<monogr>
		<title level="m">Attention-Deficit-Hyperactivity Disorder (ADHD)</title>
		<imprint>
			<date type="published" when="1007" />
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="page">8</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Operant conditioning and the orbitofrontal 1009 cortex in schizophrenic patients: unexpected evidence for intact functioning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">E</forename><surname>Wilder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Weinberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">E</forename><surname>Goldberg</surname></persName>
		</author>
		<idno type="DOI">10.1016/S0920-9964(97)00135-7</idno>
	</analytic>
	<monogr>
		<title level="j">Schizophr 1010 Res</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="169" to="174" />
			<date type="published" when="1998" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<analytic>
		<title level="a" type="main">Gain-loss frequency and final outcome in the Soochow 1012 Gambling Task: A reassessment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>Lin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">C</forename><surname>Chiu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">T</forename><surname>Huang</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Functions</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2009" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">An adaptive approach to human decision making: Learning 1014 theory, decision theory, and human performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Myung</forename><surname>Ij</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Exp Psychol Gen</title>
		<imprint>
			<biblScope unit="volume">121</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page">177</biblScope>
			<date type="published" when="1992" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<analytic>
		<title level="a" type="main">The human as delta-rule learner</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Lee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">I</forename><surname>Gold</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Kable</surname></persName>
		</author>
		<idno type="DOI">10.1037/dec0000112</idno>
	</analytic>
	<monogr>
		<title level="j">Decision</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="55" to="66" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">A Control Theoretic Model of Adaptive Learning in Dynamic Environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Ritz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">R</forename><surname>Nassar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Frank</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Shenhav</surname></persName>
		</author>
		<idno type="DOI">10.1162/jocn_a_01289</idno>
	</analytic>
	<monogr>
		<title level="j">J Cogn Neurosci</title>
		<imprint>
			<biblScope unit="volume">30</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="1405" to="1421" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Using reinforcement learning models in social neuroscience: frameworks, pitfalls and suggestions of best practices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Lengersdorff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mikus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Gläscher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lamm</surname></persName>
		</author>
		<idno type="DOI">10.1093/scan/nsaa089</idno>
	</analytic>
	<monogr>
		<title level="j">Soc Cogn Affect Neurosci</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page" from="695" to="707" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">Note on a method for calculating corrected sums of squares and products</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">P</forename><surname>Welford</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Technometrics</title>
		<imprint>
			<biblScope unit="volume">4</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="419" to="420" />
			<date type="published" when="1962" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<analytic>
		<title level="a" type="main">Comparison of several algorithms for computing sample means and variances</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">F</forename><surname>Ling</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">J Am Stat Assoc</title>
		<imprint>
			<biblScope unit="volume">69</biblScope>
			<biblScope unit="issue">348</biblScope>
			<biblScope unit="page" from="859" to="866" />
			<date type="published" when="1974" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
