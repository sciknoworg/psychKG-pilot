<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">People balance joint reward, fairness and complexity to develop social norms in a two-player game</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Dhara</forename><surname>Yu</surname></persName>
							<email>dharakyu@berkeley.edu</email>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Bill</forename><forename type="middle">D</forename><surname>Thompson</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">University of California</orgName>
								<address>
									<settlement>Berkeley</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">People balance joint reward, fairness and complexity to develop social norms in a two-player game</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:42+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>social norms</term>
					<term>theory of mind</term>
					<term>joint planning</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Social norms are a hallmark of human social intelligence, yet the reasoning processes involved in norm formation have been difficult to capture with traditional modeling frameworks. We developed a computational model of norm formation as joint planning via theory-of-mind. The model is designed to capture the distinctively human ability to flexibly develop more complex norms in more complex situations, via simulation of joint decision-making with other agents over an extended time horizon. We evaluated the predictions of the model against participant interactions in a 2-player iterated decision-making task. Across 3 conditions our model captured the way participants balanced joint reward, fairness, and complexity when forming norms.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Introduction</head><p>Human cooperation relies on the ability to develop and reason about social norms <ref type="bibr" target="#b21">(Tomasello, 2019)</ref>. Norms are group-wide expectations about how individuals in a group should act in a particular context, such that individuals are expected to both conform to a norm and to enforce norm compliance among others <ref type="bibr" target="#b2">(Bicchieri, 2005)</ref>.</p><p>One function of norms is to help people solve simple coordination problems, such as choosing which side of the road to drive on. But the power of norms goes beyond simple choices, offering solutions to complex situations that extend over time and involve conflicting incentives for individuals and groups <ref type="bibr" target="#b6">(Hawkins, Goodman, &amp; Goldstone, 2019)</ref>. For example, consider two housemates who each own a car but share a single parking spot. This is a more complex coordination problem, because what is optimal for one person-parking in the shared spot every single time-is bad for the other. Yet the housemates could quickly and intuitively develop a better solution, such as a norm of alternating weeks when each person can use the garage.</p><p>The flexibility with which people form structured norms is difficult to capture with existing modeling frameworks. For example, classical game theoretic models of interdependent choice based on utility maximization struggle to account for norms of alternation <ref type="bibr" target="#b7">(Helbing, Schönhof, Stark, &amp; Hołyst, 2005)</ref>. Evolutionary game theory models have shown that agents pre-programmed to play with the contingently cooperative "tit-for-tat" strategy can outcompete other agents <ref type="bibr" target="#b0">(Axelrod, 1984)</ref>, but such models build strategies into the model directly, offering limited insight into the cognitive and interpersonal mechanisms through which complex strategic norms arise <ref type="bibr" target="#b3">(Gavrilets, Tverskoi, &amp; Sánchez, 2024)</ref>. The adaptive nature of norm formation suggests that norms are rooted in general cognitive principles, and in particular, inferential social reasoning about what is good for the agents involved, what is fair, as well as the simplicity of a solution: an agreement to swap parking spots every 3 days for one month, and then swap every 11 days for three months is intuitively less appealing than alternating weekly.</p><p>One way to capture these key cognitive principles is to view normative reasoning as an extension of theory of mindthe ability to make inferences about the mental states of others. This theoretical framework is useful because it describes how people make predictions about how others will behave in future interactions, an essential component of norm formation. Within this perspective, the capacity to make good predictions is rooted in a person's ability to simulate joint decision-making with other agents, which in turn requires reasoning about the latent beliefs and desires that give rise to action <ref type="bibr" target="#b8">(Ho, Saxe, &amp; Cushman, 2022)</ref>. By reasoning about the mental states of other interacting agents, people can approximate the sequence of decisions most likely to be conceived by others as mutually beneficial <ref type="bibr" target="#b17">(Misyak &amp; Chater, 2014;</ref><ref type="bibr" target="#b14">Levine, Chater, Tenenbaum, &amp; Cushman, 2023)</ref>, enabling convergence to a systematic pattern of behavior and the emergence of a norm.</p><p>We developed a formal model of normative reasoning as joint planning via theory-of-mind inference. Our model combines classical formalisms in planning and decision-making with cognitive models of theory of mind and joint intentionality (Kleiman-Weiner, <ref type="bibr" target="#b11">Ho, Austerweil, Littman, &amp; Tenenbaum, 2016)</ref>, and integrates a notion of action sequence complexity as a regularizer over the combinatorial space of joint plans. The model captures the hypothesis that people trade off the joint reward, fairness and simplicity of a candidate joint plan to generate a strategic plan over an extended time horizon in iterated social decision-making settings. Our model predicts that people prefer simpler norms, but can flexibly develop more complex strategies when necessary to prevent unfair or suboptimal allocations of reward.</p><p>To test the predictions of this theory, we conducted a behavioral experiment in which participants performed an iterated cooperative decision-making task in pairs. The task involved making simultaneous decisions with a partner about who chooses which option from an array of differentially rewarding choices (parking spots with different prices in a virtual parking lot). To perform well at this task without communicating, participants needed to make inferences about the intentions and desires of their partners to develop a norm, in the form of a shared, systematic strategy for making choices. We manipulated the reward structure to induce conflicts between joint reward, fairness and complexity, enabling us to study the contingencies that influence how people develop norms. We evaluated the predictions of our model against the behavioral data, finding that our theory-of-mind model better predicted the distribution of participant norms than did simpler models that lack mechanisms to reason about fairness or complexity.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Computational framework</head><p>In this section we formalize how people generate a probability distribution over joint plans of action by trading off the reward associated with a joint plan against its complexity. We define our problem setting using the stochastic game formulation, a generalization of a Markov decision process <ref type="bibr" target="#b16">(Littman, 1994)</ref>. A 2-player stochastic game is defined as {S, A 1 , A 2 ,U 1 ,U 2 , T, γ}, where S is the joint state space for the 2 agents, and A 1 × A 2 is the joint action space. U i (s, a 1 , a 2 ) for s ∈ S, a 1 ∈ A 1 , a 2 ∈ A 2 represents the reward earned for agent i in state s with agent 1 taking action a 1 and agent 2 taking action a 2 . T (s ′ |s, a 1 , a 2 ) represents the probability of entering state s ′ from state s, with agents taking actions a 1 , a 2 . γ represents the discount factor. This formulation can also account for iterated decisions. Past work has typically modeled how agents determine optimal policies within a single interaction, making it difficult to capture strategies realized over multiple interactions. To address this we formulated the action space as one of decisions over multiple time steps, i.e. over classes of joint plans, affording the flexibility to model more complex strategies. A joint plan τ over t interactions is represented as a state in S:</p><formula xml:id="formula_0">τ = [(a 1 1 , a 1 2 ), ..., (a t 1 , a t 2 )],</formula><p>where (a k 1 , a k 2 ) represents the joint action taken by agents 1 and 2 on the kth interaction.</p><p>We define the probability of a joint plan P(τ) as follows:</p><formula xml:id="formula_1">U(τ) = w j • R j (τ) + w f • R f (τ) reward − w c •C(τ) complexity P(τ) ∝ exp (β •U(τ))</formula><p>The utility function U is comprised of two components, a reward term and a complexity term. These two terms capture how individuals, for a candidate joint plan, weight the extent to which the plan results in optimal allocation of reward-for the overall group and between individuals-and the extent to which it is simple and cognitively efficient.</p><p>Within the reward term, R j (τ) represents the joint optimality: the joint reward for all agents should they execute the given joint plan. This follows past work on modeling cooperative planning in individuals as simulating the actions of a group "we-agent" (Kleiman-Weiner et al., 2016; S. A. Wu et al., 2021). The we-agent plans over the shared state and action space of all interacting agents, representing an individual's capacity to plan with shared intentionality <ref type="bibr" target="#b22">(Tomasello, Carpenter, Call, Behne, &amp; Moll, 2005)</ref>. We assume that both agents' utilities are equally weighted in computing the joint reward:</p><formula xml:id="formula_2">R j (τ) = 0.5 • R j,1 (τ) + 0.5 • R j,2 (τ). To compute R j,i (τ)</formula><p>, that is, the joint optimality of plan τ for agent i, we use policy iteration, which computes the optimal value function that can then be used to assign a reward to a plan.</p><p>R f (τ) represents the fairness of the given joint plan: the difference in the individual rewards between agents if that plan were to be executed. Note that this is distinct from joint optimality, because a plan that is jointly optimal for multiple agents (i.e. maximizes the sum of rewards) may nonetheless result in a gap between the reward earned by each agent.</p><p>Planning over an extended time horizon surfaces a combinatorial space of candidate plans that result in equal or nearequal utility. We introduce a complexity penalty C(τ) to capture the intuition that people prefer simpler joint plans. A complexity penalty is motivated by at least two non-mutually exclusive interpretations: it can be thought of as the cognitive cost required to conceive a particular joint plan, and/or as the difficulty of coordinating the joint plan with another player. We quantified complexity using a program induction model that constructs a program that generates an observed sequence of joint actions, represented in terms of compositional operators. This model is formulated as Bayesian inference over a probabilistic context-free grammar <ref type="bibr" target="#b5">(Goodman, Tenenbaum, Feldman, &amp; Griffiths, 2008;</ref><ref type="bibr" target="#b18">Piantadosi, Tenenbaum, &amp; Goodman, 2012)</ref>, where the unit of primitive is a joint action taken by two agents. Following past work (Kleiman-Weiner et al., 2020), our model includes two compositional operators: concat(a, b) and repeat(a, n). concat(a, b) combines joint actions a and b, and repeat(a, n) replicates the joint action a n times. As concrete examples, the sequence of joint actions [a, a, a, a] is most concisely represented as the program repeat(a, 4), and the sequence [a, b, a, b] is most concisely represented as repeat(concat(a, b), 2). The complexity penalty of a joint plan is proportional to the length, in number of operations, of the simplest program π constructed to generate it:</p><formula xml:id="formula_3">C(τ) ∝ |π(τ)|.</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental Methods</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Task overview</head><p>We developed a 2-player iterated cooperative decisionmaking task <ref type="figure" target="#fig_0">(Figure 1</ref>). This task builds on a large literature on mixed-incentive games <ref type="bibr" target="#b20">(Thielmann, Böhm, Ott, &amp; Hilbig, 2021;</ref><ref type="bibr" target="#b13">Le Pargneux, Chater, &amp; Zeitoun, 2023)</ref> and is designed with intuitive reward contingencies to elicit meaningful reasoning about other participants' beliefs and intentions.</p><p>Participants are informed that they must select a parking spot in a virtual parking lot over the course of several days. Different spots cost different amounts of a virtual currency (Monetary Units; price remained fixed over days). Participants were incentivized to minimize cost paid. 1 There were <ref type="bibr">1</ref> To follow the notation of the model, we construe the price of two zones in the lot: an orange zone and a purple zone, and two parking spots per zone. Participants were informed that if they both select a spot in the same color zone, they would receive a "group discount" and pay the discount price (visible during decision-making). Participants selected a parking spot without seeing the other person's selection, and knew that collisions incur a high price. After making their decisions, participants were shown the actions that each other took and the price each participant paid.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experimental manipulation</head><p>We designed 3 different price configurations of the parking lot to examine whether emergent strategies reflected tradeoffs between reward, fairness, and complexity as predicted by our model <ref type="figure" target="#fig_0">(Figure 1</ref>). 2</p><p>Condition 1: No Conflict In Condition 1, the orange spots were equal in price, while the purple spots were unequal prices. The cost of the orange spots was lower than the mean cost of the purple spots. This condition facilitates a clear strategic equilibrium: one player picking the left orange and the other player picking the right orange (we will refer to this strategy as stable selection on orange). This strategy maximizes joint reward and fairness, and minimizes the coordination cost (picking the same spot every time is the simplest possible process). This condition serves as a control to establish that people were capable of developing cooperative, systematic norms when a simple optimal solution is available.</p><p>Condition 2: Unavoidable Compromise Condition 2 maintains the same cost structure as in Condition 1, with one difference: the first purple spot had a regular price of 11 and a discount price of 1. This manipulation introduces a conflict between the utility terms in our model: no one strategy is optimal with respect to all terms, because the the purple spots parking spots in terms of reward; picking the lowest-priced spot is equivalent to picking the highest reward option.</p><p>2 Study designs, exclusion criteria and analyses were preregistered at https://osf.io/39fsd. compromise fairness and the orange spots sacrifice reward. Under these conditions, our model predicts a more diffuse set of strategies compared to Condition 1: pairs may develop a norm of stable selection on orange (maximally fair, minimally complex, but not jointly optimal), stable selection on purple (jointly optimal, minimally complex, but not fair), or alternating selection of the cheaper and costlier spots on purple (jointly optimal, maximally fair, but more complex). In contrast, a model without a complexity penalty would be unable to account for people's preferences for systematic strategies, and a model without a reward objective would be unable to capture the preference for higher-reward strategies.</p><p>Condition 3: Fairness vs. Complexity In Condition 3, the second purple spot has a regular price of 11 and a discount price of 1. This condition is similar to Condition 2 but with one key difference: the price gap between the two purple spots is relatively smaller. Therefore, our model predicts that people are more likely in this condition, compared to Conditions 1 and 2, to develop a norm of stable assignments on purple, because the joint reward associated with the stable purple norm is greater (compared to Conditions 1 and 2) and doing so would result in a more fair allocation of reward (compared to Condition 2). In contrast, a model without a complexity penalty would predict higher rates of complex norms or a failure to form any norm at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants and procedure</head><p>We pre-registered a target sample size of 300 participants (50 pairs per condition). Participants were recruited over multiple sessions using an algorithm that had a budget for rerecruitment to replace participants that did not complete the task (e.g. due to technical errors or waiting time limits). We excluded from analysis participants who failed to select a parking spot in the allotted time and did not finish the game, as well as participants who wrote fewer than 10 characters in a pre-game writing task. After exclusions there were 102 players (51 games) in Condition 1, 102 players (51 games) in Condition 2, and 84 players (42 games) in Condition 3.</p><p>Participants were assigned at random to one of the treatments via a block random assignment algorithm. Participants viewed instructions and had to pass a short comprehension test to advance. They were shown the parking lot of their assigned treatment and were asked to write a strategic plan describing how they would ideally play the game. After writing, participants progressed to a treatment-specific waiting room and were paired with the first available partner. They played 12 trials of the game; after each trial, participants were shown their partner's move and cost paid on the previous trial, and needed to indicate the cost they themselves paid as an attention check. The task took a median time of 12 minutes. Participants were paid a base rate of $12.50/hr; they were incentivized to minimize their overall cost in the game through a performance-based compensation bonus. Participants were informed they would play multiple trials but not told precisely how many, to induce uncertainty in the time horizon. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral results</head><p>Participants established norms Participants developed norms over the course of their interactions across all 3 conditions. The task is designed in such a way that better performance, in the form of a lower cost incurred, requires a coherent strategy on the part of the two players; thus, the cost paid by participants in a pair is a key behavioral indicator of effective norm formation. </p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy classification</head><p>Having established that people successfully developed norms, we analyzed the norms that formed and examined how they differed between conditions. We defined a norm as present if participant decisions were consistent with that norm for at least 2 consecutive interactions. To identify types of norms and their frequency of appearance, we developed a simple algorithm (Algorithm 1) for classifying the norms developed within pairs over the course of a game. The algorithm detects the longest consecutive sequence of pair decisions consistent with a particular strategy, and computes the proportion of the game during which the pair exhibited each norm type. Motivated by our results showing that participants converged on coherent strategies toward the end of the experiment (see <ref type="figure" target="#fig_1">Figure 2, left, top)</ref>, we classified norms based on pair interactions for the final 4 trials of each game, although the conclusions are the same if analyzing the whole game. <ref type="figure" target="#fig_4">Figure 3</ref> shows how the types of norms that pairs developed differed across conditions. In Condition 1 (No Conflict), participants overwhelmingly converged on a norm of stable selection on orange, consistent with our hypothesis that participants would conceptualize that as the best strategy.</p><p>In Condition 2 (Unavoidable Compromise), the norms were more varied; compared to the Condition 1 control group, participants were less likely to exhibit stable selection on orange (β = −0.46, CrI = [−0, 61, −0.31]), and more likely to fail to develop any norm (β = 0.24, CrI = [0.11, 0.37]). There was no evidence for significant differences in the frequencies of the stable selection on purple (β = 0.13, CrI = Algorithm 1 Strategy classification Input: pair decisions p 1: n ← length of p 2: m ← strategy for n trials; init. to null for each element 3:</p><formula xml:id="formula_4">for i in [n, n − 1, ..., 2] do 4: S ← all subsequences of p of length i 5: for each s in S do 6:</formula><p>if there is a marked move in s then Though the frequency of stable on orange in this condition was reduced relative to the control, the plurality of participants converged on this strategy, suggesting that its optimality with respect to fairness and coordination cost outweighted the downside of a non-optimal joint reward and the complexity of alternating on purple.</p><p>In Condition 3 (Fairness vs. Complexity), participants developed a norm of stable selection on purple more often, compared to the control (β = 0.48, CrI = [0.32, 0.64]) and to Condition 2 (β = 0.35, CrI = [0.17, 0.53]). They also developed an alternating norm more frequently than in the control (β = 0.10, CrI = [0.01, 0.20]). Correspondingly, they were less likely to converge on stable selection on orange compared to the control (β = −0.75, CrI = [−0.92, −0.59]) and to Condition 2 (β = −0.29, CrI = [−0.46, −0.13]), and failed to form any norm more frequently compared to the control (β = 0.18, CrI = [0.04, 0.31]). The increased prevalence of the stable on purple norm in Condition 3 compared to Condition 2 suggests that participants' aversion to unfair outcomes was graded: they converged more frequently on an unfair norm when the price discrepancy was lesser. In both Conditions 2 and 3, alternation occurred relatively infrequently, suggesting that this more complex strategy was 1) more difficult for participants to initially conceive, or 2) more difficult to successfully implement.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Model results</head><p>Alternative models We compared our model against 2 ablated models which used just one of the reward or complexity terms in the utility calculation. The first alternative model is the reward-only model, which is equivalent to setting w c to 0 in the full model. The second alternative is the cost-only model, which is equivalent to setting w j , w f both to 0.</p><p>Parameter estimation We adapted the general formulation of this family of models to our specific task and fit the param-eters of the model to the experimental data. The model represents candidate joint plan as states in the joint state space. For example, the state</p><formula xml:id="formula_5">[(o 1 , o 2 ), (o 1 , o 2 ), (o 1 , o 2 ), (o 1 , o 2 )]</formula><p>represents the norm of player 1 selecting the 1st orange spot and player 2 selecting the second orange spot. We assumed a finite horizon of t = 4 trials, which made finding the optimal value function via policy iteration computationally tractable, but there is no distinction between a t of 4 or 100: all states in which one player selects the 1st orange and the other selects the 2nd orange at each timestep represent the same joint plan.</p><p>For every candidate joint plan, we computed the joint reward, fairness and coordination cost. Each of those 3 terms has an associated free parameter which represents the relative weighting of that component within the overall utility. To make weight parameters more straightforward to interpret, we normalized each of the joint reward, fairness and cost values to a value between 0 and 1. For joint reward and fairness, this is done by linearly rescaling the optimal outcome for the given parking lot (i.e., the smallest possible joint payment and the smallest possible gap in cumulative amount paid between the two players) to a value of 1, and the least optimal outcome to 0. We set w c = 1 3 for the complexity penalty. 3 After fixing w c , the model includes 3 free parameters: two weight parameters w j , w f , and the softmax optimality parameter β. To approximately fit model parameters to our data, we performed a grid search over the following ranges: <ref type="bibr">0, 0.11, 0.22, ..., 1.98]</ref>. To quantify model fit to the data we computed the Jensen-Shannon divergence (JSD) between the predicted and the empirical distribution of norm types for the 3 conditions. To account for potential overfitting, we split the data into train and test sets with a 70-30 split and selected the best parameter values based on minimum mean JSD across the 3 conditions, using data from pairs in the train set only. The metrics reported here reflect the mean JSD values on the unseen test set.</p><formula xml:id="formula_6">β ∈ [1, 2, 3, ..., 15]; w j , w f ∈ [</formula><p>Model predictions For each of the 3 models, we computed the probability of selecting each type of norm under all combination of parameters. 4 The best-fitting full model (parameter values β = 13, w j = 1.43, w f = 0.22) closely fit the human data (mean JSD=0.14), far outperforming the bestfitting reward-only model (mean JSD=0.63) and the bestfitting cost-only model (mean JSD=0.57). <ref type="figure" target="#fig_4">Figure 3</ref> shows the predicted distribution of norm categories under the bestfitting parameterization of the full model, plotted against the empirical distribution for all 3 conditions.</p><p>The inferred value of w j = 1.43 for the best-fitting model was substantially higher than w f = 0.22 and (fixed) w c = 0.33, providing quantitative evidence that people weigh jointly-optimal reward more heavily than a fair outcome or reducing complexity when generating norms, consistent with the qualitative patterns observed in Conditions 2 and 3. Though our model overall fit the data well, it was least aligned with participant behavior in Condition 2. The higher rate of failure to form any norm in this condition suggests there was something particularly difficult about this reward configuration. One possible explanation is that because people's preferences for different norms were less concentrated, there was a lower probability that both people in a pair were aligned on the same joint plan, resulting in a higher probability of coordination failure.</p><p>To assess the whether the fit of our model to the behavioral data reflects an overly expressive model class rather than a well-aligned theory, we analyzed the model's capacity to fit randomly-generated datasets with the same structure (triplets of 5-category probability distributions). If the model better fits our behavioral data compared to randomly-generated datasets, this provides evidence that the model is capturing something meaningful about the process generating the data; in contrast, if the model can fit any distribution as well as the experimental data, its potential to offer insight is more limited. We generated 1000 null datasets and computed the mean JSD between each null dataset and the predictions of the model under the parameter values that led to the best fit on that null dataset. The JSD distribution from the null datasets has a mean of 0.32 and standard deviation of 0.05. In contrast, the best full model fit to the experimental data achieves a mean JSD of 0.14 (falling in the first percentile of the null dataset distribution). This result provides evidence against an overly-expressive model class and indicates alignment between this model's dynamics and participant behavior.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Exploratory analysis of written plans</head><p>Before starting the game, participants wrote strategic plans. We conducted an exploratory analysis of the plans to better understand the relationship between participants' individual intentions and the norms that emerged over the course of interacting with their partners. Following past work <ref type="bibr" target="#b4">(Gilardi, Alizadeh, &amp; Kubli, 2023;</ref><ref type="bibr" target="#b19">Rathje et al., 2024)</ref>, we used a large language model (GPT-4) to classify written plans across conditions according to the category of norm expressed, using the same 5-category classification scheme as previous analyses.</p><p>We evaluated the extent to which 0, 1 or 2 participants in a pair writing a plan that described a particular strategy predicted implementation of that strategy during the game. The number of players expressing a plan was predictive of plan implementation for the three major types of norms: stable on orange (β = 0.28, CrI = [0.15, 0.40]), stable on purple (β = 0.27, CrI = [0.08, 0.45]) and alternating on purple (β = 0.28, CrI = [0.19, 0.38]). These results suggest that the initial plans that people conceptualized did influence the types of norms that developed through interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>The ability to form complex norms is underpinned by complex social reasoning. Accordingly, the core cognitive principles involved in norm formation have been difficult to capture with traditional models. We developed an account of norm formation that views this process as a form of joint planning in which participants trade off joint optimality, fairness and complexity. We formalized this theory using an integrative computational model designed to capture aspects of the process by which people simulate joint plans. The model was designed to express an overall preference for simpler joint plans, but to be flexible enough to account for adaptive formation of more complex strategies such as alternating in situations that demand additional structure. The model's predictions closely aligned with the distribution of norms participants formed in an iterated decision-making task.</p><p>Our model is limited in important ways. One key limitation is that it does not account for individual learning over the course of an interaction and does not make predictions about how an individual behaves conditioned on a history of interactions. Moving forward we hope to investigate how participants adapt their strategies based on their partners' actions via inverse planning <ref type="bibr" target="#b1">(Baker, Jara-Ettinger, Saxe, &amp; Tenenbaum, 2017;</ref><ref type="bibr" target="#b9">Jara-Ettinger, Schulz, &amp; Tenenbaum, 2020)</ref>: observing a sequence of actions and inferring the other player's intentions that could have given rise to that behavior.</p><p>Here we focused on characterizing the cognitive principles that enable norm formation by studying behavior in dyads, as opposed to in larger groups or communities. Understanding how strategies learned in one-on-one interactions ultimately give rise to societal-scale norms (C. M. <ref type="bibr" target="#b23">Wu, Dale, &amp; Hawkins, 2023)</ref> is an important avenue for future work.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 :</head><label>1</label><figDesc>Task interface, showing the different reward assignments across the 3 conditions (the cost of the orange spots remains constant across the conditions). In each spot, the top number indicates the regular price and the bottom number indicates the discount price.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head>Figure 2 :</head><label>2</label><figDesc>Left, top: mean cost paid per trial, across conditions. Error bars show standard error. Left, bottom: mean overall game cost plotted against the cost difference, for each pair. Darker squares represent the mean for all pairs in the condition. Dashed lines represented the expected mean cost for a random selection strategy. Right: example game traces, corresponding to the numbered games on the scatter plot. Each light or dark gray dot represents a participant's choice on a given trial.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_2"><head></head><label></label><figDesc>Figure 2(left, top) shows the cost paid per trial. A Bayesian mixed-effect linear regression analysis revealed an effect of trial number on the individual cost paid, including a random effect for the group. Trial number predicted price paid (β = −0.81, 95% credible interval (CrI) = [−0.92, −0.69]); there was also an interaction effect between the trial number and the treatment in Condition 2 (β = 0.28, CrI = [0.11, 0.43]), indicating reduced decreases in cost over trials in Condition 2. These results show that participants paid less over the course of a game, indicating convergence to systematic norms.Different reward contingencies led to different behaviorsParticipants' first decisions differed across conditions. Participants in Conditions 2 and 3 were more likely to select a purple spot initially, compared to Condition 1 (Condition 2: β = 0.19, CrI = [0.06, 0.32]; Condition 3: β = 0.51, CrI = [0.38, 0.64]). Over the course of the game, participants in Conditions 2 and 3 crashed more frequently compared to Condition 1 (Condition 2: β = 1.00, CrI = [0.29, 1.70]; Condition 3: β = 1.25, CrI = [0.54, 2.01]). Overall outcomes also differed between conditions(Figure 2, left, bottom). Compared to Condition 1, there was no evidence of a significant difference in the aggregate mean costs paid by participants in Condition 2 (β = 10.58, CrI =[−6.73, 28.56]) and Condition 3 (β = −16.82, CrI = [−35.55, 2.06]), even though it is in theory possible to earn a lower mean reward in those 2 conditions compared to Condition 1. However, pairs in Condition 2 and Condition 3 paid more unequal cost distributions relative to Condition 1 (Condition 2: β = 36.45, CrI = [23.59, 49.64]; Condition 3: β = 35.58, CrI = [21.82, 49.56]).Figure 2 (right) shows examples of the types of norms that players developed over the course of a game. The five categories illustrated are 1) stable selection on orange, 2) stable selection on purple, 3) alternating selection on purple, 4) some other systematic norm, i.e. a stable or alternating on a color combination not encompassed by the first 3 categories, and 5) no apparent norm.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_3"><head></head><label></label><figDesc>for 15: return m [−0.02, 0.28]) and alternating on purple (β = 0.06, CrI = [−0.03, 0.15]) norms.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head>Figure 3 :</head><label>3</label><figDesc>Full model predictions and empirical distributions of norms across the 3 conditions. Parking lot reward structure for the condition is shown in inset. Empirical distribution is based on data from all pairs.</figDesc></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">This is because the longest possible program generating a joint plan of length 4 is 3 operations, so the most complex joint plan would have an associated cost of w c •C(τ) = 1 3 • 3 = 1.4  The cost-only model has fewer free parameters, so for this model we only searched over the value of β.</note>
		</body>
		<back>

			<div type="acknowledgement">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Acknowledgments</head><p>We thank Jevan Yu and the anonymous reviewers for helpful suggestions.</p></div>
			</div>

			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title level="m" type="main">The evolution of cooperation (Rev</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Axelrod</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1984" />
			<publisher>Basic Books</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Rational quantitative attribution of beliefs, desires and percepts in human mentalizing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">L</forename><surname>Baker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">The Grammar of Society: The Nature and Dynamics of Social Norms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bicchieri</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<publisher>Cambridge University Press</publisher>
		</imprint>
	</monogr>
	<note>1st ed.</note>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">Modelling social norms: an integration of the norm-utility approach with beliefs dynamics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gavrilets</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Tverskoi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Sánchez</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<biblScope unit="volume">379</biblScope>
			<biblScope unit="page">20230027</biblScope>
			<date type="published" when="1897" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">ChatGPT outperforms crowd workers for text-annotation tasks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Gilardi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Alizadeh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kubli</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="issue">30</biblScope>
			<biblScope unit="page">120</biblScope>
			<date type="published" when="2023-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">A Rational Analysis of Rule-Based Concept Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Feldman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="108" to="154" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<analytic>
		<title level="a" type="main">The Emergence of Social Norms and Conventions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">X D</forename><surname>Hawkins</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">L</forename><surname>Goldstone</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="158" to="169" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">How individuals learn to take turns: emergence of alternating cooperation in a congestion game and the prisoner&apos;s dilemma. Advances in Complex Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Helbing</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Schönhof</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H.-U</forename><surname>Stark</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hołyst</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2005" />
			<biblScope unit="page" from="87" to="116" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Planning with Theory of Mind</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Saxe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Trends in Cognitive Sciences</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="959" to="971" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Jara-Ettinger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">E</forename><surname>Schulz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">The Naïve Utility Calculus as a unified, quantitative framework for action understanding</title>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="page">101334</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Coordinate to cooperate or compete: Abstract goals and joint intentions in social interaction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Ho</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Austerweil</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Cognitive Science Society</title>
		<meeting>the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Downloading Culture.zip: Social learning by program induction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Sosa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Thompson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Van Opheusden</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gershman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Cognitive Science Society</title>
		<meeting>the Cognitive Science Society</meeting>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<monogr>
		<title level="m" type="main">Contractualist tendencies and reasoning in moral judgment and decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Le</forename><surname>Pargneux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Zeitoun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename></persName>
		</author>
		<ptr target="io/preprints/psyarxiv/p4cyx" />
		<imprint>
			<date type="published" when="2023-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Levine</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Cushman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<monogr>
		<title level="m" type="main">Resource-rational contractualism: A triple theory of moral cognition</title>
		<ptr target="https://osf.io/p48t7" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Markov games as a framework for multi-agent reinforcement learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Littman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Eleventh International Conference on International Conference on Machine Learning</title>
		<meeting>the Eleventh International Conference on International Conference on Machine Learning</meeting>
		<imprint>
			<date type="published" when="1994" />
			<biblScope unit="page" from="157" to="163" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Virtual bargaining: a theory of social decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Misyak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Chater</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Philosophical Transactions of the Royal Society B: Biological Sciences</title>
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Bootstrapping in a language of thought: A formal model of numerical concept learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">T</forename><surname>Piantadosi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><forename type="middle">D</forename><surname>Goodman</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Cognition</title>
		<imprint>
			<biblScope unit="volume">123</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="199" to="217" />
			<date type="published" when="2012-05" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<monogr>
		<title level="m" type="main">GPT is an effective tool for multilingual psychological text analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Rathje</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D.-M</forename><surname>Mirea</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Sucholutsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Marjieh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Robertson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J V</forename><surname>Bavel</surname></persName>
		</author>
		<ptr target="https://osf.io/sekf5" />
		<imprint>
			<date type="published" when="2024" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Economic Games: An Introduction and Guide for Research</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Thielmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Böhm</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">E</forename><surname>Hilbig</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Collabra: Psychology</title>
		<imprint>
			<biblScope unit="volume">7</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2021-02" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title level="m" type="main">Becoming Human: A Theory of Ontogeny</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<publisher>Harvard University Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">Understanding and sharing intentions: The origins of cultural cognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Tomasello</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Carpenter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Call</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Behne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Moll</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="675" to="691" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Group coordination catalyzes individual and cultural intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">M</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Dale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Hawkins</surname></persName>
		</author>
		<ptr target="https://osf.io/gscy6" />
		<imprint>
			<date type="published" when="2023" />
			<publisher>OSF</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Too Many Cooks: Bayesian Inference for Coordinating Multi-Agent Collaboration</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">A</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">E</forename><surname>Wang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Evans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">B</forename><surname>Tenenbaum</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Parkes</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kleiman-Weiner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Topics in Cognitive Science</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="414" to="432" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
