<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrvoje</forename><surname>Stojić</surname></persName>
							<affiliation key="aff0">
								<orgName type="institution">Universitat Pompeu Fabra</orgName>
							</affiliation>
							<affiliation key="aff2">
								<orgName type="department" key="dep1">Department of Economics and Business</orgName>
								<orgName type="department" key="dep2">Division of Psychology and Language Sciences</orgName>
								<orgName type="institution">University College London</orgName>
								<address>
									<addrLine>Univer-sitat Pompeu Fabra; Henrik Olsson, Santa Fe Institute; Maarten Speekenbrink</addrLine>
								</address>
							</affiliation>
						</author>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Henrik</forename><surname>Olsson</surname></persName>
							<affiliation key="aff1">
								<orgName type="department">Fe Institute Maarten</orgName>
								<orgName type="institution">Speekenbrink University College London</orgName>
								<address>
									<settlement>Santa</settlement>
								</address>
							</affiliation>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Hrvoje</forename><surname>Stojic</surname></persName>
							<email>hrvoje.stojic@upf.edu</email>
							<affiliation key="aff3">
								<orgName type="department">Department of Economics and Business, Universi-tat Pompeu Fabra</orgName>
								<address>
									<addrLine>Ramon Trias-Fargas 25-27</addrLine>
									<postCode>08005</postCode>
									<settlement>Barcelona</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:03+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>decision making</term>
					<term>strategy selection</term>
					<term>reinforcement learning</term>
					<term>inferences</term>
					<term>categorization</term>
				</keywords>
			</textClass>
			<abstract>
				<p>How do people choose which decision strategy to use? When facing single tasks, research shows that people can learn to select appropriate strategies. However, what happens when, as is typical outside the psychological laboratory, they face multiple tasks? Participants were presented with two interleaved decision tasks, one from a nonlinear environment, the other from a linear environment. The environments were initially unknown and participants had to learn their properties. Through cognitive modeling, we examined the types of strategies adopted in both tasks. Based on out of sample predictions, most participants adopted a cue-based strategy in the linear environment and an exemplar-based strategy in the nonlinear environment. A context-sensitive reinforcement learning model accounts for this process. Thus, people associated different strategies to different types of environments through a trial-and-error type of process, and learned to flexibly switch between the strategies as needed. This evidence further supports the strategy selection approach to decision making which assumes that people pick and apply strategies available to them according to task demands.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>In the same way as a carpenter is able to choose between a hammer and a screwdriver to deal with a nail, the adaptive toolbox approach to judgment and decision making assumes that, when faced with a decision problem, a decision maker is able to choose an appropriate strategy from her toolbox of decision strategies <ref type="bibr" target="#b11">(Gigerenzer, Todd, &amp; the ABC Research Group, 1999;</ref><ref type="bibr" target="#b35">Payne, Bettman, &amp; Johnson, 1993;</ref><ref type="bibr" target="#b44">Scheibehenne, Rieskamp, &amp; Wagenmakers, 2013)</ref>. Entertaining the possibility that the mind carries such a toolbox, the question is then: how do we know which strategy to use in which situation? This question has been termed the strategy selection or "deciding how to decide" problem.</p><p>In the last two decades theoretical and empirical advances have been made in tackling the strategy selection problem. First theoretical attempts were cost-benefit approaches <ref type="bibr">(Beach &amp; Mitchell, 1978;</ref><ref type="bibr" target="#b8">Christensen-Szalanski, 1978;</ref><ref type="bibr" target="#b22">Lieder &amp; Griffiths, 2015;</ref><ref type="bibr" target="#b35">Payne et al., 1993;</ref><ref type="bibr" target="#b43">Russell &amp; Wefald, 1991)</ref>. According to this approach, people choose a strategy by trading the benefits of applying a strategy against its costs. The benefits are related to the strategy's accuracy, while the costs are related to the time or cognitive effort of applying the strategy. More recently, reinforcement learning approaches appeared as an alternative to cost-benefit analysis <ref type="bibr" target="#b9">(Erev &amp; Barron, 2005;</ref><ref type="bibr" target="#b42">Rieskamp &amp; Otto, 2006)</ref>. The focus of this approach is the learning process by which those strategies that result in highest average rewards end up being used relatively more than other, less rewarded strategies.</p><p>Despite these advances, there is at least one major problem not addressed theoretically or empirically. People navigate through multiple environments -classes of situations in which a certain strategy performs better than others. Not everything is a nail and situations differ -for example, when deciding between wines you might be better off using the take-the-best heuristic <ref type="bibr" target="#b10">(Gigerenzer &amp; Goldstein, 1996)</ref>, while for choosing a cheese you might want to use a similarity based strategy . The strategy selection approach implies that people should treat different environments as such and adapt to each as needed. Moreover, they must be able to recognize a certain decision situation as belonging to an environment and flexibly shift between different strategies as they encounter one environment or the other. The empirical evidence thus far, however, mostly shows that people are able to select an appropriate strategy in a single environment. For example, experiments in <ref type="bibr" target="#b34">Pachur and Olsson (2012)</ref>, <ref type="bibr" target="#b42">Rieskamp and Otto (2006)</ref> and <ref type="bibr" target="#b21">Karlsson, Juslin, and Olsson (2007)</ref> employed between-subject designs where each participant faced only one environment. <ref type="bibr">1</ref> Hence, the question if participants can adaptively select strategies in tasks with multiple environments and decision situations is still unanswered.</p><p>Improvements can also be made in terms of evaluating formal models of strategy selection. Thus far empirical evaluations were based on environments where values of alternatives were linear functions of cues or attributes and information about the function in terms of cue validities was provided to the participants <ref type="bibr" target="#b22">(Lieder &amp; Griffiths, 2015;</ref><ref type="bibr" target="#b40">Rieskamp, 2006;</ref><ref type="bibr" target="#b42">Rieskamp &amp; Otto, 2006</ref><ref type="bibr">, but see J. Hoffmann, von Helversen, &amp; Rieskamp, 2014</ref>, for a recent exception). Exemplar-based strategies <ref type="bibr" target="#b29">(Nosofsky, 1984;</ref> have not yet been included in such models. <ref type="bibr">2</ref> Given the body of evidence for exemplar-based processing and that such strategies can also perform well in nonlinear types of environments, support for any strategy selection model is incomplete when only evaluating it in linear environments. Moreover, explicitly providing information about the statistical properties of the environment greatly facilitates solving the strategy selection problem. In more realistic situations these properties have to be discovered as well, and this important aspect of the strategy selection problem has thus far been ignored.</p><p>Our objective is to put the strategy selection approach to judgment and decision making to a stronger test by evaluating it in a multi-environment setting where participants face alternating instances of two different environments on a trialto-trial basis. Moreover, one environment will be of a linear, while other of a nonlinear nature -requiring of participants to adopt qualitatively different strategies to perform well in them. Finally, the characteristics of the environments will be initially unknown and participants need to learn their properties.</p><p>We make two main contributions. First, we provide evidence that people can learn to flexibly use appropriate decision strategies on a trial-to-trial basis in initially unknown linear and nonlinear environments. This provides strong additional support for the strategy selection approach to deci-sion making. Second, our contextual version of the reinforcement learning based strategy selection model <ref type="bibr">(SSL Rieskamp &amp; Otto, 2006)</ref> accounts for how people learn to associate different decision strategies to different environments. In what follows, we first discuss the problem of strategy selection in multiple environments and examine how it fits in the landscape of existing theories of strategy selection. We then describe the design of our experiment, introduce the task and our qualitative predictions, and report the results. Then we describe the formal implementation of the contextual SSL model and assess how well it accounts for our results. We close with a discussion of our results and a call for further theoretical development with regards to the interaction between the categorization of environments and strategy selection.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Strategy selection in multiple environments</head><p>In a reply to a précis on fast-and-frugal heuristics <ref type="bibr" target="#b51">(Todd &amp; Gigerenzer, 2000)</ref>, an influential work outlining a decision making framework where strategy selection has a strong role, <ref type="bibr" target="#b24">Luce (2000)</ref> applauded the authors for presenting a different approach to studying judgment and decision making, and raised an issue of "how does one classify problems and decide upon which of several fast and frugal heuristic to employ?" (p. 758). In the same issue, <ref type="bibr" target="#b28">Morton (2000)</ref> also noticed that classifying decision problems is a necessary component of the approach. Morton imagined an agent having a set of strategies and a database of previously encountered problems. The database contains the type of problem, which strategy was applied, and its performance. When a new problem is encountered, this database can be used to classify the problem and then to select between the strategies. Decisionmaking researchers took little notice of these early observations -the issue of how people classify problems has not been addressed explicitly yet.</p><p>Classifying problems does not look like a serious issue at first glance: everybody can trivially see that choosing between cheeses is a different situation than choosing between wines. But here is the catch: while such perceptual features can signal that a decision problem is different from another one, they may not be relevant at all for determining which strategy should be used in it.</p><p>Normative research has shown that important indicators for strategy performance are statistical properties of the en-1 There are studies that examined dynamic environments, where there is a sudden shift in statistical properties and appropriate strategy <ref type="bibr" target="#b4">(Bröder &amp; Schiffer, 2006;</ref><ref type="bibr" target="#b40">Rieskamp, 2006)</ref>. However, this is a change in properties of the same environment and there was no difference in observable features that would indicate the difference between the environments.</p><p>2 In fact, <ref type="bibr" target="#b42">Rieskamp and Otto (2006)</ref> considered it to be an alternative to their SSL model, instead of possibly another strategy in the toolbox. vironment. For example, in environments where the value of an alternative is a weighted additive (linear) function of cue values, features such as dispersion of cue weights or cue inter-correlations are good predictors of strategy performance <ref type="bibr" target="#b14">(Hogarth &amp; Karelaia, 2005a</ref><ref type="bibr" target="#b15">, 2005b</ref><ref type="bibr" target="#b16">, 2006a</ref><ref type="bibr" target="#b17">, 2006b</ref><ref type="bibr" target="#b25">Martignon &amp; Hoffrage, 2002;</ref><ref type="bibr" target="#b26">Martignon &amp; Laskey, 1999)</ref>. In such linear environments optimal cue weights can have a compensatory or non-compensatory type of dispersion. A non-compensatory pattern is such that the cue with the greatest weight cannot be beaten by any pattern of values for the remainder of the cues. In a non-compensatory environment, a lexicographic strategy such as take-the-best (TTB; <ref type="bibr" target="#b10">Gigerenzer &amp; Goldstein, 1996)</ref>, which focuses on the most important cues and ignores the rest, will perform well. In an environment where the optimal cue weights have a compensatory pattern, a strategy that integrates all the cues, such as the weighted additive rule (WADD; <ref type="bibr" target="#b35">Payne et al., 1993)</ref>, will perform well. Higher inter-correlations between the cues imply higher redundancy, that is, less information is obtained from knowing the value of each additional cue. Hence, lexicographic strategies do not lose much by ignoring most of the cues and might outperform strategies that integrate all cues <ref type="bibr" target="#b14">(Hogarth &amp; Karelaia, 2005a</ref><ref type="bibr" target="#b16">, 2006a</ref>. <ref type="bibr">3</ref> Cue weight dispersion and cue inter-correlations are not immediately available perceptual features. A compensatory and non-compensatory environment might be perceptually very similar. And two environments that are perceptually very different might both be of a compensatory nature, and thus should belong to the same category with respect to decision strategies. When faced with an unknown environment, how do people infer the statistical properties of that environment in order to choose which decision strategy to apply? Taking a reinforcement learning approach to strategy selection, such inferences are not actually required. What matters is that people can learn that certain features indicate that compensatory strategies are likely to be successful, and other features are predictive of the success of non-compensatory strategies. Nonetheless, strategy selection in multiple environments involves non-trivial complexities of mapping the decision situations to the space of strategies.</p><p>What are the potential solutions to this joint problem of selecting the strategy and classifying decision situations? <ref type="bibr" target="#b22">Lieder and Griffiths (2015)</ref> propose a solution in the vein of the cost-benefit tradition, where one weighs the cost of applying each strategy against its estimated accuracy, and selecting the one that yields the best ratio. They propose using the statistical properties discussed above as features to predict the expected reward of applying each strategy through linear or logistic regression. Such an approach can work well when decision makers know the properties and relevant features of the environment well. This is the situation in which <ref type="bibr" target="#b22">Lieder and Griffiths (2015)</ref> evaluated their model -participants encountered compensatory and non-compensatory en-vironments with the validity of each cue displayed. However, their model cannot be applied as easily in situations where such environmental properties are initially unknown. Nonlinear environments pose an even greater obstacle. While the statistical properties of linear environments have been identified that predict whether TTB or WADD will fare better, features that predict whether exemplar-based strategies are more appropriate, such as those related to the nonlinearity of environments, are not yet known <ref type="bibr" target="#b34">(Pachur &amp; Olsson, 2012)</ref>.</p><p>In this paper we take a reinforcement learning approach to solving the dual problem of classifying decision situations and selecting the appropriate strategy within a situation. In the reinforcement learning approach, a strategy which accumulates more rewards when applied in a particular environment will be used more often. The SSL model <ref type="bibr" target="#b42">(Rieskamp &amp; Otto, 2006)</ref> has previously been used to describe strategy selection in single linear compensatory or noncompensatory environments with known cue validities. To deal with multiple environments, we extend SSL by assuming that decision makers use observable features to separate decision situations into different categories (e.g., cheeses and wines). Ignoring the latent statistical properties, this contextual version of SSL will run two separate reinforcement learning processes, one for each category, treating them as potentially different environments. If cheese and wine categories are indeed such that different strategies should be used in them, the model will eventually learn which strategy results in higher average reward. However, if they were such that the same strategy should have been used in both -for example, if both turned out to compensatory such that WADD performs well -then the effort was duplicated. This is a slow and potentially wasteful mechanism, but it has the advantage that the decision maker does not have to know complex statistical features such as cue inter-correlations. This is particularly useful when facing nonlinear environments, where we only need to assume that the decision maker's repertoire also contains strategies that can handle nonlinear environments, such as exemplar-based strategies <ref type="bibr" target="#b29">(Nosofsky, 1984;</ref><ref type="bibr" target="#b34">Pachur &amp; Olsson, 2012)</ref>. In addition, we assume that the decision maker's repertoire contains strategies that are able to learn, or approximate, a variety of functions that relate the cues to the value of decision alternatives. Whilst learning which strategy to use, a decision maker si-multaneously adapts individual strategies to the particulars of the environment. Hence, our contextual SSL model can work both in novel situations and in environments that decision makers know well. With sufficient experience, the individual strategies in the repertoire have adapted to the environment and it is clear which strategy will provide the maximum rewards.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview</head><p>We examined whether people are able to learn to use appropriate decision strategies when faced with multiple environments, flexibly shifting between them on a trial-by-trial basis. Participants in our experiment performed a paired comparison task where the goal was to pick the alternative with the highest criterion value. Each alternative was described by four cues and each paired comparison belonged to one of two types of environments -a linear or a nonlinear environment. In the linear environment, the task can be solved equally well by either a cue-based strategy that combines cue values in a linear fashion or an exemplar-based strategy. In the nonlinear environment, an exemplar-based strategy has a clear advantage over cue-based strategies as it can approximate the nonlinear function. The main prediction of a strategy selection approach to decision making is that in the linear environment the participants will adopt a strategy mix where cue-based strategies are used most often. In the nonlinear environment, the strategy mix should be dominated by exemplar-based strategies.</p><p>As outlined in the previous section, the reinforcement learning approach to strategy selection tackles this problem by partitioning the decision situations on the basis of perceptual information. We used two cover stories that were easy to visually differentiate -"bugs" and "comics" -that represented either the linear or nonlinear environment. If participants cannot adopt appropriate strategy mixes in this relatively simple situation, there is little hope they will be able to do so when faced with less perceptually differentiated environments.</p><p>Our analysis relies on two modeling approaches. After confirming that participants indeed learn over time in our task we first identify which strategy they have adopted in each environment. We accomplish this by fitting several cuebased and exemplar-based models separately to trials from each environment. We examine the extent to which participants have appropriately adopted different classes of strategies in each environment and narrow down the most representative strategies in both cue-based and exemplar-based class. Second, using the selected representative strategies as a strategy repertoire, we fit the contextual strategy selection learning model to both environments simultaneously, with the aim of explaining how the strategy preferences develop over time. With the first modeling exercise, besides deriving inputs for the strategy selection modeling, we obtain ev-idence of strategy use that does not rely on the precise learning mechanism we assume in the strategy selection modeling.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method 4</head><p>Participants Fifty-five participants (29 women, 26 men, M age = 21.4, age range: 18-40 years) took part in the experiment. Participants were recruited from the Universitat Pompeu Fabra subject pool. They were paid a show-up fee of three euros and an additional performance-dependent bonus (5.8 euros on average). The experiment was run in groups of about 10 people in the BES laboratory at Pompeu Fabra University. The experiment lasted for one hour on average.</p><p>Six participants did not reach the required level of accuracy in the training phase and did not continue to the test phase. Two of these participants failed to reach the required level of accuracy in the nonlinear environment, while the other four did not perform well enough in the linear environment. These participants were excluded from the analysis completely. The final sample consisted of 49 participants (27 women, 22 men, M age = 21.6, age range: 18-40 years).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials</head><p>On each trial in the learning and test phase, participants were presented with a pair of stimuli and had to choose the stimulus with the higher criterion value. The stimuli used were modified from <ref type="bibr" target="#b34">Pachur and Olsson (2012)</ref> and <ref type="bibr" target="#b33">Olsson, Enkvist, and Juslin (2006)</ref>. Fifteen unique stimuli with four binary cues were used to construct choice pairs in both the linear and nonlinear environment. <ref type="table" target="#tab_0">Table 1</ref> shows the cue patterns of all the stimuli together with their criterion value in both environments. The criterion value in the linear environment, y L , was a linear function of four cues, c 1 , c 2 , c 3 and c 4 :</p><formula xml:id="formula_0">y L = 0.1 + 0.4c 1 + 0.3c 2 + 0.2c 3 − 0.1c 4</formula><p>An independent error term was added to both items in each pair, drawn from Normal distribution with a mean of 0 and standard deviation of 0.15. The noise was added to provide probabilistic feedback and further induce the usage of a cuebased strategy <ref type="bibr" target="#b19">(Juslin, Jones, Olsson, &amp; Winman, 2003)</ref>. Following <ref type="bibr" target="#b33">Olsson et al. (2006)</ref>, the criterion value in the nonlinear environment, y NL , was a nonlinear function of the linear criterion values:</p><formula xml:id="formula_1">y NL ≈ 4.0508y L − 0.0367y 2 L − 110.8225</formula><p>No noise term was added in the nonlinear environment. The environments were randomly interleaved in the training and test phases. The purpose of the training phase was to allow participants to learn how to solve the tasks. The training phase consisted of four blocks, 84 trials in each block -44 trials from the linear and 40 from the nonlinear environment -giving 336 trials in total. For the linear environment we created 44 pairs using 10 unique stimuli -all possible combinations except for one pair where the stimuli had identical criterion levels. For the nonlinear environment, we used five unique stimuli and created all possible pairs, 10 in total, and repeated these 10 pairs four times. The stimuli used in the training phase are marked as "Old" in <ref type="table" target="#tab_0">Table 1</ref>. We used smaller number of unique stimuli in the nonlinear environment to induce people further to adopt an exemplar-based strategy <ref type="bibr" target="#b33">(Olsson et al., 2006)</ref>.</p><p>The purpose of the test phase was to more clearly assess the strategy mix adopted in each environment and to see the extent to which participants generalized what they learned in the learning phase. For the linear environment, we used five new unique stimuli together with old ones to create 18 pairs. Seven pairs with old stimuli from the training phase were repeated four times and the remaining nine pairs that included at least one new stimulus were repeated eight times, giving 116 trials in total. For the nonlinear environment, we selected from the pairs used in <ref type="bibr" target="#b34">Pachur and Olsson (2012)</ref> those that maximized the discrimination between cue-based and exemplar based strategies. The resulting 17 pairs include eight new stimuli, together with old ones. Three pairs with old stimuli were repeated four times and the remaining 14 pairs with at least one new exemplar were repeated eight times, giving 124 trials in total. In the whole test phase there were 240 pairs. Participants did not receive feedback on their choices.</p><p>We used two different cover stories for the linear and the nonlinear task -poisonous "bugs" and dangerous "comics". In the bugs story participants had to choose which bug was more poisonous, and in the comics story they had to choose which comic figure was more dangerous. The stimuli consisted of pictures of either bugs or comic figures, and both bugs and comic figures varied on four binary cues. In bugs -antennae, spots on the back, wings, and legs, were either present or absent. Similarly, in comic figures -hair, ears, nose, and stripes on the shirt, were either present or absent. Pictures of bugs and comics were a subset of those in J. <ref type="bibr" target="#b12">Hoffmann et al. (2014)</ref>.</p><p>The mapping of bugs or comics to the linear and nonlinear environment, and physical features (e.g., hair, ears) to the cues (c1, . . . , c 4 ), was determined at random for each participant. For instance, for one participant the first trial might correspond to linear environment represented as a choice between bugs, where c 1 corresponded to the presence of antennae. For another participant, the first trial might correspond to the nonlinear environment represented as well as a choice between bugs, but c 1 corresponded to the presence of wings. Trials from both environments were randomly interleaved for each participant. Order of the trials was randomized within each block in the training phase and in the whole test phase. Position of the stimuli on the screen (left or right) was also randomized on each trial.</p><p>To proceed to the test phase, participants had to reach 70% accuracy in both environments in the last block of the training phase. When participants did not satisfy this criterion, we provided them with another block of trials and checked their accuracy again. Participants who failed to reach the required level of accuracy after two additional training blocks were not allowed to continue the experiment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Procedure</head><p>Participants completed the experiment on desktop computers, using custom software written in Python and the Psy-choPy library <ref type="bibr" target="#b36">(Peirce, 2007)</ref>. At the beginning of the experiment, participants completed an informed consent form. They then received on-screen instructions about the task and earnings. All instructions were presented in Spanish.</p><p>To motivate participants, we told them that while the task would initially be difficult, they could improve with practice. Moreover, depending on their performance they could earn additional money: on every trial they could earn experimental units (EU's) -they gained 10 EU's for a correct choice and lost 10 EU's for an incorrect choice. The exchange rate was 1 euro for 500 EU's. Participants started the experiment with zero EU's and they could see the running total during the training phase, but not the test phase.</p><p>We did not provide participants with information on the exact number of rounds in each phase, instead we told them that the experiment would take 60 minutes on average to complete. The test phase was announced at the beginning of the instructions but without specific details, which were provided only at the start of the test phase. Earnings in the test phase were computed in the same way as in the training phase.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Behavioral analysis</head><p>We used the proportion of expected correct choices (choosing the alternative which is expected to have the highest criterion value) in a block of trials as performance measure.</p><p>Training phase. <ref type="figure" target="#fig_0">Figure 1</ref> shows the performance in the learning phase for each environment. Participants performed substantially better than chance already in the first block, achieving a mean accuracy of 0.76 in the linear and 0.68 in the nonlinear environment. In fact, in the linear environment, performance was better than chance even on the very  <ref type="bibr" target="#b2">(Brehmer, 1974;</ref><ref type="bibr" target="#b5">Busemeyer, Byun, Delosh, &amp; McDaniel, 1997;</ref><ref type="bibr" target="#b33">Olsson et al., 2006)</ref> and the linear environment is consistent with this belief; hence, initial guesses that a bug or comic with more features present is more poisonous or dangerous were correct on average. Overall, participants improved during the training phase, reaching a mean accuracy of 0.85 in the linear environment by the last block. A Wilcoxon signed rank test shows a significant difference in choice accuracy between the first and last block, M di f f = .09, Z = 989, p ≤ .0001. A similar result holds for the nonlinear environment, where participants achieved 0.90 by the last block, which is significantly higher than performance in the first block, M di f f = .22, Z = 1175, p ≤ .0001.</p><p>In the last training block, performance in the nonlinear environment reached a higher level than in the linear environment, as shown by a Wilcoxon signed rank test on the difference in choice accuracy between the environments, M di f f = .049, Z = 262, p = .0003. This indicates that the linear environment was more difficult to learn than the nonlinear environment, at least with the amount of training trials in our experiment. Although there is some evidence that people can learn nonlinear functions better than linear ones (J. <ref type="bibr" target="#b12">Hoffmann et al., 2014;</ref><ref type="bibr" target="#b13">J. A. Hoffmann, von Helversen, &amp; Rieskamp, 2013;</ref><ref type="bibr" target="#b52">von Helversen &amp; Rieskamp, 2008)</ref>, most studies show the opposite (e.g. <ref type="bibr" target="#b3">Brehmer, 1994;</ref><ref type="bibr" target="#b5">Busemeyer et al., 1997)</ref>. In our experiment, the small number of exemplars and deterministic feedback used in the nonlinear envi-ronment evidently facilitated learning compared to the linear environment.</p><p>Note that the results of block five and six are based on responses of a subset of participants who completed an additional one or two blocks in the training phase. Five participants completed two additional training blocks due to poor performance in the linear environment, while 13 participants completed one additional block (six of these due to poor performance in the linear environment). In <ref type="figure" target="#fig_0">Figure B1</ref> in Appendix B we illustrate choice accuracies separately for groups of subjects that did or did not require additional training blocks. While slower learners took more time, by the end of the training phase they achieved performance levels similar to the faster learners. For this reason here and in the rest of the article we plot the results of all participants together, but point out that some results (i.e., those in block 5 and 6) are based on a subset of participants.</p><p>Decrease in response time is another behavioral signature of learning. The time to make a choice in both environments almost halved by the last block in the training phase, from 4.61 to 2.85 seconds, M di f f = 1.76, Z = 1225, p ≤ .0001. Moreover, on average participants took more time to make a choice in the linear environment, M di f f = .38, Z = 990, p ≤ .0001 (Wilcoxon signed-rank test).</p><p>Test phase. How well did the participants generalize their knowledge from the training phase to the test phase? In the test phase participants encountered pairs with new stimuli and they did not receive feedback on their choices. Results of block five and six come from a subset of participants that took additional one or two blocks in the training phase. Error bars represent standard errors of group means of each block of trials. Points are displaced horizontally to make them easy to distinguish. In addition, we display mean accuracy in the very first trial and across the first ten trials, marked with numbers one and ten, respectively.</p><p>ing block: in the linear environment it decreased from 0.85 to 0.68 and in the nonlinear environment from 0.90 to 0.80. The difference in accuracy between nonlinear and linear environments found in the training phase persisted in the test phase, M di f f = .114, Z = 290, p = .001. Response times in the test phase were very similar to those obtained in the last training block. The decrease in performance from training to test phase was expected as the pairs in the test phase contained many new items that participants had not experienced before. The somewhat larger decrease in the linear environment was partly due to the slower learners. As shown in <ref type="figure" target="#fig_0">Figure B1</ref> in Appendix B, those participants who needed two additional training blocks had particularly poor performance in the linear environment. Without these five subjects, the mean accuracy in the linear environment in the test phase increases to 0.71. Interestingly, their performance in the nonlinear environment did not suffer at all.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Identifying the strategies adopted by the participants</head><p>We used cognitive modeling to investigate which decision strategies participants relied on in the linear and nonlinear environments. We expected that participants would adopt an exemplar-based strategy in the nonlinear environment and a cue-based strategy in the linear environment. While both classes of strategies can perform well in the linear environment, we expected the probabilistic feedback and fewer repetitions of stimuli to tip the scale in favor of cue-based strategies.</p><p>We used several models from the literature as representatives of each type of strategy. The cue-abstraction model (CAM, <ref type="bibr" target="#b34">Pachur &amp; Olsson, 2012)</ref> and weighted additive (WADD, <ref type="bibr" target="#b35">Payne et al., 1993)</ref> model are representative cue-based strategies. To represent the exemplar-based strategies we used two versions of the generalized context model (GCM, ) that were specifically adapted for pairwise comparison tasks as used here. We describe the models in more detail in the following sections, while the estimation procedure and overview of estimated parameters can be found in Appendix A. In <ref type="table">Table 2</ref> we list the models we set out to investigate. We examined several other variants of these models in an exploratory manner, their results and parameters are presented in Appendix A, however, we do not focus on these in the main text.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Overview of the models representing each type of strategy. We used more than one model per type of strategy as we are mainly interested whether a certain type of strategy has been adopted. Previous research has shown significant individual variation in which particular cue-or exemplar model describes behavior best in an environment. For instance, some people are better described by the WADD model and some by the CAM in a linear environment (e.g., <ref type="bibr" target="#b34">Pachur &amp; Olsson, 2012)</ref>. Including several instantiations of cue-and exemplar-based models should reduce the chance of falsely rejecting our hypotheses due to the particular choice of model.</p><p>The weighted additive (WADD) model. The weighted additive model <ref type="bibr" target="#b35">(Payne et al., 1993)</ref> and take-the-best heuristic <ref type="bibr" target="#b10">(Gigerenzer &amp; Goldstein, 1996)</ref> are popular models for describing the behavior in pairwise comparison tasks. We used the probabilistic generalization of these models developed by <ref type="bibr" target="#b1">Bergert and Nosofsky (2007)</ref>. In the WADD model the probability that A will be chosen over B is given by</p><formula xml:id="formula_2">P(A; A, B) = (Σ a∈FA w a ) γ (Σ a∈FA w a ) γ + (Σ b∈FB w b ) γ ,</formula><p>where γ ≥ 0 is a free response scaling parameter and w j (0 ≤ w j ≤ 1) are the weights assigned to each individual cue, constrained to sum to 1. FA and FB denote the set of discriminating cues favoring alternatives A and B, respectively. 5 Generalized take-the-best (gTTB) is a special case with scaling factor γ set to 1. Although the predictions of two models are equivalent in that case, the implied psychological processes are different. In the main text we present the result for WADD model since gTTB is a special case of WADD. We report results specifically for gTTB in Appendix A.</p><p>As these models are based on a linear combination of cues, they are especially well suited for linear environments. This gives them an edge in linear environments, but prevents them from performing well in nonlinear environments. Scaling parameter γ can additionally capture potential inter-individual differences in sensitivity to differences in evidence between alternatives.</p><p>Overall, the WADD model had four parameters -γ, w 1 , w 2 and w 3 , while the gTTB model had three parametersw 1 , w 2 , and w 3 .</p><p>Cue-abstraction model (CAM). The cue abstraction model <ref type="bibr" target="#b19">(Juslin et al., 2003;</ref><ref type="bibr" target="#b34">Pachur &amp; Olsson, 2012)</ref> is another model that combines evidence in a linear way. Alternatives are evaluated jointly by looking at the difference of each cue value ∆c j = c jA − c jB , j = 1, .., 4. The importance of each cue difference is reflected in its cue weight w j ≥ 0. The higher the cue weights are, the more they will influence the choice. The probability that alternative A will be chosen over alternative B is given by</p><formula xml:id="formula_3">P(A; A, B) = e Σ j w j ∆c j 1 + e Σ j w j ∆c j ,</formula><p>Essentially, CAM is a logistic regression model without an intercept. It is also similar to the WADD model; the main difference being that CAM transforms the evidence into choice probabilities through a logistic function and allows for more subjectivity in weights. Even though the models produce similar predictions, empirically researchers have found differences in terms of fit to choice behavior <ref type="bibr" target="#b34">(Pachur &amp; Olsson, 2012)</ref>. We tested two versions of the model. In CAM c the weights are constrained to lie between 0 and 1 and to sum to 1, i.e. 0 ≤ w j ≤ 1, and 4 j=1 w j = 1, while in CAM u they are unconstrained. The constraint prevents the weights from becoming very large which can reduce overfitting and may help the model to generalize better. Because the constraint implied positive effects for all cues, we reversed the direction of some cues using the same procedure as for WADD and gTTB. We focus on the more general CAM u and we examined CAM c in an exploratory manner. Results of CAM c are reported in Appendix A. CAM u had four parametersw 1 , w 2 , w 3 and w 4 , while CAM c had three parametersw 1 , w 2 , and w 3 .</p><p>The generalized context model (GCM). The generalized context model is a memory-based exemplar model widely used in category learning <ref type="bibr" target="#b30">(Nosofsky, 1986)</ref>, but also <ref type="bibr">5</ref> In our environments some cues have a negative effect on the criterion and the sign of the difference between the cue values of two alternatives needs to be reversed (multiplied by minus 1) whenever the difference is not equal to zero. For each environment we fitted the WADD to the actual winning alternatives with all possible combinations of cue reversals. In the linear environment the WADD with fourth cue reversed performed the best, and in the nonlinear the WADD with second, third and fourth cue reversed was the best. When fitting the model to each individual we reversed the cues according to these results. for continuous judgments <ref type="bibr" target="#b19">(Juslin et al., 2003;</ref><ref type="bibr" target="#b47">Speekenbrink &amp; Shanks, 2010)</ref>. GCM assumes that previous experiences are stored as instances in memory and when a new situation arises, a prediction is generated by combining exemplars stored in memory according to their similarity to the new situation. The similarity component allows the model to mimic both linear and nonlinear functions, which is why it can perform well in both types of environment.</p><p>We used the GCM developed for pairwise comparison tasks by <ref type="bibr" target="#b32">Nosofsky and Bergert (2007)</ref>. The model compares the probe (the current pair of alternatives) to the previously encountered exemplars (pairs of alternatives) that are kept in the memory. The model determines how similar the probe p is to each exemplar i through an exponentially decreasing function of the distance d(p, i) between the probe and exemplar</p><formula xml:id="formula_4">S (p, i) = e −λd(p,i) q ,</formula><p>where 0 ≤ λ ≤ 10 is a sensitivity parameter and q = 1 for the exponential, and q = 2 for the Gaussian similarity function. The distance function is the generalized Minkowski distance</p><formula xml:id="formula_5">d(p, i) = Σ J j=1 w j |c p j − c i j | r ] 1/r</formula><p>with Minkowski parameter r being either 1 or 2. c p j and c i j are the cue values of probe p and exemplar i, respectively, for cue j. w j , 0 ≤ w j ≤ 1, are attention weights assigned to each individual cue, constrained to sum to 1. The more closely the cue values of the probe and the exemplar correspond to each other, the smaller the distance between them and the greater the similarity. <ref type="bibr" target="#b32">Nosofsky and Bergert (2007)</ref> proposed two versions, depending on how the decision situation is represented. In what we call a "paired" representation, the model assumes that winning alternatives are stored as exemplars of a winners category, W, while losing alternatives are stored as exemplars of a losers category, L. Similarities to the winners and losers categories for alternative A are computed separately as</p><formula xml:id="formula_6">S (A, W) = i∈W s(A, i) and S (A, L) = i∈L s(A, i)</formula><p>The relative evidence for alternative A is given by</p><formula xml:id="formula_7">G A = S (A, W) γ S (A, W) γ + S (A, L) γ</formula><p>where 0 ≤ γ ≤ 10 is a free scaling parameter. Finally, the probability that alternative A is chosen is given by P <ref type="figure">(A; A, B</ref></p><formula xml:id="formula_8">) = G A G A + G B</formula><p>The "joint" representation version of the model similarly assumes that pairs of alternatives are stored as exemplars in winners and losers categories. If the feedback indicates that alternative A is a correct choice, then the pair AB is stored in the winners category as a vector where alternative B is concatenated to alternative A, while a vector BA, where A is concatenated to B, is stored in the losers category. The attention weights are the same for both alternatives and in this representation they are simply duplicated and concatenated to form a vector of the same length as pairs AB and BA. The probability that alternative A is chosen is given by</p><formula xml:id="formula_9">P(A; A, B) = S (AB, W) γ S (AB, W) γ + S (AB, L) γ</formula><p>where S (AB, W) and S (AB, L) represent similarities of the pair AB to each exemplar in the winners and losers categories, respectively, based on the same distance and similarity computations as paired representation.</p><p>We focused on GCM versions with Minkowski distance parameter r = 1 and exponential similarity function q = 1, which we report in the main text. This model with the paired representation is denoted as pGCM γ 11 and the version with the joint representation as jGCM γ 11 . Both models had a total of five parameters: λ, γ, w 1 , w 2 and w 3 . Given the binary nature of features in our task, Minkowski and similarity parameters should not matter that much, but we explored both paired and joint versions with different combinations these parameters. In one variant we also set the scaling parameter to one. Results of all models are presented in Appendix A.</p><p>Best fitting models in each environment. <ref type="figure">Figure 2</ref> summarizes the test set generalization results of the selected models. Following <ref type="bibr" target="#b53">Wagenmakers and Farrell (2004)</ref> we computed log likelihood (LL) weights for each of the four models in our candidate set, separately for each environment. LL weights allow for better interpretation of observed relative differences in model performances. Weight can be interpreted as the probability that a particular model is the best model, given the data and the set of models in the comparison set. See Appendix A for more details on LL weight computation.</p><p>As can be seen in the figure, on average, CAM u predicted participants' choices in the linear environment best, while in the nonlinear environment jGCM γ 11 and pGCM γ 11 performed about equally well, with CAM u closely trailing behind. In the linear environment CAM u has the greatest probability of being the best model among the four (0.57), being more than two times more likely than jGCM γ 11 (0.16) and pGCM γ</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>11</head><p>(0.23). WADD fared poorly, having only 0.04 probability of being the best model. For the nonlinear environment the results are less clear. Evidence is favoring jGCM γ 11 and pGCM γ 11 , with probabilities of 0.37 and 0.35 respectively, but only with a small margin over CAM u with probability of 0.28. The finding that CAM u performed well also in the nonlinear environment shows that a subset of participants did not adapt well and tried to apply a cue-based strategy in the nonlinear environment too.</p><p>Classifying individuals according to the strategy used. Average results do not tell us exactly how well adapted the participants are. We classified participants as users of those strategies that best predicted their choices in the test phase, separately for the linear and nonlinear environment (numbers denoted with N in <ref type="figure">Figure 2</ref>). In the linear environment most participants were best described by one of the cue-based strategies. In the nonlinear environment most participants were best described by one of the exemplar-based strategies, although the number of participants best described by the CAM u model was also large. Thus, for a majority of the participants, we found evidence that they were able to adaptively switch between strategies from trial to trial, as they encountered different environments.</p><p>In the linear environment, 19 participants were best described by one of the exemplar-based strategies. Recall that in the linear environment both classes of strategies can achieve good performance, while in the nonlinear environment only exemplar-based strategies can achieve good performance. In the nonlinear environment there were 15 participants that were best predicted by CAM u . These participants either did not learn to select a more appropriate strategy for the nonlinear environment or failed to separate decision situations into two different environments.</p><p>Overall, 12 participants used exemplar-based strategy in both environments, while 8 used cue-based strategy exclusively. 29 participants adopted exemplar-based strategy in one environment and cue-based in the other, 7 of which used them in unexpected fashion -exemplar strategy in the linear and cue-based strategy in the nonlinear environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contextual strategy selection learning</head><p>The previous analysis showed that the majority of participants successfully adopted a cue-or exemplar-based strategy in the linear environment, and an exemplar-based strategy in the nonlinear environment. However, that analysis did little to inform how the associations between strategies and environments were learned.</p><p>To describe this process in our experiment, we used a contextual version of the reinforcement learning based SSL model <ref type="bibr" target="#b42">(Rieskamp &amp; Otto, 2006)</ref>. In contrast to the original SSL, we assume that people form two categories of situations based on perceptual features -the "bugs" and the "comics" category. Our version of SSL then learns which strategy is more successful separately for the "bugs" and the "comics" category. Moreover, our strategies are probabilistic and the repertoire contains exemplar-based strategies that can perform well in the nonlinear environments. We fitted the model to the training phase for each individual, exam-ined what strategies were adopted and how well the choices in the test phase are predicted with the particular strategy mix adopted in the training phase.</p><p>The model. The original SSL model <ref type="bibr" target="#b42">(Rieskamp &amp; Otto, 2006)</ref> assumes that people have a repertoire of strategies they can apply to the decision problem at hand. A crucial assumption in the model is that rewards obtained from the choices reinforce the strategies instead of specific alternatives. The main implication of the model is that the strategy that on average leads to higher rewards will be chosen more often.</p><p>In the contextual SSL (CSSL) we assume that the decision problem that is encountered can be a member of one of E environments. The first step is then to categorize the problem as belonging to one of the environments, e ∈ 1, ..., E. We assume there is a vector of contextual features x and that there exist a mapping, f (x), from contextual features to environment categories, e ∈ 1, ..., E. The contextual features can take any form, for example the time available for making a decision, cue weights, (non)compensatoriness of the cue weights, or simply perceptual features of the alternatives. In light of our discussion in the introduction, what is relevant is that problems are differentiated -there is no further meaning ascribed to any of the categories. Our experiment was designed so that the mapping function, f (x), is particularly simple; we made it highly likely that participants use perceptual features -bugs and comics -to partition the problems into two categories. And as this indeed is a useful way to partition the problems, they are likely to stick with it. Hence, for the purposes of the present experiment, we assume that the model employs a simple deterministic function from a single contextual feature, x ∈ {bugs, comics}, to two environments, e ∈ 1, 2.</p><p>In the second step, the model chooses a strategy from the repertoire where strategy expectancies are conditional on the environment. Expectancy is a measure of preference for a certain strategy in an environment. The probability of choosing strategy s from repertoire S in environment e at trial t is defined as</p><formula xml:id="formula_10">P t (s|e) = Q t (s|e) θ S s Q t (s|e) θ ,</formula><p>where Q t (s|e) is the expectancy of strategy s in environment e at trial t and θ is a sensitivity parameter. When θ = 1 we obtain <ref type="bibr" target="#b23">Luce's (1959)</ref> choice rule. Initial expectancies are defined by Q 1 (s|e) = r max wβ s , where 0 &lt; w &lt; 10 is an initial association parameter, r max is the maximum reward that can be obtained with a correct decision in the task (10 experimental points in our case), and the β s parameter describes the initial bias toward a certain strategy (with 0 ≤ β s ≤ 1, and s β s = 1). In addition, if Q t (s|e) falls below some minimum level ρ due to negative payoffs, it is set to ρ = 0.0001. .4</p><p>.5</p><p>.6</p><p>.7</p><p>.8</p><p>.9</p><formula xml:id="formula_11">1.0 C A M u W A D D p G C M 1 1 g j G C M 1 1 g C A M u W A D D p G C M 1 1 g j G C M 1 1 g</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Log likelihood weights</head><p>Cue-based strategy Exemplar-based strategy <ref type="figure">Figure 2</ref>. Model performance in predicting individual choices in the test phase, presented separately for each environment. Performance is expressed as mean log likelihood weight across participants, computed for these four models in the comparison set. Numbers above the bars represent number of participants whose choices in the test phase were best predicted by each of the models. Most people were best predicted with cue-based strategies in the linear environment, and with exemplar-based strategies in the nonlinear environment.</p><p>After applying the selected strategy a reward is obtained and this reward is the basis for updating the expectancies of the strategies:</p><formula xml:id="formula_12">Q t (s|e) = Q t−1 (s|e) + I t−1 (s|e)r t−1 (s|e)</formula><p>where I t−1 (s|e) is an indicator function, and r t−1 (s|e) is the reinforcement. <ref type="bibr">6</ref> In our case reinforcement is the payoff that the strategy produces, either 10 or -10 experimental points. We implemented two types of indicator function: deterministic and proportional. The deterministic indicator function equals 1 if the strategy s was applied, and 0 if it was not. How do we infer that the strategy was chosen? If the strategy prediction coincides with the participant's choice (that is, if the probability of choosing the alternative is greater than 0.5), and if other strategies predict a different choice, we assume that the participant has chosen that strategy. If more than one strategy prediction coincides with the participant's choice, we assume that I t−1 (s|e) equals the probability with which the model predicts the selection of those strategies in a given environment, P t (s|e). In this case, the strategy preferences do not change as ratio of expectancies will remain constant.</p><p>In the original SSL model only a deterministic indicator function was used since the authors considered only deterministic strategies. The proportional indicator function takes the probability with which each strategy predicts the participant's choice and produces a weight normalized by the sum of the probabilities. This mechanism provides a more gradual strategy learning process. Since this mechanism would lead to smaller relative differences between the strategy expectancies, we used proportional indicator function in combination with a sensitivity parameter θ in the choice rule as a free parameter. Since we do not directly observe which strategy was employed, the proportional indicator function makes a more reasonable choice than the deterministic ones. We assumed there are two strategies in the repertoire -a representative of exemplar-based strategies and a representative of cue-based strategies. Following the results of modeling the test phase choices, we chose jGCM γ 11 to be the representative of exemplar-based strategies, and CAM u as representative of cue-based strategies. Strategies also have free parameters. This is another deviation from the original SSL model, besides partitioning according to the observable features and proportional indicator function. In CAM u cue weights are free parameters, and in jGCM γ 11 γ, λ and attention weights are free parameters. Hence, learning occurs on multiple levels -adapting the strategy mix at the strategy selection level, and adapting the strategies themselves to each environment. <ref type="bibr">7</ref> Overall there were three parameters on the strategy learning level, the initial association parameter w, initial strategy bias parameter β s and sensitivity parameter θ. We varied whether a deterministic or proportional indicator function was used, marked with prefix d and p respectively. When a deterministic indicator function was used we fixed θ to one, reducing the number of parameters by one.</p><p>Results of modeling the strategy selection learning. Modeling results in terms of projective fit in the test phase are depicted in <ref type="figure">Figure 3</ref>. Details of the fitting procedure can be found in Appendix A, and estimated parameters in <ref type="table">Table A2</ref> in the same Appendix. We compared the context sensitive CSSL model with the original SSL model (for details, see <ref type="bibr" target="#b42">Rieskamp &amp; Otto, 2006)</ref> containing the same two strategies in the repertoire and governed by the same strategy selection parameters. We also fitted single strategies CAM u and jGCM γ 11 to choices from both environments, to investigate how the strategy selection models compare to simpler explanations using single strategies.</p><p>We can see that the contextual versions of SSL fared better than the original SSL and single strategy models. dCS S L model with deterministic indicator function predicted participants' choices in the test phase the best, reaching probability of 0.26 of being the best model among the six we have considered. pCS S L θ performed worse, reaching probability of 0.17, but still better than dS S L and pS S L θ models that have probabilities 0.11 and 0.16 respectively of being best models. Interestingly, the version with the deterministic indicator function had a worse performance in this case. Numbers above the columns indicate the number of individuals best fitted with the model. These show that 21 participants are best described by one of the CSSL models, while 14 are best described with one of the SSL models. Although CSSL models predict participants' choices better, the advantage over simpler SSL models does not look immediately impressive. However, the advantage is considerable given that CSSL models are more complex, effectively having twice as many parameters (when strategy-specific parameters are taken into account) and still perform well on the held-out sample.</p><p>With respect to the single strategy models, given that choices of many participants in the nonlinear environment were best predicted with the CAM u model, we expected CAM u to perform well when fitted to the whole data. Indeed, CAM u has probability of 0.19 of being the best model, second only to the dCS S L model, and nine participants were best predicted with this model. jGCM γ 11 model performed the worst, reaching probability of 0.11 and predicting choices of five participants the best. Overall, single strategy models performed as well as the SSL (but not CSSL) models.</p><p>Which strategies do CSSL models adopt in each of the environments? <ref type="figure">Figure 4</ref> shows the evolution of probability of choosing the exemplar-based strategy (as represented by the jGCM γ 11 model) over blocks of trials, presented in terms of averages across the participants. As we expected, by the end of the training phase the exemplar strategy was the preferred one in the nonlinear environment; dCS S L and pCS S L θ models ended up with probabilities of 0.73 and 0.71 of choosing the exemplar strategy. There is very little difference between the models in terms of evolution of strategy preferences as well. Inspecting the end-of-training strategy mixtures for both CSSL models, most participants can be described as having a higher probability to use the cue-based strategy in the linear environment and the exemplar strategy in the nonlinear -31 for dCS S L and 39 for pCS S L θ model. Fewer participants are described with mixtures that favor exemplar strategies (12 for dCS S L and 5 for pCS S L θ ) or cuebased strategies (6 for dCS S L and 4 for pCS S L θ ) in both environments. Only one participant was described by the pCS S L θ model as preferring the exemplar strategy in the linear and the cue-based strategy in the nonlinear environment.</p><p>The parameters for the initial preference toward a strategy, w and β, were shared across environments. For most participants parameter values indicate a weak initial preference for the cue-based strategy as both CSSL models started with a weak initial preference for the CAM u model. In the linear environment this preference was kept more or less constant throughout the training phase (ending at probabilities of 0.35 for dCS S L model, and 0.39 for pCS S L θ ). In the nonlinear environment the change in strategy expectancies was strong and steered rapidly in favor of the exemplar strategy. There are substantial deviations in the fifth and sixth block of the training phase. This is due to several slower learners on which these data points are based, that had different evolution of strategy mixtures.</p><p>The difference between the environments in which strategy is mostly adopted is the source of improvement offered by CSSL in comparison to the SSL and single strategy models. It results in a weak preference for the cue-based strategy in the linear environment and strong preference for the exemplar-based strategy in the nonlinear environment. In .7</p><p>.8</p><p>.9</p><formula xml:id="formula_13">1.0 C A M u j G C M 1 1 e p S S L q d S S L p C S S L q d C S S L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Log likelihood weights</head><p>Single strategy Original SSL Contextual SSL <ref type="figure">Figure 3</ref>. Model performance in predicting choices in the test phase for contextual strategy selection learning models (CSSL), original strategy selection learning models (SSL), and two single strategy models -CAM u and jGCM γ 11 . Performance is expressed as mean log likelihood weight across participants, computed for these six models in the comparison set. Numbers above the bars represent number of participants whose choices in the test phase were best predicted by each of the models. contrast, SSL can learn only a single strategy mixture that works best on average over all environments and here both SSL models develop a strong preference for the exemplarbased strategy. These differences can be seen more clearly in <ref type="figure">Figure B2</ref> in Appendix B, where model performance is shown separately for the environments. We can see that because the CSSL models predict choices in the linear environment much better than the SSL models, whose performance suffers in the linear environment.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>We presented an experiment where participants were asked to solve two interleaved choice tasks. In one task (the linear environment), a cue-based strategy was more appropriate while in the other (the nonlinear environment), an exemplar-based strategy was more appropriate. During the training phase, participants learned to solve the tasks well. Their choices in the test phase, where they also encountered previously unseen alternatives, were critical for our modeling approach. In our first modeling analysis, using an outof-sample prediction criterion, we found that on average the cue-based CAM u model predicted participants' choices in the linear environment best, while the exemplar-based jGCM γ 11 predicted choices best in the nonlinear environment. This modeling evidence does not rely on assumptions of how strategy preferences are learned. Thus, our results show that majority of the participants in our experiment have appropriately adopted a cue-based strategy in the linear environment and an exemplar-based strategy in the nonlinear environment, and were able to flexibly shift between them as they encountered a decision problem from one environment to another. However, a substantial number of participants appeared to use a cue-based strategy (CAM u ) in the nonlinear environment. These participants either failed to separate the two environments and adopted the same strategy in both, or they simply failed to adapt adequately to the nonlinear environment <ref type="bibr" target="#b2">(Brehmer, 1974;</ref><ref type="bibr" target="#b5">Busemeyer et al., 1997;</ref><ref type="bibr" target="#b33">Olsson et al., 2006)</ref>. We favor the latter explanation. <ref type="bibr" target="#b48">Stojić, Olsson, and Analytis (2016)</ref> find that differences in speed of learning could account for the inter-individual variation in strategy adoption within conditions. Hence, we believe these participants were slow learners who would have adopted an exemplar-based strategy given sufficient experience.</p><p>We found that participants' choice accuracy in both environments decreased substantially from training to test phase. This drop was not expected in the linear environment. .4</p><p>.5</p><p>.6</p><p>.7</p><p>.8</p><p>.9  <ref type="figure">Figure 4</ref>. Strategies adopted by CSSL models over time in each environment in the training phase, expressed in probabilities of choosing the exemplar strategy, jGCM γ 11 . Probability that the CAM u model is selected is one minus probability of choosing the exemplar strategy. Test phase strategy mixture is simply the mixture from the last trial in the training phase. Points are averages across participants, where for each participant an average across the block was taken. Results of block five and six come from a subset of participants that took additional one or two blocks in the training phase. the advantages of cue-based strategies over exemplar-based strategies is their ability to accurately extrapolate outside the range of experienced exemplars <ref type="bibr" target="#b5">(Busemeyer et al., 1997)</ref>. If participants truly used a cue-based strategy in the linear environment they should have no difficulty generalizing their knowledge to the new items in the test phase. However, there were important differences in difficulty between the environments, so this makes the comparison harder. Moreover, cue-based strategies can be poor at extrapolation as well, depending on the specifics of the learning process <ref type="bibr" target="#b27">(McDaniel &amp; Busemeyer, 2005)</ref> and if the weights have not been learned sufficiently well.</p><p>In our second modeling analysis we have fitted a contextual version of the strategy selection learning (CSSL) model, with CAM u and jGCM γ 11 in the strategy repertoire, representing cue-based and exemplar-based strategies. The model implements a trial-and-error mechanism by which participants learn over time to associate environments to the strategy which works best within it. The CSSL model predicted the behavior of the participants better than simpler explanations in the form of the original SSL and single strategy models. The evolution of strategy expectancies in the CSSL was consistent with our earlier findings identifying which strategy was used in each environment. Our CSSL model shows an initial preference for a cue-based strategy, as also found in previous studies <ref type="bibr" target="#b42">(Rieskamp &amp; Otto, 2006)</ref>. In the linear environment this preference is maintained, while in the nonlinear environment it changes substantially throughout the training phase in favor of an exemplar-based strategy.</p><p>In this modeling analysis, many of the participants best fitted with SSL or single strategy models were also the ones that incorrectly used a cue-based strategy in the nonlinear environment, as shown in the first modeling analysis. However, there are inconsistent classifications as well, e.g., participants classified as adaptive on the basis of the first modeling exercise that were not best predicted by a CSSL model in the second modeling analysis. Such differences are most likely due to using only CAM u and jGCM γ 11 in CSSL's strategy repertoire. This was necessary for practical reasons, but it resulted in forcing these two strategies on all participants, while in the first modeling analysis participants were fitted with several models from both cue-and exemplar-based class. Some differences were also expected since the two modeling approaches differ substantially.</p><p>In several previous studies it was shown that people adopt different strategies in different environments (e.g., <ref type="bibr" target="#b21">Karlsson et al., 2007;</ref><ref type="bibr" target="#b34">Pachur &amp; Olsson, 2012)</ref>. Crucially, however, their experiments employed between-subject designs such that single participants were not exposed to multiple environments. Consequently, they were concerned less with the mechanisms through which strategies are adopted, focusing instead on identifying the dominant strategy adopted by participants. <ref type="bibr" target="#b12">(J. Hoffmann et al., 2014</ref>) is one of the rare studies that used a within-subject design. In their experiments participants performed a multiple cue probability learning task belonging to a linear environment or multiplicative environment, although participants were exposed to them in separate blocks. They found that participants' responses in the linear environment were best described with a linear regression model, while responses in the multiplicative environment were best described with an exemplar model. However, they investigated the role of episodic memory in strategy adoption and did not examine the influence of environment classification on strategy selection, or attempt to model the mechanism behind adopting the strategies in multiple environments.</p><p>Lieder and Griffiths (2015) also used a within-subject design, aiming to shed more light on the strategy selection mechanism. Based on their results they concluded that their feature-based cost-benefit model described participants' behavior better than the reinforcement learning approach of the SSL model <ref type="bibr" target="#b42">(Rieskamp &amp; Otto, 2006)</ref>. In their experiments they used two similar environments -compensatory and noncompensatory, both of which are linear. Moreover, they have presented cue validities to the participants that made it easy to estimate the accuracy of each strategy. On the other hand, our study favors the reinforcement learning approach as it can deal with much more complex situations, where the importance of features to classify environments still has to be learned. A cost-benefit based strategy selection approach such as the model proposed by <ref type="bibr" target="#b22">Lieder and Griffiths (2015)</ref> would find it difficult to explain how people solve the strategy selection problem in this setting.</p><p>In contrast to the cost-benefit model developed by <ref type="bibr" target="#b22">Lieder and Griffiths (2015)</ref>, the CSSL model does not require predetermined features to classify environments. For example, the CSSL model does not need to know the statistical properties of the environment to classify it as one in which an exemplar strategy would work best. All that is needed is that decision situations are separated into different categories, which strategy works best in that category can be learned. In our experiment we used a very clear visual feature that participants could use to partition the situations into two groups -one situation was always represented as deciding between "bugs", and the other between "comic" figures. One could argue that we have made the partitioning task too easy and the task lost much on its external validity. The present study can be thought of as a proof of principle -if participants had difficulty with associating different strategies to two easily distinguishable environments, there would be little hope that they would be able to do it in more complex realistic scenarios. In future work, we aim to test the model in situations where the features distinguishing environments are more subtle.</p><p>Another concern relates to the scalability of the reinforcement learning approach to such situations. When there are many potential features to distinguish between environments, there is a danger of identifying too many categories. Such over-categorization is wasteful as it reduces the amount of experience with each category, so that learning which strategy works best for that category is difficult. A direction we aim to explore in the future is to combine reinforcement learning with a similarity-based mechanism to generalize over categories. For example, if one learns to prefer a certain strategy when deciding between apples, then based on some similarity measure you might start with a similar strategy when deciding between oranges, but perhaps not when deciding between televisions.</p><p>Finally, it is important to note that the issue of categorizing environments extends to any "cognitive toolbox" theory that assumes the existence of a repertoire of mechanisms that can be selected. Such theories are gaining in popularity and can be found in many areas in psychology, from developmental psychology to categorization (for a recent overview, see f <ref type="bibr" target="#b44">Scheibehenne et al., 2013)</ref>. Dual system theory can also be seen as a toolbox type of theory (e.g. <ref type="bibr" target="#b20">Kahneman, 2011;</ref><ref type="bibr" target="#b46">Shiffrin &amp; Schneider, 1977)</ref>, where there are two tools in the toolbox -System 1 and System 2 -and the question is how you choose which one to apply when facing multitudes of problems. The problem of categorizing environments is intimately connected to the strategy selection problem, and as we argued above, solving it requires more than a straightforward extension of strategy selection in a single environment. Without successfully addressing both categorization and strategy selection, the toolbox approaches to cognition will be found lacking.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table A1</head><p>Summary of parameter estimates for models in identifying the strategies adopted by the participants in each environment together with their performances in the test phase as indicated by their negative log transformed likelihood, −log(L). We report means and standard deviations in parenthesis for each parameter. For all models except CAM u only three weight parameters were free parameters, the fourth was constrained by those three. = Constrained cue abstraction model; WADD = Weighted additive model; gT T B = generalized take-the-best model; GCM = Generalized context model, prefix p and j denote paired and joint representation respectively, first number in subscripted suffix denotes Minkowski distance parameter while the second denotes similarity function parameter, superscript suffix γ denotes whether scaling parameter was used as well; Envir. = Type of environment; # = Number of parameters; w 1−4 = Weight parameters, for GCM models these are attention parameters.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table A2</head><p>Summary of parameter estimates for strategy selection models. We report means and standard deviations in parenthesis for each parameter. S S L models used strategy parameters for CAM u and jGCM γ 11 for which means are reported in the first two rows of this table, while CS S L models used environment-specific parameters for which means are reported in <ref type="table" target="#tab_0">Table A1</ref>. For jGCM γ 11 only three weight parameters were free parameters, the fourth was constrained by those three. .4</p><formula xml:id="formula_15">Model # w β θ γ λ w 1 w 2 w 3 w 4 CAM u 4 - - - -<label>-</label></formula><p>.5</p><p>.6</p><p>.7</p><p>.8</p><p>.9</p><p>1.0</p><formula xml:id="formula_16">C A M u j G C M 1 1 e p S S L q d S S L p C S S L q d C S S L C A M u j G C M 1 1 e p S S L q d S S L p C S S L q d C S S L</formula></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Log likelihood weights</head><p>Single strategy Original SSL Contextual SSL <ref type="figure">Figure B2</ref>. Model performance in predicting choices in the test phase for contextual strategy selection learning models (CSSL), original strategy selection learning models (SSL), and two single strategy models -CAM u and jGCM γ 11 , computed separately for trials in the linear and nonlinear environment. Performance is expressed as mean log likelihood weight across participants, computed for these six models in the comparison set. Numbers above the bars represent number of participants whose choices in the test phase were best predicted by each of the models.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head>Figure 1 .</head><label>1</label><figDesc>Mean accuracy in the test phase dropped compared to the last train-Accuracy of participants' choices in blocks of trials in the training phase and in the test phase. Training blocks consist of 44 linear and 40 nonlinear trials. Result for a block is a mean of individual mean accuracies across trials in a block.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_1"><head></head><label></label><figDesc>Par. = Number of free parameters in the model; CAM u = Unconstrained cue abstraction model; WADD = Weighted additive model; GCM = Generalized context models.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_4"><head></head><label></label><figDesc>One of N = 49 N = 18 N = 5 N = 49 N = 49 N = 18 N = 5 N =</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_5"><head></head><label></label><figDesc>u = Unconstrained cue abstraction model; jGCM γ 11 = Generalized context model with joint representation, Minkowski and similarity parameters equal to 1 and free scaling parameter; S S L = Context-free strategy selection learning model, prefix d and p denote deterministic and proportional update, while the suffix θ denotes additional free scaling parameter; CS S L = Contextual strategy selection learning model, prefix d and p denote deterministic and proportional update, while the suffix θ denotes additional free scaling parameter; # = Number of parameters; w 1−4 = Weight or attention parameters.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Cue patterns and continuous criterion values of the 15 exemplars used in linear and nonlinear environment in the Experiment. Old = exemplar used in both training and test phase; New = new exemplar that occurs only in the test phase. first trial. People tend to have strong prior beliefs that cueoutcome relations are positive and linear</figDesc><table><row><cell>Exemplar No.</cell><cell></cell><cell>Cues</cell><cell></cell><cell></cell><cell cols="2">Linear environment</cell><cell cols="2">Nonlinear environment</cell></row><row><cell></cell><cell cols="7">Cue 1 Cue 2 Cue 3 Cue 4 Expected criterion Role Criterion</cell><cell>Role</cell></row><row><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.10</cell><cell>Old</cell><cell>0</cell><cell>New</cell></row><row><cell>2</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0.00</cell><cell>New</cell><cell>0.35</cell><cell>Old</cell></row><row><cell>3</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0.30</cell><cell>Old</cell><cell>0.62</cell><cell>New</cell></row><row><cell>4</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0.20</cell><cell>Old</cell><cell>0.82</cell><cell>Old</cell></row><row><cell>5</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0.40</cell><cell>Old</cell><cell>0.82</cell><cell>New</cell></row><row><cell>6</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0.60</cell><cell>Old</cell><cell>-</cell><cell>-</cell></row><row><cell>7</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0.50</cell><cell>Old</cell><cell>-</cell><cell>-</cell></row><row><cell>8</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0</cell><cell>0.50</cell><cell>New</cell><cell>0.94</cell><cell>Old</cell></row><row><cell>9</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>1</cell><cell>0.40</cell><cell>Old</cell><cell>1</cell><cell>New</cell></row><row><cell>10</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>0</cell><cell>0.70</cell><cell>New</cell><cell>0.97</cell><cell>New</cell></row><row><cell>11</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>1</cell><cell>0.60</cell><cell>New</cell><cell>0.88</cell><cell>New</cell></row><row><cell>12</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>0</cell><cell>0.80</cell><cell>Old</cell><cell>0.88</cell><cell>Old</cell></row><row><cell>13</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1</cell><cell>0.70</cell><cell>Old</cell><cell>0.71</cell><cell>New</cell></row><row><cell>14</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0</cell><cell>1.00</cell><cell>New</cell><cell>0.47</cell><cell>Old</cell></row><row><cell>15</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>1</cell><cell>0.90</cell><cell>Old</cell><cell>0.16</cell><cell>New</cell></row><row><cell>Note.</cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell><cell></cell></row></table><note></note></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_2"><head></head><label></label><figDesc>Note. CAM u = Unconstrained cue abstraction model; CAM c</figDesc><table><row><cell>Envir.</cell><cell>Model</cell><cell>#</cell><cell>−log(L)</cell><cell>γ</cell><cell>λ</cell><cell>w 1</cell><cell>w 2</cell><cell>w 3</cell><cell>w 4</cell></row><row><cell>Linear</cell><cell>CAM u</cell><cell>4</cell><cell>81 (95)</cell><cell>-</cell><cell>-</cell><cell cols="3">12.88 (55.38) 7.11 (13.92) 4.64 (17.19)</cell><cell>1.03 (6.53)</cell></row><row><cell></cell><cell>CAM c</cell><cell>3</cell><cell>72 (9)</cell><cell>-</cell><cell>-</cell><cell>0.43 (0.36)</cell><cell>0.55 (0.35)</cell><cell>0.02 (0.06)</cell><cell>0 (0)</cell></row><row><cell></cell><cell>WADD</cell><cell cols="2">4 530 (454)</cell><cell>∞</cell><cell>-</cell><cell>0.44 (0.38)</cell><cell>0.48 (0.4)</cell><cell>0.06 (0.09)</cell><cell>0.02 (0.03)</cell></row><row><cell></cell><cell>gT T B</cell><cell cols="2">3 532 (455)</cell><cell>-</cell><cell>-</cell><cell>0.43 (0.34)</cell><cell>0.47 (0.36)</cell><cell>0.08 (0.09)</cell><cell>0.02 (0.03)</cell></row><row><cell></cell><cell>jGCM γ 11 jGCM γ 12 jGCM γ 21</cell><cell>5 5 5</cell><cell>69 (28) 71 (23) 70 (23)</cell><cell>11.16 (8.21) 10.69 (8.01) 12.15 (8.22)</cell><cell>7.98 (7.83) 9.61 (8.29) 7.91 (7.98)</cell><cell>0.22 (0.21) 0.23 (0.17) 0.27 (0.3)</cell><cell>0.22 (0.23) 0.25 (0.22) 0.23 (0.28)</cell><cell>0.37 (0.32) 0.36 (0.29) 0.37 (0.36)</cell><cell>0.19 (0.27) 0.16 (0.19) 0.13 (0.25)</cell></row><row><cell></cell><cell cols="2">pGCM 11 4 pGCM γ 5 11 pGCM γ 5 12 pGCM γ 21 5</cell><cell>72 (7) 72 (27) 71 (27) 77 (36)</cell><cell cols="2">-10.47 (7.07) 11.46 (6.87) 14.26 (7.55) 20 (0) 14.51 (7.7) 10.76 (7.06) 12.76 (7.59)</cell><cell>0.32 (0.11) 0.39 (0.3) 0.32 (0.2) 0.42 (0.38)</cell><cell>0.33 (0.14) 0.18 (0.24) 0.24 (0.22) 0.18 (0.29)</cell><cell>0.25 (0.12) 0.24 (0.28) 0.27 (0.25) 0.23 (0.31)</cell><cell>0.1 (0.11) 0.19 (0.26) 0.18 (0.19) 0.17 (0.29)</cell></row><row><cell cols="2">Nonlinear CAM u</cell><cell cols="2">4 175 (147)</cell><cell>-</cell><cell>-</cell><cell>9.32 (8.32)</cell><cell cols="2">-10.92 (9.13) -0.35 (0.77)</cell><cell>-2.92 (3.17)</cell></row><row><cell></cell><cell>CAM c</cell><cell>3</cell><cell>73 (9)</cell><cell>-</cell><cell>-</cell><cell>0.76 (0.28)</cell><cell>0.07 (0.11)</cell><cell>0.15 (0.23)</cell><cell>0.02 (0.08)</cell></row><row><cell></cell><cell>WADDt</cell><cell cols="2">4 538 (360)</cell><cell>∞</cell><cell>-</cell><cell>0.65 (0.38)</cell><cell>0.12 (0.1)</cell><cell>0.14 (0.23)</cell><cell>0.09 (0.17)</cell></row><row><cell></cell><cell>gT T Bt</cell><cell cols="2">3 500 (322)</cell><cell>-</cell><cell>-</cell><cell>0.6 (0.27)</cell><cell>0.21 (0.11)</cell><cell>0.13 (0.21)</cell><cell>0.07 (0.15)</cell></row><row><cell></cell><cell>jGCM γ 11 jGCM γ 12 jGCM γ 21</cell><cell cols="2">5 181 (185) 5 239 (304) 5 184 (373)</cell><cell>6.61 (7.16) 6.46 (7.53) 7.19 (7.88)</cell><cell>12.77 (7.47) 15.13 (6.78) 12.39 (7.36)</cell><cell>0.16 (0.22) 0.18 (0.2) 0.22 (0.33)</cell><cell>0.37 (0.31) 0.32 (0.23) 0.42 (0.38)</cell><cell>0.25 (0.24) 0.31 (0.18) 0.21 (0.31)</cell><cell>0.22 (0.23) 0.19 (0.2) 0.14 (0.21)</cell></row><row><cell></cell><cell cols="5">81 (20) 116 (72) 5 142 (100) pGCM 11 4 pGCM γ 5 11 pGCM γ 12 pGCM γ 21 5 112 (102) 13.52 (7.43) 10.45 (7.54) -19.87 (0.48) 11.08 (7.11) 10.45 (7.53) 10.32 (6.6) 12.96 (6.46)</cell><cell>0.1 (0.18) 0.18 (0.21) 0.16 (0.19) 0.13 (0.23)</cell><cell>0.34 (0.15) 0.37 (0.35) 0.23 (0.26) 0.55 (0.42)</cell><cell>0.3 (0.25) 0.34 (0.29) 0.41 (0.18) 0.25 (0.35)</cell><cell>0.26 (0.19) 0.11 (0.14) 0.2 (0.16) 0.06 (0.13)</cell></row></table><note></note></figure>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="3">Other characteristics of environments have also been studied. The link between strategy effectiveness and properties like the number of observations, number of cues, and dominance relations is currently unclear<ref type="bibr" target="#b11">(Gigerenzer et al., 1999;</ref><ref type="bibr" target="#b25">Martignon &amp; Hoffrage, 2002;</ref><ref type="bibr" target="#b26">Martignon &amp; Laskey, 1999)</ref>. Under time pressure people use more frugal heuristic strategies like TTB (e.g.<ref type="bibr" target="#b41">Rieskamp &amp; Hoffrage, 2008)</ref>. Cognitive effort also plays a role. People with better episodic memory have a stronger tendency to use exemplar-based strategies (J.<ref type="bibr" target="#b12">Hoffmann et al., 2014)</ref>, presumably because employing this strategy is less costly for these people.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="4">Software, together with exact instructions and stimuli used in the experiment, is publicly available at the Open Science Framework website: https://osf.io/3q5if/. Raw data from the experiment is publicly available on Figshare: http://dx.doi.org/ 10.6084/m9.figshare.1585822.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="6">The update equation looks different than the usual delta learning rule<ref type="bibr" target="#b38">(Rescorla &amp; Wagner, 1972)</ref>. This works equally well as in this context the absolute value of the strategy expectancy does not matter much, only relative values play a role. This learning rule might then obviate the need for the temperature parameter in the choice rule above.</note>
			<note xmlns="http://www.tei-c.org/ns/1.0" place="foot" n="7">Note however that, for the sake of simplicity, the models that we use to represent the strategies are not learning models that adapt their parameters on a trial-by-trial basis. Instead, for each individual we estimate the parameters of each model and environment separately, and then use them in the CSSL model.</note>
		</body>
		<back>
			<div type="annex">
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Appendix A Parameter Estimation and Model Selection</head><p>Identifying the strategies adopted by the participants All choice models were fitted to each individual participant's choices in the last two blocks in the training phase, separately for trials in the linear environment and nonlinear environment. Parameters were found by minimizing the log likelihood of the data given the choice probabilities predicted by the model. The likelihood of the data set, L, of model i is given by</p><p>where T is total number of trials being modeled, and P(M t = C t ) is probability of model making the same choice as participant made in trial t. Number of trials was 88 for the linear and 80 for the nonlinear environment. Optimization was done on the log transformed likelihood, −ln(L(data|M i )), using the Nelder-Mead simplex algorithm implemented in the optim function in R (R Core Team, 2015). For model selection we used a version of generalization criterion <ref type="bibr" target="#b7">(Busemeyer &amp; Wang, 2000</ref>) -for each model we used parameters estimated on the training data from one environment and predicted choices in the test phase of the same environment that were designed to discriminate better between the CAM and GCM models. As a measure of model performance we used log transformed likelihood, while for model comparison we used log likelihood weights (LL weights), following <ref type="bibr" target="#b53">Wagenmakers and Farrell (2004)</ref>. Similar to AIC or BIC weights, LL weights is a simple transformation of raw log likelihood scores that can be directly interpreted as conditional probabilities for each model. From the differences in log likelihoods we obtain an estimate of the relative likelihood L of the model i by</p><p>where L(data|M min ) is the likelihood of the model in our comparison set with the minimum likelihood, i.e. the best model. Then we normalize the relative model likelihoods to obtain the LL weights</p><p>where K is the number of models in the comparison set. This makes the weights dependent on models that are being compared, stressing the relative aspect of the model comparison.</p><p>We have always compared four models -CAM u , WADD, pGCM γ 11 and jGCM γ 11 , that we set out to investigate as primary models, even though we did fit more than these four. Importantly, LL weights allow for better interpretation of observed differences in model performances. Weight w i can be interpreted as the probability that M i is the best model, given the data and the set of models in the comparison set.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Contextual strategy selection learning</head><p>The fitting procedure is the same as in identifying the strategy used by participants in the linear and nonlinear environment, however the models were fitted to all blocks in the training phase and both environments jointly. When estimating parameters for strategy selection models, SSL and CSSL, we fixed the strategy parameters -for SSL models to the ones estimated for single strategies (CAM u and jGCM γ 11 fitted to both environments), and for CSSL models the parameters estimated according to the procedure from the previous section. This was implemented on individual level. Model comparison followed the procedure described in the previous section, but here six models comprised the comparison set -</p><p>Appendix B</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Additional results</head><p>Linear environment Nonlinear environment .</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>5</head><p>.6</p><p>.7</p><p>.8</p><p>.9</p><p>1.0 1 2 3 4 5 6 Test 1 2 3 4 5 6 Test Block Proportion of correct choices Fast (N=31) Medium (N=13) Slow (N=5) <ref type="figure">Figure B1</ref>. Choice accuracy in blocks in the training and the test phase. Participants that took additional one or two blocks in the training phase are illustrated separately, they are marked as slow or medium speed of reaching the accuracy level.</p></div>			</div>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<analytic>
		<title level="a" type="main">A contingency model for the selection of decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><forename type="middle">; L R</forename><surname>Auguie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">R</forename><surname>Mitchell</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=gridExtraBeach" />
	</analytic>
	<monogr>
		<title level="j">Academy of Management Review</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="439" to="449" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
	<note>gridExtra: functions in Grid graphics</note>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">A response-time approach to comparing generalized rational and take-the-best models of decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Bergert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.33.1.107</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="107" to="129" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Hypotheses about relations between scaled variables in the learning of probabilistic inference tasks. Organizational Behavior and Human Performance</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
		<idno type="DOI">10.1016/0030-5073(74</idno>
		<imprint>
			<date type="published" when="1974" />
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="90002" to="90008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The psychology of linear judgement models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Brehmer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">87</biblScope>
			<biblScope unit="page" from="137" to="154" />
			<date type="published" when="1994" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<analytic>
		<title level="a" type="main">Adaptive flexibility and maladaptive routines in selecting fast and frugal decision strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bröder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Schiffer</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.32.4.904</idno>
	</analytic>
	<monogr>
		<title level="m">Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="904" to="918" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">Learning functional relations based on experience with input-output pairs by humans and artificial neural networks</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Byun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">L</forename><surname>Delosh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Knowledge, concepts and categories. studies in cognition</title>
		<editor>K. Lamberts &amp; D. R. Shanks</editor>
		<imprint>
			<date type="published" when="1997" />
			<biblScope unit="page" from="408" to="437" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Cambridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Us</surname></persName>
		</author>
		<imprint>
			<publisher>MIT Press</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<analytic>
		<title level="a" type="main">Model Comparisons and Model Selections Based on Generalization Criterion Methodology</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y.-M</forename><surname>Wang</surname></persName>
		</author>
		<idno type="DOI">10.1006/jmps.1999.1282</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">44</biblScope>
			<biblScope unit="page" from="171" to="189" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">Problem solving strategies: A selection mechanism, some implications, and some data</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Christensen-Szalanski</surname></persName>
		</author>
		<idno type="DOI">10.1016/0030-5073(78)90019-3</idno>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human</title>
		<imprint>
			<biblScope unit="volume">22</biblScope>
			<biblScope unit="page" from="307" to="323" />
			<date type="published" when="1978" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<analytic>
		<title level="a" type="main">On adaptation, maximization, and reinforcement learning among cognitive strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Erev</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Barron</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.112.4.912</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">112</biblScope>
			<biblScope unit="page" from="912" to="943" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Reasoning the fast and frugal way: Models of bounded rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">G</forename><surname>Goldstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">103</biblScope>
			<biblScope unit="page" from="650" to="669" />
			<date type="published" when="1996" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<monogr>
		<title level="m" type="main">Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Research Group</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<analytic>
		<title level="a" type="main">Pillars of judgment: how memory abilities affect performance in rule-based and exemplar-based judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0037989</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">143</biblScope>
			<biblScope unit="page" from="2242" to="2261" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">Deliberation&apos;s blindsight: how cognitive load can improve judgments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Hoffmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno>doi: 10.1177/ 0956797612463581</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Science</title>
		<imprint>
			<biblScope unit="volume">24</biblScope>
			<biblScope unit="page" from="869" to="879" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<analytic>
		<title level="a" type="main">Ignoring information in binary choice with continuous variables: When is less more</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jmp.2005.01.001</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Mathematical Psychology</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page" from="115" to="124" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Simple Models for Multiattribute Choice with Many Alternatives: When It Does and Does Not Pay to Face Trade-offs with Binary Attributes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1287/mnsc.1050.0448</idno>
	</analytic>
	<monogr>
		<title level="j">Management Science</title>
		<imprint>
			<biblScope unit="volume">51</biblScope>
			<biblScope unit="page" from="1860" to="1872" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Regions of Rationality: Maps for Bounded Agents</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1287/deca.1060.0063</idno>
	</analytic>
	<monogr>
		<title level="j">Decision Analysis</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="124" to="144" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<analytic>
		<title level="a" type="main">Take-the-best&quot; and other simple strategies: Why and when they work &quot;well&quot; with binary cues</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1007/s11238-006-9000-8</idno>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">61</biblScope>
			<biblScope unit="page" from="205" to="249" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Heuristic and linear models of judgment: matching rules and environments</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Hogarth</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Karelaia</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.114.3.733</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">114</biblScope>
			<biblScope unit="page" from="733" to="758" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">Cue abstraction and exemplar memory in categorization</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Jones</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Winman</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.29.5.924</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">29</biblScope>
			<biblScope unit="page" from="924" to="941" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b20">
	<monogr>
		<title level="m" type="main">Thinking, fast and slow</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2011" />
			<pubPlace>New York, NY, US: Farrar, Straus and Giroux</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<analytic>
		<title level="a" type="main">Adaptive changes between cue abstraction and exemplar memory in a multiplecue judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Karlsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1140" to="1146" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">When to use which heuristic: A rational solution to the strategy selection problem</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Lieder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">L</forename><surname>Griffiths</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 37th annual conference of the cognitive science society</title>
		<meeting>the 37th annual conference of the cognitive science society<address><addrLine>Austin, TX, US</addrLine></address></meeting>
		<imprint>
			<publisher>Cognitive Science Society</publisher>
			<date type="published" when="2015" />
			<biblScope unit="page" from="1" to="6" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<monogr>
		<title level="m" type="main">Individual Choice Behavior</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1959" />
			<publisher>Wiley</publisher>
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Fast, frugal, and surprisingly accurate heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">D</forename><surname>Luce</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="757" to="758" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<analytic>
		<title level="a" type="main">Fast, frugal, and fit: Simple heuristics for paired comparison</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Theory and Decision</title>
		<imprint>
			<biblScope unit="volume">52</biblScope>
			<biblScope unit="page" from="29" to="71" />
			<date type="published" when="2002" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Bayesian Benchmarks for Fast and Frugal Heuristics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Martignon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">B</forename><surname>Laskey</surname></persName>
		</author>
		<editor>G. Gigerenzer, P. M. Todd, &amp; A. Group</editor>
		<imprint>
			<date type="published" when="1999" />
			<publisher>Oxford University Press</publisher>
			<biblScope unit="page" from="169" to="189" />
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
	<note>Simple heuristics that make us smart</note>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">The conceptual basis of function learning and extrapolation: comparison of rulebased and associative-based models</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">A</forename><surname>Mcdaniel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Busemeyer</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03196347</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="page" from="24" to="42" />
			<date type="published" when="2005" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<analytic>
		<title level="a" type="main">Heuristics all the way up?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Morton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="758" to="759" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Choice, similarity, and the context theory of classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.10.1.104</idno>
	</analytic>
	<monogr>
		<title level="m">ogy: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="1984" />
			<biblScope unit="volume">10</biblScope>
			<biblScope unit="page" from="104" to="114" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1986" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<analytic>
		<title level="a" type="main">Attention, similarity, and the identification-categorization relationship</title>
		<idno>doi: 10.1037/ 0096-3445.115.1.39</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">115</biblScope>
			<biblScope unit="page" from="39" to="61" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<analytic>
		<title level="a" type="main">Limitations of Exemplar Models of Multi-Attribute Probabilistic Inference</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Nosofsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">B</forename><surname>Bergert</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.33.6.999</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<biblScope unit="volume">33</biblScope>
			<biblScope unit="page" from="999" to="1019" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<analytic>
		<title level="a" type="main">Go with the flow: How to master a nonlinear multiple-cue judgment task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A.-C</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Enkvist</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Juslin</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.32.6.1371</idno>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1371" to="1384" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Type of learning task impacts performance and strategy selection in decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Pachur</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<idno>doi: 10.1016/ j.cogpsych.2012.03.003</idno>
	</analytic>
	<monogr>
		<title level="j">Cognitive Psychology</title>
		<imprint>
			<biblScope unit="volume">65</biblScope>
			<biblScope unit="page" from="207" to="240" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title level="m" type="main">The adaptive decision maker</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Payne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">R</forename><surname>Bettman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Johnson</surname></persName>
		</author>
		<imprint>
			<date type="published" when="1993" />
			<publisher>Cambridge University Press</publisher>
			<pubPlace>New York, NY, US</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">PsychoPy -Psychophysics software in Python</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">W</forename><surname>Peirce</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.jneumeth.2006.11.017</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Neuroscience Methods</title>
		<imprint>
			<biblScope unit="volume">162</biblScope>
			<biblScope unit="page" from="8" to="13" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<monogr>
		<title level="m" type="main">R: A language and environment for statistical computing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>R Core Team</surname></persName>
		</author>
		<ptr target="http://www.r-project.org" />
		<imprint>
			<date type="published" when="2015" />
			<pubPlace>Vienna, Austria</pubPlace>
		</imprint>
	</monogr>
	<note>: R Foundation for Statistical Computing</note>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">A theory of Pavlovian conditioning: Variations in the effectiveness of reinforcement and nonreinforcement</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">A</forename><surname>Rescorla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">R</forename><surname>Wagner</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Classical conditioning ii: Current research and theory</title>
		<editor>A. H. Black &amp; W. F. Prokasy</editor>
		<meeting><address><addrLine>New York, NY, US</addrLine></address></meeting>
		<imprint>
			<publisher>Appleton-Century-Crofts</publisher>
			<date type="published" when="1972" />
			<biblScope unit="page" from="64" to="99" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<monogr>
		<title level="m" type="main">doMC: Foreach parallel adaptor for the multicore package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Revolutionanalytics</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=doMC" />
		<imprint>
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Perspectives of probabilistic inferences: Reinforcement learning and an adaptive network compared</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno type="DOI">10.1037/0278-7393.32.6.1355</idno>
	</analytic>
	<monogr>
		<title level="m">Journal of Experimental Psychology: Learning, Memory, and Cognition</title>
		<imprint>
			<date type="published" when="2006" />
			<biblScope unit="volume">32</biblScope>
			<biblScope unit="page" from="1355" to="1370" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Inferences under time pressure: how opportunity costs affect strategy selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Hoffrage</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.actpsy.2007.05.004</idno>
	</analytic>
	<monogr>
		<title level="j">Acta Psychologica</title>
		<imprint>
			<biblScope unit="volume">127</biblScope>
			<biblScope unit="page" from="258" to="76" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<analytic>
		<title level="a" type="main">SSL: a theory of how people learn to select strategies</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">E</forename><surname>Otto</surname></persName>
		</author>
		<idno type="DOI">10.1037/0096-3445.135.2.207</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">135</biblScope>
			<biblScope unit="page" from="207" to="236" />
			<date type="published" when="2006" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Principles of metareasoning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Russell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Wefald</surname></persName>
		</author>
		<idno>doi: 10.1016/ 0004-3702(91</idno>
	</analytic>
	<monogr>
		<title level="j">Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">49</biblScope>
			<biblScope unit="page">90015</biblScope>
			<date type="published" when="1991" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<analytic>
		<title level="a" type="main">Testing adaptive toolbox models: a Bayesian hierarchical approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Scheibehenne</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<idno>doi: 10.1037/ a0030777</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">120</biblScope>
			<biblScope unit="page" from="39" to="64" />
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<monogr>
		<title level="m" type="main">tikzDevice: R Graphics Output in LaTeX Format</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Sharpsteen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Bracken</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=tikzDevice" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<analytic>
		<title level="a" type="main">Controlled and automatic human information processing: II. Perceptual learning, automatic attending and a general theory</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">M</forename><surname>Shiffrin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Schneider</surname></persName>
		</author>
		<idno type="DOI">10.1037/0033-295X.84.2.127</idno>
	</analytic>
	<monogr>
		<title level="j">Psychological Review</title>
		<imprint>
			<biblScope unit="volume">84</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="127" to="190" />
			<date type="published" when="1977" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">Learning in a changing environment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Shanks</surname></persName>
		</author>
		<idno type="DOI">10.1037/a0018620</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">139</biblScope>
			<biblScope unit="page" from="266" to="298" />
			<date type="published" when="2010" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">Explaining inter-individual variability in strategy selection: A cue weight learning approach</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">P</forename><surname>Analytis</surname></persName>
		</author>
		<ptr target="http://acs.ist.psu.edu/iccm2016/proceedings/stojic2016iccm.pdf" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 14th International Conference on Cognitive Modeling</title>
		<editor>D. Reitter &amp; F. E. Ritter</editor>
		<meeting>the 14th International Conference on Cognitive Modeling<address><addrLine>University Park, PA</addrLine></address></meeting>
		<imprint>
			<publisher>Penn State</publisher>
			<date type="published" when="2016" />
			<biblScope unit="page" from="144" to="150" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<monogr>
		<title level="m" type="main">Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments -Project files. Open Science Framework</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<ptr target="Retrievedfromosf.io/3q5if" />
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<monogr>
		<title level="m" type="main">Not everything looks like a nail: Learning to select appropriate decision strategies in multiple environments -Raw data from experiments. figshare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Stojić</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Olsson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Speekenbrink</surname></persName>
		</author>
		<idno type="DOI">10.6084/m9.figshare.1585822</idno>
		<imprint>
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Précis of Simple heuristics that make us smart</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">M</forename><surname>Todd</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Behavioral and Brain Sciences</title>
		<imprint>
			<biblScope unit="volume">23</biblScope>
			<biblScope unit="page" from="727" to="780" />
			<date type="published" when="2000" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<analytic>
		<title level="a" type="main">The mapping model: a cognitive theory of quantitative estimation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Von Helversen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Rieskamp</surname></persName>
		</author>
		<idno>doi: 10.1037/ 0096-3445.137.1.73</idno>
	</analytic>
	<monogr>
		<title level="j">Journal of Experimental Psychology: General</title>
		<imprint>
			<biblScope unit="volume">137</biblScope>
			<biblScope unit="page" from="73" to="96" />
			<date type="published" when="2008" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">AIC model selection using Akaike weights</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E.-J</forename><surname>Wagenmakers</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Farrell</surname></persName>
		</author>
		<idno type="DOI">10.3758/BF03206482</idno>
	</analytic>
	<monogr>
		<title level="j">Psychonomic Bulletin &amp; Review</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="page" from="192" to="196" />
			<date type="published" when="2004" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">Reshaping Data with the reshape Package</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Statistical Software</title>
		<imprint>
			<biblScope unit="volume">21</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="1" to="20" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<monogr>
		<title level="m" type="main">ggplot2: elegant graphics for data analysis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2009" />
			<publisher>Springer</publisher>
			<pubPlace>New York</pubPlace>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<monogr>
		<title level="m" type="main">dplyr: A Grammar of Data Manipulation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Wickham</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Francois</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=dplyr" />
		<imprint>
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<monogr>
		<title level="m" type="main">fOptions: Basics of Option Valuation</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wuertz</surname></persName>
		</author>
		<ptr target="http://cran.r-project.org/package=fOptions" />
		<imprint>
			<date type="published" when="2013" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
