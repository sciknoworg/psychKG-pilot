<?xml version="1.0" encoding="UTF-8"?>
<TEI xml:space="preserve" xmlns="http://www.tei-c.org/ns/1.0" 
xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" 
xsi:schemaLocation="http://www.tei-c.org/ns/1.0 /opt/grobid/grobid-home/schemas/xsd/Grobid.xsd"
 xmlns:xlink="http://www.w3.org/1999/xlink">
	<teiHeader xml:lang="en">
		<fileDesc>
			<titleStmt>
				<title level="a" type="main">The Inherited Bias Effect: the propagation of artificial intelligence biases to human decisions</title>
			</titleStmt>
			<publicationStmt>
				<publisher/>
				<availability status="unknown"><licence/></availability>
			</publicationStmt>
			<sourceDesc>
				<biblStruct>
					<analytic>
						<author>
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Lucía</forename><surname>Vicente</surname></persName>
						</author>
						<author role="corresp">
							<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Helena</forename><surname>Matute</surname></persName>
							<email>matute@deusto.es</email>
						</author>
						<author>
							<affiliation key="aff0">
								<orgName type="department">Department of Psychology</orgName>
								<orgName type="institution">Deusto University</orgName>
								<address>
									<settlement>Bilbao</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff1">
								<orgName type="department">Departamento de Psicología, Universidad de Deusto</orgName>
								<address>
									<addrLine>Avenida Universidades, 24</addrLine>
									<postCode>48007</postCode>
									<settlement>Bilbao</settlement>
									<country key="ES">Spain</country>
								</address>
							</affiliation>
						</author>
						<author>
							<affiliation key="aff2">
								<orgName type="institution">Lucía</orgName>
								<address>
									<addrLine>Vicente https://orcid.org/0000-0003-2769</addrLine>
									<postCode>5028</postCode>
									<settlement>Helena Matute</settlement>
								</address>
							</affiliation>
						</author>
						<title level="a" type="main">The Inherited Bias Effect: the propagation of artificial intelligence biases to human decisions</title>
					</analytic>
					<monogr>
						<imprint>
							<date/>
						</imprint>
					</monogr>
					<idno type="DOI">10.13039/501100011033</idno>
				</biblStruct>
			</sourceDesc>
		</fileDesc>
		<encodingDesc>
			<appInfo>
				<application version="0.6.1" ident="GROBID" when="2025-06-29T13:00+0000">
					<desc>GROBID - A machine learning software for extracting information from scholarly documents</desc>
					<ref target="https://github.com/kermitt2/grobid"/>
				</application>
			</appInfo>
		</encodingDesc>
		<profileDesc>
			<textClass>
				<keywords>
					<term>Author contributions statement: L.V.: Conceptualization</term>
					<term>Methodology</term>
					<term>Formal analysis</term>
					<term>Software</term>
					<term>Visualization</term>
					<term>Writing-original draft</term>
					<term>Writing-review &amp; editing. H.M.: Conceptualization</term>
					<term>Methodology</term>
					<term>Supervising</term>
					<term>Writing-review &amp; editing Artificial intelligence</term>
					<term>decision support systems</term>
					<term>bias</term>
					<term>human-AI interaction</term>
					<term>health</term>
					<term>decision-making</term>
					<term>diagnosis</term>
					<term>HCI</term>
				</keywords>
			</textClass>
			<abstract>
				<p>Artificial intelligence recommendations are sometimes erroneous and biased. In our research, we hypothesized that people who perform a (simulated) medical diagnostic task assisted by a biased AI system will reproduce the system&apos;s bias in their own decisions, even when they move to a context without AI support. In three experiments, participants completed a medical-themed classification task with or without the help of a biased AI system. The biased recommendations by the AI influenced participants&apos; decisions. Moreover, when those participants, assisted by the AI, moved on to perform the task without assistance, they made the same errors as the AI had made during the previous phase. Thus, participants&apos; responses mimicked AI bias even when the AI was no longer making suggestions. These results provide evidence of human inheritance of AI bias.</p>
			</abstract>
		</profileDesc>
	</teiHeader>
	<text xml:lang="en">
		<body>
<div xmlns="http://www.tei-c.org/ns/1.0"><p>Over the last decades, the number of tools based on artificial intelligence (AI) designed to assist human decisions has increased in many professional fields such as justice <ref type="bibr" target="#b38">(Green &amp; Chen, 2019;</ref><ref type="bibr" target="#b97">Valdivia et al., 2022)</ref>, personnel selection <ref type="bibr" target="#b51">(Kupfer et al., 2023;</ref><ref type="bibr" target="#b53">Lacroux &amp; Martin-Lacroux, 2022</ref>) and healthcare <ref type="bibr" target="#b2">(Adlung et al., 2021;</ref><ref type="bibr" target="#b27">Esteva et al., 2019;</ref><ref type="bibr" target="#b93">Topol, 2019;</ref><ref type="bibr" target="#b99">Yu et al., 2018)</ref>. In the medical realm, the advent of AI-based decision support systems has been welcomed as a promise to minimize errors in human decision-making <ref type="bibr" target="#b32">(Garcia-Vidal et al., 2019;</ref><ref type="bibr" target="#b41">Hinton, 2018;</ref><ref type="bibr" target="#b60">Loftus et al., 2020;</ref><ref type="bibr" target="#b84">Shortliffe &amp; Sepúlveda, 2018)</ref>.</p><p>Such optimism is founded on the impressive precision that artificial intelligence has reached in some clinical tasks such as image-based diagnostics, predicting the outcomes of interventions, or recommending treatments <ref type="bibr" target="#b27">(Esteva et al., 2019;</ref><ref type="bibr" target="#b39">Gulshan et al., 2016;</ref><ref type="bibr" target="#b78">Rajpurkar et al., 2022)</ref>. Thus, AI tools can help health professionals in, for example, diagnosis and triage tasks <ref type="bibr" target="#b64">(Lyell et al., 2021)</ref> by offering them specific and quite accurate data-driven recommendations <ref type="bibr" target="#b43">(Hollister &amp; Bonham, 2018;</ref><ref type="bibr">Sutton et al., 2020)</ref>. This cooperation between natural and artificial intelligence is hoped to augment clinicians' knowledge and capabilities, as well as compensate for some of the weaknesses of their human minds, such as cognitive biases <ref type="bibr" target="#b8">(Berthet, 2022;</ref><ref type="bibr" target="#b10">Blumenthal-Barby &amp; Krieger, 2015;</ref><ref type="bibr" target="#b22">Croskerry et al., 2023;</ref><ref type="bibr" target="#b82">Saposnik et al., 2016)</ref> and vulnerability to fatigue <ref type="bibr" target="#b58">(Linder et al., 2014;</ref><ref type="bibr" target="#b71">Neprash &amp; Barnett, 2019)</ref>, and therefore reduce diagnostic errors, improving clinical decisions <ref type="bibr" target="#b49">(Kahneman et al., 2021)</ref>. But these AI tools are not free of errors and biases themselves.</p><p>Despite their promising benefits, the introduction of AI-based decision support systems in clinical contexts has also raised concerns about the peril of using biased AI to assist medical decisions <ref type="bibr" target="#b18">(Cho, 2021;</ref><ref type="bibr" target="#b72">Norori et al., 2021;</ref><ref type="bibr" target="#b77">Parikh et al., 2019)</ref>. People tend to perceive artificial intelligence algorithms as objective, secure <ref type="bibr" target="#b86">(Sundar &amp; Kim, 2019</ref>) and impartial <ref type="bibr" target="#b20">(Claudy et al., 2022)</ref>, but AI algorithms are a product of human design, so they often inherit our mistakes and biases <ref type="bibr" target="#b31">(Fry, 2018;</ref><ref type="bibr" target="#b74">O'Neil, 2016)</ref>.</p><p>Although AI-based tools have proven to be quite accurate, their performance is far from perfect and most of them still need to be validated in real-world settings <ref type="bibr" target="#b93">(Topol, 2019)</ref>.</p><p>Thus, while AI can help to overcome some of the limitations of human reasoning, other new problems may arise in the human-AI interaction <ref type="bibr" target="#b79">(Rastogi et al., 2022)</ref>. Biased AI systems could sometimes diminish rather than augment the correctness of clinical decisions in that collaborative AI-human decision-making <ref type="bibr" target="#b44">(Howard et al., 2020;</ref><ref type="bibr" target="#b55">Lai et al., 2021)</ref>.</p><p>Bias in an algorithm is defined as a systematic error in its outputs or processes <ref type="bibr" target="#b29">(Fletcher et al., 2021;</ref><ref type="bibr" target="#b68">Mehrabi et al., 2021)</ref>. One important potential source of bias in AI systems is biases or imbalances in the data used to train the algorithms <ref type="bibr" target="#b23">(Danks &amp; London, 2017;</ref><ref type="bibr" target="#b68">Mehrabi et al., 2021;</ref><ref type="bibr" target="#b72">Norori et al., 2021;</ref>. AI algorithms identify patterns and generate predictions based on historical data (i.e. what happened in the past). High-quality data sets used to feed the algorithms are difficult to obtain <ref type="bibr" target="#b2">(Adlung et al., 2021)</ref>, especially when they pertain to clinical data <ref type="bibr" target="#b98">(Wiens et al., 2019)</ref>. Consequently, if a given data set contains imbalances or biases <ref type="bibr" target="#b56">(Larrazabal et al., 2020)</ref>, the AI systems trained with these data will learn and potentially reproduce those biases <ref type="bibr" target="#b75">(Obermeyer &amp; Mullainathan, 2019)</ref>.</p><p>In the healthcare area, the data used to train the algorithms is usually a product of past human decisions, for example, medical decisions about what kind of patient requires a certain test or what kind of patient would benefit more from a given treatment. When the historical record of these choices shows an extended systematic error such as, for instance, a misdiagnosis of a certain pathology in young patients, the AI system trained with such historical data will simply inherit this error <ref type="bibr">(Obermeyer &amp; Lee, 2017)</ref>. It is relevant to note the technical nature of AI bias, as it is, in essence, a mathematical or statistical artefact. However, AI bias can result in discrimination or prejudice towards a person or group of people (High-Level Expert Group on AI, 2019) since the patterns embedded in the historical data often reflect systematic social and economic inequities. When an artificial intelligence system is trained with data that does not represent the diversity of the reality and population groups to which an AI tool is to be applied <ref type="bibr" target="#b56">(Larrazabal et al., 2020)</ref>, the model will produce undesirable effects due to the difficulty in generalising its predictions to social groups or environments with characteristics underrepresented in that databases <ref type="bibr" target="#b15">(Buolamwini &amp; Gebru, 2018;</ref><ref type="bibr" target="#b24">DeCamp &amp; Lindvall, 2020)</ref>. As a consequence, AI recommendations may exhibit systematic errors such as, for example, under-diagnosis in historically underservedpatient populations, such as patients of low socioeconomic status, female patients or Black and Hispanic patients <ref type="bibr" target="#b83">(Seyyed-Kalantari et al., 2021)</ref>.</p><p>In high-stakes areas such as healthcare, clinicians assume the responsibility and accountability for the decisions of the AI-human team (European Commission, 2021).</p><p>Thus, they are expected to supervise the outcomes of their artificial counterparts. Since there is a risk of bias (i.e., systematic errors) in the recommendations of AI-based decision support systems, health professionals should interpret AI advice as just an additional piece of evidence to help them in the decision-making process. Hence, they need to critically supervise and decide whether the AI advice is correct or useful for each decision <ref type="bibr" target="#b89">(Suresh et al., 2020)</ref> Some evidence has pointed out that this effective oversight and control of AI by humans could be possible <ref type="bibr" target="#b81">(Reverberi et al., 2022;</ref><ref type="bibr" target="#b85">Solans et al., 2022;</ref><ref type="bibr" target="#b95">Tschandl et al., 2020)</ref>, while another corpus of research has documented an excessive trust towards AI recommendations, which calls into question the ability of humans to exercise a good supervision of algorithmic outcomes <ref type="bibr" target="#b11">(Bogert et al., 2022;</ref><ref type="bibr" target="#b62">Logg et al., 2019;</ref><ref type="bibr" target="#b80">Rebitschek et al., 2021)</ref>. The tendency to over-rely on artificial intelligence can lead to humans uncritically adhering to AI recommendations, even incorrect ones <ref type="bibr" target="#b36">(Goddard et al., 2012</ref><ref type="bibr" target="#b37">(Goddard et al., , 2014</ref><ref type="bibr" target="#b89">Suresh et al., 2020)</ref>.</p><p>Human over-reliance on AI advice seems to be modulated by the context and the characteristics of the task (e.g., subjective vs objective) in which AI and humans collaborate <ref type="bibr" target="#b3">(Agudo &amp; Matute, 2021;</ref><ref type="bibr" target="#b16">Castelo et al., 2019;</ref><ref type="bibr" target="#b19">Chong et al., 2023;</ref><ref type="bibr" target="#b40">Himmelstein &amp; Budescu, 2023;</ref><ref type="bibr" target="#b57">Lee, 2018)</ref>. In the clinical context, algorithmic advice is usually seen as trustworthy because artificial intelligence is perceived as accurate in objective and analytical tasks <ref type="bibr" target="#b5">(Araujo et al., 2020;</ref><ref type="bibr" target="#b16">Castelo et al., 2019;</ref><ref type="bibr" target="#b62">Logg et al., 2019)</ref>, and these are the ones that are common in the medical domain, such as diagnosis and image classification. Thus, there are reasons to believe that decision-making in a health context could be particularly vulnerable to human over-reliance on AI advice, and therefore humans could tend to accept the recommendations of AI algorithms even when they are noticeably biased or erroneous.</p><p>There is some evidence that incorrect AI recommendations can have a detrimental influence on clinicians ' decision-making <ref type="bibr" target="#b25">(Dratsch et al., 2023;</ref><ref type="bibr" target="#b34">Gaube et al., 2021;</ref><ref type="bibr" target="#b67">Lyell et al., 2017</ref><ref type="bibr" target="#b66">Lyell et al., , 2018</ref>. As an example, a recent study showed that when prescribing antidepressants in different scenarios, incorrect AI recommendations led to a reduction in the accuracy of the clinician's decisions in comparison to a baseline and a correct advice condition <ref type="bibr" target="#b47">(Jacobs et al., 2021)</ref>. These results suggest that occasional mistakes in the AI recommendations can make people err, but our main concern refers to the presence of systematic biases in AI systems and to the potential of humans to perpetuate those biases. Thus, it is necessary to explore how humans react to systematic errors in AI advice, because AI bias may have a more profound impact on human behaviour than occasional and random errors. To our knowledge, very few investigations have addressed the effect of biased artificial intelligence systems on human behaviour <ref type="bibr" target="#b85">(Solans et al., 2022)</ref>, and even fewer studies have focused, specifically, on the impact of algorithmic bias on human decisions in a clinical context. The present research aims to answer two main questions. The first one is whether biased recommendations of an AI system can influence human behaviour, specifically decision-making, in a medical context. The recent study of Adam et al. <ref type="bibr" target="#b0">(Adam et al., 2022)</ref> represented an interesting starting point to this problem since they directly explored the influence of biased recommendations of an algorithm on the human response to mental health emergencies. These authors reported that the biased recommendations strongly influenced the decisions of experts and non-experts on how to respond to a crisis, while the decisions of participants without the advice of the algorithm were unbiased. In addition, we believe that to fully explore the potential impact of AI biases on human behaviour, it is also necessary to answer a second question. This question is whether, after the interaction with a biased AI system, people would reproduce those biases in their own decisions when they move on to a context without their artificial partner. The reader should consider the following scenario: given the case of a group of people accustomed to performing a specific task with the suggestions of a biased AI-based decision support system, is there a risk that the system's biased recommendations will exert a training effect such that people will reproduce the AI bias when making decisions on their own? Could the system influence the behaviour of these people so that they inherit the AI bias, even in a context without AI recommendations?</p><p>The potential inheritance of AI bias and its propagation through human decisions is a phenomenon that remains unexplored. The current research aims to examine how biased AI recommendations can influence people's decision-making in a health-related task and to test whether the impact of the biased advice on human behaviour extends beyond the phase in which the AI recommendations are explicitly present. That is, we will explore whether human decision-makers can inherit the bias of an artificial intelligence system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Overview of the experiments</head><p>In a series of three experiments, we empirically tested whether (a) people follow the biased recommendations offered by an AI system, even if this advice is noticeably erroneous sometimes (Experiment 1); (b) people who have performed a task assisted by the biased recommendations will reproduce the same type of errors than the system when they have to do the same task without assistance, showing an inherited bias (Experiment 2); and (c) performing a task first without assistance will prevent people from following the biased recommendations of an AI and, thus, from committing the same errors, when they later perform the same task assisted by a biased AI system.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 1</head><p>The first experiment tested the influence of explicitly biased recommendations made by a fictitious AI system on participants' behaviour using a classification task with a medical-themed story: a simulation of an image-based diagnosis.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Ethics statement</head><p>The Ethical Review Board of the University of Deusto reviewed and approved the methodology reported in this article and the experiments were conducted according the approved guidelines. Informed consent was obtained from all participants. Due to ethical considerations, as well as to prevent the influence of prior knowledge and beliefs on experiments' results, the clinical context, the classification task, the artificial intelligence system and its recommendations, the tissue sample images, patients and syndromes used in these experiments, were all fictitious.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A group of 169 Psychology students took part in the experiment (73.6% female, 20.7% male, 2.4% non-binary, mean age = 18.4, SD = 0.79). Their participation was anonymous and we did not ask for any personal data other than age and gender.</p><p>Participants were randomly assigned to either one of two groups, assisted by AI (n = 85) and unassisted (n = 84). The post hoc sensitivity analysis showed that, with this sample size, we obtained a power of 0.80 to detect a size effect of d = 0.38 or higher in a test of difference between two independent means.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Procedure</head><p>In the three experiments we used the same experimental task: a classification task framed in a fictitious health context. With this procedure we tried to simulate a clinical decision-making process that was assisted by a biased AI system for some participants, while others performed the task without assistance.</p><p>The experimental task was constructed though Qualtrics, a platform that also facilitated the data collection. We wanted to simulate a clinical decision-making process with a medical diagnosis task that was simple to learn, but also challenging enough to require sustained attention. With this aim, we used the stimuli created by Blanco et al.</p><p>(2022) in their study related to causal illusion. Each stimulus consisted of a matrix of 50</p><p>x 50 pixels which represented a human tissue sample obtained from a given patient.</p><p>Each tissue sample contained 2500 cells of two colours (dark pink and light yellow) randomly distributed in the matrix space so that there were no two identical samples.</p><p>The proportion of dark and light cells in each tissue sample was variable, so we created a large set of different stimuli with varying levels of discrimination difficulty. The different proportions of dark and light cells for different stimuli were 80/20, 70/30, 60/40, 40/60, 30/70, and 20/80.</p><p>In the classification task, participants were instructed to observe a series of tissue samples, to decide, for each sample, whether it was affected or not by a fictitious disease called Lindsay Syndrome. Each tissue sample had cells of two colours, but one of them was presented in a greater proportion and volunteers were instructed to follow this criterion to identify the presence of the syndrome. A greater proportion of dark than light cells was described in the instructions as "Positive", that is, affected by the Lindsay Syndrome. If the tissue sample had a greater proportion of light than dark cells, then it should be classified as a "Negative" because it was not affected by the syndrome.</p><p>It is important to note that the assignment of dark and light colours to the positive/negative categories was randomly decided for each participant (in this section we will describe only one of the two possible assignments for simplicity, but the reader should bear in mind that half of the participants viewed the opposite one).</p><p>To ensure that all participants correctly understood the instructions the experiment begun with a practice phase in which participants categorised six tissue samples with different dark/light colours proportions. Each sample was presented twice, so that the practice phase consisted of two blocks of six stimuli, presented one per trial, that is 12 trials in total. In the first block, the six samples were presented in order of difficulty. In the second block, the same six samples were presented in random order. If participants did not get five correct classifications out of six trials in the second block, they had to repeat all the practice phase.</p><p>Once the volunteers finished the practice phase, they were randomly distributed into two groups, AI-assisted and unassisted. The design of the experiments is summarized in <ref type="table" target="#tab_0">Table 1</ref>. The task of the participants was to classify a series of 60 tissue samples following the criteria they had just learned in the previous phase. In the AI-assisted group, in each trial, the tissue sample and the AI recommendation were presented simultaneously. The recommendation had the form of an orange label with the text "POSITIVE +", or a blue label with the text "NEGATIVE -", placed above the tissue sample. In the unassisted group, only the tissue sample was presented in each trial. Both groups viewed the same stimuli, the only difference between them was the presence or absence of the advice of the fictitious AI. The sequence of trials included ten stimuli (i.e., tissue samples) of each of the dark/light cell proportions, that is, 80/20, 70/30, 60/40, 40/60, 30/70 and 20/80, resulting in a total of 60 stimuli. <ref type="figure">Figure 1</ref> shows some examples of trials in both the unassisted and the AI-assisted groups.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 1</head><p>Screenshots showing examples of trials in the unassisted (top) and <ref type="bibr">AI-assisted conditions (bottom)</ref>.</p><p>The AI of our experiment was quite reliable because it correctly classified 50 tissue samples out of 60, which corresponded to approximately 80% correct classifications. However, the AI showed a bias that consisted on a systematic error in the recommendations on the 10 stimuli with the proportion of dark/light cells 40/60. In these samples, there was a contradiction between the evidence (i.e., number of dark/light cells in the tissue) and the recommendation given by the AI. For example, following the instructions, the 40/60 tissue samples had a greater number of light cells so they should be classified as negative, however, the recommendation given by the AI for the 40/60 samples was positive.</p><p>The order of the stimuli was randomly assigned to the sequence of 60 trials, with one exception: the stimulus 40/60, where the AI recommendation was erroneous, did not appear during the first 10 trials of the sequence of 60 trials. This manipulation tried to keep certain level of trust in the AI system before the problematic stimuli showed up.</p><p>We wanted the AI bias not to be so evident from the beginning of the task. The 40/60 stimulus did appear in the sequence of the next 50 trials, randomly intermixed with the stimulus of other proportions.</p><p>After the classification task was finished, we asked participants, as a manipulation check, whether the AI algorithm had been offered them recommendations during the task. Volunteers then answered, on a Likert scale from 1 (not at all) to 9</p><p>(completely), a series of questions about their own performance on the task, about their trust on the artificial intelligence used in this experiment, and about their trust in artificial intelligence in the area of health, in general.</p><p>The main dependent variable in our experiment was the number of misclassifications of the ten 40/60 tissue samples of the task. Although the stimulus 40/60 was more difficult to classify than others, its discrimination was clear, and it was possible to detect the AI mistakes easily so, we expected the unassisted group to classify them correctly. However, since the AI showed a rather high reliability, we expected volunteers in the group assisted by the biased AI to get used to performing the task following the AI recommendations and without careful examination of the tissue sample. As a result, the AI-assisted group would misclassify more often the 40/60 stimuli, where the recommendations were erroneous, than the unassisted group.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Data selection criteria</head><p>If participants failed to reach the threshold of five correct classifications out of six trials in the second attempt of the practice phase, their data were excluded from the analyses. In addition, data from participants who misclassified tissue samples on more than half of the trials of the first phase of the classification task (i.e., more than 30 trials out of 60), were excluded from the analyses, as they were, presumably, paying little attention.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 2</head><p>Mean number of misclassifications of the 40/60 stimuli in the AI-assisted group and the unassisted group.</p><p>Note. Error bars represent 95% CI.</p><p>As expected, participants who performed the task assisted by a biased AI made more errors than unassisted participants (see <ref type="figure">Figure 2</ref>). The mean number of misclassifications of the 40/60 trials was 2.21 (SD = 3.17) in group AI-assisted, and 0.69 (SD = 1.83) in the unassisted group. This difference was significant, t(167) = 3.81, p &lt;.001, d = 0.586 . These results showed that the explicit recommendations of a biased On average, participants though they had performed the task fairly well and showed a moderate trust in AI in the area of health. In the AI-assisted group we found a positive correlation between participants' incorrect classifications of the 40/60 samples and how helpful they considered the AI of the experiment to be, r = .544, p &lt;.001, the accuracy they attributed to the AI recommendations in the task, r = .563, p &lt;.001, and their confidence in AI in the health domain in general, r = .470, p &lt;.001.</p><p>These results evidenced human compliance with the AI recommendations during a decision-making process. A large part of participants from the AI-assisted group reproduced the AI bias in their own responses to the medical task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 2</head><p>The purpose of Experiment 2 was (a) to replicate the observation of Experiment 1 that a biased AI can influence human decision-making, (b) to test whether such influence persists when the AI is no longer present, and (c) to test whether this influence generalizes to novel stimuli as well. Additionally, we now also measured and analysed changes in the participants' behaviour over the sequence of trials during the classification task.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>The final sample included 199 participants (65.3% female, 30.7% male, 4% nonbinary, mean age = 26.2, SD = 6.95). We initially recruited 200 participants through Prolific Academic, but data from one participant was excluded due to the data exclusion criteria described in Experiment 1. Participation in the experiment was offered only to those applicants in Prolific Academic's pool who speak English fluently and had not participated in previous experiments from our research team. Volunteers were randomly distributed between two groups, AI-assisted (n = 100) and unassisted (n = 99). A sensitivity analysis showed that, with this sample size, we obtained a power of 0.80 to detect a small-sized effect (f= 0.09) for a repeated measures ANOVA with withinbetween interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Procedure</head><p>The procedure was similar to that of Experiment 1. The practice phase and the classification task with 60 trials were identical to those of the previous experiment. The only difference during the 60 trials phase was that in Experiment 2 the order of appearance of each stimulus was randomly assigned to a fixed position in the 60-trial sequence of the task. The creation of this fixed randomised sequence ensured that all participants viewed each stimulus in the same position through the task which facilitated the measurement of changes in the behaviour of both groups and its comparison, with particular attention to participants' responses to those trials where the AI recommendation was erroneous.</p><p>The main novelty in Experiment 2, with respect to Experiment 1, was the addition of a second phase of 25 trials in which both groups had to sort the tissue samples without assistance (see <ref type="table" target="#tab_0">Table 1</ref>). That is, participants in the unassisted group continued performing the task as in the previous phase, while AI-assisted participants switched to performing the task without assistance. An additional feature of this second phase was the introduction of five trials of novel and ambiguous stimuli with a dark/light cell ratio of 50/50, so that it was not possible to assign these stimuli to either one of the two categories, positive or negative, based on the instructions received or on specific recommendations of the AI during the previous phase. Thus, for this second phase, we expected that participants in the AI-assisted group would tend to classify both the 40/60 and the 50/50 samples in the same category as the AI biased recommendation suggested for the 40/60 stimuli in the previous phase. By contrast, we expected participants in the non-assisted group to classify correctly the 40/60 stimuli and to classify the 50/50 ambiguous stimuli randomly. We would interpret these results as an inheritance of the bias. Thereby, the purpose of this experiment is not only to reproduce but also to extend the results of Experiment 1, showing that biased AI recommendations may influence participants' behaviour even when the AI is no longer present and even in novel conditions. Also, in this phase, stimuli with the dark/light cell ratio 80/20 and 20/80 were not included in the classification task, because we considered them too easy and we were mainly interested in participants' classification of the 40/60 and 50/50 stimuli.</p><p>Thus, the second phase of the task consisted on five stimuli of each of the 70/30, 60/40, 50/50, 40/60, and 30/70 proportions, resulting in 25 trials. The order of appearance of each trial was randomly assigned to a fixed position in the 25-trial sequence of the task.</p><p>We measured an additional dependent variable in this phase: the number of times each participant classified the five 50/50 stimuli in the same direction as the bias of the AI recommendations. We named this variable as biased classifications.</p><p>At the end of the classification task, participants answered the same postexperimental questions as in Experiment 1. In the present Experiment 2, we added two questions to ask volunteers directly whether they based their answers on the recommendations and whether they detected any errors in the AI recommendations.</p><p>Experiment 2 was preregistered at https://aspredicted.org/CJG_ZLN</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Results and Discussion</head><p>As expected, the AI-assisted group made more errors in the classification of the 40/60 stimuli in both phases of the task, than the unassisted group. Importantly, even in Phase 2, that both groups performed without the support of AI recommendations, the AI-assisted group committed significantly more misclassifications than the unassisted group (see <ref type="figure">Figure 3)</ref>. These impressions were confirmed by a mixed ANOVA 3 (Block)</p><p>x 2 (Group) that showed a main effect of Group, F (1,197) = 41.3, p &lt;. 001, η 2 p = .173, a main effect of Block, F (2,394) = 25.3, p &lt;. 001, η 2 p = .114, and a Group x Block, interaction F (2,394) = 17.4, p &lt;. 001, η 2 p = .081.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 3</head><p>Mean number of misclassifications of the 40/60 stimuli in the AI-assisted group and the unassisted group along the task.</p><p>Note. The 40/60 trials of the task were divided into three blocks: the ten 40/60-stimuli trials of the first phase of the task were divided into two blocks of five trials each, resulting in Block 1 and 2, and the five 40/60-stimuli trials of the third phase of the task formed Block 3. Error bars represent 95% CI.</p><p>Within group post-hoc comparisons, with Tukey correction, showed an increase in the 40/60 misclassifications in the AI-assisted group between Block 1 and Block 2, t(197) = -4.657, pt &lt; .001, as well as a decrease between Block 2 and Block 3, in which this group no longer had the AI recommendations, t(197) = 8.87, pt &lt; .001. In this last phase, although none of the two groups were assisted by the biased AI, there was still a significant difference between them t(197) = 3.66, pt = .004, the AI-assisted group did not reduce their errors enough to reach the performance of the non-assisted group.</p><p>One of the main novelties of the second phase of Experiment 2 was the addition of five tissue samples with a 50/50 dark/light cell proportion. Since neither of the groups received instructions or AI recommendations on how to classify these stimuli, we expected the AI-assisted group to classify the ambiguous novel 50/50 stimuli in the same direction as the AI bias from the previous phase. An independent samples t-test showed that the AI-assisted group made more biased classifications of the 50/50 samples, M = 2.91, SD = 2.13, than the unassisted group, M = 2.15, SD = 2.02, with a small but significant difference between the groups, t(197) = 2.58, p = .011, d = 0.366. This suggest that the inherited bias is not constrained to the stimuli where the AI made errors, but can also generalize to novel stimuli that had not been seen before and had not received any previous AI recommendation.</p><p>Regarding the post-experimental questions, 58% of participants from the AIassisted group detected errors in the IA advice. Moreover, similar to Experiment 1, participants who made more errors in the classification task also found the AI of our experiment more helpful, r = .638, p &lt; .001, perceived it to be more accurate, r = .612, p &lt; .001, and trusted more, in general, in the usefulness of AI in the health context, r = .492, p &lt; .001.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Experiment 3</head><p>Experiment 3 tried to replicate the bias inheritance effect observed in Experiment 2 for the IA-assisted group in the 40/60 and 50/50 stimuli during the nonassisted phase. In addition, we sought to extend the results of the previous experiments by analysing the effect of the order in which the AI-assisted phase takes place. We hypothesised that performing the classification task without assistance first, could have a protective effect against the biased recommendations when participants switched to performing the task assisted by the misleading AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Method</head></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Participants</head><p>A group of 197 participants (49.2% male, 47.7 % female, 3% non-binary, mean age = 27.1, SD = 8.28) from Prolific Academic took part in the experiment (initially we recruited 200 participants but data from three of them were excluded following the data exclusion criteria described in Experiment 1). Participation in the experiment was offered only to those applicants in Prolific Academic's pool who speak English fluently and had not taken part in previous studies carried out by our research team. Volunteers were randomly assigned to groups AI-assisted → unassisted (n = 98) and unassisted → AI-assisted (n = 99). A sensitivity analysis showed that, with this sample size, we obtained a power of 0.80 to detect a small-sized effect (f = 0.08) for a repeated measures ANOVA with within-between interaction.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Materials and Procedure</head><p>The main difference on the design of Experiment 3 with the previous experiments is that all participants went through both experimental conditions, that is assisted by the biased AI recommendations and unassisted, but in different order (see <ref type="table" target="#tab_0">Table 1</ref>). Thus, the procedure of Experiment 3 was similar to that of the previous experiments, but with some modifications to adapt it to the design of the present experiment. Specifically, a change in the number of trials in Phase 1 and Phase 2, and some slight adjustments in the task instructions were necessary.</p><p>In Experiment 3, each of the two phases of the task had 40 trials. <ref type="table">Table 2 depicts</ref> the number of trials of each type of stimuli for the AI-assisted and the unassisted phases of the task. The ten 40/60 stimuli appeared intermixed with stimuli of other proportions as in the previous experiments. The order of trials within each phase was random and identical for both groups, but in neither case did the 40/60 stimulus appear among the first five trials of the sequence. The unassisted phase of the task was characterised by the inclusion of five ambiguous stimuli (see <ref type="table">Table 2</ref>).</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Table 2</head><p>Number of trials for each type of tissue sample of different dark/light cells proportions from the AI-assisted and unassisted phases of the task. Given that all participants were assisted by the AI in one phase of the task, but were unassisted in another phase, the task instructions and screens explicitly informed participants when the AI system was connected and gave them recommendations, and when the AI was off, so that they had to perform the task without assistance. In Experiment 3 two images were included to emphasise this information.</p><p>The post-experimental questions in Experiment 3 were the same as in Experiment 2, but we made a modification to the question about whether the AI had been on and specified that we were referring to whether it had been connected at any point throughout the task. We thought that this specification was necessary because the group AI-assisted → unassisted might have interpreted that this question referred only to the last part of the task. Experiment 3 was preregistered in https://aspredicted.org/8JS_FMS</p><p>Results and Discussion</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Figure 4</head><p>Mean of misclassifications of the 40/60 stimuli in the AI-assisted→ unassisted group and the unassisted→ AI-assisted group along the task.</p><p>Note. The ten 40/60 trials of Phase 1 were divided into two blocks, Block 1 and 2, of five trials each. The same procedure was followed with the ten 40/60 trials of Phase 2, that were also divided in two blocks of five trials, Block 3 and 4. In total, we created four blocks of five 40/60 trials each. Error bars represent 95%</p><p>The group that completed the first phase (i.e., Blocks 1 and 2) assisted by the biased AI made more errors in 40/60 trials than group unassisted. Interestingly, when there was a change in task conditions between Blocks 2 and 3, we observed an increase in 40/60 misclassifications for the unassisted → AI-assisted group, but did not observe an opposite trajectory for the AI-assisted → unassisted group. When this group transited from the AI-assisted to the unassisted phase, its mean number of errors in 40/60 trials was not reduced. During the second phase (i.e., Blocks 3 and 4) both groups committed a similar number of errors, although in this second phase the unassisted → AI-assisted group received biased recommendations from the AI and the AI-assisted → unassisted group did not. Thus, the group of participants who completed Blocks 1 and 2, assisted by the AI recommendations exhibited the same errors as the AI system when, during the next phase, in Blocks 3 and 4, they had to perform the task without guidance (see <ref type="figure">Figure   4</ref>).</p><p>These impressions were confirmed by a mixed ANOVA 3 (Block) x 2 (Group) that showed a main effect of Group, F (1,195) = 7.59, p = .006, ⴄ 2 p = .037, a main effect of Block F (1,585) = 26.0, p &lt; .001, ⴄ 2 p = .118, and a Group x Block interaction, F</p><p>(1,585) = 43.8, p &lt; .001, ⴄ 2 p = .183. For the unassisted → AI-assisted group, post-hoc comparisons (Tukey correction) confirmed an increase in 40/60 errors between Block 2</p><p>and Block 3, t(195) = 8.75, p &lt; .001, when this group switched to performing the task with the AI assistance. Conversely, for the AI-assisted → unassisted group an increase in 40/60 errors was detected between Block 1 and Block 2, t(195) = -4.05, p = .002, during the AI-assisted phase of the task, but no differences were observed between the other blocks. So, there was not a significant decrease in the number of 40/60 misclassifications for this group when they switched from Block 2 to Block 3, that is, to the phase without AI recommendations, t(195) = 2.86, p = .085. This suggests that the responses of the AI-assisted → unassisted group reproduced the systematic errors of the AI recommendations during the unassisted phase, a result that supports the inheritance bias effect.</p><p>Similarly, the mean number of biased classifications of the 50/50 ambiguous stimuli during the unassisted phase in the AI-assisted → unassisted group was 3.72 (SD = 2.02) and 2.65 (SD = 1.88) in the unassisted → AI-assisted group. This difference was significant, t(195) = -4.28, p &lt; .001, d = -.609. Both results replicated those observed in Experiment 2, and add support to the human inheritance of AI bias effect.</p><p>It is important to note that in this experiment 80.7% of participants detected mistakes in the AI recommendations. Although participants found that the AI was not entirely accurate, many of them still relied on the AI recommendations to perform the task. In contrast to previous experiments, in this experiment we did not observe a positive correlation between the number of 40/60 misclassifications and how much participants considered AI to be helpful, r = .051, p = .479, accurate, r = .055, p = .442, and reliable in the health domain, r = .083, p = .246. Thus, in this experiment, participants' responses seemed to be less influenced by their prior trust in AI.</p></div>
<div xmlns="http://www.tei-c.org/ns/1.0"><head>Discussion</head><p>Our results show that biased recommendations made by AI systems can adversely impact human decisions in professional fields such as healthcare. Moreover, they also show that such biased recommendations can influence human behaviour in the long term. Humans reproduce the same biases displayed by the AI, even time after the end of their collaboration with the biased system, and in response to novel stimuli.</p><p>Although this inheritance bias effect could have serious implications, to the best of our knowledge it had not yet been explored in any empirical research.</p><p>Intending to empirically test the potential effect of the human inheritance of the AI bias, we conducted three experiments. As we have hypothesized, the AI-assisted participants made more errors than the unassisted participants in the classification task, both during the AI-aided and non-aided phases, a result consistently observed over the three experiments. These results are robust: we obtained the same effect in a laboratory experiment conducted under controlled conditions with a sample of University students (Experiment 1) and in two online experiments with an international sample recruited via Prolific Academic (Experiment 2 and Experiment 3).</p><p>Importantly, Experiments 2 and 3 evidence that participants from the AI-assisted group still misclassified, specifically, the 40/60 stimulus in the non-aided phase of the task, meaning that their mistakes when performing the task by themselves mimicked the bias previously shown by the AI during the first phase. Moreover, we also observed a tendency in the AI-assisted group to categorize the new 50/50 stimuli during the unassisted phase in the same direction as the AI classified the 40/60 stimuli during the previous phase. We interpret that participants used the AI recommendations as a cue to categorise ambiguous stimuli, which could not be classified according to the classification criteria specified in the instructions.</p><p>In sum, we observed an inheritance effect of the AI biased recommendations from the first phase of the task on participants' responses during the second phase, where they were no longer supported by the AI. We believe that this is the most interesting and novel result of our present work because it shows an influence of AI bias on human decisions that extends beyond the stage and stimuli in which the AI recommendations are explicitly present. Thus, AI biases could have the potential to propagate through humanity. To our knowledge, this inheritance of the bias effect has not been previously revealed in any empirical research.</p><p>The presence of AI erroneous recommendations for the 40/60 samples resulted in the AI-assisted group misclassifying significantly more 40/60-samples than the group unassisted. In Experiments 2 and 3, we also analysed changes in participants' behaviour over the sequence of trials, and observed an increase in the number of 40/60 misclassifications throughout the AI-assisted phase. This result suggests that participants' monitoring of the information decreased and the tendency to rely on the AI recommendations to make their judgments increased as their experience with the AI increased. This could be due to fatigue but also to habituation and increased trust in the AI recommendations.</p><p>The "Negative" or "Positive" recommendation labels, in blue and orange colours, were probably more salient to participants' attention than the tissue samples that they had to classify, which were, in comparison, more complex. Thus, the tissue samples required effortful observation and processing to make a correct judgement about the presence (i.e., positive) or absence (i.e., negative) of the syndrome.</p><p>Recommendation labels provided by the AI could have interfered with the volunteers' assessment of tissue sample objective information <ref type="bibr" target="#b44">(Howard et al., 2020)</ref>. Volunteers may also have been reluctant to engage in a deep assessment of the reliability of each AI recommendation <ref type="bibr" target="#b13">(Buçinca et al., 2021)</ref> and, instead, they probably developed general rules about whether or not to follow AI suggestions, what diminished their ability to detect and correct the biased advice <ref type="bibr" target="#b54">(Lai &amp; Tan, 2019)</ref>.</p><p>During the unassisted phase of the task, we detected a reduction in the errors made by the AI-assisted group, but they still misclassified the 40/60 stimuli more than the unassisted group. This effect could have two possible interpretations: (a) a difficulty for participants in the AI-assisted group to regain control over the task because they had to change to slower and more conscious processing <ref type="bibr" target="#b48">(Kahneman, 2003)</ref> when they no longer had AI support <ref type="bibr" target="#b70">(Moulton et al., 2007)</ref> or (b) a training effect of the recommendations made by the AI on our participants' responses so that they learnt from the AI bias.</p><p>Regarding our first interpretation, if participants trusted AI recommendations to the detriment of analytic or effortful processing <ref type="bibr" target="#b13">(Buçinca et al., 2021;</ref><ref type="bibr" target="#b79">Rastogi et al., 2022)</ref> during Phase 1, then when they moved to Phase 2, and they needed to take complete control of the task, they would have needed some time to adjust to the new task demands and redirect attentional resources. It seems that, the transition from automated to controlled performance was slow, and participants were still heavily influenced by AI bias. The errors derived from this slow transition had no serious consequences in our experiments, but there are professional areas, such as healthcare,</p><p>where the consequences of decisions taken under the influence of an inherited bias could be fatal.</p><p>Concerning the second interpretation stated above, in Experiment 3, we did not observe a decrease in the errors made by the AI-assisted group in the transition from the AI-assisted to the unassisted phase. Maybe AI recommendations modelled participants' behaviours so that they learnt a new classification criterion based on the biased AI output. This could explain why the mean number of 40/60 misclassifications remained high in the context without the AI for the participants who had previously been supported by the biased AI in Experiment 3. If errors in the unassisted phase of the task were only due to difficulty in regaining control over the information processing, these errors should have been progressively reduced throughout successive trials of the task.</p><p>The results of our three experiments support a human over-reliance on the recommendations of AI systems <ref type="bibr" target="#b0">(Adam et al., 2022;</ref><ref type="bibr" target="#b47">Jacobs et al., 2021)</ref>, and add the new finding of the inherited bias effect. Human trust in automation influences the tendency to over-accept algorithmic outcomes <ref type="bibr" target="#b36">(Goddard et al., 2012</ref><ref type="bibr" target="#b37">(Goddard et al., , 2014</ref> even when they are noticeably wrong. This means that humans are not only willing to rely on AI because they are "cognitive misers", that take mental shortcuts when making decisions, but also because they perceive artificial intelligence to be trustworthy <ref type="bibr" target="#b5">(Araujo et al., 2020;</ref><ref type="bibr" target="#b50">Kool &amp; Botvinick, 2018)</ref>. It has been suggested that trust could induce compliance with AI advice due to an authority effect <ref type="bibr" target="#b6">(Baudel et al., 2020)</ref>. In Experiments 1 and 2, we detected that participants who perceived the AI of the experiment as more helpful and accurate, and trusted more in the usefulness of artificial intelligence in healthcare in general, were those who followed the AI recommendations more often, and committed more errors in the classifications task as revealed by the positive and significative correlations observed between the mean number of 40/60 misclassifications in the task and the participants' answers to the post-experimental questions.</p><p>As a limitation to our present work, it could be argued that our experimental task was a simulation of clinical decision-making with a fictitious diagnostic process and a fictitious artificial intelligence system. Although our experiments simplify a potential real-world setting, we believe that our controlled experimental task can help to analyse which basic psychological processes mediate on human-AI collaboration. We created a classification task with a low level of uncertainty, in which participants were provided with a clear classification criterion to perform the task, in which the error in the recommendations was systematic, controlled, and noticeable by the control participants, and in which prior expertise had no influence. These characteristics make our experimental task a fruitful method to study human reliance on AI algorithms and the potential inheritance of their biases.</p></div><figure xmlns="http://www.tei-c.org/ns/1.0" xml:id="fig_0"><head></head><label></label><figDesc>AI influenced participants' behaviour and increased the number of errors in a health framed task.</figDesc></figure>
<figure xmlns="http://www.tei-c.org/ns/1.0" type="table" xml:id="tab_0"><head>Table 1</head><label>1</label><figDesc>Design summary of the three experiments</figDesc><table><row><cell>Experiment</cell><cell>Group</cell><cell cols="2">Classification Task</cell></row><row><cell></cell><cell></cell><cell>Phase 1</cell><cell>Phase 2</cell></row><row><cell>Experiment 1</cell><cell>Assisted</cell><cell>AI-assisted</cell><cell>-</cell></row><row><cell></cell><cell>Unassisted</cell><cell>Unassisted</cell><cell>-</cell></row><row><cell>Experiment 2</cell><cell>Assisted</cell><cell>AI-assisted</cell><cell>Unassisted</cell></row><row><cell></cell><cell>Unassisted</cell><cell>Unassisted</cell><cell>Unassisted</cell></row><row><cell>Experiment 3</cell><cell>Assisted-Unassisted</cell><cell>AI-assisted</cell><cell>Unassisted</cell></row><row><cell></cell><cell>Unassisted-Assisted</cell><cell>Unassisted</cell><cell>AI-assisted</cell></row></table><note></note></figure>
		</body>
		<back>
			<div type="references">

				<listBibl>

<biblStruct xml:id="b0">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Adam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Balagopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Alsentzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Christia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b1">
	<analytic>
		<title level="a" type="main">Mitigating the impact of biased artificial intelligence in emergency decisionmaking</title>
		<idno type="DOI">10.1038/s43856-022-00214-4</idno>
		<ptr target="https://doi.org/10.1038/s43856-022-00214-4" />
	</analytic>
	<monogr>
		<title level="j">Communications Medicine</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b2">
	<monogr>
		<title level="m" type="main">Machine learning in clinical decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Adlung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Cohen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Mor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Elinav</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.medj.2021.04.006</idno>
		<ptr target="https://doi.org/10.1016/j.medj.2021.04.006" />
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="page" from="642" to="665" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b3">
	<analytic>
		<title level="a" type="main">The influence of algorithms on political and dating decisions</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">U</forename><surname>Agudo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Matute</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2021-04-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b4">
	<monogr>
		<title/>
		<idno type="DOI">10.1371/journal.pone.0249454</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0249454" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b5">
	<analytic>
		<title level="a" type="main">In AI we trust? Perceptions about automated decision-making by artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Araujo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Helberger</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Kruikemeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">H</forename><surname>De Vreese</surname></persName>
		</author>
		<idno type="DOI">10.1007/s00146-019-00931-w</idno>
		<ptr target="https://doi.org/10.1007/s00146-019-00931-w" />
	</analytic>
	<monogr>
		<title level="j">AI &amp; SOCIETY</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="611" to="623" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b6">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Baudel</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Verbockhaven</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Roy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Cousergue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Laarach</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b7">
	<monogr>
		<title level="m" type="main">Addressing Cognitive Biases in Augmented Business Decision Systems</title>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b8">
	<analytic>
		<title level="a" type="main">The Impact of Cognitive Biases on Professionals&apos; Decision-Making: A Review of Four Occupational Areas</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Berthet</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="page">12</biblScope>
			<date type="published" when="2022-01" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b9">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2021.802439</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2021.802439" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b10">
	<analytic>
		<title level="a" type="main">Cognitive biases and heuristics in medical decision making: A critical review using a systematic search strategy</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">S</forename><surname>Blumenthal-Barby</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Krieger</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Medical Decision Making</title>
		<imprint>
			<biblScope unit="volume">35</biblScope>
			<biblScope unit="issue">4</biblScope>
			<biblScope unit="page" from="539" to="557" />
			<date type="published" when="2015" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b11">
	<analytic>
		<title level="a" type="main">Human preferences toward algorithmic advice in a word association task</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Bogert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lauharatanahirun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Schecter</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b12">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41598-022-18638-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-18638-2" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b13">
	<analytic>
		<title level="a" type="main">To Trust or to Think: Cognitive Forcing Functions Can Reduce Overreliance on AI in AI-assisted Decisionmaking</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Buçinca</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B</forename><surname>Malaya</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="issue">CSCW1</biblScope>
			<biblScope unit="page">5</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b14">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3449287</idno>
		<ptr target="https://doi.org/10.1145/3449287" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b15">
	<analytic>
		<title level="a" type="main">Gender shades: Intersectional accuracy disparities in commercial gender classification</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Buolamwini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Gebru</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceeding of Maniche Learning Research</title>
		<meeting>eeding of Maniche Learning Research</meeting>
		<imprint>
			<date type="published" when="2018" />
			<biblScope unit="volume">81</biblScope>
			<biblScope unit="page" from="1" to="15" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b16">
	<analytic>
		<title level="a" type="main">Task-Dependent Algorithm Aversion</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Castelo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Bos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Lehmann</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Journal of Marketing Research</title>
		<imprint>
			<biblScope unit="volume">56</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="809" to="825" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b17">
	<monogr>
		<title/>
		<idno type="DOI">10.1177/0022243719851788</idno>
		<ptr target="https://doi.org/10.1177/0022243719851788" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b18">
	<analytic>
		<title level="a" type="main">Rising to the challenge of bias in health care AI</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Cho</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-021-01577-2</idno>
		<ptr target="https://doi.org/10.1038/s41591-021-01577-2" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2079" to="2081" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b19">
	<analytic>
		<title level="a" type="main">The Evolution and Impact of Human Confidence in Artificial Intelligence and in Themselves on AI-Assisted Decision-Making in Design</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Chong</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Raina</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goucher-Lambert</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Kotovsky</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cagan</surname></persName>
		</author>
		<idno type="DOI">10.1115/1.4055123</idno>
		<ptr target="https://doi.org/10.1115/1.4055123" />
	</analytic>
	<monogr>
		<title level="j">Journal of Mechanical Design</title>
		<imprint>
			<biblScope unit="volume">145</biblScope>
			<biblScope unit="issue">3</biblScope>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
	<note>Transactions of the ASME</note>
</biblStruct>

<biblStruct xml:id="b20">
	<analytic>
		<title level="a" type="main">Artificial Intelligence Can&apos;t Be Charmed: The Effects of Impartiality on Laypeople&apos;s Algorithmic Preferences</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Claudy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Aquino</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Graso</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">13</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2022-06" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b21">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2022.898027</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2022.898027" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b22">
	<analytic>
		<title level="a" type="main">The challenge of cognitive science for medical diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Croskerry</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">G</forename><surname>Campbell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Petrie</surname></persName>
		</author>
		<idno type="DOI">10.1186/s41235-022-00460-z</idno>
		<ptr target="https://doi.org/10.1186/s41235-022-00460-z" />
	</analytic>
	<monogr>
		<title level="m">Cognitive Research: Principles and Implications</title>
		<imprint>
			<date type="published" when="2023" />
			<biblScope unit="volume">8</biblScope>
			<biblScope unit="page">13</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b23">
	<analytic>
		<title level="a" type="main">Algorithmic Bias in Autonomous Systems</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Danks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>London</surname></persName>
		</author>
		<idno type="DOI">10.24963/ijcai.2017/654</idno>
		<ptr target="https://doi.org/10.24963/ijcai.2017/654" />
	</analytic>
	<monogr>
		<title level="m">Proceedings of the Twenty-Sixth International Joint Conference on Artificial Intelligence</title>
		<meeting>the Twenty-Sixth International Joint Conference on Artificial Intelligence</meeting>
		<imprint>
			<date type="published" when="2017" />
			<biblScope unit="volume">0</biblScope>
			<biblScope unit="page" from="4691" to="4697" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b24">
	<analytic>
		<title level="a" type="main">Latent bias and the implementation of artificial intelligence in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Decamp</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Lindvall</surname></persName>
		</author>
		<idno type="DOI">10.1093/jamia/ocaa094</idno>
		<ptr target="https://doi.org/10.1093/jamia/ocaa094" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2020" to="2023" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b25">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Dratsch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">X</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Rezazade Mehrizi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kloeckner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Mähringer-Kunz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Püsken</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Baeßler</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Sauer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Maintz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pinto Dos Santos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b26">
	<monogr>
		<title level="m" type="main">Automation Bias in Mammography: The Impact of Artificial Intelligence BI-RADS Suggestions on Reader Performance</title>
		<idno type="DOI">10.1148/radiol.222176</idno>
		<ptr target="https://doi.org/10.1148/radiol.222176" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b27">
	<analytic>
		<title level="a" type="main">A guide to deep learning in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Esteva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Robicquet</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Ramsundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Kuleshov</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Depristo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Chou</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Cui</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Corrado</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thrun</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Dean</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-018-0316-z</idno>
		<ptr target="https://doi.org/10.1038/s41591-018-0316-z" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="24" to="29" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b28">
	<monogr>
		<title level="m" type="main">Proposal for a Regulation laying down harmonised rules on artificial intelligence (Articifical intelligence act) and amending certain union legislative acts. COM (2021) 206 final</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>European Commision</surname></persName>
		</author>
		<ptr target="https://digital-strategy.ec.europa.eu/en/library/proposal-regulation-laying-down-harmonised-rules-artificial-intelligence" />
		<imprint>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b29">
	<analytic>
		<title level="a" type="main">Addressing Fairness, Bias, and Appropriate Use of Artificial Intelligence and Machine Learning in Global Health</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">R</forename><surname>Fletcher</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Nakeshimana</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Olubeko</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Artificial Intelligence</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="17" />
			<date type="published" when="2021-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b30">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/frai.2020.561802</idno>
		<ptr target="https://doi.org/10.3389/frai.2020.561802" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b31">
	<monogr>
		<title level="m" type="main">Hello World: Being Human in the Age of Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Fry</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2018" />
			<publisher>W. W. Norton &amp; Company</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b32">
	<monogr>
		<title level="m" type="main">Artificial intelligence to support clinical decision-making processes</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Garcia-Vidal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Sanjuan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Puerta-Alcalde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Moreno-García</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Soriano</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b33">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><surname>Ebiomedicine</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ebiom.2019.07.019</idno>
		<ptr target="https://doi.org/10.1016/j.ebiom.2019.07.019" />
		<imprint>
			<biblScope unit="volume">46</biblScope>
			<biblScope unit="page" from="27" to="29" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b34">
	<analytic>
		<title level="a" type="main">Do as AI say: susceptibility in deployment of clinical decision-aids</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Gaube</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Raue</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Merritt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">J</forename><surname>Berkowitz</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Lermer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">F</forename><surname>Coughlin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">V</forename><surname>Guttag</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Colak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Npj Digital Medicine</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">4</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b35">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41746-021-00385-9</idno>
		<ptr target="https://doi.org/10.1038/s41746-021-00385-9" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b36">
	<analytic>
		<title level="a" type="main">Automation bias: A systematic review of frequency, effect mediators, and mitigators</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roudsari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Wyatt</surname></persName>
		</author>
		<idno type="DOI">10.1136/amiajnl-2011-000089</idno>
		<ptr target="https://doi.org/10.1136/amiajnl-2011-000089" />
	</analytic>
	<monogr>
		<title level="j">Journal of the American Medical Informatics Association</title>
		<imprint>
			<biblScope unit="volume">19</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="121" to="127" />
			<date type="published" when="2012" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b37">
	<analytic>
		<title level="a" type="main">Automation bias: Empirical results assessing influencing factors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Goddard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Roudsari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">C</forename><surname>Wyatt</surname></persName>
		</author>
		<idno type="DOI">10.1016/j.ijmedinf.2014.01.001</idno>
		<ptr target="https://doi.org/10.1016/j.ijmedinf.2014.01.001" />
	</analytic>
	<monogr>
		<title level="j">International Journal of Medical Informatics</title>
		<imprint>
			<biblScope unit="volume">83</biblScope>
			<biblScope unit="issue">5</biblScope>
			<biblScope unit="page" from="368" to="375" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b38">
	<analytic>
		<title level="a" type="main">The principles and limits of algorithm-in-the-loop decision making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Green</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Chen</surname></persName>
		</author>
		<idno type="DOI">10.1145/3359152</idno>
		<ptr target="https://doi.org/10.1145/3359152" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2019" />
			<publisher>CSCW</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b39">
	<analytic>
		<title level="a" type="main">Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Gulshan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Peng</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Coram</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">C</forename><surname>Stumpe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Narayanaswamy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Venugopalan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Widner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Madams</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Cuadros</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Kim</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Raman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">C</forename><surname>Nelson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">L</forename><surname>Mega</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">R</forename><surname>Webster</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2016.17216</idno>
		<ptr target="https://doi.org/10.1001/jama.2016.17216" />
	</analytic>
	<monogr>
		<title level="j">JAMA -Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">316</biblScope>
			<biblScope unit="issue">22</biblScope>
			<biblScope unit="page" from="2402" to="2410" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b40">
	<analytic>
		<title level="a" type="main">Preference for human or algorithmic forecasting advice does not predict if and how it is used</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Himmelstein</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">V</forename><surname>Budescu</surname></persName>
		</author>
		<idno type="DOI">10.1002/bdm.2285</idno>
		<ptr target="https://doi.org/10.1002/bdm.2285" />
	</analytic>
	<monogr>
		<title level="j">Journal of Behavioral Decision Making</title>
		<imprint>
			<biblScope unit="volume">36</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="24" />
			<date type="published" when="2023" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b41">
	<analytic>
		<title level="a" type="main">Deep learning-a technology with the potential to transform health care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Hinton</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA -Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">11</biblScope>
			<biblScope unit="page" from="1101" to="1102" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b42">
	<monogr>
		<title/>
		<idno type="DOI">10.1001/jama.2018.11100</idno>
		<ptr target="https://doi.org/10.1001/jama.2018.11100" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b43">
	<analytic>
		<title level="a" type="main">Should Electronic Health Record-Derived Social and Behavioral Data Be Used in Precision Medicine Research?</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Hollister</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">L</forename><surname>Bonham</surname></persName>
		</author>
		<idno type="DOI">10.1001/amajethics.2018.873</idno>
		<ptr target="https://doi.org/10.1001/amajethics.2018.873" />
	</analytic>
	<monogr>
		<title level="j">AMA Journal of Ethics</title>
		<imprint>
			<biblScope unit="volume">20</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="873" to="880" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b44">
	<monogr>
		<title level="m" type="main">Human-algorithm teaming in face recognition: How algorithm outcomes cognitively bias human decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">J</forename><surname>Howard</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">R</forename><surname>Rabbitt</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><forename type="middle">B</forename><surname>Sirotin</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b45">
	<analytic>
		<title/>
	</analytic>
	<monogr>
		<title level="j">PLoS ONE</title>
		<imprint>
			<biblScope unit="volume">15</biblScope>
			<biblScope unit="page" from="1" to="18" />
			<date type="published" when="2020-08-08" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b46">
	<monogr>
		<title/>
		<idno type="DOI">10.1371/journal.pone.0237855</idno>
		<ptr target="https://doi.org/10.1371/journal.pone.0237855" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b47">
	<analytic>
		<title level="a" type="main">How machine-learning recommendations influence clinician treatment selections: the example of the antidepressant selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Jacobs</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">F</forename><surname>Pradier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">H</forename><surname>Mccoy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">H</forename><surname>Perlis</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">Z</forename><surname>Gajos</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41398-021-01224-x</idno>
		<ptr target="https://doi.org/10.1038/s41398-021-01224-x" />
	</analytic>
	<monogr>
		<title level="j">Translational Psychiatry</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">11</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b48">
	<analytic>
		<title level="a" type="main">A Perspective on Judgment and Choice: Mapping Bounded Rationality</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<idno type="DOI">10.1037/0003-066X.58.9.697</idno>
		<ptr target="https://doi.org/10.1037/0003-066X.58.9.697" />
	</analytic>
	<monogr>
		<title level="j">American Psychologist</title>
		<imprint>
			<biblScope unit="volume">58</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="697" to="720" />
			<date type="published" when="2003" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b49">
	<analytic>
		<title level="a" type="main">Noise: A Flaw in Humam Judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kahneman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Sibony</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Sunstein</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Suparyanto dan Rosad</title>
		<imprint>
			<publisher>William Collins</publisher>
			<date type="published" when="2015" />
			<biblScope unit="volume">5</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b50">
	<analytic>
		<title level="a" type="main">Mental labour</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">W</forename><surname>Kool</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Botvinick</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41562-018-0401-9</idno>
		<ptr target="https://doi.org/10.1038/s41562-018-0401-9" />
	</analytic>
	<monogr>
		<title level="j">Nature Human Behaviour</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="899" to="908" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b51">
	<analytic>
		<title level="a" type="main">Check the box! How to deal with automation bias in AI-based personnel selection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Kupfer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Prassl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Fleiß</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Malin</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thalmann</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">B</forename><surname>Kubicek</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="volume">14</biblScope>
			<biblScope unit="page" from="1" to="16" />
			<date type="published" when="2023-04" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b52">
	<monogr>
		<title/>
		<idno type="DOI">10.3389/fpsyg.2023.1118723</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2023.1118723" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b53">
	<analytic>
		<title level="a" type="main">Should I Trust the Artificial Intelligence to Recruit? Recruiters&apos; Perceptions and Behavior When Faced With Algorithm-Based Recommendation Systems During Resume Screening</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lacroux</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Martin-Lacroux</surname></persName>
		</author>
		<idno type="DOI">10.3389/fpsyg.2022.895997</idno>
		<ptr target="https://doi.org/10.3389/fpsyg.2022.895997" />
	</analytic>
	<monogr>
		<title level="j">Frontiers in Psychology</title>
		<imprint>
			<biblScope unit="page">13</biblScope>
			<date type="published" when="2022-07" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b54">
	<analytic>
		<title level="a" type="main">On human predictions with explanations and predictions of machine learning models: A case study on deception detection</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Tan</surname></persName>
		</author>
		<idno type="DOI">10.1145/3287560.3287590</idno>
		<ptr target="https://doi.org/10.1145/3287560.3287590" />
	</analytic>
	<monogr>
		<title level="m">FAT* 2019 -Proceedings of the 2019 Conference on Fairness, Accountability, and Transparency</title>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="29" to="38" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b55">
	<analytic>
		<title level="a" type="main">Human-AI Collaboration in Healthcare : A Review and Research Agenda</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Lai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Kankanhalli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Ong</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of the 54th Hawaii International Conference on System Sciences</title>
		<meeting>the 54th Hawaii International Conference on System Sciences</meeting>
		<imprint>
			<date type="published" when="2021" />
			<biblScope unit="page" from="390" to="399" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b56">
	<analytic>
		<title level="a" type="main">Gender imbalance in medical imaging datasets produces biased classifiers for computeraided diagnosis</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">J</forename><surname>Larrazabal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Nieto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><surname>Peterson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">H</forename><surname>Milone</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Ferrante</surname></persName>
		</author>
		<idno type="DOI">10.1073/pnas.1919012117</idno>
		<ptr target="https://doi.org/10.1073/pnas.1919012117" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the National Academy of Sciences</title>
		<imprint>
			<biblScope unit="volume">117</biblScope>
			<biblScope unit="issue">23</biblScope>
			<biblScope unit="page" from="12592" to="12594" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b57">
	<analytic>
		<title level="a" type="main">Understanding perception of algorithmic decisions: Fairness, trust, and emotion in response to algorithmic management</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">K</forename><surname>Lee</surname></persName>
		</author>
		<idno type="DOI">10.1177/2053951718756684</idno>
		<ptr target="https://doi.org/10.1177/2053951718756684" />
	</analytic>
	<monogr>
		<title level="j">Big Data &amp; Society</title>
		<imprint>
			<biblScope unit="volume">5</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">205395171875668</biblScope>
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b58">
	<analytic>
		<title level="a" type="main">Time of day and the decision to prescribe antibiotics</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Linder</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">N</forename><surname>Doctor</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">W</forename><surname>Friedberg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Reyes Nieva</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Birks</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Meeker</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">R</forename><surname>Fox</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Internal Medicine</title>
		<imprint>
			<biblScope unit="volume">174</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2029" to="2031" />
			<date type="published" when="2014" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b59">
	<monogr>
		<title/>
		<idno type="DOI">10.1001/jamainternmed.2014.5225</idno>
		<ptr target="https://doi.org/10.1001/jamainternmed.2014.5225" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b60">
	<analytic>
		<title level="a" type="main">Artificial Intelligence and Surgical Decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><forename type="middle">J</forename><surname>Loftus</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">J</forename><surname>Tighe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">C</forename><surname>Filiberto</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">A</forename><surname>Efron</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">C</forename><surname>Brakenridge</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">M</forename><surname>Mohr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rashidi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">R</forename><surname>Upchurch</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Bihorac</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">JAMA Surgery</title>
		<imprint>
			<biblScope unit="volume">155</biblScope>
			<biblScope unit="issue">2</biblScope>
			<biblScope unit="page" from="148" to="158" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b61">
	<monogr>
		<title/>
		<idno type="DOI">10.1001/jamasurg.2019.4917</idno>
		<ptr target="https://doi.org/10.1001/jamasurg.2019.4917" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b62">
	<analytic>
		<title level="a" type="main">Algorithm appreciation: People prefer algorithmic to human judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">M</forename><surname>Logg</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><forename type="middle">A</forename><surname>Minson</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">A</forename><surname>Moore</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Organizational Behavior and Human Decision Processes</title>
		<imprint>
			<biblScope unit="page" from="90" to="103" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b63">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.obhdp.2018.12.005</idno>
		<ptr target="https://doi.org/10.1016/j.obhdp.2018.12.005" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b64">
	<analytic>
		<title level="a" type="main">How machine learning is embedded to support clinician decision making: An analysis of FDA-approved medical devices</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lyell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Shah</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Magrabi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">BMJ Health and Care Informatics</title>
		<imprint>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">28</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b65">
	<monogr>
		<title/>
		<idno type="DOI">10.1136/bmjhci-2020-100301</idno>
		<ptr target="https://doi.org/10.1136/bmjhci-2020-100301" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b66">
	<analytic>
		<title level="a" type="main">The Effect of Cognitive Load and Task Complexity on Automation Bias in Electronic Prescribing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lyell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Magrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
		<idno type="DOI">10.1177/0018720818781224</idno>
		<ptr target="https://doi.org/10.1177/0018720818781224" />
	</analytic>
	<monogr>
		<title level="j">Human Factors</title>
		<imprint>
			<biblScope unit="volume">60</biblScope>
			<biblScope unit="issue">7</biblScope>
			<biblScope unit="page" from="1008" to="1021" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b67">
	<analytic>
		<title level="a" type="main">Automation bias in electronic prescribing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Lyell</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Magrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">Z</forename><surname>Raban</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><forename type="middle">G</forename><surname>Pont</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">T</forename><surname>Baysari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">O</forename><surname>Day</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Coiera</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-017-0425-5</idno>
		<ptr target="https://doi.org/10.1186/s12911-017-0425-5" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">17</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="10" />
			<date type="published" when="2017" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b68">
	<analytic>
		<title level="a" type="main">A Survey on Bias and Fairness in Machine Learning</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Mehrabi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Morstatter</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Saxena</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Lerman</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Galstyan</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">ACM Computing Surveys</title>
		<imprint>
			<biblScope unit="issue">6</biblScope>
			<biblScope unit="page">54</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b69">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3457607</idno>
		<ptr target="https://doi.org/10.1145/3457607" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b70">
	<analytic>
		<title level="a" type="main">Slowing down when you should: A new model of expert judgment</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">A E</forename><surname>Moulton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Regehr</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mylopoulos</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">M</forename><surname>Macrae</surname></persName>
		</author>
		<idno type="DOI">10.1097/ACM.0b013e3181405a76</idno>
		<ptr target="https://doi.org/10.1097/ACM.0b013e3181405a76" />
	</analytic>
	<monogr>
		<title level="j">Academic Medicine</title>
		<imprint>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="109" to="116" />
			<date type="published" when="2007" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b71">
	<analytic>
		<title level="a" type="main">Association of Primary Care Clinic Appointment Time With Opioid Prescribing</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">T</forename><surname>Neprash</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">L</forename><surname>Barnett</surname></persName>
		</author>
		<idno type="DOI">10.1001/jamanetworkopen.2019.10373</idno>
		<ptr target="https://doi.org/10.1001/jamanetworkopen.2019.10373" />
	</analytic>
	<monogr>
		<title level="j">JAMA Network Open</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">8</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b72">
	<analytic>
		<title level="a" type="main">Addressing bias in big data and AI for health care: A call for open science</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Norori</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Q</forename><surname>Hu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">M</forename><surname>Aellen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">D</forename><surname>Faraci</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Tzovara</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Patterns</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b73">
	<monogr>
		<title/>
		<idno type="DOI">10.1016/j.patter.2021.100347</idno>
		<ptr target="https://doi.org/10.1016/j.patter.2021.100347" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b74">
	<monogr>
		<title level="m" type="main">Weapons of Math Desctruction</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>O'neil</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2016" />
			<publisher>Crown Publishers</publisher>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b75">
	<monogr>
		<title level="m" type="main">Dissecting Racial Bias in an Algorithm that Guides Health Decisions for 70 Million People</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Obermeyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Mullainathan</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2019" />
			<biblScope unit="page" from="89" to="89" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b76">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3287560.3287593</idno>
		<ptr target="https://doi.org/10.1145/3287560.3287593" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b77">
	<analytic>
		<title level="a" type="main">Addressing Bias in Artificial Intelligence in Health Care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">B</forename><surname>Parikh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Teeple</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">S</forename><surname>Navathe</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2019.18058</idno>
		<ptr target="https://doi.org/10.1001/jama.2019.18058" />
	</analytic>
	<monogr>
		<title level="j">JAMA</title>
		<imprint>
			<biblScope unit="volume">322</biblScope>
			<biblScope unit="issue">24</biblScope>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b78">
	<analytic>
		<title level="a" type="main">AI in health and medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Rajpurkar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">O</forename><surname>Banerjee</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-021-01614-0</idno>
		<ptr target="https://doi.org/10.1038/s41591-021-01614-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="31" to="38" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b79">
	<analytic>
		<title level="a" type="main">Deciding Fast and Slow: The Role of Cognitive Biases in AI-assisted Decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rastogi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Wei</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">R</forename><surname>Varshney</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Dhurandhar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><surname>Tomsett</surname></persName>
		</author>
		<idno type="DOI">10.1145/3512930</idno>
		<ptr target="https://doi.org/10.1145/3512930" />
	</analytic>
	<monogr>
		<title level="j">Proceedings of the ACM on Human-Computer Interaction</title>
		<imprint>
			<biblScope unit="volume">6</biblScope>
			<biblScope unit="issue">CSCW1</biblScope>
			<biblScope unit="page" from="1" to="22" />
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b80">
	<analytic>
		<title level="a" type="main">People underestimate the errors made by algorithms for credit scoring and recidivism prediction but accept even fewer errors</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><forename type="middle">G</forename><surname>Rebitschek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Gigerenzer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">G</forename><surname>Wagner</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-021-99802-y</idno>
		<ptr target="https://doi.org/10.1038/s41598-021-99802-y" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">11</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="11" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b81">
	<analytic>
		<title level="a" type="main">Experimental evidence of effective human-AI collaboration in medical decision-making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Reverberi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Rigon</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Solari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hassan</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Cherubini</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Antonelli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Awadie</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Bernhofer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Carballal</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Dinis-Ribeiro</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Fernández-Clotett</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><forename type="middle">F</forename><surname>Esparrach</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Gralnek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Y</forename><surname>Higasa</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirabayashi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">T</forename><surname>Hirai</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Iwatate</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Kawano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Mader</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Cherubini</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41598-022-18751-2</idno>
		<ptr target="https://doi.org/10.1038/s41598-022-18751-2" />
	</analytic>
	<monogr>
		<title level="j">Scientific Reports</title>
		<imprint>
			<biblScope unit="volume">12</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page">14952</biblScope>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b82">
	<analytic>
		<title level="a" type="main">Cognitive biases associated with medical decisions: a systematic review</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Saposnik</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Redelmeier</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><forename type="middle">C</forename><surname>Ruff</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Tobler</surname></persName>
		</author>
		<idno type="DOI">10.1186/s12911-016-0377-1</idno>
		<ptr target="https://doi.org/10.1186/s12911-016-0377-1" />
	</analytic>
	<monogr>
		<title level="j">BMC Medical Informatics and Decision Making</title>
		<imprint>
			<biblScope unit="volume">16</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="14" />
			<date type="published" when="2016" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b83">
	<analytic>
		<title level="a" type="main">Underdiagnosis bias of artificial intelligence algorithms applied to chest radiographs in under-served patient populations</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">L</forename><surname>Seyyed-Kalantari</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Zhang</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">B A</forename><surname>Mcdermott</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">Y</forename><surname>Chen</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-021-01595-0</idno>
		<ptr target="https://doi.org/10.1038/s41591-021-01595-0" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">27</biblScope>
			<biblScope unit="issue">12</biblScope>
			<biblScope unit="page" from="2176" to="2182" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b84">
	<analytic>
		<title level="a" type="main">Clinical Decision Support in the Era of Artificial Intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">H</forename><surname>Shortliffe</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><forename type="middle">J</forename><surname>Sepúlveda</surname></persName>
		</author>
		<idno type="DOI">10.1001/jama.2018.17163</idno>
		<ptr target="https://doi.org/10.1001/jama.2018.17163" />
	</analytic>
	<monogr>
		<title level="j">JAMA -Journal of the American Medical Association</title>
		<imprint>
			<biblScope unit="volume">320</biblScope>
			<biblScope unit="issue">21</biblScope>
			<biblScope unit="page" from="2199" to="2200" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b85">
	<analytic>
		<title level="a" type="main">Human Response to an AI-Based Decision Support System: A User Study on the Effects of Accuracy and Bias</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Solans</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Beretta</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Portela</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Castillo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Monreale</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">Proceedings of ACM Conference (Conference&apos;17)</title>
		<meeting>ACM Conference (Conference&apos;17)</meeting>
		<imprint>
			<publisher>Association for Computing Machinery</publisher>
			<date type="published" when="2022" />
			<biblScope unit="volume">1</biblScope>
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b86">
	<analytic>
		<title level="a" type="main">Machine heuristic: When we trust computers more than humans with our personal information</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><forename type="middle">S</forename><surname>Sundar</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Kim</surname></persName>
		</author>
		<idno type="DOI">10.1145/3290605.3300768</idno>
		<ptr target="https://doi.org/10.1145/3290605.3300768" />
	</analytic>
	<monogr>
		<title level="m">Conference on Human Factors in Computing Systems -Proceedings, 1-9</title>
		<imprint>
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b87">
	<analytic>
		<title level="a" type="main">A Framework for Understanding Sources of Harm throughout the Machine Learning Life Cycle. Equity and Access in Algorithms</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Guttag</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Mechanisms, and Optimization</title>
		<imprint>
			<biblScope unit="volume">1</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="1" to="9" />
			<date type="published" when="2021" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b88">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3465416.3483305</idno>
		<ptr target="https://doi.org/10.1145/3465416.3483305" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b89">
	<analytic>
		<title level="a" type="main">Misplaced Trust: Measuring the Interference of Machine Learning in Human Decision-Making</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Suresh</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Lao</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Liccardi</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="m">WebSci 2020 -Proceedings of the 12th ACM Conference on Web Science</title>
		<imprint>
			<date type="published" when="2020" />
			<biblScope unit="page" from="315" to="324" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b90">
	<monogr>
		<title/>
		<idno type="DOI">10.1145/3394231.3397922</idno>
		<ptr target="https://doi.org/10.1145/3394231.3397922" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b91">
	<monogr>
		<title/>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">T</forename><surname>Sutton</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Pincock</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Baumgart</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><forename type="middle">C</forename><surname>Sadowski</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">R</forename><forename type="middle">N</forename><surname>Fedorak</surname></persName>
		</author>
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b92">
	<analytic>
		<title level="a" type="main">An overview of clinical decision support systems: benefits, risks, and strategies for success</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">I</forename><surname>Kroeker</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41746-020-0221-y</idno>
		<ptr target="https://doi.org/10.1038/s41746-020-0221-y" />
	</analytic>
	<monogr>
		<title level="j">Npj Digital Medicine</title>
		<imprint>
			<biblScope unit="volume">3</biblScope>
			<biblScope unit="issue">1</biblScope>
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b93">
	<analytic>
		<title level="a" type="main">High-performance medicine: the convergence of human and artificial intelligence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">E</forename><forename type="middle">J</forename><surname>Topol</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">1</biblScope>
			<biblScope unit="page" from="44" to="56" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b94">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41591-018-0300-7</idno>
		<ptr target="https://doi.org/10.1038/s41591-018-0300-7" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b95">
	<analytic>
		<title level="a" type="main">Human-computer collaboration for skin cancer recognition</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><surname>Tschandl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rinner</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">Z</forename><surname>Apalla</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">G</forename><surname>Argenziano</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">N</forename><surname>Codella</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Halpern</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Janda</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Lallas</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Longo</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Malvehy</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Paoli</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Puig</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Rosendahl</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><forename type="middle">P</forename><surname>Soyer</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><surname>Zalaudek</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">H</forename><surname>Kittler</surname></persName>
		</author>
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">26</biblScope>
			<biblScope unit="issue">8</biblScope>
			<biblScope unit="page" from="1229" to="1234" />
			<date type="published" when="2020" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b96">
	<monogr>
		<title/>
		<idno type="DOI">10.1038/s41591-020-0942-0</idno>
		<ptr target="https://doi.org/10.1038/s41591-020-0942-0" />
		<imprint/>
	</monogr>
</biblStruct>

<biblStruct xml:id="b97">
	<monogr>
		<title level="m" type="main">Judging the algorithm: A case study on the risk assessment tool for gender-based violence</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Valdivia</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">C</forename><surname>Hyde-Vaamonde</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>García-Marcos</surname></persName>
		</author>
		<imprint>
			<date type="published" when="2022" />
		</imprint>
	</monogr>
	<note>implemented in the Basque country</note>
</biblStruct>

<biblStruct xml:id="b98">
	<analytic>
		<title level="a" type="main">Do no harm: a roadmap for responsible machine learning for health care</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">J</forename><surname>Wiens</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Saria</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Sendak</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Ghassemi</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">V</forename><forename type="middle">X</forename><surname>Liu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">F</forename><surname>Doshi-Velez</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Jung</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><surname>Heller</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">D</forename><surname>Kale</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">M</forename><surname>Saeed</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">P</forename><forename type="middle">N</forename><surname>Ossorio</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">S</forename><surname>Thadaney-Israni</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><surname>Goldenberg</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41591-019-0548-6</idno>
		<ptr target="https://doi.org/10.1038/s41591-019-0548-6" />
	</analytic>
	<monogr>
		<title level="j">Nature Medicine</title>
		<imprint>
			<biblScope unit="volume">25</biblScope>
			<biblScope unit="issue">9</biblScope>
			<biblScope unit="page" from="1337" to="1340" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b99">
	<analytic>
		<title level="a" type="main">Artificial intelligence in healthcare</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">A</forename><forename type="middle">L</forename><surname>Beam</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<idno type="DOI">10.1038/s41551-018-0305-z</idno>
		<ptr target="https://doi.org/10.1038/s41551-018-0305-z" />
	</analytic>
	<monogr>
		<title level="j">Nature Biomedical Engineering</title>
		<imprint>
			<biblScope unit="volume">2</biblScope>
			<biblScope unit="issue">10</biblScope>
			<biblScope unit="page" from="719" to="731" />
			<date type="published" when="2018" />
		</imprint>
	</monogr>
</biblStruct>

<biblStruct xml:id="b100">
	<analytic>
		<title level="a" type="main">Framing the challenges of artificial intelligence in medicine</title>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">K</forename><forename type="middle">H</forename><surname>Yu</surname></persName>
		</author>
		<author>
			<persName xmlns="http://www.tei-c.org/ns/1.0"><forename type="first">I</forename><forename type="middle">S</forename><surname>Kohane</surname></persName>
		</author>
		<idno type="DOI">10.1136/bmjqs-2018-008551</idno>
		<ptr target="https://doi.org/10.1136/bmjqs-2018-008551" />
	</analytic>
	<monogr>
		<title level="j">BMJ Quality and Safety</title>
		<imprint>
			<biblScope unit="volume">28</biblScope>
			<biblScope unit="issue">3</biblScope>
			<biblScope unit="page" from="238" to="241" />
			<date type="published" when="2019" />
		</imprint>
	</monogr>
</biblStruct>

				</listBibl>
			</div>
		</back>
	</text>
</TEI>
